<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title>3D甜甜圈</title>
    <url>/2022/11/17/3D%E7%94%9C%E7%94%9C%E5%9C%88/</url>
    <content><![CDATA[<p>在终端绘制一个有光追效果的3D甜甜圈！这篇文章是<a href="https://www.a1k0n.net/2011/07/20/donut-math.html">Donut math: how donut.c works – a1k0n.net</a>的翻译，感谢原作者的内容创作！我加入了一些自己的心得体会和python实现代码。</p>
<span id="more"></span>
<p>它的核心是一个<code>FrameBuffer</code>以及一个用于渲染光照效果的<code>Zbuffer</code>。由于这是一个低解析度的ASCII艺术，我使用了一些作弊的小技巧。整个代码所做的工作就是把环体表面的像素按照特定的角度进行映射，但即便这样看上去效果也挺好的。每个绘制的“像素”按照光照强度有以下层级的划分：<code>[.,-~:;=!*#$@]</code>，不需要任何光线追踪技术（其本质就是每个字符所占的实际像素大小）。</p>
<p>那么如何实现呢？我们从3D视角的图形渲染数学基础开始。下面的图是一个人在屏幕面前观测一个3D物品的示意。</p>
<p><img src="https://www.a1k0n.net/img/perspective.png" alt="eye"></p>
<center>From:www.a1k0n.net</center>

<p>在一个二维的荧幕上渲染一个3D物品，我们需要将三维空间的每一个点$(x,y,x)$映射到距观测者$z’$个单位的固定的平面上，这样可以得到对应的坐标$(x’,y’)$。因为我们在侧边观测的问题，我们只能看到$z$轴和$y$轴，但同样的规律也适用于$x$轴（假设我们进行的是一个俯视）。这种映射非常简单，注意到原始物体，$y$轴，点$(x,y,z)$和新的映射点$(x’,y’,z’)$形成了一对相似三角形，因此他们的相似比可以计算出来。</p>
<script type="math/tex; mode=display">
\frac{y'}{z'}=\frac{y}{z}\\
y'=\frac{yz'}{z}</script><p>要把一个三维的坐标映射到二维，我们通过屏幕观测距离$z’$进行缩放。由于$z’$是一个固定的常量（我们这里假设观测者不动吧）而不是坐标中的一部分，我们给他重命名为$K_1$，因此我们的映射等式变成了：</p>
<script type="math/tex; mode=display">
(x',y')=(\frac{K_1x}{z},\frac{K_1 y}{z})</script><p>我们可以选择$K_1$的取值，它将控制在二维窗口上图形的展示。比如说，如果我们有100$\times$100的像素窗口，那么视觉中心就是在$(50,50)$。如果我们想要观测一个三维空间中有10个单位宽度的物体，并且观测者距离它的距离为5个单位，那么$K_1$应该设置为能使$x=10,z=5$的地方仍能在屏幕上，并且新的映射满足$x’&lt;50$即$K_1&lt;25$。</p>
<p>当我们在绘制一系列的点时，我们可能会对相同位置$(x’,y’)$中绘制多个点，但是这些点的高度（二维平面上再加一个$z$轴）不同，所以我们使用一个<code>zbuffer</code>来维持这些高度值。如果我们需要在一个位置绘制点，首先我们需要检查该处是否已经有点了，同时计算$z^{-1}=\frac{1}{z}$对我们的后续工作非常有用，因为：</p>
<ul>
<li>$z^{-1}=0$代表深度无限深，所以只需要初始化<code>zbuffer</code>中所有值为0即可，这些0代表的是背景离我们无限远。</li>
<li>$z^{-1}$可以在计算$x’,y’$的时候重复使用：进行一次除法（得到$z^{-1}$）然后使用两次乘法（计算$x’,y’$）会比计算两次除法（计算$x’,y’$）更加高效。</li>
</ul>
<p>现在我们可以开始画一个甜甜圈了，AKA <a href="https://baike.baidu.com/item/环面/2127101">环面</a>（博客原文是跳转到wiki的，国内打不开我就百度百科了）。环面是一个立体图形，所以我们的方法是先在二维平面上画一个圆形，然后绕环面的中心轴旋转一周即可得到。这里是旋转得到环面的一个示意图：</p>
<p><img src="https://www.a1k0n.net/img/torusxsec.png" alt="torus"></p>
<center>From:www.a1k0n.net Here</center>

<p>那么我们在$xy$平面上有一个半径为$R_1$的并且中心点为$(R_2,0,0)$的圆，通过从$[0,2 \pi]$旋转角度$\theta$得到环面：</p>
<script type="math/tex; mode=display">
(x,y,z)=(R_2,0,0)+(R_1\cos\theta,R_1 \sin \theta,0 )</script><p>现在我们让我们的圆形绕着$y$轴再旋转另一个角度——叫他$\phi$吧。在三维空间绕某一个轴旋转，最标准的方式就是使用<a href="https://baike.baidu.com/item/旋转矩阵/3265181">旋转矩阵</a>啦。跟着公式我们可以将前面得到的点绕着$y$轴旋转得到：</p>
<script type="math/tex; mode=display">
\begin{aligned}
&(R_2 +R_1 \cos \theta, R_1\sin \theta, 0)
\begin{bmatrix}
\cos \phi&0 & \sin \phi\\
0        &1 &0\\
-\sin \phi & 0& \cos \phi
\end{bmatrix}\\
=&((R_2 + R_1 \cos \theta)\cos \phi, R_1\sin\theta,-(R_2+R_1\cos \theta)\sin \phi)
\end{aligned}</script><p>但是先等等！我们还需要同时让甜甜圈绕至少两个轴旋转才能有那种动画的效果，在原始的代码中，它们就是<code>A</code>和<code>B</code>：他们分别代表的是绕着$x$轴和绕着$y$轴旋转的角度。是不是觉得有点复杂了？它们的结果就是矩阵的相乘，但是我都没打算去算结果呢：</p>
<script type="math/tex; mode=display">
(R_2 +R_1 \cos \theta, R_1\sin \theta, 0)\cdot
\begin{bmatrix}
\cos \phi&0 & \sin \phi\\
0        &1 &0\\
-\sin \phi & 0& \cos \phi
\end{bmatrix}\\\cdot
\begin{bmatrix}
1 & 0& 0\\
0 & \cos A&\sin A\\
0&-\sin A & \cos A
\end{bmatrix}\cdot
\begin{bmatrix}
\cos B & \sin B& 0\\
-\sin B & \cos b&0\\
0&0 & 1
\end{bmatrix}</script><p>上面那一大坨东西可以给我们甜甜圈表面的点坐标$(x,y,z)$，为了得到真实的屏幕中的坐标，我们还需要：</p>
<ul>
<li>把甜甜圈移动到观测者的位置（观测者在原始的位置）——因此我们只需要给$z$加上一点常数让它往后移动就好。</li>
<li>从三位图形映射到我们的二维平面上。</li>
</ul>
<p>因此，我们需要另外的一个常数，我们叫他$K_2$吧，用于表示甜甜圈到观测值的距离，因此我们的映射应该是这个样子的：</p>
<script type="math/tex; mode=display">
(x',y')=(\frac{K_1x}{K_2 + z},\frac{K_1 y}{K_2 + z})</script><p>$K_1$和$K_2$联合的作用可以改变观测的视角，让观测的图形的深度更加起伏。</p>
<p>现在，我们将使用一个$3\times3$的矩阵乘法完成上面的这些工作。但是我们要简化一下计算的复杂度，矩阵乘法的任何一个“0”都会成为我们的化简关键。感谢数学！我们得到了完整的结果如下：</p>
<script type="math/tex; mode=display">
\begin{bmatrix}
x\\y\\z
\end{bmatrix}
=\begin{bmatrix}
(R_2+R_1\cos\theta)(\cos B \cos \phi + \sin A\sin B \sin\phi)-R_1 \cos A \cos B\sin \theta\\
(R_2+R_1\cos\theta)(\cos \phi \sin B-\cos B \sin A \sin \phi)+R_1 \cos A \cos B\sin \theta\\
\cos A(R_2 + R_1 \cos \theta)\sin \phi + R_1\sin A\sin \theta
\end{bmatrix}</script><p>好吧…好像不是很好看的结果，但是我们可以将一些中间结果先提前算出来，比如说$(R_2 + R_1 \cos \theta)$以及各种$\cos(\cdot)/\sin(\cdot)$，并在代码中重复使用他们。事实上我还有一个更加不同的思路来实现，但是我还是留给大家当作练习吧（？）（原始的代码计算某个角度的正余弦值是使用了诱导公式完成的）</p>
<p>现在我们知道了在哪里要放置像素了，但我们还没有考虑怎么给他上光照和绘画。要想计算光照，我们需要知道<a href="https://en.wikipedia.org/wiki/Surface_normal">表面法向量</a>——即每一点上垂直于表面的方向。如果我们有这个的话，我们可以使用法向量和光的方向的<a href="http://en.wikipedia.org/wiki/Dot_product">点积</a>来计算得到光照，这个的光照的方向选择可以是任意的。我们可以根据光照角度与表面法向量的夹角余弦值大小判断光照强度：如果点积的结果大于0，那么这个面就是面对着光；如果点积的结果小于0，那么这个表面是背离光的。点积的结果值越大，说明光照强度更猛，代表了更多的光照射在这个表面。</p>
<p>然而要计算表面的法向量需要求解该点的偏导数，这无疑计算起来很复杂。回想以下我们前面的处理，从圆形上取一个点，并按照环面的中心轴旋转，然后再绕着另外两个轴旋转。该点的表面的法向量很明显就是原始单位圆上的表面法向量。</p>
<p>所以我们的法向量$(N_x,N_y,N_z)$可以通过上面的过程推导出来，只要我们不是从$(\cos \theta,\sin \theta,0)$开始的就好。我们使用相同的旋转：</p>
<script type="math/tex; mode=display">
(N_x,N_y,N_z)=(\cos\theta,\sin \theta, 0)\cdot
\begin{bmatrix}
\cos \phi&0&\sin \phi\\
0 &1 &0\\
-\sin \phi & 0 & \cos \phi
\end{bmatrix}
\cdot
\begin{bmatrix}
1 &0 &0\\
0 & \cos A & \sin A\\
0 & -\sin A& \cos A
\end{bmatrix}</script><p>但我们选哪个光照方向呢？不如选择照亮后上方吧，对应的光照方向为$(0,1,-1)$。严格来说的话，这个光照向量应该经过归一化处理的，前面应该提取出一个$\sqrt{2}$的幅度，但其实没关系啦（我的理解是计算根号又要增加运算所以不值）我们会在后面进行补偿。因此我们可以计算出上面的$(x,y,z)$，我你们可以把$x$给扔掉了，只看$y,z$两个部分：</p>
<script type="math/tex; mode=display">
\begin{aligned}
L&=(N_x,N_y,N_z)\cdot(0,1,-1)\\
 &=\cos\phi\cos\theta\sin B - \cos A \cos\theta\sin \phi -\sin A \sin\theta + \cos B (\cos A \sin \theta -\cos \theta \sin A \sin \phi)
\end{aligned}</script><p>再一次见到了不好看的形式，但是没关系只要我们提前把所有的$\cos(\cdot)/\sin(\cdot)$给算出来就行了。</p>
<p>现在我们只需要选择合适的$R_1,R_2,K_1,K_2$就好了。在原始的代码中，我选择了$R_1$ = 1以及 $R_2$ =2 ，$K_2$我选择为5。</p>
<p>现在我们把所有的碎片拼凑起来，伪代码大概长这个样子：</p>
<figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="type">const</span> <span class="type">float</span> theta_spacing = <span class="number">0.07</span>;</span><br><span class="line"><span class="type">const</span> <span class="type">float</span> phi_spacing   = <span class="number">0.02</span>;</span><br><span class="line"></span><br><span class="line"><span class="type">const</span> <span class="type">float</span> R1 = <span class="number">1</span>;</span><br><span class="line"><span class="type">const</span> <span class="type">float</span> R2 = <span class="number">2</span>;</span><br><span class="line"><span class="type">const</span> <span class="type">float</span> K2 = <span class="number">5</span>;</span><br><span class="line"><span class="comment">// Calculate K1 based on screen size: the maximum x-distance occurs</span></span><br><span class="line"><span class="comment">// roughly at the edge of the torus, which is at x=R1+R2, z=0.  we</span></span><br><span class="line"><span class="comment">// want that to be displaced 3/8ths of the width of the screen, which</span></span><br><span class="line"><span class="comment">// is 3/4th of the way from the center to the side of the screen.</span></span><br><span class="line"><span class="comment">// screen_width*3/8 = K1*(R1+R2)/(K2+0)</span></span><br><span class="line"><span class="comment">// screen_width*K2*3/(8*(R1+R2)) = K1</span></span><br><span class="line"><span class="type">const</span> <span class="type">float</span> K1 = screen_width*K2*<span class="number">3</span>/(<span class="number">8</span>*(R1+R2));</span><br><span class="line"></span><br><span class="line">render_frame(<span class="type">float</span> A, <span class="type">float</span> B) &#123;</span><br><span class="line">  <span class="comment">// precompute sines and cosines of A and B</span></span><br><span class="line">  <span class="type">float</span> cosA = <span class="built_in">cos</span>(A), sinA = <span class="built_in">sin</span>(A);</span><br><span class="line">  <span class="type">float</span> cosB = <span class="built_in">cos</span>(B), sinB = <span class="built_in">sin</span>(B);</span><br><span class="line"></span><br><span class="line">  <span class="type">char</span> output[<span class="number">0.</span>.screen_width, <span class="number">0.</span>.screen_height] = <span class="string">&#x27; &#x27;</span>;</span><br><span class="line">  <span class="type">float</span> zbuffer[<span class="number">0.</span>.screen_width, <span class="number">0.</span>.screen_height] = <span class="number">0</span>;</span><br><span class="line"></span><br><span class="line">  <span class="comment">// theta goes around the cross-sectional circle of a torus</span></span><br><span class="line">  <span class="keyword">for</span> (<span class="type">float</span> theta=<span class="number">0</span>; theta &lt; <span class="number">2</span>*pi; theta += theta_spacing) &#123;</span><br><span class="line">    <span class="comment">// precompute sines and cosines of theta</span></span><br><span class="line">    <span class="type">float</span> costheta = <span class="built_in">cos</span>(theta), sintheta = <span class="built_in">sin</span>(theta);</span><br><span class="line"></span><br><span class="line">    <span class="comment">// phi goes around the center of revolution of a torus</span></span><br><span class="line">    <span class="keyword">for</span>(<span class="type">float</span> phi=<span class="number">0</span>; phi &lt; <span class="number">2</span>*pi; phi += phi_spacing) &#123;</span><br><span class="line">      <span class="comment">// precompute sines and cosines of phi</span></span><br><span class="line">      <span class="type">float</span> cosphi = <span class="built_in">cos</span>(phi), sinphi = <span class="built_in">sin</span>(phi);</span><br><span class="line">    </span><br><span class="line">      <span class="comment">// the x,y coordinate of the circle, before revolving (factored</span></span><br><span class="line">      <span class="comment">// out of the above equations)</span></span><br><span class="line">      <span class="type">float</span> circlex = R2 + R1*costheta;</span><br><span class="line">      <span class="type">float</span> circley = R1*sintheta;</span><br><span class="line"></span><br><span class="line">      <span class="comment">// final 3D (x,y,z) coordinate after rotations, directly from</span></span><br><span class="line">      <span class="comment">// our math above</span></span><br><span class="line">      <span class="type">float</span> x = circlex*(cosB*cosphi + sinA*sinB*sinphi)</span><br><span class="line">        - circley*cosA*sinB; </span><br><span class="line">      <span class="type">float</span> y = circlex*(sinB*cosphi - sinA*cosB*sinphi)</span><br><span class="line">        + circley*cosA*cosB;</span><br><span class="line">      <span class="type">float</span> z = K2 + cosA*circlex*sinphi + circley*sinA;</span><br><span class="line">      <span class="type">float</span> ooz = <span class="number">1</span>/z;  <span class="comment">// &quot;one over z&quot;</span></span><br><span class="line">      </span><br><span class="line">      <span class="comment">// x and y projection.  note that y is negated here, because y</span></span><br><span class="line">      <span class="comment">// goes up in 3D space but down on 2D displays.</span></span><br><span class="line">      <span class="type">int</span> xp = (<span class="type">int</span>) (screen_width/<span class="number">2</span> + K1*ooz*x);</span><br><span class="line">      <span class="type">int</span> yp = (<span class="type">int</span>) (screen_height/<span class="number">2</span> - K1*ooz*y);</span><br><span class="line">      </span><br><span class="line">      <span class="comment">// calculate luminance.  ugly, but correct.</span></span><br><span class="line">      <span class="type">float</span> L = cosphi*costheta*sinB - cosA*costheta*sinphi -</span><br><span class="line">        sinA*sintheta + cosB*(cosA*sintheta - costheta*sinA*sinphi);</span><br><span class="line">      <span class="comment">// L ranges from -sqrt(2) to +sqrt(2).  If it&#x27;s &lt; 0, the surface</span></span><br><span class="line">      <span class="comment">// is pointing away from us, so we won&#x27;t bother trying to plot it.</span></span><br><span class="line">      <span class="keyword">if</span> (L &gt; <span class="number">0</span>) &#123;</span><br><span class="line">        <span class="comment">// test against the z-buffer.  larger 1/z means the pixel is</span></span><br><span class="line">        <span class="comment">// closer to the viewer than what&#x27;s already plotted.</span></span><br><span class="line">        <span class="keyword">if</span>(ooz &gt; zbuffer[xp,yp]) &#123;</span><br><span class="line">          zbuffer[xp, yp] = ooz;</span><br><span class="line">          <span class="type">int</span> luminance_index = L*<span class="number">8</span>;</span><br><span class="line">          <span class="comment">// luminance_index is now in the range 0..11 (8*sqrt(2) = 11.3)</span></span><br><span class="line">          <span class="comment">// now we lookup the character corresponding to the</span></span><br><span class="line">          <span class="comment">// luminance and plot it in our output:</span></span><br><span class="line">          output[xp, yp] = <span class="string">&quot;.,-~:;=!*#$@&quot;</span>[luminance_index];</span><br><span class="line">        &#125;</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="comment">// now, dump output[] to the screen.</span></span><br><span class="line">  <span class="comment">// bring cursor to &quot;home&quot; location, in just about any currently-used</span></span><br><span class="line">  <span class="comment">// terminal emulation mode</span></span><br><span class="line">  <span class="built_in">printf</span>(<span class="string">&quot;\x1b[H&quot;</span>);</span><br><span class="line">  <span class="keyword">for</span> (<span class="type">int</span> j = <span class="number">0</span>; j &lt; screen_height; j++) &#123;</span><br><span class="line">    <span class="keyword">for</span> (<span class="type">int</span> i = <span class="number">0</span>; i &lt; screen_width; i++) &#123;</span><br><span class="line">      <span class="built_in">putchar</span>(output[i,j]);</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="built_in">putchar</span>(<span class="string">&#x27;\n&#x27;</span>);</span><br><span class="line">  &#125;</span><br><span class="line">  </span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>我用<code>Python</code>重写了下，顺便加了个按下空格开启/关闭<code>RTX</code>效果的东西：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> math</span><br><span class="line"></span><br><span class="line">WIDTH =  <span class="number">30</span></span><br><span class="line">HEIGHT = <span class="number">30</span> </span><br><span class="line"></span><br><span class="line">R1 = <span class="number">1</span></span><br><span class="line">R2 = <span class="number">2</span></span><br><span class="line"></span><br><span class="line">K2 = <span class="number">5</span></span><br><span class="line">K1 = (WIDTH*K2*<span class="number">3</span>)/(<span class="number">8</span>*(R1+R2))</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">THETA_STEP = <span class="number">0.07</span></span><br><span class="line">PHI_STEP = <span class="number">0.02</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">render_frame</span>(<span class="params">A, B,RTX_ON</span>):</span><br><span class="line">    output= []</span><br><span class="line">    zbuffer = []</span><br><span class="line">    <span class="keyword">for</span> _ <span class="keyword">in</span> <span class="built_in">range</span>(HEIGHT + <span class="number">1</span>):</span><br><span class="line">        zbuffer.append([<span class="number">0</span>] * (WIDTH+<span class="number">0</span>)) </span><br><span class="line">        output.append([<span class="string">&#x27; &#x27;</span>] * (WIDTH+<span class="number">0</span>))</span><br><span class="line"></span><br><span class="line">    cosA = math.cos(A)</span><br><span class="line">    sinA = math.sin(A)</span><br><span class="line">    cosB = math.cos(B)</span><br><span class="line">    sinB = math.sin(B)</span><br><span class="line"></span><br><span class="line">    theta = <span class="number">0</span></span><br><span class="line">    <span class="keyword">while</span> theta &lt; <span class="number">2</span> * math.pi:</span><br><span class="line">        theta += THETA_STEP</span><br><span class="line">        </span><br><span class="line">        costheta = math.cos(theta)</span><br><span class="line">        sintheta = math.sin(theta)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># circlex = R1 * (1+costheta) * costheta</span></span><br><span class="line">        <span class="comment"># circley = R1 * (1+costheta) * sintheta</span></span><br><span class="line"></span><br><span class="line">        circlex = R2 + R1 * costheta</span><br><span class="line">        circley = R1 * sintheta</span><br><span class="line">        phi = <span class="number">0</span></span><br><span class="line">        <span class="keyword">while</span> phi &lt; math.pi * <span class="number">2</span>:</span><br><span class="line">            phi += PHI_STEP</span><br><span class="line">            cosphi = math.cos(phi)</span><br><span class="line">            sinphi = math.sin(phi)</span><br><span class="line">            <span class="comment">#原始代码把circlex、circley放到这里了，我觉得重复计算了移到外面了</span></span><br><span class="line">            </span><br><span class="line"></span><br><span class="line">            x = circlex*(cosB*cosphi + sinA*sinB*sinphi) - circley*cosA*sinB</span><br><span class="line">            y = circlex*(sinB*cosphi - sinA*cosB*sinphi) + circley*cosA*cosB</span><br><span class="line">            z = K2 + cosA*circlex*sinphi + circley*sinA</span><br><span class="line"></span><br><span class="line">            ooz = <span class="number">1</span>/z</span><br><span class="line"></span><br><span class="line">            xp = <span class="built_in">int</span>(WIDTH/<span class="number">2</span> + K1 * ooz * x)</span><br><span class="line">            yp = <span class="built_in">int</span>(HEIGHT/<span class="number">2</span> - K1 * ooz * y)</span><br><span class="line"></span><br><span class="line">            L = cosphi*costheta*sinB - cosA*costheta*sinphi - sinA*sintheta + cosB*(cosA*sintheta - costheta*sinA*sinphi)</span><br><span class="line"></span><br><span class="line">            <span class="keyword">if</span> L &gt; <span class="number">0</span>:</span><br><span class="line">                <span class="keyword">if</span> ooz &gt; zbuffer[xp][yp]:</span><br><span class="line">                    zbuffer[xp][yp] = ooz</span><br><span class="line">                    luminance_index = <span class="built_in">int</span>(L*<span class="number">8</span>)</span><br><span class="line">                    output[xp][yp] = <span class="string">&quot;.,-~:;=!*#$@&quot;</span>[luminance_index] <span class="keyword">if</span> RTX_ON <span class="keyword">else</span> <span class="string">&#x27;.&#x27;</span></span><br><span class="line">                    </span><br><span class="line"></span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&#x27;\x1b[H&#x27;</span>)</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(HEIGHT):</span><br><span class="line">        <span class="keyword">for</span> j <span class="keyword">in</span> <span class="built_in">range</span>(WIDTH):</span><br><span class="line">            <span class="built_in">print</span>(<span class="string">&#x27;\033[1;36m&#123;&#125;\033[0m&#x27;</span>.<span class="built_in">format</span>(output[i][j]),end =<span class="string">&#x27; &#x27;</span>)</span><br><span class="line">        <span class="built_in">print</span>()</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"> </span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&quot;__main__&quot;</span>:</span><br><span class="line">    A = <span class="number">1.0</span>  </span><br><span class="line">    B = <span class="number">1.0</span>  </span><br><span class="line">    RTX_ON = <span class="literal">True</span></span><br><span class="line">    <span class="keyword">while</span> <span class="literal">True</span>:</span><br><span class="line">        render_frame(A, B, RTX_ON)</span><br><span class="line">        A += <span class="number">0.08</span></span><br><span class="line">        B += <span class="number">0.03</span></span><br></pre></td></tr></table></figure>
]]></content>
      <categories>
        <category>摸鱼记录</category>
      </categories>
      <tags>
        <tag>图形学</tag>
        <tag>摸鱼产物</tag>
      </tags>
  </entry>
  <entry>
    <title>区块链技术的基本原理以及简单应用</title>
    <url>/2022/07/29/BlockChain/</url>
    <content><![CDATA[<p>2008年11月1日，一位自称中本聪(Satoshi Nakamoto)的人发表了《比特币:一种点对点的电子现金系统》一文，阐述了基于P2P网络技术、加密技术、时间戳技术、区块链技术等的电子现金系统的构架理念，这标志着比特币的诞生。两个月后理论步入实践，2009年1月3日第一个序号为0的创世区块诞生。几天后2009年1月9日出现序号为1的区块，并与序号为0的创世区块相连接形成了链，标志着区块链的诞生。下面将阐述区块链的基本原理与功能并用代码实现区块链仿真以及一个简单的应用，同时讨论它的安全性与可靠性。</p>
<p><img src="https://s2.loli.net/2022/05/27/kQPiEU64zp9b3fR.png" style="zoom:33%;" /></p>
<span id="more"></span>
<h2 id="区块链技术的原理"><a href="#区块链技术的原理" class="headerlink" title="区块链技术的原理"></a>区块链技术的原理</h2><h3 id="问题的提出"><a href="#问题的提出" class="headerlink" title="问题的提出"></a>问题的提出</h3><p>区块链技术源于中本聪提出的一个问题：<strong>能否搭建一种基于密码学原理而非信用的电子现金系统，使得交易双方不需要通过第三方或其他金融机构？</strong></p>
<p>这个问题在现实中就是：能否实现一种没有第三方监管，但又能保证每个人都不会造假的交易方案？在日常生活中常见的网络支付手段是先从端发起通过支付软件查询对应的人民银行（第三方）账户检验账户余额是否充足，随后在这个账户中记录这笔钱的去向。当每笔交易都被双方正确记录下时，我们就认为这是一个可靠可行的支付系统。这个系统可行的前提是，我们相信从软件到人民银行这个过程中，所有数据都是不会被修改的。如果没有这些可信任的第三方，我们又如何完成一笔交易？</p>
<h3 id="一个解决方案"><a href="#一个解决方案" class="headerlink" title="一个解决方案"></a>一个解决方案</h3><p>中本聪的提出的解决方法是构建一个去中心化的网络，即大家一起记账。系统中每产生一笔交易就要广播一次，目的是让系统中的每个人知道发生了一笔交易。交易会被记录在一个”账本“里，也就是“区块”，当区块连接起来后就成为了区块链。区块的结构组成如下表格所示：</p>
<div class="table-container">
<table>
<thead>
<tr>
<th>大小</th>
<th>字段</th>
<th>描述</th>
</tr>
</thead>
<tbody>
<tr>
<td>4 Bytes</td>
<td>区块大小</td>
<td>用字节表示区块大小</td>
</tr>
<tr>
<td>80 Bytes</td>
<td>区块头</td>
<td>组成区块头的大小</td>
</tr>
<tr>
<td>1-9（可变整数）</td>
<td>交易计数器</td>
<td>交易数量</td>
</tr>
<tr>
<td>/</td>
<td>交易</td>
<td>记录区块链的交易消息</td>
</tr>
</tbody>
</table>
</div>
<p>在这个系统中每一个”人”都拿着一个相同且实时更新的”账本“。显然账本的可靠性奠定了支付的安全性，因此接下来有两个新的问题：</p>
<ul>
<li>谁去记账？</li>
<li>如何保证账本没有造假？</li>
</ul>
<h3 id="共识机制-amp-工作量证明的引入"><a href="#共识机制-amp-工作量证明的引入" class="headerlink" title="共识机制&amp;工作量证明的引入"></a>共识机制&amp;工作量证明的引入</h3><p>假设系统中每一个人都参与记账，那么会出现大家记录的交易信息以及记录的时间都不一样，这导致了账本无法被认可的问题，所以我们需要推选出一个可以承担”记账人“角色的人完成这一工作，也就是”<strong>共识机制（Consensus Mechanism）</strong>“。中本聪提出的解决方法是做题：”每一个区块前面加入一个随机数，然后进行散列函数运算（如SHA256），但只接受前面有若干个（Nonce）0的结果。通过改变随机数使得前面的0的个数等于Nonce，那么就完成一次记账的工作”。</p>
<p>实际中的区块的哈希值是由区块头数据进行二次SHA256生成的，即：</p>
<p><code>Hash=SHA256(SHA256(blockHeader))</code></p>
<p>比特币中的区块头包含了如下信息：</p>
<div class="table-container">
<table>
<thead>
<tr>
<th>大小</th>
<th>字段</th>
<th>描述</th>
</tr>
</thead>
<tbody>
<tr>
<td>4 Bytes</td>
<td>版本</td>
<td>版本号，追踪区块链版本</td>
</tr>
<tr>
<td>32 Bytes</td>
<td>父区块哈希值</td>
<td>引用区块链中父区块的哈希值</td>
</tr>
<tr>
<td>32 Bytes</td>
<td>Merkel根</td>
<td>该区块中交易的Merkel树根的哈希值</td>
</tr>
<tr>
<td>4 Bytes</td>
<td>时间戳</td>
<td>该区块产生的近似时间(精确到秒的Unix时间戳)</td>
</tr>
<tr>
<td>4 Bytes</td>
<td>难度目标</td>
<td>该区块工作量证明算法的难度目标</td>
</tr>
<tr>
<td>4 Bytes</td>
<td>Nonce</td>
<td>用于工作量证明算法的计数器</td>
</tr>
</tbody>
</table>
</div>
<p>由于SHA256单向散列函数的特性，只能通过暴力运算才能试出满足条件的随机数值，暴力运算所消耗的资源（计算机的算力、电力等）被称为”<strong>工作量证明（Proof-of-Work）</strong>“。当某一个人先试验出来这个随机数后，便会向系统其他人广播自己运算的结果。其他人可以马上拿到他算出的结果进行检验，并保存下来，这样就保证了系统中每一个人都能拿到实时最新的账本。为了鼓励记账，系统会对第一个完成运算的实施奖励（比特币）以鼓动记账的积极性。SHA256的实现原理如下图所示：</p>
<p><img src="https://i.loli.net/2021/06/25/XvJDGnlSqyLkhF8.png" alt="image-20210625165355912" style="zoom:67%;" /></p>
<h3 id="解决造假的问题。"><a href="#解决造假的问题。" class="headerlink" title="解决造假的问题。"></a>解决造假的问题。</h3><p>规定在区块头里加入上一个区块的哈希值，也称为哈希指针，通过哈希指针可以让每一个区块首尾相连直到第一个区块（创世区块）。如果改变任意一个区块里的数据，对应的哈希值就会改变，当哈希指针无法与上一个区块的哈希值对应时，该区块往后的区块就失效了，因此要重新计算往后区块的哈希值，直到修改完这个区块后的所有区块。</p>
<h3 id="原理框图"><a href="#原理框图" class="headerlink" title="原理框图"></a>原理框图</h3><p>下图展示的是当前的比特币区块链的组成结构以及运行原理图：</p>
<p><img src="https://i.loli.net/2021/06/25/xJGw7n2bdMYuKZ9.png" style="zoom: 80%;" /></p>
<h2 id="区块链的基本模块实现"><a href="#区块链的基本模块实现" class="headerlink" title="区块链的基本模块实现"></a>区块链的基本模块实现</h2><p>上文讨论了区块链的基本原理，下文即用代码实现区块链各个模块以及功能。尽量对照中本聪原始论文进行模拟、设计编程。</p>
<h3 id="交易"><a href="#交易" class="headerlink" title="交易"></a>交易</h3><p>我们定义，一枚电子货币（an electronic coin）是这样的一串数字签名：每一位所有者通过对前一次交易和下一位拥有者的公钥(Public key) 签署一个随机散列的数字签名，并将这个签名附加在这枚电子货币的末尾，电子货币就发送给了下一位所有者。而收款人通过对签名进行检验，就能够验证该链条的所有者。在程序实现中，我们采用<code>json</code>数据进行交易信息的存储。之所以应用json，是因为它的通用性和高效解析性，方便程序运算。</p>
<h3 id="时间戳服务器-区块的类"><a href="#时间戳服务器-区块的类" class="headerlink" title="时间戳服务器/区块的类"></a>时间戳服务器/区块的类</h3><p>原始论文中指出，”时间戳服务器通过对以区块(block)形式存在的一组数据实施随机散列而加上时间戳，并将该随机散列进行广播，就像在新闻或世界性新闻组网络（Usenet）的发帖一样……每个时间戳应当将前一个时间戳纳入其随机散列值中，每一个随后的时间戳都对之前的一个时间戳进行增强(reinforcing)，这样就形成了一个链条（Chain）。“因此我们可以将区块类的属性简化成如下模型：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">Block</span>:</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, index, timestamp, transactions, previous_proof, previous_hash</span>):</span><br><span class="line">        <span class="comment"># 一个区块包含的基本元素（索引，时间戳，工作量证明，交易信息，前一个区块的哈希值）</span></span><br><span class="line">        self.index = index</span><br><span class="line">        self.timestamp = timestamp</span><br><span class="line">        self.transactions = transactions</span><br><span class="line">        self.previous_hash = previous_hash</span><br><span class="line">        self.proof = self.proof_of_work(previous_proof)</span><br><span class="line">        self.<span class="built_in">hash</span> = self.hash_block()</span><br></pre></td></tr></table></figure>
<h3 id="工作量证明函数"><a href="#工作量证明函数" class="headerlink" title="工作量证明函数"></a>工作量证明函数</h3><p>工作量证明本质上是一个计数器，在中本聪的论文中，他提到的方法是寻找满足条件的随机数。在这里无意检验算SHA256的运算难度，仅仅观察系统运行性能，因此更改了工作量证明函数，即不断寻找能同时被9和上一个符合的随机数整除的数。代码如下所示：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">proof_of_work</span>(<span class="params">self, previous_proof</span>):</span><br><span class="line">    <span class="comment"># index为0表明为创世区块，工作量证明设置为0</span></span><br><span class="line">    <span class="keyword">if</span> self.index == <span class="number">0</span>:</span><br><span class="line">        incrementor = <span class="number">0</span></span><br><span class="line">        <span class="keyword">return</span> incrementor</span><br><span class="line">    <span class="comment"># 非创世区块工作量证明计算</span></span><br><span class="line">    <span class="keyword">if</span> previous_proof == <span class="number">0</span>:  <span class="comment"># 避免除0出错的问题</span></span><br><span class="line">        previous_proof = <span class="number">1</span></span><br><span class="line">    incrementor = previous_proof + <span class="number">1</span></span><br><span class="line">    <span class="keyword">while</span> <span class="keyword">not</span> (incrementor % <span class="number">9</span> == <span class="number">0</span> <span class="keyword">and</span> incrementor % previous_proof == <span class="number">0</span>):</span><br><span class="line">        incrementor += <span class="number">1</span></span><br><span class="line">    <span class="keyword">return</span> incrementor</span><br></pre></td></tr></table></figure>
<p>如果执意要使用中本聪的方案，下面也有实现方法，但不建议在模拟使用：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">proof_of_work</span>(<span class="params">self, previous_proof</span>):</span><br><span class="line">    <span class="comment"># index为0表明为创世区块，工作量证明设置为0</span></span><br><span class="line">    <span class="keyword">if</span> self.index == <span class="number">0</span>:</span><br><span class="line">        incrementor = <span class="number">0</span></span><br><span class="line">        <span class="keyword">return</span> incrementor</span><br><span class="line">    <span class="comment"># 非创世区块工作量证明计算</span></span><br><span class="line">    <span class="keyword">if</span> previous_proof == <span class="number">0</span>:  <span class="comment"># 避免除0出错的问题</span></span><br><span class="line">        previous_proof = <span class="number">1</span></span><br><span class="line">    incrementor = previous_proof + <span class="number">1</span></span><br><span class="line">    <span class="keyword">while</span> <span class="keyword">not</span> (sha256(<span class="built_in">str</span>(incrementor)+transactions) [<span class="number">0</span>:diff]!= diff * <span class="string">&#x27;0&#x27;</span>:<span class="comment">#diff是设定的难度，现行比特币一般取72</span></span><br><span class="line">        incrementor += <span class="number">1</span></span><br><span class="line">    <span class="keyword">return</span> incrementor</span><br></pre></td></tr></table></figure>
<h3 id="哈希值的生成"><a href="#哈希值的生成" class="headerlink" title="哈希值的生成"></a>哈希值的生成</h3><p>这里为了简化了一下运算难度，仅进行一次SHA256运算。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">hash_block</span>(<span class="params">self</span>):</span><br><span class="line">    sha = hashlib.sha256()</span><br><span class="line">    sha.update((<span class="built_in">str</span>(self.index) + <span class="built_in">str</span>(self.timestamp) + <span class="built_in">str</span>(self.transactions) + <span class="built_in">str</span>(self.previous_hash) + <span class="built_in">str</span>(</span><br><span class="line">        self.proof)).encode(<span class="string">&#x27;utf-8&#x27;</span>))</span><br><span class="line">    <span class="keyword">return</span> sha.hexdigest()</span><br></pre></td></tr></table></figure>
<h3 id="创世区块的生成"><a href="#创世区块的生成" class="headerlink" title="创世区块的生成"></a>创世区块的生成</h3><p>创世区块是最特殊的一个区块。我们仅需规定它的时间戳属性即可，其他的函数已经完成了它的其他属性计算。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">create_genesis_block</span>():</span><br><span class="line">    <span class="comment"># index为0，时间为生成该区块的时间，工作量证明为0，交易信息为空，哈希值为0</span></span><br><span class="line">    <span class="keyword">return</span> Block(<span class="number">0</span>, date.datetime.now(), [], <span class="number">0</span>, <span class="string">&quot;0&quot;</span>)</span><br></pre></td></tr></table></figure>
<h3 id="区块链中添加区块"><a href="#区块链中添加区块" class="headerlink" title="区块链中添加区块"></a>区块链中添加区块</h3><p>这一步的函数只完成了添加的操作，本质上是列表的添加。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">add_block_to_blockchain</span>(<span class="params">blockchain, new_transactions</span>):</span><br><span class="line">    <span class="comment"># 新区块各个要素的值</span></span><br><span class="line">    last_block = blockchain[-<span class="number">1</span>]</span><br><span class="line">    this_index = last_block.index + <span class="number">1</span></span><br><span class="line">    this_timestamp = date.datetime.now()</span><br><span class="line">    current_transactions = new_transactions</span><br><span class="line">    previous_proof = last_block.proof</span><br><span class="line">    previous_hash = last_block.<span class="built_in">hash</span></span><br><span class="line">    <span class="comment"># 生成新块并添加到链</span></span><br><span class="line">    blockchain.append(Block(this_index, this_timestamp, current_transactions, previous_proof, previous_hash))</span><br><span class="line">    <span class="keyword">return</span> blockchain</span><br></pre></td></tr></table></figure>
<p>在实际应用中，可以增加条件判断来完成哈希指针的检验工作。至此为止，区块链所有的基本模块已经实现。更具有现实意义的、更复杂的如Merkel树、Merkel树根等属性在这里不再加以展开。</p>
<h3 id="网络节点"><a href="#网络节点" class="headerlink" title="网络节点"></a>网络节点</h3><p>区块链网络工作的过程是：</p>
<ol>
<li>新的交易向全网进行广播； </li>
<li>每一个节点（Node）都将收到的交易信息纳入一个区块中； </li>
<li>每个节点都尝试在自己的区块中找到一个具有足够难度的工作量证明； </li>
<li>当一个节点找到了一个工作量证明，它就向全网进行广播； </li>
<li>当且仅当包含在该区块中的所有交易<strong>都是有效的且之前未存在过的</strong>，其他节点才认同该区块的有效性； </li>
<li>其他节点表示它们接受该区块，表示接受的方法则是：在跟随该区块的末尾，制造新的区块以延长该链条，而将被接受区块的随机哈希值视为先于新区快的随机哈希值。</li>
</ol>
<p>在区块链的运作过程所，每一个节点在争取“记账”的权力——有共识的区块，因此节点们都在努力算，首先算出来的可被接受。</p>
<p>在我们的程序实现中，我们可以采用Flask或Django等Web框架进行仿真模拟各个节点。</p>
<h2 id="区块链的简单应用"><a href="#区块链的简单应用" class="headerlink" title="区块链的简单应用"></a>区块链的简单应用</h2><h3 id="应用场景"><a href="#应用场景" class="headerlink" title="应用场景"></a>应用场景</h3><p>由于区块链具有的难以篡改的特性，因此用于记录一些重要的但数量多的数据有较大优势。在区块链中，传递的数据是<code>json</code>文件，在网页端中传递数据通常都会使用到它。引入一个场景：在当今自媒体呈爆炸式增长的时代，每个人获取的信息也越来越多，其中有很多信息存在时效性以及疑义性，二者不可兼得。目前的情况是由于碎片化的时间，很少有人会去追溯新闻事件的发展，因此造成了信息传播的误差。在这里我们试图利用区块链技术完成一个可溯的新闻客户端，持续追踪新闻信息的发展与变动。</p>
<h3 id="实现方法"><a href="#实现方法" class="headerlink" title="实现方法"></a>实现方法</h3><p>利用Flask框架搭建一个Web测试平台，观察区块链的实现。通过添加节点、以及模块功能分离，可以模拟节点运作。为了节约前端开发时间，故不进行前端页面的渲染，使用Postman作为简单的交互工具进行区块链系统中的操作模拟。在这之前，我们要先获取合适的数据。通过对<a href="houxv.app">后续</a>网站爬虫，我们可以得到<code>json.json</code>中的数据：</p>
<p><img src="https://i.loli.net/2021/06/25/FfMlk6P9gUbcIWa.png" alt="image-20210625192801969"></p>
<p>这些数据可以作为一个交易，流通在网络中。为更好模拟，我们采取功能分离的方法，设置三个节点完成对应的操作：</p>
<ul>
<li>挖矿节点<code>Mine</code></li>
<li>交易放入节点<code>Transaction</code></li>
<li>广播节点<code>chain</code></li>
</ul>
<p>挖矿节点用于调用工作量证明函数，交易放入节点只是提供POST方法接口，放入新的交易，广播节点用于观察数据变化。</p>
<p>代码如下：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 实例化节点（创建一个节点）</span></span><br><span class="line">node = Flask(__name__)</span><br><span class="line"><span class="comment"># 为该节点生成一个全局唯一的地址（为节点创建一个随机的名字）</span></span><br><span class="line">node_identifier = <span class="built_in">str</span>(uuid4()).replace(<span class="string">&#x27;-&#x27;</span>, <span class="string">&#x27;&#x27;</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 查看运行信息</span></span><br><span class="line"><span class="meta">@node.route(<span class="params"><span class="string">&#x27;/&#x27;</span></span>)</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">run_message</span>():</span><br><span class="line">    <span class="keyword">return</span> <span class="string">&#x27;Hello! Runing on http://127.0.0.1:5000/&#x27;</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 挖矿</span></span><br><span class="line"><span class="meta">@node.route(<span class="params"><span class="string">&#x27;/mine&#x27;</span>, methods=[<span class="string">&#x27;GET&#x27;</span>]</span>)</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">mine</span>():</span><br><span class="line">    <span class="comment"># 获取交易信息的一个拷贝（非引用），避免“广播”错误，否则仅发送交易信息，就直接导致原有区块交易信息的改变</span></span><br><span class="line">    <span class="comment"># 只有在挖矿的时候，才会将new_transaction信息加入到新块中</span></span><br><span class="line">    new_transactions = this_node_transactions.copy()</span><br><span class="line">    add_block_to_blockchain(blockchain, new_transactions)</span><br><span class="line">    mined_block = blockchain[-<span class="number">1</span>]</span><br><span class="line">    <span class="comment">#    # 添加到此处</span></span><br><span class="line">    <span class="keyword">del</span> (this_node_transactions[:])</span><br><span class="line">    <span class="keyword">return</span> jsonify([&#123;</span><br><span class="line">        <span class="string">&quot;index&quot;</span>: mined_block.index,</span><br><span class="line">        <span class="string">&quot;timestamp&quot;</span>: <span class="built_in">str</span>(mined_block.timestamp),</span><br><span class="line">        <span class="string">&quot;transactions&quot;</span>: mined_block.transactions,</span><br><span class="line">        <span class="string">&quot;proof&quot;</span>: mined_block.proof,</span><br><span class="line">        <span class="string">&quot;hash&quot;</span>: mined_block.<span class="built_in">hash</span></span><br><span class="line">    &#125;])</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 查看区块链</span></span><br><span class="line"><span class="meta">@node.route(<span class="params"><span class="string">&#x27;/chain&#x27;</span>, methods=[<span class="string">&#x27;GET&#x27;</span>]</span>)</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">full_chain</span>():</span><br><span class="line">    response = []</span><br><span class="line">    <span class="keyword">for</span> block <span class="keyword">in</span> blockchain:</span><br><span class="line">        block_index = <span class="built_in">str</span>(block.index)</span><br><span class="line">        block_timestamp = <span class="built_in">str</span>(block.timestamp)</span><br><span class="line">        block_transactions = <span class="built_in">str</span>(block.transactions)</span><br><span class="line">        block_proof = <span class="built_in">str</span>(block.proof)</span><br><span class="line">        block_hash = block.<span class="built_in">hash</span></span><br><span class="line">        block = &#123;</span><br><span class="line">            <span class="string">&quot;index&quot;</span>: block_index,</span><br><span class="line">            <span class="string">&quot;timestamp&quot;</span>: block_timestamp,</span><br><span class="line">            <span class="string">&quot;transactions&quot;</span>: block_transactions,</span><br><span class="line">            <span class="string">&quot;proof&quot;</span>: block_proof,</span><br><span class="line">            <span class="string">&quot;hash&quot;</span>: block_hash</span><br><span class="line">        &#125;</span><br><span class="line">        response.append(block)</span><br><span class="line">    response.append(&#123;<span class="string">&#x27;len&#x27;</span>: <span class="built_in">len</span>(blockchain)&#125;)</span><br><span class="line">    <span class="keyword">return</span> jsonify(response)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 发送交易</span></span><br><span class="line"><span class="meta">@node.route(<span class="params"><span class="string">&#x27;/transaction&#x27;</span>, methods=[<span class="string">&#x27;POST&#x27;</span>]</span>)</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">transaction</span>():</span><br><span class="line">    <span class="comment">#    if request.method == &#x27;POST&#x27;:</span></span><br><span class="line">    <span class="comment"># 检查所需的字段是否在POST数据中</span></span><br><span class="line">    values = request.get_json()</span><br><span class="line">    required = [<span class="string">&#x27;id&#x27;</span>, <span class="string">&#x27;type&#x27;</span>, <span class="string">&#x27;object&#x27;</span>,<span class="string">&#x27;publish_at&#x27;</span>,<span class="string">&#x27;object_key&#x27;</span>,<span class="string">&#x27;title&#x27;</span>,<span class="string">&#x27;summary&#x27;</span>]</span><br><span class="line">    <span class="keyword">if</span> <span class="keyword">not</span> <span class="built_in">all</span>(k <span class="keyword">in</span> values <span class="keyword">for</span> k <span class="keyword">in</span> required):</span><br><span class="line">        <span class="keyword">return</span> <span class="string">&#x27;Missing values&#x27;</span>, <span class="number">400</span></span><br><span class="line">    <span class="comment"># Then we add the transaction to our list</span></span><br><span class="line">    this_node_transactions.append(values)</span><br><span class="line">    <span class="comment"># Because the transaction was successfully</span></span><br><span class="line">    <span class="comment"># submitted, we log it to our console</span></span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;New transaction&quot;</span>)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;type: &#123;&#125;&quot;</span>.<span class="built_in">format</span>(values[<span class="string">&#x27;type&#x27;</span>]))</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;object: &#123;&#125;&quot;</span>.<span class="built_in">format</span>(values[<span class="string">&#x27;object&#x27;</span>]))</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;publish_at: &#123;&#125;&quot;</span>.<span class="built_in">format</span>(values[<span class="string">&#x27;publish_at&#x27;</span>]))</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;object_key: &#123;&#125;&quot;</span>.<span class="built_in">format</span>(values[<span class="string">&#x27;object_key&#x27;</span>]))</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;title: &#123;&#125;&quot;</span>.<span class="built_in">format</span>(values[<span class="string">&#x27;title&#x27;</span>]))</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;summary: &#123;&#125;&quot;</span>.<span class="built_in">format</span>(values[<span class="string">&#x27;summary&#x27;</span>]))</span><br><span class="line">    <span class="keyword">return</span> <span class="string">&quot;Transaction submission successful\n&quot;</span></span><br></pre></td></tr></table></figure>
<h3 id="实现效果"><a href="#实现效果" class="headerlink" title="实现效果"></a>实现效果</h3><p>由于没有编写前端页面，故采用POSTMAN观察数据交互过程：</p>
<h4 id="初始化"><a href="#初始化" class="headerlink" title="初始化"></a>初始化</h4><p>在打开<a href="http://127.0.0.1:5000/chain">http://127.0.0.1:5000/chain</a> 并点击Send后，得到如下结果：</p>
<p><img src="https://i.loli.net/2021/06/25/NQ2Oeiv1In3tBjA.png" alt="image-20210625193627211"></p>
<p>可以清楚看到创世区块的建立时间，以及交易部分的空白。</p>
<h4 id="放入交易"><a href="#放入交易" class="headerlink" title="放入交易"></a>放入交易</h4><p>当在<code>transaction</code>节点中放入一笔交易后（使用Post方法在transaction上传一段json数据），结果如图所示：</p>
<p><img src="https://i.loli.net/2021/06/25/qyJjXxwnQvFDcPW.png" alt="image-20210625193920139"></p>
<p>返回结果显示”交易“成功。观察刚刚的广播节点：</p>
<p><img src="https://i.loli.net/2021/06/25/xIuKo9gpzfdXkiQ.png" alt="image-20210625194104079" style="zoom:80%;" /></p>
<p>没有观察到”交易”的产生，因为还没有人“挖矿”。</p>
<h4 id="挖矿并广播"><a href="#挖矿并广播" class="headerlink" title="挖矿并广播"></a>挖矿并广播</h4><p>在<code>mine</code>节点中使用GET方法，完成广播工作：</p>
<p><img src="https://i.loli.net/2021/06/25/fbs5SeYVW9yXGpI.png" alt="image-20210625194642407" style="zoom:80%;" /></p>
<p>回到广播节点页，观察此时的数据：</p>
<p><img src="https://i.loli.net/2021/06/25/JwNlAGfiaI8OKcv.png" alt="image-20210625194808133" style="zoom:67%;" /></p>
<p>可以观察到此时的<code>Transaction</code>已经不是空数组了，同时还记录了挖矿完成的时间。放入一笔交易对同一节点重复多次挖矿操作后再操作，观察时间消耗：</p>
<p><img src="https://i.loli.net/2021/06/25/8dtEQsLnqFzBKvC.png" alt="image-20210625195249084"></p>
<p>在后台中的记录：</p>
<p><img src="https://i.loli.net/2021/06/25/HfFb6KNSLBPIC71.png" alt="image-20210625195816783" style="zoom: 67%;" /></p>
<p>通过简单的Timestamp相减计算，可以观察到计算的时间在成倍的增加，而工作量证明的数据也正如我们所设的那般指数增加，满足如下数学关系：</p>
<script type="math/tex; mode=display">
proof=9\times2^{n-1}</script><h2 id="区块链安全性的讨论"><a href="#区块链安全性的讨论" class="headerlink" title="区块链安全性的讨论"></a>区块链安全性的讨论</h2><p>从上面的仿真应用中我们可以看出，运算的难度其实是随着所设的工作量证明函数有关的。因此设计合理的工作量证明函数在区块链技术中非常重要。设想如下场景：</p>
<p><em>“一个攻击者试图比诚实节点产生链条更快地制造替代性区块链。即便它达到了这一目的，但是整个系统也并非就此完全受制于攻击者的独断意志了，比方说凭空创造价值，或者掠夺本不属于攻击者的货币。这是因为节点将不会接受无效的交易，而诚实的节点永远不会接受一个包含了无效信息的区块。一个攻击者能做的，最多是更改他自己的交易信息，并试图拿回他刚刚付给别人的钱。”</em></p>
<p>要篡改区块链，攻击节点就要比诚信节点更多地挖出区块，让自己的虚假链生产速度大于诚信节点的生产速度。我们可以简化一下这个数学问题：</p>
<blockquote>
<p>假设攻击者制造出下一区块的成功率$p$，诚信节点制造下一个区块的成功率为$q$，$q_z$为消除了$z$个差距的成功率，则有</p>
<script type="math/tex; mode=display">
q_z=\begin {cases}
{1,q\geq p\\
(\frac{p}{q} )^z,q<p}
\end {cases}</script><p>假如攻击者算力不如诚实节点算力，那么它攻破这条链的成功几率就随着时间呈指数下降越来越小。现实中我们的交易需要一个确认时间，在这种情况下，运气好的攻击者在等待的时间攻破了这条长链的话，可以将准备好的假链接上在区块链中，从而攻破区块链，因此要设定一个合适的等待时间。</p>
<p>假设诚信节点的区块生产速度是恒定的一个定值$t$,而且它并不知道攻击者的运算进展，这样潜在攻击者的运算进展就成为一个泊松分布，分布期望为：</p>
<script type="math/tex; mode=display">
E（\lambda）=z ·\frac{q}{p}</script><p>当此情形，为了计算攻击者追赶上的概率，将攻击者取得进展区块数量的泊松分布的概率密度，乘以在该数量下攻击者依然能够追赶上的概率。</p>
<script type="math/tex; mode=display">
P(z)={\sum_{k!}^{\lambda^ke^{-\lambda}}·
\begin {cases}
(\frac{q}{p})^{z-k},k\leq z\\
1,k>z
\end {cases}}\\
=1-\sum_{k=0}^{z}\frac{\lambda^k e^{- \lambda}}{k!}[1-(\frac{q}{p})^{z-k}]</script></blockquote>
<p>编程对该函数求和，并计算取不同q、p计算z值。</p>
<center><img src="https://i.loli.net/2021/06/25/XJNlPAZEFV9Ujy3.png" alt="image-20210625212342045" style="zoom: 67%;" /></center>
<center><img src="https://i.loli.net/2021/06/25/Rn7jpoF9dZXJikD.png" alt="image-20210625212409923" style="zoom: 67%;" /></center>
<center><img src="https://i.loli.net/2021/06/25/M7XT16cxKHgq9wk.png" alt="image-20210625212746175" style="zoom: 67%;" /></center>



<p>纵向比较可以观察到，不论等待时间取多大，在攻击成功概率为0.5时，都能成功篡改区块链，因此破坏区块链的条件是拥有超过全网50%的算力进行运算；</p>
<p>横向对比可以观察到，增加等待时间后，同等攻击成功概率的情况下，篡改区块链的成功率越来越低，接近为零，因此增加等待时间是一个有效的保护措施，但这个保护时间不宜太长，否则不利于交易池中放入新的交易。</p>
<h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>通过python、Postman实现基本的区块链仿真以及简单应用，让我收获良多，其中区块链的去中心化思想、区块化、工作量证明机制非常吸引人，相信能在未来拥有更多的应用场景。本次编程考虑到了时间紧迫以及主力机性能，故没有完全复现中本聪所提出的其他机制如硬盘空间回收、简化支付确认、价值组合与分割以及隐私的实现，但在日后会完成进一步的应用实践与区块链的能力探索。配套代码见我的<a href="https://gitee.com/dafeigy/block-chain">Gitee仓库</a>。</p>
]]></content>
      <categories>
        <category>通信技术</category>
        <category>加密技术</category>
      </categories>
      <tags>
        <tag>区块链</tag>
        <tag>通信</tag>
        <tag>数字签名</tag>
      </tags>
  </entry>
  <entry>
    <title>CMA均衡Matlab仿真实验</title>
    <url>/2022/11/03/CMA/</url>
    <content><![CDATA[<h1 id="CMA均衡算法实验"><a href="#CMA均衡算法实验" class="headerlink" title="CMA均衡算法实验"></a>CMA均衡算法实验</h1><p>均衡是为了弥补信号在非理想信道下传播时对波形造成的失真进行“修补”，假如把信道输入到非理想信道再到信号输出的过程看作时域下信号与一个系统的系统函数卷积再加上特定的噪声的结果，那么均衡所做的就是拟合这个系统函数“求逆”的结果，使得经过信道的信号在经过这个“求逆”的操作后恢复原本的信号波形。大部分情况下，信道情况是未知的，在这种情况下对输出信道进行均衡的话有主要两种方法：依赖辅助数据进行信道估计和盲均衡方法。依赖辅助数据的方法就是在正式发送数据前先发送一段训练序列，通过已知的训练序列对比在接收端经过信道后的序列进行对比从而对信道进行估计，这种方法应用很广，在资源充足的情况下可以获得较好的效果，OFDM技术中长短训练序列的使用正是这一思想的体现：</p>
<p><img src="https://s2.loli.net/2022/11/12/VNzIbeLtRpE9k7W.png" alt="image-20221025191837355"></p>
<p>另一种方法则是不依赖训练序列的均衡方法，它靠接受到的信号进行自适应均衡，这种不依赖训练序列的方法称为盲均衡。下面的CMA（Constant Modulus Algorithm）即恒模算法就是隶属于Bussgang类盲均衡算法中的一种。CMA算法具有计算复杂度低，易于实时实现，收敛性能好等优点，代价函数只与接收序列的幅值有关，而与相位无关，故对载波相位不敏感。</p>
<span id="more"></span>
<h2 id="CMA均衡原理"><a href="#CMA均衡原理" class="headerlink" title="CMA均衡原理"></a>CMA均衡原理</h2><p>一般的均衡过程的原理框图如下所示：</p>
<p><img src="https://s2.loli.net/2022/10/26/JX9G6uVkP4jMxvq.png" alt="image-20221026101739233"></p>
<center><small>图1. 均衡流程</small></center>

<p>均衡器的输入信号可表示为：</p>
<script type="math/tex; mode=display">
y(n) = x(n)*h(n) + noise(n)</script><p>其中，$x(n)$是信源信号，$h(n)$是信道的系统函数，$noise(n)$为高斯信道白噪声。均衡的输出为：</p>
<script type="math/tex; mode=display">
\hat x(n) = w(n)*y(n)\\</script><p>均衡的目标即为通过改变滤波器参数组让输出的序列$\hat x(n)$无限逼近原始的信息序列$x(n)$。一般来说如果要估计信道的系统函数，我们可以通过给定训练序列作为$x(n)$输入，观察最终的$\hat x(n)$即可通过一系列的方法对$h(n)$进行估计$\hat h(n)$，从而设计恰当的FIR滤波器充当均衡器。</p>
<p><img src="https://s2.loli.net/2022/10/26/m9nIiloRDadPq4p.png" alt="image-20221026101835743" style="zoom: 50%;" /></p>
<center><small>图2. 均衡器等价构造：一个有限长的FIR滤波器</small></center>

<p>然而CMA算法不需要训练数据作为依赖, 它的本质是通过误差函数来迭代FIR滤波器的参数组$W_n$。滤波器一般用长度为$L$的FIR滤波器实现，其构成参数（抽头系数）$w(n)$为：</p>
<script type="math/tex; mode=display">
W(n) = [w_0(n),    w_1(n),\dots,w_{L-1}(n)]</script><p>输入均衡其的符号序列表示为：</p>
<script type="math/tex; mode=display">
Y(n) = [y(n),y(n-1),\dots,y(n-L+1)]</script><p>定义CMA算法的代价函数：</p>
<script type="math/tex; mode=display">
J(W_n)=[|(\hat x(n)|^2-R_2)^2]</script><p>其中$R_2$代表了期望的收敛半径，是一个依赖于信源序列高阶统计量的一个实常数，定义为：</p>
<script type="math/tex; mode=display">
R_2 = \frac{E[|\hat x(n)|^{2p}]}{E[|\hat x(n)|^p]}</script><p>其中，$p$由信源决定，对于在复平面对称的4QAM信号p取值为2。我们的目标是找到最适合的$W_n^\star$使得代价函数的值最小，即：</p>
<script type="math/tex; mode=display">
\begin {align}
W_n^{\star}&= \arg \min_{\{W_n\}} (J(W_n))\\
&=\arg \min_{W_n}(E[(|\hat x(n)|^2-R_2)^2])
\end{align}</script><p>求解上式可以使用梯度下降法，即对$J(W_n)$计算其关于$W_n(n)$的偏导，即可得知$W_n(n)$中的每一组分对$J(W_n)$大小的影响。通过计算当前损失函数的偏导与设定的$\mu$值相乘的结果，再用当前的$W_n(n)$与该值相减即可得到下一时刻梯度变化最大的$W_n(n)$，通过不断地迭代即可得到最优的$W_n$，此时偏导数部分几乎不再变化，参数组也随之收敛：</p>
<script type="math/tex; mode=display">
W(n+1) = W(n)-\mu\frac{\partial J(W(n))}{\partial W(n)}</script><p>将损失函数表达式代入上式，即可得到$W(n)$的迭代更新式：</p>
<script type="math/tex; mode=display">
W(n+1)=W(n)+\mu \hat x(n)[R_2-|\hat x(n)|^2]Y^\star(n)</script><h2 id="CMA仿真实验"><a href="#CMA仿真实验" class="headerlink" title="CMA仿真实验"></a>CMA仿真实验</h2><h3 id="使用CMA算法均衡4QAM信号"><a href="#使用CMA算法均衡4QAM信号" class="headerlink" title="使用CMA算法均衡4QAM信号"></a>使用CMA算法均衡4QAM信号</h3><p>采用4QAM对原始的<code>3000</code>个比特信息流进行调制，将调制后的信号经过参数矩阵为$H$的滤波器以拟合信号在非理想信道下传播时的码间串扰，随后将输出与信噪比为<code>snr</code>的高斯加性白噪声叠加作为均衡器输入的信号。对均衡器而言，设定三个不同的参数$\mu_1=0.01,\mu_2=0.005,\mu_3=0.001$，并迭代5000轮观察该参数对均衡结果的影响。在4QAM调制中，采用MSE观察均衡结果。在该实验下，MSE定义为损失函数的平方：</p>
<script type="math/tex; mode=display">
MSE = (R_2-|\hat x(n)^2|)^2</script><p>原始的比特流经由4QAM调制后的星座图与经过信道与高斯加性白噪声（snr=10）叠加后的星座图：</p>
<center><img src="https://s2.loli.net/2022/10/26/1l2FQMU4WsTLqyk.png" style="zoom:40%;" /><img src="https://s2.loli.net/2022/10/26/8m17WDoZJGRwVdQ.png" style="zoom:40%;" /></center>

<p>经过5000次迭代后，不同$\mu$值下的星座图：</p>
<center><img src="https://s2.loli.net/2022/10/26/qMN3KhyAQaWJpT1.png" alt="Equ-0.01" style="zoom:40%;" /><img src="https://s2.loli.net/2022/10/26/3fAxmcs78lIB5rn.png" alt="equ 0.005" style="zoom:40%;" /><img src="https://s2.loli.net/2022/10/26/2XWxVnmLbcQSioF.png" alt="equ 0.001" style="zoom:40%;" /></center>

<center>SNR=20dB下均衡后信号图，对应μ值分别为0.01，0.005和0.001</center>

<p>可以看到原本分散的符号聚拢在原始星座图的四个点附近。在信噪比较差(SNR=5dB)时，结果如图所示：</p>
<center><img src="https://s2.loli.net/2022/10/26/1l2FQMU4WsTLqyk.png" style="zoom:40%;" /><img src="https://s2.loli.net/2022/10/26/Xuktc2N4jAmDfJ9.png"  style=zoom:40%;/></center>

<p>均衡后的星座图如下所示：</p>
<center><img src="https://s2.loli.net/2022/10/26/t3fnX6slwvGE5LF.png" alt="Equ-0.01" style="zoom:40%;" /><img src="https://s2.loli.net/2022/10/26/Sn4VjB73wkQL9Ns.png" alt="equ 0.005" style="zoom:40%;" /><img src="https://s2.loli.net/2022/10/26/dCPSFRunwfiNshe.png" alt="equ 0.001" style="zoom:40%;" /></center>

<center>SNR=5dB下均衡后信号图，对应μ值分别为0.01，0.005和0.001</center>

<p>两种信噪比下，迭代次数与MSE关系对比如图：</p>
<p><img src="https://s2.loli.net/2022/10/26/QOwoT8fS26HNmCs.png" alt="image-20221026102630396" style="zoom: 67%;" /></p>
<center>SNR=20dB时，不同μ值的MSE情况</center>

<p><img src="https://s2.loli.net/2022/10/26/bmgzxMkV1N8dSsF.png" alt="image-20221026102648393" style="zoom:67%;" /></p>
<center>SNR=5dB时，不同μ值的MSE情况</center>

<p>细节图：</p>
<center><img src="C:\Users\cybercolyce\AppData\Roaming\Typora\typora-user-images\image-20221025205942835.png" style="zoom: 30%;" /><img src="C:\Users\cybercolyce\AppData\Roaming\Typora\typora-user-images\image-20221025210130389.png" style="zoom:30%;" /></center>

<center>左：SNR 20dB；右：SNR 5dB</center>

<p>可知$\mu$的选择对MSE影响有重要影响。图中黄色曲线代表$\mu_2 = 0.05$的迭代情况，绿色曲线代表$\mu_3=0.001$的迭代，红色曲线为$\mu_1=0.01$，尽管三条曲线都在迭代初期已有下降趋势，但可以从细节图中看出，MSE下降最快的时$\mu_2=0.005$的黄色曲线，绿色曲线尽管也能收敛，但其收敛速度不如黄色曲线，红色曲线的来回震荡则说明参数设置的不合理，灵敏度过大以至于不能落入梯度为0的位置；同时也可从图中看出均衡对信号的修复能力也是有限的，在低信噪比情况下尽管恰到的学习参数可以让参数收敛，但其收敛效果非常有限，如20dB的信噪比下MSE收敛可到0.005，但在5dB信噪比下收敛的MSE只能到达0.6左右。</p>
<h3 id="CMA算法对原始比特流波形影响"><a href="#CMA算法对原始比特流波形影响" class="headerlink" title="CMA算法对原始比特流波形影响"></a>CMA算法对原始比特流波形影响</h3><p>对于信号的原始比特流信息，经过调制后不好直观展示，因此使用OOK调制将比特映射到集合{-1，1}上，设定系统传输环境如下：</p>
<ul>
<li>码元速率：10e9</li>
<li>码元抽样点数（过采样次数）：8</li>
<li>码元个数：256</li>
<li>调制方式：OOK调制</li>
<li>判决门限：0.5</li>
</ul>
<p>让信号序列经过高斯加性白噪声信道并经过均衡，在最终判决得到如下结果：</p>
<p><img src="C:\Users\cybercolyce\AppData\Roaming\Typora\typora-user-images\image-20221025213953375.png" alt="image-20221025213953375"></p>
<p>可以从图中看出均衡后的序列可还原出原本的信号波形，但会有一定的时滞。</p>
<h2 id="附录"><a href="#附录" class="headerlink" title="附录"></a>附录</h2><h3 id="实验一代码"><a href="#实验一代码" class="headerlink" title="实验一代码"></a>实验一代码</h3><figure class="highlight matlab"><table><tr><td class="code"><pre><span class="line"><span class="comment">% QAM_main.h</span></span><br><span class="line">clear all;</span><br><span class="line">clc;</span><br><span class="line">M=<span class="number">4</span>;        <span class="comment">% Modulation Scale</span></span><br><span class="line">n=<span class="number">5000</span>;     <span class="comment">% Num bits</span></span><br><span class="line">m=<span class="number">3000</span>;     <span class="comment">% Num Iteration</span></span><br><span class="line"></span><br><span class="line"><span class="comment">% Channel params, change value or length whatever you like</span></span><br><span class="line">H=[<span class="number">0.005</span> <span class="number">0.009</span> <span class="number">-0.024</span> <span class="number">0.854</span> <span class="number">-0.218</span> <span class="number">0.049</span> <span class="number">-0.016</span>];   <span class="comment">%That&#x27;s quite a bad channel</span></span><br><span class="line">snr = <span class="number">5</span>;   <span class="comment">% SNR of awgn that need to be added after H(n)*x(n)</span></span><br><span class="line">L=<span class="number">7</span>;       <span class="comment">% CMA FIR scale, need to be set as an odd num</span></span><br><span class="line"></span><br><span class="line"><span class="comment">% \mu rate</span></span><br><span class="line">u1=<span class="number">0.01</span>;    </span><br><span class="line">u2=<span class="number">0.005</span>;</span><br><span class="line">u3=<span class="number">0.001</span>;</span><br><span class="line"></span><br><span class="line"><span class="comment">% mse buffer</span></span><br><span class="line">mse_av1=<span class="built_in">zeros</span>(<span class="number">1</span>,n-L+<span class="number">1</span>);</span><br><span class="line">mse_av2=mse_av1;</span><br><span class="line">mse_av3=mse_av2;</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> <span class="built_in">j</span>=<span class="number">1</span>:m</span><br><span class="line">    <span class="comment">% Generate Source bit</span></span><br><span class="line">    s=randi([<span class="number">0</span> M<span class="number">-1</span>],<span class="number">1</span>,n);</span><br><span class="line">    <span class="comment">% QAM modulation</span></span><br><span class="line">    qam_msg = qammod(s,M);</span><br><span class="line">    <span class="comment">% Calculate R2</span></span><br><span class="line">    R2=(<span class="built_in">abs</span>(qam_msg).^<span class="number">4</span>)/(<span class="built_in">abs</span>(qam_msg).^<span class="number">4</span>);</span><br><span class="line"></span><br><span class="line">    <span class="comment">% Go through FIR to approximate transmit channel&#x27;s ISI and add AGWN</span></span><br><span class="line">    s2=filter(H,<span class="number">1</span>,qam_msg);</span><br><span class="line">    x=awgn(s2,snr,<span class="string">&#x27;measured&#x27;</span>);</span><br><span class="line">    </span><br><span class="line">    <span class="comment">%Init the W_n</span></span><br><span class="line">    w1 = <span class="built_in">zeros</span>(<span class="number">1</span>,L);</span><br><span class="line">    w1((L+<span class="number">1</span>)/<span class="number">2</span>) = <span class="number">1</span>;</span><br><span class="line">    w2=w1;</span><br><span class="line">    w3=w1;</span><br><span class="line">    <span class="keyword">for</span> <span class="built_in">i</span>=<span class="number">1</span>:n-L+<span class="number">1</span></span><br><span class="line">        <span class="comment">% Invert the input series for calculate discrete convolution</span></span><br><span class="line">        y=x(<span class="built_in">i</span>+L<span class="number">-1</span>:<span class="number">-1</span>:<span class="built_in">i</span>);</span><br><span class="line">        z1(<span class="built_in">i</span>)=w1*y&#x27;;</span><br><span class="line">        z2(<span class="built_in">i</span>)=w2*y&#x27;; </span><br><span class="line">        z3(<span class="built_in">i</span>)=w3*y&#x27;;</span><br><span class="line"></span><br><span class="line">        <span class="comment">% Calculate Loss Function</span></span><br><span class="line">        e1=R2-(<span class="built_in">abs</span>(z1(<span class="built_in">i</span>))^<span class="number">2</span>); </span><br><span class="line">        e2=R2-(<span class="built_in">abs</span>(z2(<span class="built_in">i</span>))^<span class="number">2</span>);</span><br><span class="line">        e3=R2-(<span class="built_in">abs</span>(z3(<span class="built_in">i</span>))^<span class="number">2</span>);</span><br><span class="line"></span><br><span class="line">        <span class="comment">% Update FIR params</span></span><br><span class="line">        w1=w1+u1*e1*y*z1(<span class="built_in">i</span>);</span><br><span class="line">        w2=w2+u2*e2*y*z2(<span class="built_in">i</span>);</span><br><span class="line">        w3=w3+u3*e3*y*z3(<span class="built_in">i</span>);</span><br><span class="line"></span><br><span class="line">        <span class="comment">% Calculate MSE</span></span><br><span class="line">        mse1(<span class="built_in">i</span>)=e1^<span class="number">2</span>; </span><br><span class="line">        mse2(<span class="built_in">i</span>)=e2^<span class="number">2</span>;</span><br><span class="line">        mse3(<span class="built_in">i</span>)=e3^<span class="number">2</span>;</span><br><span class="line">    <span class="keyword">end</span>;</span><br><span class="line">    mse_avl=mse_av1+mse1; </span><br><span class="line">    mse_av2=mse_av2+mse2;</span><br><span class="line">    mse_av3=mse_av3+mse3;</span><br><span class="line"><span class="keyword">end</span>;</span><br><span class="line">mse_av1=mse_av1/m;</span><br><span class="line">mse_av2=mse_av2/m;</span><br><span class="line">mse_av3=mse_av3/m;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="built_in">plot</span>([<span class="number">1</span>:n-L+<span class="number">1</span>],mse_avl,<span class="string">&#x27;r&#x27;</span>,[<span class="number">1</span>:n-L+<span class="number">1</span>],mse_av2,<span class="string">&#x27;y&#x27;</span>,[<span class="number">1</span>:n-L+<span class="number">1</span>],mse_av3,<span class="string">&#x27;g&#x27;</span>);</span><br><span class="line"><span class="built_in">legend</span>(<span class="string">&#x27;u1=0.01&#x27;</span>,<span class="string">&#x27;u2=0.005&#x27;</span>,<span class="string">&#x27;u3=0.001&#x27;</span>)</span><br><span class="line">title(<span class="string">&#x27;MSE vs. Iteration Using CMA&#x27;</span>);</span><br><span class="line">xlabel(<span class="string">&#x27;Iteration&#x27;</span>,<span class="string">&#x27;fontsize&#x27;</span>,<span class="number">14</span>);</span><br><span class="line">ylabel(<span class="string">&#x27;MSE&#x27;</span>,<span class="string">&#x27;fontsize&#x27;</span>,<span class="number">14</span>);</span><br><span class="line"><span class="built_in">hold</span> on</span><br><span class="line"></span><br><span class="line">scatterplot(qam_msg);</span><br><span class="line">title(<span class="string">&quot;Origin 4QAM&quot;</span>);</span><br><span class="line"><span class="built_in">hold</span> on</span><br><span class="line"></span><br><span class="line">scatterplot(x);</span><br><span class="line">title(<span class="string">&quot;Noise 4QAM&quot;</span>);</span><br><span class="line"><span class="built_in">hold</span> on</span><br><span class="line"></span><br><span class="line">scatterplot(z1);</span><br><span class="line">title(<span class="string">&quot;Equalized 4QAM --u -0.01&quot;</span>);</span><br><span class="line"><span class="built_in">hold</span> on</span><br><span class="line"></span><br><span class="line">scatterplot(z2);</span><br><span class="line">title(<span class="string">&quot;Equalized 4QAM --u -0.005&quot;</span>);</span><br><span class="line"><span class="built_in">hold</span> on</span><br><span class="line"></span><br><span class="line">scatterplot(z3);</span><br><span class="line">title(<span class="string">&quot;Equalized 4QAM --u -0.001&quot;</span>);</span><br><span class="line"><span class="built_in">hold</span> on</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<h3 id="实验二代码"><a href="#实验二代码" class="headerlink" title="实验二代码"></a>实验二代码</h3><figure class="highlight matlab"><table><tr><td class="code"><pre><span class="line"><span class="comment">% CMA.m</span></span><br><span class="line"><span class="function"><span class="keyword">function</span> <span class="params">[y,epsilon,H_matrix]</span>=<span class="title">CMA</span><span class="params">(x,M,mu)</span></span></span><br><span class="line"><span class="comment">% y: 输出信号</span></span><br><span class="line"><span class="comment">% e: 误差输出 </span></span><br><span class="line"><span class="comment">% w: 最终滤波器系数</span></span><br><span class="line"> </span><br><span class="line"><span class="comment">% 输入参数：</span></span><br><span class="line"><span class="comment">% x: 输入信号</span></span><br><span class="line"><span class="comment">% M：滤波器长度</span></span><br><span class="line"><span class="comment">% mu: 因子</span></span><br><span class="line"></span><br><span class="line"><span class="comment">% FIR 系数</span></span><br><span class="line">H_matrix = <span class="built_in">zeros</span>(<span class="number">1</span>,M);</span><br><span class="line">H_matrix((M+<span class="number">1</span>)/<span class="number">2</span>) = <span class="number">1</span>;<span class="comment">%H_matrix((M+1)/2) = 1;</span></span><br><span class="line"><span class="comment">% 输入向量长度</span></span><br><span class="line">N=<span class="built_in">length</span>(x);</span><br><span class="line"><span class="comment">% 执行CMA</span></span><br><span class="line">m = <span class="number">1</span>;</span><br><span class="line"><span class="keyword">for</span> n = M:<span class="number">2</span>:N </span><br><span class="line">    <span class="comment">% 倒序输入</span></span><br><span class="line">    filter_in = x(n:<span class="number">-1</span>:n-M+<span class="number">1</span>);</span><br><span class="line">    <span class="comment">% 计算输出</span></span><br><span class="line">    y(m) = H_matrix*filter_in;</span><br><span class="line">    <span class="comment">% 误差计算</span></span><br><span class="line">    epsilon(m) = y(m)*(<span class="number">1</span> - <span class="built_in">abs</span>(y(m))^<span class="number">2</span>);</span><br><span class="line">    <span class="comment">% 滤波器系数更新</span></span><br><span class="line">    H_matrix = H_matrix + mu*epsilon(m)*filter_in&#x27;;</span><br><span class="line">    m = m + <span class="number">1</span>;</span><br><span class="line"><span class="keyword">end</span></span><br><span class="line"><span class="keyword">end</span></span><br><span class="line"></span><br><span class="line"><span class="comment">%CMA_OOK.m</span></span><br><span class="line"><span class="comment">% 参数初始化</span></span><br><span class="line">clear all;</span><br><span class="line">clc;</span><br><span class="line">Ts = <span class="number">10e-9</span>; <span class="comment">% 码元周期，以秒为单位，倒数为传输速率</span></span><br><span class="line">N_sample = <span class="number">8</span>; <span class="comment">% 单个码元抽样点数</span></span><br><span class="line">dt = Ts / N_sample; <span class="comment">% 抽样时间间隔</span></span><br><span class="line">N = <span class="number">2</span>^<span class="number">8</span>; <span class="comment">% 码元数</span></span><br><span class="line">t = <span class="number">0</span> : dt : (N * N_sample - <span class="number">1</span>) * dt; <span class="comment">% 序列传输时间</span></span><br><span class="line">dt1 = Ts; <span class="comment">% 抽样时间间隔</span></span><br><span class="line">t1 = <span class="number">0</span> : dt1 : (N<span class="number">-1</span>) * dt1; <span class="comment">% 序列传输时间</span></span><br><span class="line">gt0 = -<span class="built_in">ones</span>(<span class="number">1</span>, N_sample);<span class="comment">% NRZ</span></span><br><span class="line">gt1 = <span class="built_in">ones</span>(<span class="number">1</span>, N_sample); </span><br><span class="line"></span><br><span class="line"><span class="comment">% 生成随机序列</span></span><br><span class="line">RAN = randi([<span class="number">0</span> <span class="number">1</span>],N,<span class="number">1</span>);</span><br><span class="line"><span class="built_in">figure</span>(<span class="number">1</span>);</span><br><span class="line">subplot(<span class="number">5</span>,<span class="number">1</span>,<span class="number">1</span>);</span><br><span class="line"><span class="built_in">plot</span>(t1,RAN);</span><br><span class="line">axis([<span class="number">0</span>,<span class="number">1000</span>*dt,<span class="number">-1.5</span>,<span class="number">1.5</span>]);</span><br><span class="line">title(<span class="string">&#x27;原始随机序列&#x27;</span>);</span><br><span class="line"></span><br><span class="line"><span class="comment">% 8倍过采样序列</span></span><br><span class="line">se1 = [];</span><br><span class="line"><span class="keyword">for</span> <span class="built_in">i</span> = <span class="number">1</span> : N</span><br><span class="line">   <span class="keyword">if</span> RAN(<span class="built_in">i</span>)==<span class="number">1</span></span><br><span class="line">       se1 = [se1 gt1];</span><br><span class="line">   <span class="keyword">else</span></span><br><span class="line">       se1 = [se1 gt0];</span><br><span class="line">   <span class="keyword">end</span></span><br><span class="line"><span class="keyword">end</span></span><br><span class="line">subplot(<span class="number">5</span>,<span class="number">1</span>,<span class="number">2</span>);</span><br><span class="line"><span class="built_in">plot</span>(t,se1);</span><br><span class="line">axis([<span class="number">0</span>,<span class="number">1000</span>*dt,<span class="number">-1.5</span>,<span class="number">1.5</span>]);</span><br><span class="line">title(<span class="string">&#x27;8倍过采样序列&#x27;</span>);</span><br><span class="line"></span><br><span class="line"><span class="comment">% 通过高斯信道</span></span><br><span class="line">noise = <span class="number">0.2</span>*<span class="built_in">randn</span>(<span class="number">1</span>,<span class="built_in">length</span>(se1));</span><br><span class="line">se1_addnoise = se1 + noise;</span><br><span class="line">subplot(<span class="number">5</span>,<span class="number">1</span>,<span class="number">3</span>);</span><br><span class="line"><span class="built_in">plot</span>(t,se1_addnoise);</span><br><span class="line">axis([<span class="number">0</span>,<span class="number">1000</span>*dt,<span class="number">-1.5</span>,<span class="number">1.5</span>]);</span><br><span class="line">title(<span class="string">&#x27;加噪声后序列&#x27;</span>);</span><br><span class="line"></span><br><span class="line"><span class="comment">% 均衡</span></span><br><span class="line">resample_data = se1_addnoise(<span class="number">1</span>:<span class="number">4</span>:<span class="keyword">end</span>); <span class="comment">% 数据降为2倍过采样</span></span><br><span class="line">M = <span class="number">15</span>;</span><br><span class="line">mu = <span class="number">0.001</span>;</span><br><span class="line">R = <span class="number">1</span>;</span><br><span class="line">[y,e,w] = CMA(resample_data&#x27;,M,mu);</span><br><span class="line">subplot(<span class="number">5</span>,<span class="number">1</span>,<span class="number">4</span>);</span><br><span class="line"><span class="built_in">plot</span>(t1(<span class="number">1</span>:<span class="keyword">end</span><span class="number">-7</span>),y);</span><br><span class="line">axis([<span class="number">0</span>,<span class="number">1000</span>*dt,<span class="number">-1.5</span>,<span class="number">1.5</span>]);</span><br><span class="line">title(<span class="string">&#x27;均衡后序列&#x27;</span>);</span><br><span class="line"></span><br><span class="line"><span class="comment">% 判决</span></span><br><span class="line">y(y &gt;= <span class="number">0.5</span>) = <span class="number">1</span>;</span><br><span class="line">y(y &lt;= <span class="number">-0.5</span>) = <span class="number">0</span>;</span><br><span class="line">result = [y RAN(<span class="number">1</span>:N<span class="number">-7</span>)&#x27;];</span><br><span class="line">subplot(<span class="number">5</span>,<span class="number">1</span>,<span class="number">5</span>);</span><br><span class="line"><span class="built_in">plot</span>(t1(<span class="number">1</span>:<span class="keyword">end</span><span class="number">-7</span>),y);</span><br><span class="line">axis([<span class="number">0</span>,<span class="number">1000</span>*dt,<span class="number">-1.5</span>,<span class="number">1.5</span>]);</span><br><span class="line">title(<span class="string">&#x27;判决后序列&#x27;</span>);</span><br></pre></td></tr></table></figure>
]]></content>
      <categories>
        <category>通信技术</category>
        <category>学习记录</category>
      </categories>
      <tags>
        <tag>CMA</tag>
        <tag>自适应均衡</tag>
        <tag>Matlab</tag>
      </tags>
  </entry>
  <entry>
    <title>【文献翻译】使用深度强化学习游玩雅达利游戏</title>
    <url>/2022/07/29/DQN%20%E5%8E%9F%E5%A7%8B%E8%AE%BA%E6%96%87%E7%BF%BB%E8%AF%91/</url>
    <content><![CDATA[<center><h1>摘要</center>

<blockquote>
<p>我们提出首个直接通过传感器高维输入并成功地学习到策略控制的深度学习模型。这个模型的是一个卷积神经网络的结构，它使用Q-learning的变种进行训练，使用远摄关的图片作为输入，输出是预测未来收益的价值。我们将我们的方法运用至Arcade Learning环境中的雅达利2600的七个游戏里，在没有调整算法的结构的条件下，我们发现它在其中六个游戏中取得比之前方法更好的表现，它在其中三个游戏中取得了超越人类专家的表现。</p>
</blockquote>
<span id="more"></span>
<h2 id="引言"><a href="#引言" class="headerlink" title="引言"></a>引言</h2><p>直接从像视觉和语音等高维传感输入信息来学习控制智体一直以来都是强化学习(RL)的一个挑战。大部分成功的RL在这些领域的操作应用都需要依赖人工干预的线性价的值函数或策略函数进行特征提取整合。显然，这些RL算法的表现严重依赖于所选取的特征的质量。</p>
<p>最近深度学习的优势是它能够从原生的传感器数据中提取深层次的特征，并在计算机视觉任务[11,22,16]和语言识别任务[6,7]中取得突破性进展。这些方法使用了一系列的神经网络结构，包括卷积神经网络、多层感知机，受限玻尔兹曼机器和循环神经网络，他们都在监督和无监督学习中得到了应用,这样一来似乎很自然地会思考相似的技术是否能对RL的传感器数据有所帮助。</p>
<p>然而强化学习在从深度学习的观点来看有几个挑战。首先大部分成功的深度学习案例都需要大量的人工标注的训练数据。从另一个方面来说，RL的算法必须要能从量化的奖罚信号中进行学习，而这些奖罚信号通常都是充满噪声、延迟和离散的。执行动作后的以及随之而来的奖罚可能需要等待非常久的时间，在这一点上和有监督学习中的输入与输出的直接关联相比就显得艰难非常。另一个问题是绝大多数的深度学习算法都是基于样本数据之间是独立的这一假设的，但是在强化学习中通常就是状态与状态之间紧密相连，关系复杂。并且，在RL中数据概率分布会随着算法学习到新的行为而随之改变，这对深度学习基于固定概率的条件来说无疑是个的问题。</p>
<p>本文提出了一种可以克服这些挑战以学习到成功的控制策略的卷积神经网络，而它仅需要使用复杂的RL环境中的原生视频数据。这个网络使用了一种Q-learning 的变种算法[26]进行训练，使用随机梯度下降法进行网络参数的更新。为了避免相关数据和概率不变的问题，我们使用了一种经验回放机制[13]，他能够随机地从经验池中抽取这些学习的经验，因此这能平缓训练时对先前学习到的动作分布概率。</p>
<p><img src="https://s2.loli.net/2022/05/26/6w8c9R5T7DOHEBm.gif" alt="img" style="zoom:150%;" /></p>
<p><small>图1  雅达利2600五种游戏的屏幕截图：（从左至右）Pong, Breakout, Space Invaders, Seaquest, Beam Rider</small></p>
<p>我们将我们的方法应用于在Arcade Learning Environment(ALE)[3]中一系列的雅达利2600游戏中。雅达利2600是一个充满挑战性的RL测试平台，它为智体提供了高纬度的视觉输入信息(210*160大小的RGB彩色图像，屏幕刷新率为60Hz)以及为人类设计的苦难但多样有趣的挑战任务。我们的目标是去创建一个单独的神经网络作为智体使它能够成功的学习玩尽可能多的游戏。这个网路并不会被提供任何游戏相关的信息或者人为给定的视觉特征，并且也不能直接读取游戏环境的内存数据，它只能从视觉信息、奖罚西欧马屁、游戏结束信号以及一个可选则的动作空间进行学习，就和人类玩家一样。更进一步，网络结构和所有的超参数将在训练过程中保持不变。目前网络已经在7个中的6个游戏中超越之前的所有强化学习算法的性能，并且在三个游戏中甚至还取得了超越人类专家游玩的水平。图片[1]展示了五个用于训练的游戏截图。</p>
<h2 id="背景"><a href="#背景" class="headerlink" title="背景"></a>背景</h2><p>我们将问题转换为如下场景：智体在环境$\cal \varepsilon$即雅达利2600模拟器中，在每一个时间步中智体从一系列的合法动作集合$\cal A=\{1,…,K\}$中，选取一个动作$a_t$。这个选择的动作将会被传递至模拟器中并更改了游戏的底层交互数据和游戏得分，一般来说$\sf \varepsilon$是随机的。这些底层的交互数据对智体而言不可见，对它而言它只能从模拟器中观测到一张图片$x_t\in X^d$，这张图片其实一个原生的像素值的向量，描绘了当前的模拟器画面。除此之外，智体还会接收到一个奖罚信号$r_t$，代表了游戏的分的变化。注意一般来说游戏分数取决于之前的动作决策序列和观测；关于动作决策的评价反馈可能在决策做出之后的许多时间步之后才得到。</p>
<p>由于智体只能观测到当前屏幕的图片信息，我们的任务只能观测到片面的信息，比如说对于整个游戏当前的状态而言，仅用一张图片$x_t$是很难表述的。因此我们需要考虑动作序列和观测的序列$s_t=x_1,x_2,…,x_{t-1},x_t$，我们将基于这些序列学习游戏的策略。我们认为所有的在模拟器中迭代的序列将在有限的时间步中终止。这种规范化使得我么你的问题变成一个庞大但有限的马尔可夫决策过程（MDP），在这种情况中每一个序列是一个独立的状态。最终，我们可以在马尔科夫链中使用标准的强化学习算法，仅简单地使用完整的状态序列$s_t$作为每一个时间的表征。</p>
<p>​        智体学习的目标是通过选择一个能在未来带来最大化回报的动作，并将这个动作与模拟器交互。我们基于“未来的回报将会随着每一个时间步以一个折扣因子$\gamma$的倍率进行衰减”这一标准的设想，定义未来$t$时刻未来折扣汇报$R_t = \sum_{t’=t}^{T}\gamma^{t’-t}r_{t’}$，其中$T$是终止时的时间步。我们定义一个最优动作-价值函数$Q^{*}$，它表示为在观测一些序列$s$后根据任一策略采取一些动作$a$所期望得到的最大回报值，定义如下：$Q^{*}(s,a)=\max_\pi\Bbb E[R_t|s_t=s,a_t=a,\pi]$，其中$\pi$是一个策略，表述了一个状态到动作的映射的关系（或者状态到动作的概率分布映射）。</p>
<p>​        最优的动作价值函数遵循一个非常的性质，即贝尔曼方程。它基于如下的设想：如果某一状态的最优的动作价值$Q^{*}$在下一个时间步中成为了所有可行动作的参考，那么最优的策略就是选择动作价值最高的动作$a’$以获取最大化的期望值$r+\gamma Q^{*}(s’,a;)$，</p>
<script type="math/tex; mode=display">
Q^{*}(s,a)=\Bbb E_{s'\sim\varepsilon}[r+\gamma \max_{a'}Q^{\*}(s',a')|_{s,a}]</script><p>​        许多强化学习算法的背后逻辑就是找到用于衡量动作价值函数的方法，通过使用贝尔曼方程作为迭代更新，更新的动作价值为$Q_{i+1}(s,a)=\Bbb E[r+\gamma \max_{a’}Q_i(s’,a’)|s,a]$。这种动作价值的迭代算法会依最优的动作价值函数收敛，即当$i\rightarrow\infty$时$Q_i\rightarrow Q^{*}$[23]。在实践中，这种方法是非常不切实际的，因为动作价值函数是会依据每一个状态序列进行独立的估计且不具备泛化能力。因此，我们很自然地会想到用一个近似的函数取拟合动作价值函数，$Q(s,a;\theta)\approx Q^{*}(s,a)$。在强化学习领域常会使用一个线性的函数进行拟合，但是有时一个非线性的函数也会被用于拟合，比如说神经网络。我们参考使用了一个权重为$\theta$的神经网络作为价值评估网络——Q网络。Q网络可以通过最小化变化的每一迭代$i$过程中损失函数序列值$L_i(\theta_i)$来训练：</p>
<script type="math/tex; mode=display">
L_i(\theta_i)=\Bbb E_{s,a\sim \rho(·)}[(y_i-Q(s,a;\theta_i))^2]</script><p>​        其中$y_i=\Bbb E_{s’\sim\varepsilon}[r+\gamma \max_{a’}Q(s’,a;\theta_{i-1})-Q(s,a;\theta_i)|_{s,a}]$是迭代$i$过程中的目标值，$\rho(s,a)$是一个基于所有状态$s$和动作$a$的概率分布，我们称之为行为分布。在前一步的迭代过程中的网络参数$\theta_{i-1}$会在优化损失函数值$L_i(\theta_i)$时被冻结（即不是所有时候都是冻结的），注意到目标值是基于神经网络的参数权重的，这和我们在有监督学习中的目标值有所区别，在监督学习中这个值在学习时一般都是固定住的。我们使用如下的梯度进行损失函数的微分：</p>
<script type="math/tex; mode=display">
\nabla_{\theta_i}L_i(\theta_i)= \Bbb E_{s,a\sim\rho(·);s'\sim\varepsilon}[(r+\gamma\max_{a'}Q(s',a';\theta_{i-1})-Q(s,a;\theta_i))\nabla_{\theta_i}Q(s,a;\theta_i)]</script><p>​        比起按上述公式的梯度计算完整的期望值，我们通常使用随机梯度下降方法进行计算以优化损失。如果权重在每一个时间步根据行为分布$\rho$、模拟器环境$\varepsilon$的单个样本替换期望继续宁更新，那么我们就得到了熟悉的Q-learning算法了[26]。</p>
<p>​        注意到这是个model-free的算法，即它通过直接使用模拟器的环境$\varepsilon$抽样解决强化学习的问题，但不需要针对这个模拟器的环境$\varepsilon$进行建模和估计。同时它也是off-policy的，也就是说它会学习一个贪心的策略 $a=max_aQ(s,a;\theta)$同时也会以一定恰当的概率分布对状态空间进行探索。在实践中，我们一般使用贪心$\epsilon$策略，即使用$1-\epsilon$的概率使用决策的动作输出，以概率$\epsilon$选择一个随机的动作。</p>
<h2 id="相关工作"><a href="#相关工作" class="headerlink" title="相关工作"></a>相关工作</h2><p>​        也许强化学习中的最广为人知的成功故事是IBM 的 Gerald Tesauro 开发的一个玩西洋双陆棋戏的程序——TD-gammom ，也即一个通过强化学习自学如何下棋的神经网络，并获得了超越人类水平的成绩[24]。TD-gammom使用了一个model-free的和Q-learning近似的强化学习算法，使用一个多个的隐藏层的网络用于感知特征以拟合价值函数。</p>
<p>​        然而早期在尝试复现TD-gammom的时候，包括尝试在棋类游戏中使用相同的算法时，围棋和跳棋的效果就不如人意了。这就引来了一阵关于TD-gammom的方法是一个只能在双陆棋得到应用的成功特例的说法，也许是因为投骰子的随机性对状态空间的探索提供了帮助并且也使得它的价值函数尤其平缓顺滑[19]。</p>
<p>更进一步说，model-free的强化学习算法比如Q-learning使用了非线性函数进行动作价值函数的拟合[25]，也许off-policy的学习方式确实会导致Q网络的发散的情况[1]。这些争议与讨论带来的就是强化学习的主要理论工作转移到了线性函数的拟合以获取更好的收敛性和收敛的保障[25]。</p>
<p>​        最近，深度学习和强化学习的结合的趋势再次复苏。深度神经网络已经被应用于评估环境$\varepsilon$，受限玻尔兹曼机也被用于拟合价值函数[21]或者行为决策[9]。除此之外，最近梯度时分差分的方法的提出为Q-learning的发散问题带来了部分条件下的解决的方案。这些方法被证明当使用一个固定的用非线性函数拟合的策略可以保证模型的收敛[14]，或者可以使用一个受限的Q-learning的变种方法[15]用线性函数学习拟合一个控制策略，然而这些方法都没扩展至非线性的控制问题上。</p>
<p>​        也许之前和我们方法最接近的方法就是使用神经拟合Q-learning（NFQ）[20]，它使用公式2的损失函数进行优化，并且使用RPROP算法进行Q网络的参数更新。然而，它在每一个迭代计算的基于使用依据数据集大小的代价进行批量更新，因此我们认为随机梯度更新在每一个迭代过程中的大规模数据集中计算的代价将会是一个非常小的常数。NFQ同样被成功应用于简单的真实世界控制任务，而且也是使用简单的树蕨输入，首先通过自动笔爱你吗其去歇息低维度的任务表征，然后将NFQ应用于该表征中进行控制[12]。与之对比，我们的方法是一个端到端的强化学习过程，直接以视觉作为输入，结果也显示这种方法一样能通过动作价值函数的评价直接学习到特征。Q-learning在之前也被应用于结合了经验回放机制和简单的神经网络[13]中，但其输入也是基于低维度的状态而不是原始的视觉信息输入。</p>
<p>​        使用雅达利2600模拟器作为强化学习平台是参考了Marc G Bellemare[3]等的论文，他们将线性函数拟合和普通视觉信息输入应用在强化学习算法中。然后，实验的结果在后续使用更多特征和tug-of-war散列法随机映射至低维空间中的方法的改进后得到提升[2]。HyperNEAT进化架构[8]也被应用于Atari平台，用来（分别针对每款不同的游戏）形成一个表示游戏策略的神经网络。 当用模拟器的重置机制来与确定性序列做反复对抗训练时，我们发现这些策略可以利用几款Atari游戏中的设计缺陷。</p>
<h2 id="深度强化学习"><a href="#深度强化学习" class="headerlink" title="深度强化学习"></a>深度强化学习</h2><p>​        计算机视觉和语音识别领域最近取得的一些突破，靠的就是可以在大型训练集上高效地训练深度神经网络。 其中最成功的方法是通过使用基于随机梯度下降的轻量级更新，直接用原始输入进行训练。向深度神经网络输入足够多的数据，这样常常可以学习到比人工生成的特征更好的表征[11]。 这些成功案例为我们的强化学习方法提供了启发。我们的目标是将强化学习算法与深度神经网络对接起来，这里所说的神经网络可以直接学习RGB图像，并通过使用随机梯度更新来有效地处理训练数据。</p>
<p>​        Tesauro的TD-Gammon架构为这种方法提供了一个起点。该架构利用算法与环境的直接交互（或通过自玩，西洋双陆棋）产生的策略性经验样本$(s_t,a_t,r_t,s_{t+1},a_{t+1})$，对价值函数估计网络的参数进行更新。由于该算法在20年前能超越了水平最高的人类西洋双陆棋玩家，所以我们想知道，二十年的硬件改进以及现代深度神经网络架构和可扩展RL算法是否能让强化学习实现重大进展。</p>
<p>​        不同于TD-Gammon和类似的在线方法，我们使用了一种叫做“经验回放”[13]的方法：将智体在每个时间步长$e_t=(s_t,a_t,r_t,s_{t+1})$上的经验储存在数据集$\cal D=e_1,…,e_N,$中，将许多episode的经验汇集至经验池中。在算法进行内部循环时，我们将Q-learning算法更新或小批量更新应用于经验样本$\cal e\sim\cal D$，这些样本是从经验池中随机抽取的。 执行经验回放后，智体根据$\epsilon$贪心策略选择动作决策。由于用任意长度的历史表征作为神经网络的输入较难实现，所以我们的Q函数使用的是函数$\phi$生成的固定长度的历史表征。 算法1给出了完整的算法流程，我们将之称为深度Q-learning算法。</p>
<p><img src="https://s2.loli.net/2022/05/26/AoOKdq4CNsDGiPu.png" alt="image-20220526094753105"></p>
<p>​        </p>
<p>这种方法和标准的online Q-learning相比有几个优点[23]。受限，每一步的经验都可能会在许多网络权重更新中起作用，数据的有效性大幅增加。其次由于样本之间存在很强的相关性，直接学习连续样本效率很低；随机化样本会破坏这些相关性，减少更新的方差。第三，当学习策略时，当前的参数确定用于训练参数的下一数据样本。举个例子，如果最大化动作是向左移动，训练样本将由左侧的样本主导;如果最大化动作切换到右边，训练数据分布也会切换到右边。很容易看出，这样可能会产生不必要的反馈循环，并且参数也可能会被困在局部最小值，甚至发生严重的发散[25]。通过使用经验回放，在先前状态下的行为分布就会得到变得均匀，这样学习过程就会变得平缓化，并参数也不会出现振荡或发散。需要指出，当使用经验池抽取经验进行学习时off-policy的方法的学习非常有必要（因为我们当前的参数和产生经验使用的参数不同），这就启发了我们使用Q-learning。</p>
<p>​        在实践中，我们的算法仅在经验池中存储最后N个经验元组，并且在执行更新时均匀地从D中随机采样。 这种方法在某些方面有一定局限，因为存储缓冲器并不区分重要的经验；而且由于存储容量N有限，存储缓冲器总是用最新的转移重写记忆。同样，均匀采样使得回放记忆中的所有转移具有相等的重要性。 更复杂的抽样策略可能会强调可以提供最多信息的转换，类似于优先扫除[17] 。</p>
<h3 id="预处理和模型结构"><a href="#预处理和模型结构" class="headerlink" title="预处理和模型结构"></a>预处理和模型结构</h3><p>​    直接使用原始的Atari框架（128色的210×160像素图像）可能在计算上要求很高，所以我们应用了一个基本的预处理步骤来减少输入维数。进行预处理时，首先将原始帧的RGB图像表示转换成灰度图像，并将其下采样成110×84图像。通过从图像上裁剪一个可以大致捕获到游戏区域的的84×84画面，获得最终的输入表征。 然后进行最后的裁剪，因为我们使用的是Alex等提出的的2D卷积GPU实现[11]，需要方形的输入图像。在该论文的实验中，算法1的函数$\phi$将该预处理过程应用于历史记忆的最后4帧，并将它们叠加以生成Q函数的输入。</p>
<p>​    用神经网络参数化Q函数的方法有许多种。 由于Q函数可以将历史动作对映射到其Q值的标量估计上，所以先前的一些的方法可以将历史和动作作为神经网络的输入[20,12]。 这类架构的主要缺点是需要单独进行一次前向传递来计算每个动作的Q值，这样会导致计算成本与动作数呈正比。 在我们使用的架构中，其中每个可能的动作都对应一个单独的输出单元，神经网络的输入只有状态表征。 输出则对应于输入状态的单个动作的预测Q值。 这类架构的主要优点是只需进行一遍前进传递，就可以计算某一给定状态下所有可能动作的Q值。 </p>
<p>​    下面我们将描述七个Atari游戏所使用的架构。 神经网络的输入是由$\phi$产生的84×84×4图像。 第一个隐藏层用16个步长（stride）为4的8×8卷积核与输入图像进行卷积， 并使用非线性的激活函数ReLU函数[10,18]。 第二个隐层用32个步长为2的4×4卷积核进行卷积，应用同样的非线性激活函数ReLU函数。最后一个隐层为完全连接层，由256个激活函数单元组成。输出层是一个线性的完全连接层，每个有效的动作对应一个输出。在我们研究的游戏中，有效动作的数量在4到18之间变化。我们把用该方法训练的卷积网络称为深度Q网络（DQN）。</p>
<h2 id="实验"><a href="#实验" class="headerlink" title="实验"></a>实验</h2><p>​        截至目前，我们用7款流行的ATARI游戏进行了试验——Beam Rider、Breakout、Enduro、Pong、Q*bert、Seaquest和Space Invader。在这7款游戏中，我们使用相同的网络架构、学习算法和超参数设置，以证明我们的方法还是能够在不获取特定游戏信息的条件下成功应用于多种游戏中。当在真实且未改动的游戏中对智体进行评估时，我们在训练期间只对游戏的奖励机制作出了一个改变。由于各游戏的得分范围大不相同，我们将所有正奖励都设定为1，将所有负奖励设定为-1，无变化情况设为0奖励。这样的奖励设置可以限制误差范围，便于在多种游戏中使用同一学习率。同时，该奖励机制还会影响智体的表现，因为它无法区分不同大小的奖励。</p>
<p>​        在这些试验中，我们使用的是mini batch大小为32的RMSProp算法。训练中的行为策略为：ϵ-greedy的ϵ在前100万帧从1 线性下降到0.1，然后保持在0.1不变。我们共训练了100万帧，并使用了最近100万帧的回放记忆。</p>
<p>​        在按照前文中的方法玩Atari游戏时，我们还使用了一种简单的跳帧技巧[3]。更确切地说，智体在每隔k帧而不是在每一帧观察并选择动作，在跳过的帧中则重复它的最后一个动作。由于模拟器向前运行一步需要的计算量少于智体选择一个动作的计算量，这种方法可以使智体在不大幅增加运行时间的情况下将游戏次数增加约k倍。除了Space Invader这款游戏，我们在其他游戏中都将k设为4，如果在这款游戏中将k设为4，就会看不见激光，因为跳过的帧与激光闪烁的时长相重叠。将k设定为3就可以看到激光，k值的改变就是不同游戏间的唯一超参数差异。</p>
<h3 id="训练和稳定性"><a href="#训练和稳定性" class="headerlink" title="训练和稳定性"></a>训练和稳定性</h3><p>​        在监督学习中，通过使用训练集和验证集评估模型，我们可以轻易地追踪模型在训练期间的性能。但是在强化学习中，在训练期间准确评估智体的性能可能会十分困难。如Marc G Bellemare所述[3]，我们的评估指标是在若干游戏中智体在某一episode或游戏中得到的总奖励的平均值。而且我们在训练中周期性地计算该指标。总奖励均值指标往往很嘈杂，因为权重的小小改变可能会导致策略访问的状态的分布发生很大的变化。图2中最左侧的两个线图显示了总奖励均值在游戏Seapuest和Breakout的训练期间是如何变化的。这两个总奖励均值线图确实很嘈杂，给人的印象是学习算法的运行不稳定。</p>
<p><img src="https://s2.loli.net/2022/05/26/uqRvEcmjGKDf9h5.png" alt="image-20220526095121441"></p>
<p><small>图2：  左边两图分别展示了训练时Breakout和Seaquest每回合的平均奖励值。数据是使用$\varepsilon=0.05$的$\varepsilon -greedy$策略在运行10000步计算得到的。右图的两图则分别展示了Breakout和Seaquest部分状态下的平均最大的动作价值。大约每三十分钟每一个回合约有50000条抽样数据用于更新</small></p>
<p><img src="https://s2.loli.net/2022/05/26/Qr4Mp86NOykVTxL.png" alt="image-20220526100408551"></p>
<p><small>图3  最左端的图表展示了Seaquest的30帧数据预测的价值函数。三张屏幕截图分别对应图表中的A，B，C三个时刻。</small></p>
<p>​        右侧的两个线图则较为稳定，指标是指策略的预估动作分值函数Q，该函数的作用是预测在任何给定状态下智体遵循其策略所能获得的惩罚后的奖励。我们在训练开始前运行某一随机策略，收集固定数量的状态，并追踪这些状态的最大预测Q值的均值。从图2最右侧的两个线图可以看出，预测平均Q值的增加趋势要比智体获得的总奖励的均值平缓得多，其余5个游戏的平均Q值的增长曲线也很平缓。除了预测Q值在训练期间有较为平缓的增长，我们在试验中未发现任何发散问题。这表明，除了缺乏理论上的收敛保证，我们的方法能够使用强化学习信合和随机梯度下滑以稳定的方式训练大型神经网络。</p>
<h3 id="可视化和价值函数"><a href="#可视化和价值函数" class="headerlink" title="可视化和价值函数"></a>可视化和价值函数</h3><p>​        图3给出了游戏Seaquest中学到的价值函数的可视化形式。从图中可以看出，当屏幕左侧出现敌人后预测值出现跳跃（点A）。然后代理想敌人发射鱼雷，当鱼雷快要集中敌人时预测值达到最高点（点B）。最后当敌人消失后预测值差不多恢复到原始值（点C）。图3表明我们的方法能够在较为复杂一系列的事件中学习价值函数的变化方式。</p>
<h3 id="主要的评估"><a href="#主要的评估" class="headerlink" title="主要的评估"></a>主要的评估</h3><p>​        我们将我们的结果与Marc中提出的方法进行了比较。该方法被称为“Sarsa”，Sarsa算法借助为Atari任务人工设计的多个特征集来学习线性策略，我们在[3,,4]中给出了表现最佳的特征集的得分[3]。Contingency算法的基本思路和Sarsa法相同，但是该方法可以通过学习智体控制范围内的屏幕区域的表征，来增强特征集[4]。需要指出，这两种方法都通过背景差分法吸纳了大量关于计算机视觉问题的知识，并将128种颜色中的每种颜色都作为一个单独的通道。由于许多Atari游戏中每种类型的目标所用的颜色通常都各不相同，将每种颜色作为一个单独的通道，这种做法类似于生成一个单独的二元映射，对每种目标类型进行编码。相比之下，我们的代理只接收原始RGB屏幕截图输入，并且必须学习自行检测目标。</p>
<p>​        除了给出学习代理（learned agents）的得分，我们还给出了人类专业游戏玩家的得分，以及一种均匀地随机选择动作的策略。人类玩家的表现将表示为玩了两小时游戏后得到的奖励中值。需要指出，我们给出的人类玩家的得分要比Bellemare等人[3]论文中给出的得分高得多。至于学习方法，我们遵循的是Bellemare等人的论文==[3,5]==中使用的评估策略，并且我们还通过将$\epsilon$设定为0.05运行 ε 贪心策略来获得固定步数的平均得分。表1的前5行给出了所有游戏的各游戏平均得分。在这7款游戏中，我们的方法（标记为DQN）虽然没有吸纳任何关于输入的先验知识，结果还是大幅超越了其他学习方法.。</p>
<p>​        我们同样将文献[8]中的策略搜索方法囊括进表格的后三行进行比较，并做出了两组使用该方法的结果。HNeat Best 的得分反映了通过使用人工标注的目标检测法现实游戏物体位置和类型.HNeat Pixel的得分反映的是使用特定的8种颜色通道代表雅达利游戏模拟器的特定物体类型。这两种方法依赖于确定的状态序列且不存在随机的扰动，因此与其他方法对比时对比的是单个会和下的最佳表现。相反的，我们的算法是在贪心$\epsilon$策略下进行评估的，因此必须对所有可能的情况进行归一化。然而，我们发现在所有展示的游戏中，除了Space Invaders这款游戏不单是我们算法的最优表现还是我们的平均表现都能达到一个相对较好的效果。</p>
<p><img src="https://s2.loli.net/2022/05/26/aZeD57p8KGwxCWk.png" alt="image-20220526100647570"></p>
<p><small>表1  上端的表格对比了使用贪心值为0.0.5的$\varepsilon-greedy$的不同学习方式平均总奖励。下端的表格展示了HNeat和DQN在单个回合中最佳表现分数。HNeat做出确定性策略与DQN使用$\varepsilon-greedy$的效果相同。</small></p>
<p>​        最终我们发现我们的方法在Breakout，Enduro和Pong这三款游戏中达到了超越人类专家水平的水准，并且在Beam Rider种取得了与人类水平相近的成绩。Q*bert，Seaquest，Space Invaders这三款游戏我们依然与人类专家水平相比有较大的差距，但它充满了挑战性，因为他们需要网络找到一个从更长远的时间层面上考察的策略。</p>
<h2 id="结论"><a href="#结论" class="headerlink" title="结论"></a>结论</h2><p>​        本文介绍了一种新的强化学习的深度学习模型，并通过在雅达利2600游戏中证明了其对困难游戏的控制能力，而它仅需要原始的像素信息作为输入。我们同时也展示了一种结合了随机批量更新和经验回放机制Q-learning的变种算法来降低训练强化学习中的深度神经网络难度。我们的方法在七个测试的游戏中的六个取得SOTA成果，并且没有调整过超参数和网络模型结构。</p>
<h2 id="参考文献"><a href="#参考文献" class="headerlink" title="参考文献"></a>参考文献</h2><p>[1] Leemon Baird. Residual algorithms: Reinforcement learning with function approximation. In <em>Proceedings of the 12th International Conference on Machine Learning (ICML 1995)</em>, pages 30–37. Morgan Kaufmann, 1995.</p>
<p>[2] Marc Bellemare, Joel Veness, and Michael Bowling. Sketch-based linear value function ap- proximation. In <em>Advances in Neural Information Processing Systems 25</em>, pages 2222–2230, 2012.</p>
<p>[3] Marc G Bellemare, Yavar Naddaf, Joel Veness, and Michael Bowling. The arcade learning environment: An evaluation platform for general agents. <em>Journal of Artificial Intelligence</em> <em>Research</em>, 47:253–279, 2013.</p>
<p>[4] Marc G Bellemare, Joel Veness, and Michael Bowling. Investigating contingency awareness using atari 2600 games. In <em>AAAI</em>, 2012.</p>
<p>[5] Marc G. Bellemare, Joel Veness, and Michael Bowling. Bayesian learning of recursively fac- tored environments. In <em>Proceedings of the Thirtieth International Conference on Machine</em> <em>Learning</em> <em>(ICML</em> <em>2013)</em>, pages 1211–1219, 2013.</p>
<p>[6] George E. Dahl, Dong Yu, Li Deng, and Alex Acero. Context-dependent pre-trained deep neural networks for large-vocabulary speech recognition. <em>Audio, Speech, and Language Pro-</em> <em>cessing,</em> <em>IEEE</em> <em>Transactions</em> <em>on</em>, 20(1):30 –42, January 2012.</p>
<p>[7] Alex Graves, Abdel-rahman Mohamed, and Geoffrey E. Hinton. Speech recognition with deep recurrent neural networks. In <em>Proc.</em> <em>ICASSP</em>, 2013.</p>
<p>[8] Matthew Hausknecht, Risto Miikkulainen, and Peter Stone. A neuro-evolution approach to general atari game playing. 2013.</p>
<p>[9] Nicolas Heess, David Silver, and Yee Whye Teh. Actor-critic reinforcement learning with energy-based policies. In <em>European</em> <em>Workshop</em> <em>on</em> <em>Reinforcement</em> <em>Learning</em>, page 43, 2012.</p>
<p>[10] Kevin Jarrett, Koray Kavukcuoglu, MarcAurelio Ranzato, and Yann LeCun. What is the best multi-stage architecture for object recognition? In <em>Proc. International Conference on Com-</em> <em>puter</em> <em>Vision</em> <em>and</em> <em>Pattern</em> <em>Recognition</em> <em>(CVPR</em> <em>2009)</em>, pages 2146–2153. IEEE, 2009.</p>
<p>[11] Alex Krizhevsky, Ilya Sutskever, and Geoff Hinton. Imagenet classification with deep con- volutional neural networks. In <em>Advances in Neural Information Processing Systems 25</em>, pages 1106–1114, 2012.</p>
<p>[12] Sascha Lange and Martin Riedmiller. Deep auto-encoder neural networks in reinforcement learning. In <em>Neural Networks (IJCNN), The 2010 International Joint Conference on</em>, pages 1–8. IEEE, 2010.</p>
<p>[13] Long-Ji Lin. Reinforcement learning for robots using neural networks. Technical report, DTIC Document, 1993.</p>
<p>[14] Hamid Maei, Csaba Szepesvari, Shalabh Bhatnagar, Doina Precup, David Silver, and Rich Sutton. Convergent Temporal-Difference Learning with Arbitrary Smooth Function Approxi- mation. In <em>Advances</em> <em>in</em> <em>Neural</em> <em>Information</em> <em>Processing</em> <em>Systems</em> <em>22</em>, pages 1204–1212, 2009.</p>
<p>[15] Hamid Maei, Csaba Szepesva´ri, Shalabh Bhatnagar, and Richard S. Sutton. Toward off-policy learning control with function approximation. In <em>Proceedings of the 27th International Con-</em> <em>ference</em> <em>on</em> <em>Machine</em> <em>Learning</em> <em>(ICML</em> <em>2010)</em>, pages 719–726, 2010.</p>
<p>[16] Volodymyr Mnih. <em>Machine Learning for Aerial Image Labeling</em>. PhD thesis, University of Toronto, 2013.</p>
<p>[17] Andrew Moore and Chris Atkeson. Prioritized sweeping: Reinforcement learning with less data and less real time. <em>Machine</em> <em>Learning</em>, 13:103–130, 1993.</p>
<p>[18] Vinod Nair and Geoffrey E Hinton. Rectified linear units improve restricted boltzmann ma- chines. In <em>Proceedings of the 27th International Conference on Machine Learning (ICML</em> <em>2010)</em>, pages 807–814, 2010.</p>
<p>[19] Jordan B. Pollack and Alan D. Blair. Why did td-gammon work. In <em>Advances in Neural</em> <em>Information</em> <em>Processing</em> <em>Systems</em> <em>9</em>, pages 10–16, 1996.</p>
<p>[20] Martin Riedmiller. Neural fitted q iteration–first experiences with a data efficient neural re- inforcement learning method. In <em>Machine Learning: ECML 2005</em>, pages 317–328. Springer, 2005.</p>
<p>[21] Brian Sallans and Geoffrey E. Hinton. Reinforcement learning with factored states and actions.</p>
<p><em>Journal</em> <em>of</em> <em>Machine</em> <em>Learning</em> <em>Research</em>, 5:1063–1088, 2004.</p>
<p>[22] Pierre Sermanet, Koray Kavukcuoglu, Soumith Chintala, and Yann LeCun. Pedestrian de- tection with unsupervised multi-stage feature learning. In <em>Proc. International Conference on</em> <em>Computer</em> <em>Vision</em> <em>and</em> <em>Pattern</em> <em>Recognition</em> <em>(CVPR</em> <em>2013)</em>. IEEE, 2013.</p>
<p>[23] Richard Sutton and Andrew Barto. <em>Reinforcement Learning:</em> <em>An Introduction</em>. MIT Press, 1998.</p>
<p>[24] Gerald Tesauro. Temporal difference learning and td-gammon. <em>Communications of the ACM</em>, 38(3):58–68, 1995.</p>
<p>[25] John N Tsitsiklis and Benjamin Van Roy. An analysis of temporal-difference learning with function approximation. <em>Automatic</em> <em>Control,</em> <em>IEEE</em> <em>Transactions</em> <em>on</em>, 42(5):674–690, 1997.</p>
<p>[26] Christopher JCH Watkins and Peter Dayan. Q-learning. <em>Machine learning</em>, 8(3-4):279–292, 1992.</p>
]]></content>
      <categories>
        <category>强化学习</category>
        <category>文献翻译</category>
      </categories>
      <tags>
        <tag>强化学习</tag>
        <tag>文献翻译</tag>
      </tags>
  </entry>
  <entry>
    <title>Street Fighter vs. DQN Fighter</title>
    <url>/2022/07/29/DQN%E8%87%AA%E6%88%91%E5%AE%9E%E8%B7%B5/</url>
    <content><![CDATA[<h2 id="Introduction"><a href="#Introduction" class="headerlink" title="Introduction"></a>Introduction</h2><p>I would like to apply an improved DQN to the Game Street Fighter V, an action game published by CAPCOM in 2016. This project was inspired by LinYi and I try to use DQN without HPE(Human Pose Estimation) due to the limitation of my hardware.</p>
<p><img src="https://s2.loli.net/2022/05/27/DSw9adIUvW3q86K.png" style="zoom:67%;" /></p>
<p>I try to train a model with less time training and more robust to any other Acion fighting game. This may be cool and difficult since I need to prepare my exam while handling other projects in this very year. </p>
<span id="more"></span>
<h2 id="Preparing"><a href="#Preparing" class="headerlink" title="Preparing"></a>Preparing</h2><h3 id="Before-we-start"><a href="#Before-we-start" class="headerlink" title="Before we start"></a>Before we start</h3><p>We need access to some in-game factors that help game agent better comprehend the situation(Though these factors are simply shown in the screen,I would like to use in-game memory to get which is faster and relieve GPU’s burden if use CV method to convert these images’ info).</p>
<p><img src="https://i.loli.net/2021/09/08/84P5qBKMUWn6JLb.png" alt="image-20210908230408019" style="zoom: 67%;" /></p>
<p>However,CAPCOM use anti-spam to block the access to read memory while the game runs,which may crash the game if you turn some basic memory search tools like <code>CheatEngine</code>.I use this <a href="https://bbs.pediy.com/thread-195729.htm">Tool</a> to avoid detection and it actually works!(By the way ,the unzip code is <code>qq295991</code>).</p>
<p>In addition,you should open the software before you launch the game,and change the default settings to this:</p>
<p><img src="https://i.loli.net/2021/09/08/sGI6nJjkTADOZbd.png" alt="image-20210908230121851" style="zoom: 80%;" /></p>
<p>Then you can search the factors you need and locate their base&amp;offset address.</p>
<p><img src="https://i.loli.net/2021/09/08/13NdY7S6WtCLczw.png" alt="image-20210908230121851" style="zoom: 80%;" /></p>
<p>The Following Problem is that when I use <code>openProcess</code> in <code>win32api</code> to get value of the factors it returns the error like this:</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">Traceback (most recent call last):</span><br><span class="line">  File <span class="string">&quot;G:/SFV/Tool/factors.py&quot;</span>, line <span class="number">180</span>, <span class="keyword">in</span> &lt;module&gt;</span><br><span class="line">    hp = Gamefactors()</span><br><span class="line">  File <span class="string">&quot;G:/SFV/Tool/factors.py&quot;</span>, line <span class="number">55</span>, <span class="keyword">in</span> __init__</span><br><span class="line">    hProcess = win32api.OpenProcess(</span><br><span class="line">pywintypes.error: (<span class="number">5</span>, <span class="string">&#x27;OpenProcess&#x27;</span>, <span class="string">&#x27;Access Denied.&#x27;</span>)</span><br></pre></td></tr></table></figure>
<p>It really takes me a long time to find the solution:( I look up the MSDN and find this:</p>
<blockquote>
<p>If the caller has enabled the SeDebugPrivilege privilege, the requested access is granted regardless of the contents of the security descriptor.</p>
</blockquote>
<p>Which means I need the <code>SeDebugPrivilege</code> huh…So I write a function to get more privileges:</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">get_extra_privs</span>():  <span class="comment"># get more access to the game</span></span><br><span class="line">    <span class="comment"># Try to give ourselves some extra privs (only works if we&#x27;re admin):</span></span><br><span class="line">    <span class="comment"># SeBackupPrivilege   - so we can read anything</span></span><br><span class="line">    <span class="comment"># SeDebugPrivilege    - so we can find out about other processes (otherwise OpenProcess will fail for some)</span></span><br><span class="line">    <span class="comment"># SeSecurityPrivilege - ??? what does this do?</span></span><br><span class="line"></span><br><span class="line">    th = win32security.OpenProcessToken(win32api.GetCurrentProcess(),</span><br><span class="line">                                        win32con.TOKEN_ADJUST_PRIVILEGES | win32con.TOKEN_QUERY)</span><br><span class="line">    privs = win32security.GetTokenInformation(th, win32security.TokenPrivileges)</span><br><span class="line">    newprivs = []</span><br><span class="line">    <span class="keyword">for</span> privtuple <span class="keyword">in</span> privs:</span><br><span class="line">        <span class="keyword">if</span> privtuple[<span class="number">0</span>] == win32security.LookupPrivilegeValue(<span class="literal">None</span>, <span class="string">&quot;SeBackupPrivilege&quot;</span>) <span class="keyword">or</span> privtuple[</span><br><span class="line">            <span class="number">0</span>] == win32security.LookupPrivilegeValue(<span class="literal">None</span>, <span class="string">&quot;SeDebugPrivilege&quot;</span>) <span class="keyword">or</span> privtuple[</span><br><span class="line">            <span class="number">0</span>] == win32security.LookupPrivilegeValue(<span class="literal">None</span>, <span class="string">&quot;SeSecurityPrivilege&quot;</span>):</span><br><span class="line">            <span class="comment"># print(&quot;Added privilege &quot; + str(privtuple[0]))</span></span><br><span class="line">            newprivs.append((privtuple[<span class="number">0</span>], <span class="number">2</span>))  <span class="comment"># SE_PRIVILEGE_ENABLED</span></span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            newprivs.append((privtuple[<span class="number">0</span>], privtuple[<span class="number">1</span>]))</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Adjust privs</span></span><br><span class="line">    privs = <span class="built_in">tuple</span>(newprivs)</span><br><span class="line">    win32security.AdjustTokenPrivileges(th, <span class="literal">False</span>, privs)</span><br></pre></td></tr></table></figure>
<p> Now we need to access these factors: </p>
<ul>
<li>Player&amp;Rival’s HP</li>
<li>Player&amp;Rival’s EX</li>
<li>Player&amp;Rival’s VT</li>
<li>Player&amp;Rival’s location</li>
</ul>
<p>Yet we need to notice that player’s &amp; rival’s location are not in float type while HPs are in normal byte type, so we need a function to transfer Byte type to Float type:</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">byte2Float</span>(<span class="params">s</span>):  <span class="comment"># Convert byte to float</span></span><br><span class="line">    <span class="keyword">try</span>:</span><br><span class="line">        i = <span class="built_in">int</span>(s, <span class="number">10</span>)  <span class="comment"># convert from Dec to a Python int</span></span><br><span class="line">        cp = pointer(c_int(i))  <span class="comment"># make this into a c integer</span></span><br><span class="line">        fp = cast(cp, POINTER(c_float))  <span class="comment"># cast the int pointer to a float pointer</span></span><br><span class="line">        a = fp.contents.value</span><br><span class="line">    <span class="keyword">except</span>:</span><br><span class="line">        a = <span class="number">0</span></span><br><span class="line">    <span class="keyword">finally</span>:</span><br><span class="line">        <span class="keyword">return</span> a</span><br></pre></td></tr></table></figure>
<h3 id="Why-not-define-a-class"><a href="#Why-not-define-a-class" class="headerlink" title="Why not define a class?"></a>Why not define a class?</h3><p>We can add function to this class to reduce the time spent on accessing these factors:</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">Hp_getter</span>():</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self</span>):</span><br><span class="line">        get_extra_privs()</span><br><span class="line">        hd = win32gui.FindWindow(<span class="literal">None</span>, <span class="string">&quot;StreetFighterV&quot;</span>)</span><br><span class="line">        pid = win32process.GetWindowThreadProcessId(hd)[<span class="number">1</span>]</span><br><span class="line">        self.process_handle = win32api.OpenProcess(<span class="number">0x1F0FFF</span>, <span class="literal">False</span>, pid)</span><br><span class="line">        self.kernal32 = ctypes.windll.LoadLibrary(<span class="string">r&quot;C:\\Windows\\System32\\kernel32.dll&quot;</span>)</span><br><span class="line"></span><br><span class="line">        self.hx = <span class="number">0</span></span><br><span class="line">        <span class="comment"># get dll address</span></span><br><span class="line">        hProcess = Kernel32.OpenProcess(</span><br><span class="line">            PROCESS_QUERY_INFORMATION | PROCESS_VM_READ,</span><br><span class="line">            <span class="literal">False</span>, pid)</span><br><span class="line">        hModule = EnumProcessModulesEx(hProcess)</span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> hModule:</span><br><span class="line">            temp = win32process.GetModuleFileNameEx(self.process_handle, i.value)</span><br><span class="line">            <span class="keyword">if</span> temp[-<span class="number">18</span>:] == <span class="string">&quot;StreetFighterV.exe&quot;</span>:</span><br><span class="line">                self.StreetFighter=i.value</span><br><span class="line">                <span class="built_in">print</span>(self.StreetFighter)</span><br></pre></td></tr></table></figure>
<p>And by the way no thanks:</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">EnumProcessModulesEx</span>(<span class="params">hProcess</span>):</span><br><span class="line">    buf_count = <span class="number">256</span></span><br><span class="line">    <span class="keyword">while</span> <span class="literal">True</span>:</span><br><span class="line">        LIST_MODULES_ALL = <span class="number">0x03</span></span><br><span class="line">        buf = (ctypes.wintypes.HMODULE * buf_count)()</span><br><span class="line">        buf_size = ctypes.sizeof(buf)</span><br><span class="line">        needed = ctypes.wintypes.DWORD()</span><br><span class="line">        <span class="keyword">if</span> <span class="keyword">not</span> Psapi.EnumProcessModulesEx(hProcess, ctypes.byref(buf), buf_size, ctypes.byref(needed),</span><br><span class="line">                                          LIST_MODULES_ALL):</span><br><span class="line">            <span class="keyword">raise</span> OSError(<span class="string">&#x27;EnumProcessModulesEx failed&#x27;</span>)</span><br><span class="line">        <span class="keyword">if</span> buf_size &lt; needed.value:</span><br><span class="line">            buf_count = needed.value // (buf_size // buf_count)</span><br><span class="line">            <span class="keyword">continue</span></span><br><span class="line">        count = needed.value // (buf_size // buf_count)</span><br><span class="line">        <span class="keyword">return</span> <span class="built_in">map</span>(ctypes.wintypes.HMODULE, buf[:count])</span><br></pre></td></tr></table></figure>
]]></content>
      <categories>
        <category>强化学习</category>
        <category>游戏智能</category>
      </categories>
      <tags>
        <tag>强化学习</tag>
        <tag>街头霸王</tag>
        <tag>DQN</tag>
      </tags>
  </entry>
  <entry>
    <title>D2D通信中的网络编码技术调查</title>
    <url>/2022/11/14/D2D%E7%BD%91%E7%BB%9C%E7%BC%96%E7%A0%81/</url>
    <content><![CDATA[<h1 id="D2D通信中的网络编码技术调查"><a href="#D2D通信中的网络编码技术调查" class="headerlink" title="D2D通信中的网络编码技术调查"></a>D2D通信中的网络编码技术调查</h1><h2 id="引言"><a href="#引言" class="headerlink" title="引言"></a>引言</h2><p>当今的通信技术更迭已经来到了第五代，在这一时期通信的场景更加复杂，数据更加庞大，种类更加广泛。如何在频谱资源有限的情况下提高无线通信系统的性能是当前无线通信的热门研究方向。D2D(Device to Device)通信技术被视作5G通信中可以降低延迟、提高网络吞吐量并且扩大网络覆盖范围的重要技术，标准化组织3GPP已经将其列入新一代移动通信系统的发展框架中，并称为第五代移动通信的关键技术之一。D2D同通信依靠通信网络中相邻设备之间的链路进行直接的信息交互。一旦D2D通信链路建立，信息的流动就无需再经过核心设备或中间设备的干预与处理而是直接进行交互，从而大幅降低核心网络的压力并提高网络吞吐量与频谱利用率，使大规模的网络可以更为灵活、智能、高效地运行。然而随着通信技术的发展，通信业务的服务需求激增对一种覆盖范围更广的通信范式，传统的单跳D2D通信不再能够支撑起海量的服务需求了，因为两个设备之间的通信距离相当有限。为了解决这一问题，多跳的D2D通信机制在扩大通信范围上取得了良好的表现。</p>
<span id="more"></span>
<p>另一值得关注的技术——网络编码，也被认为是能提升网络吞吐量、降低传输延迟以及扩大通信覆盖范围的关键技术。尽管网络编码提出伊始以及后续相关工作是基于有线网络进行的，但网络编码的思想同样可以在无线通信领域中进行理论的研究与应用的探索。不同于传统的通信网络，网络编码在每一个通信网节点做的工作不是“存储-转发”，而是“计算-转发”。这种“计算”是为了减少传输数据包时的数据重复冗余而进行的，图1给出了使用网络编码技术在D2D通信中的一个简易示例。</p>
<p><img src="https://s2.loli.net/2022/11/12/iKLfgYqtHz6FmUC.png" alt="image-20221112150921219" style="zoom:50%;" /></p>
<p>图中的三台设备A，B，C都需要通过gNodeB从服务器中下载视频。假设视频的帧数据由四个数据包组成$\mathbb P=\{p_1,p_2,p_3,p_4\}$并使用$H$表示设备收到的帧，$W$表示设备接收失败需要重新获取的帧。图中的设备A中，$H_A=\{p_2,p_3,p_4\}$即表示设备A成功接收到了数据包$p_2,p_3,p_4$，丢失了数据包$p_1$；假如没有使用网络编码技术，三台设备一共缺失了3个数据包，因此服务器一共需要分别给三台设备发送3个数据包；然而如果使用网络编码技术后，仅需要传输两个数据包即可：设备A传输编码后的已有数据$p_2\oplus p_3 \oplus p_4$到设备B和设备C处；设备C传输编码后的已有数据$p_1 \oplus p_3 \oplus p_4$到设备A和设备B。设备B中仅靠来自设备C和设备A的编码数据通过异或操作即可得到缺失的数据$p_3$，此时服务器仅需向设备A传输数据$p_2$以及向设备C传输$p_1$通过异或操作即可复原出缺失的数据包。可见，通过网络编码可以减少传输过程中的信令回传同时也保障了数据的传输。</p>
<p>在上述的例子中，D2D网络中的各个设备可作为通信网络中的节点，不但可以对已有数据进行编码亦可对新到达的数据包进行编码，这一机制可以因编码带来的延迟。举个例子，假如网络中的某一节点一轮需要接受40个数据包，每一个包达到的间隔是25ms，那么第一轮传输时需要耗时1秒等待所有包到达才可进行编码、发送编码数据包；但是在第二轮传输时，在收到第一个包后即可使用已有的第一轮的40个包缓存进行编码传送数据。这一方法同时还能提高通信的安全性，因为在一个多跳的D2D通信场景中，每一个节点接收到的信息都是经过编码的，对比部分节点存储了原始信息的情况，网络编码可以提高通信系统的安全性。</p>
<p>与蓝牙、WiFi、ZigBee等近距离通信技术相比，D2D通信的主要优势在于蜂窝授权频谱的使用，通信双方之间的距离增加后还能同时保证用户体验质量，而这是其他常用的近距离通信技术不具备的，即使用这些技术不能保障距离增加时的通信质量。D2D通信与其他近距离通信技术的性能对比如表所示。</p>
<p>综上所述，多跳的D2D技术与网络编码技术的结合在无线通信的系统中性能提升起到重要作用。</p>
<h2 id="技术介绍"><a href="#技术介绍" class="headerlink" title="技术介绍"></a>技术介绍</h2><h3 id="多跳D2D技术"><a href="#多跳D2D技术" class="headerlink" title="多跳D2D技术"></a>多跳D2D技术</h3><p>D2D通信也称为终端直连通信，它是两个对等的用户节点直接通信的一种方式，于2008年由高通高斯在IMT-A workshop会议首次提出。在由D2D通信终端组成的分布式网络中，用户节点同时扮演客户端与服务器的角色，他们互相之间能彼此感知对方的存在并收发信号。</p>
<p>然而，当D2D通信终端在通信过程中因信号覆盖问题发生通信中断时，如果重新接入蜂窝网络则需要向基站发送繁琐的信令，并重新等待分配无线频谱资源，这一过程无疑严重影响了通信质量。因此为增大D2D通信网络覆盖范围，可采用基于中继辅助的多跳D2D通信，通过多跳连接增大D2D通信覆盖区域以降低D2D通信的终端概率，增加通信系统的可靠性。</p>
<p>多跳的含义在于使用多个中继节点进行信号的传递以扩大通信覆盖范围。在现实场景下，由于所处环境的不规则以及地理位置的复杂性，单跳的D2D可能无法帮助处于信号覆盖盲区的用户接入网络，但如果使用多个中继节点进行信息数据的传递，是可以将处于信号盲区的用户接入网络的，如==图==所示。</p>
<p><img src="https://s2.loli.net/2022/11/14/fdARvNhZ1Ib2Eac.png" style="zoom: 50%;" /></p>
<p>实际上，多跳的通信方式在商用领域进行了探索，日本的任天堂公司旗下的游戏机Nintendo Switch在均衡位于云端的服务器压力时也会让用户设备承担部分的数据转发业务以提升近距离的多人联机游戏的体验。</p>
<p>这种多跳的D2D通信是D2D技术的延伸拓展，尽管它组成的网络与无线自组织网络的网络拓扑结构类似，但在本质上有许多区别。多跳D2D通信系统中的通信链路可以复用蜂窝网络用户的频谱资源，在蜂窝用户占用频谱资源的同时D2D用户也可以利用该频谱资源传输数据，基于此提高频谱增益，扩大系统容量；自组织网络智能独占频谱资源，不能复用蜂窝频谱因此不能带来频谱增益；同时多跳D2D可以通过其他设施（比如基站）辅助通信，进行通信会话的建立、无线频谱资源的分配等，而自组织网络没有设施辅助也没有控制中心，其网络结构中的所有节点地位平等。</p>
<h3 id="网络编码技术"><a href="#网络编码技术" class="headerlink" title="网络编码技术"></a>网络编码技术</h3><p>长久以来网络通信采用的“存储-转发”完成信息的传输，但信息存储复制的过程对设备资源占用较大，且对信息处理的效率低；直到网络编码这一技术于二十世纪末兴起并开始在通信的各个领域进行探索，传统的信息传输方式得以提升。作为一种在宽带无线通信的新技术，网络编码可以让通信网络中的中间节点对接收信息进行编码并发送出去，其编码方式基于有限域相关理论，提升了网络吞吐量于网络的鲁棒性，使多播网络可达最大容量。现阶段的网络编码技术主要有物理层网络编码、模拟网络编码、随机线性网络编码、及时解码网络编码几种。本文主要介绍一种常用的随机线性网络编码（RLNC）技术。</p>
<p>随机线性网络编码技术核心是利用节点的运算能力，在节点发送多个信息包的线性编码组合，在接收节点得到足够的线性编码组合后，通过运算获得原始信息包。假设要对有$P$个原始信息包$X_1,X_2,\dots,X_P$的数据进行随机线性网络编码，编码后的结果为$C_1$:</p>
<script type="math/tex; mode=display">
C_1 = [\xi_{1,1},\xi_{1,2},\dots,\xi_{1,P}]
\begin {bmatrix}
X_1\\X_2\\\vdots\\X_P
\end {bmatrix}</script><p>其中，$[\xi_{1,1},\xi_{1,2},\dots,\xi_{1,P}]$为随机线性网络编码的编码矩阵，矩阵的每一元素均随机从有限域$\mathbb F$中抽取，随后编码系数按==图==所示与已编码数据共同组成传输的数据包。</p>
<p><img src="https://s2.loli.net/2022/11/14/KoSqJDvtTnUeWcN.png" alt="image-20221114102907486" style="zoom: 25%;" /></p>
<p>当有$P$个节点接收原始数据包时，有：</p>
<script type="math/tex; mode=display">
\begin{bmatrix}
C_1\\C_2\\\vdots\\C_p
\end{bmatrix}
=
\begin{bmatrix}
\xi_{1,1}&\xi_{1,2}&\dots  &\xi_{1,P}\\
\xi_{2,1}&\xi_{2,2}&\dots  &\xi_{2,P}\\
\vdots   &\vdots   &\ddots &\vdots   \\
\xi_{P,1}&\xi_{P:,2}&\dots  &\xi_{P,P}
\end{bmatrix}
\begin{bmatrix}
X_1\\X_2\\\vdots\\X_P
\end{bmatrix}</script><p>与上文提及的例子不同之处在于，节点发送的编码的权重$\xi_{i,j}$不再是确定的有限域元素，而是随机的有限域元素，这些随机选择的元素也会随着编码组合一同发送出去。在接收节点处收到若干编码组合后，通过线性运算即可还原出原始的信息包。对于一个RLNC编码数据包的译码，需要其编码矩阵满秩才可保证编码结果可译。对于一个$P\times P$的RLNC编码矩阵，由于是随机从有限域$GF(q)$中选取元素作为矩阵的元素，因此编码矩阵满秩的概率为：</p>
<script type="math/tex; mode=display">
\prod_{i=0}^{P-1} (1-q^{i-P})</script><p>当传输的包数量较大时，在传输$N=P+4$个包的时候，基本认为该矩阵满秩，从而保证了数据安全性的同时也可在接收端的可解性。</p>
<h2 id="多跳D2D通信系统建模"><a href="#多跳D2D通信系统建模" class="headerlink" title="多跳D2D通信系统建模"></a>多跳D2D通信系统建模</h2><h3 id="多跳D2D通信系统框架"><a href="#多跳D2D通信系统框架" class="headerlink" title="多跳D2D通信系统框架"></a>多跳D2D通信系统框架</h3><p>针对多跳D2D通信系统建立系统模型如图所示。单个蜂窝小区内，gNodeB管理蜂窝小区的频谱资源，CUE（Cellular User Equipment）通过蜂窝链路接入gNodeB，DU1和DU2是需要信息交互的两个用户，他们通过D2D链路进行通信。由于两个终端设备距离较远，直连的D2D链路可靠性低，通过中继用户建立多跳D2D链路完成二者的信息交互。中继组(Relay Group)是由协助DU1和DU2建立多跳通信的多个空闲用户组成的，负责转发DU1和DU2的数据包，他们与DU1，DU2的数据交互均通过D2D链路完成。</p>
<p>当 D2D 用户复用蜂窝下行资源进行通信时，D2D 通信会对蜂窝用户产生干扰， 会严重影响蜂窝用户的通信体验。同时，D2D 通信接收端也会收到来自基站信号的干扰，因为基站的发射功率远远大于 D2D 用户发射信号功率，整个通信系统会受到严重的干扰。当 D2D 用户复用蜂窝上行资源进行通信时，蜂窝用户向基站发送信号的同时，D2D 发送端向 D2D 接收端发送数据。此时，D2D 发送端发送的信号会对基站产生干扰，而蜂窝用户不会受到干扰，蜂窝用户发送的信号会对 D2D 接收端产生干扰。因为基站能够控制蜂窝通信和 D2D 通信，基站通过限制蜂窝用户的最大发送功率使其对 D2D 用户造成的干扰处于可接受范围内。因此，当 D2D 用户复用上行资源进行通信时，系统受到的干扰处于可控范围中。多跳D2D通信会话建立过程如==图==所示。</p>
<p><img src="https://s2.loli.net/2022/11/14/5hGxuUXzWSp361J.png" style="zoom: 67%;" /></p>
<h3 id="多跳D2D通信过程"><a href="#多跳D2D通信过程" class="headerlink" title="多跳D2D通信过程"></a>多跳D2D通信过程</h3><p>在多跳 D2D 数据传输过程中，中继在转发数据包时，不同于传统的存储转发策略，采用网络编码技术对数据包编码转发在增强数据安全性的同时，更能节省数据传输次数，提高频谱利用率。随机线性网络编码（RLNC）根据有限域上的矩阵运算对数据包进行处理，通过矩阵求逆运算解码数据包。节点在根据 RLNC 进行编码时并不需要了解具体的网络拓扑，只对已缓存的数据包进行线性组合即可生成新的编码包，在转发时将随机编码系数矩阵和编码包一起发送出去。下面分析==图 3.1 和图 3.2 所示==系统模型的具体通信过程，DU1 和 DU2 的每一轮的信息交换都分两个阶段完成，每一轮结束后都重复进行这两个通信阶段，直至 DU1 和 DU2 通信结束。</p>
<p>第一个通信阶段中，DU1和DU2分别在第一个和第二个时隙向中继组用户广播自己的数据包，每一个中继用户组用户都维护一个用于缓存接收状态的列表，中继用户$R_k$如果成功收到来自DU1发来的第$i$个数据包时，将对应的接收状态更新为1，否则置为0；对于DU2也同理。假设中继用户$R_k$在第$t$轮通信中成功收到了$m_t$个来自DU1的数据包以及$n_t$个来自DU2的数据包，编码时从有限域$GF(2^m)$中选取元素构成编码矩阵$M_k=\begin{bmatrix}b_{11}&amp;\dots&amp; b_{1m_t+n_t}\\\vdots&amp;\ddots&amp;\vdots\\b_{n1}&amp;\dots&amp; b_{nm_t+n_t}\end{bmatrix}$，以完成对$m_t+n_t$个数据进行编码得到编码包$\{p_1,p_2,\dots,p_n\}$。记为编码包矩阵为$P_{raw}^T=[p_1^1,\dots,p_{m_t}^1,p_1^2,\dots,p_{n_t}^2]^T$，则形成的新编码包$P_{en}^T$为：</p>
<script type="math/tex; mode=display">
\begin{aligned}
P_{en}^T &= M_k P_{raw}^T\\
         &= \begin{bmatrix}b_{11}&\dots& b_{1m_t+n_t}\\\vdots&\ddots&\vdots\\b_{n1}&\dots& b_{nm_t+n_t}\end{bmatrix}
         \begin{bmatrix}p_1^1\dots p_{m_t}^1p_1^2 \dots p_{n_t}^2\end{bmatrix}^T\\
         & = \begin{bmatrix}p_1p_2\dots p_n\end{bmatrix}^T

\end{aligned}</script><p>由于 DU1 和 DU2 复用上行蜂窝频谱，这个通信阶段的 D2D 通信不会对蜂窝 用户 CUE 产生干扰，gNodeB 会受到 D2D 通信的干扰，同时 CUE 与 gNodeB 之间的通信会对 RG 产生干扰，==文献[46]==中的干扰控制算法可以保证蜂窝通信和 D2D 通信能正常通信。</p>
<p>在第二个通信阶段，中继组 中每个中继用户在不同时隙内将自己的编码包和编码系数通过 D2D 链路广播给 DU1 和 DU2，只要 DU1 和 DU2 接收 的编码包的系数矩阵达到满秩，就可以通过==式(3.2)==成功解码得到期望的数据包，完成当前这一轮 DU1 和 DU2 的通信。</p>
<script type="math/tex; mode=display">
\begin{aligned}
P_{raw}^T &= M_k^{-1} P_{en}^T\\
         &= \begin{bmatrix}b_{11}&\dots& b_{1m_t+n_t}\\\vdots&\ddots&\vdots\\b_{n1}&\dots& b_{nm_t+n_t}\end{bmatrix}^{-1}
         \begin{bmatrix}p_1p_2\dots p_n\end{bmatrix}^T\\
         & = \begin{bmatrix}p_1^1 \dots p_{m_t}^1 p_1^2 \dots p_{n_t}^2\end{bmatrix}^T

\end{aligned}</script><p>在第二个通信阶段，RG 中的用户会对 gNodeB 产生叠加干扰，而 DU1 和 DU2 会收到来自 CUE 的干扰信号。</p>
<h3 id="多跳D2D中继策略选择"><a href="#多跳D2D中继策略选择" class="headerlink" title="多跳D2D中继策略选择"></a>多跳D2D中继策略选择</h3><p>在上节的多跳D2D通信过程可以看出，多跳D2D通信系统对中继节点的性能依赖非常高，其性能直接影响整个多跳D2D通信系统。为了提高通信系统的性能，主要从降低中继次数以降低传输时延、整个系统的能耗以及带宽资源。==文献==给出了一种基于预期传输次数最小原则下的多跳D2D通信中继选择策略，将向gNodeB发送中继的空闲用户加入到集合中。然而这个集合的元素即空闲用户的选择不是全部选择，而是依据空闲用户对提升服务的终端的吞吐量的选择的,过多的中继不但会增加系统能耗，甚至还会造成带宽资源的浪费以及过多转发相同数据的冗余，而中继策略就是选择最少的中继个数使得 DU1 和 DU2 获得最大的吞吐量。每个中继用户要对收到的数据包利用随机线性网络编码进行编码，然后向 DU1 和 DU2 发送编码后的数据包。DU1 和 DU2 收到每个中继发送的数据包后，通过解码可以计算出这一轮数据传输的吞吐量。DU1 和 DU2 根据每一个中继在该轮通信中对系统吞吐量的影响，判断该中继是否为有效中继。具体过程如下：</p>
<ol>
<li>gNodeB基站根据式确定中继集合：<script type="math/tex; mode=display">
\begin{cases}
d_{SD}\geq d\\
d_{SR_i}\leq d\\
d_{R_iD}\leq d
\end{cases}</script></li>
</ol>
<p>   其中，$d$是最大的D2D通信距离，$R_i$是中继集合中的用户，$d_{SR_i}$是DU1到中继用户$R_i$的距离，$d_{R_iD}$为$R_i$到DU2的距离。</p>
<ol>
<li><p>根据式至式计算DU1到$R_i$，DU2到$R_i$、$R_i$到RU1以及$R_i$到DU2的预期传输次数：</p>
<script type="math/tex; mode=display">
\begin{equation}
ETX_{i1}=\frac{1}{1-p_{SR_i}}
\end{equation}\\

\begin{equation}
ETX_{i2}=\frac{1}{1-p_{DR_i}}
\end{equation}

\begin{equation}
ETX_{i3}=\frac{1}{1-p_{R_iS}}
\end{equation}

\begin{equation}
ETX_{i4}=\frac{1}{1-p_{R_iD}}
\end{equation}</script><p>其中，$p_{SR_i},p_{DR_i},p_{R_iS},p_{R_iD}$分别为DU1到中继用户$R_i$、DU2到$R_i$、$R_i$到RU1以及$R_i$到DU2通信链路的丢包率。</p>
</li>
<li><p>对2.中结果进行求和，并对每一个中继用户进行2中的运算后，筛选满足式的中继节点加入集合$A$中：</p>
<script type="math/tex; mode=display">
ETX_i\leq \delta</script><p>其中，$\delta$为完成通信最小预期的传输次数。</p>
</li>
<li><p>得到中继节点集合后，根据每一个节点的$ETX$计算值对集合进行降序排列得到$\Omega=A^{ETX}$，令$c_1^t$和$c_2^t$分别为第$t$轮中DU1和DU2解码后的信息量。针对用户DU1，判断有效性的方法如下：</p>
<ol>
<li>若$c_{1/R_i}^t &lt; c_1^t$，则$R_i^{ETX}$为有效中继且$\Omega=A^{ETX}$</li>
<li>若$c_{1/R_i}^t = c_1^t$，则$R_i^{ETX}$为无效中继且$\Omega=A_{/R_i}^{ETX}$</li>
</ol>
<p>其中，$c_{1/R_i}^t$是将$R_i^{ETX}$从集合$A$中移除后的DU1可解码信息量，$\Omega=A_{/R_i}^{ETX}$为从集合$A$中移除中继$R_i^{ETX}$。</p>
<p>针对DU2，判断有效性的方法如下：</p>
<ol>
<li>若$c_{2/R_i}^t &lt; c_2^t$，则$R_i^{ETX}$为有效中继且$\Omega=A^{ETX}$</li>
<li>若$c_{2/R_i}^t = c_2^t$，则$R_i^{ETX}$为无效中继且$\Omega=A_{/R_i}^{ETX}$</li>
</ol>
<p>其中，$c_{2/R_i}^t$是将$R_i^{ETX}$从集合$A$中移除后的DU2可解码信息量，$\Omega=A_{/R_i}^{ETX}$为从集合$A$中移除中继$R_i^{ETX}$。为降低运算复杂度，中继选择过程在第一轮通信结束后进行，经过判断后将判断结果反馈至中继用户组中的中继用户，中继用户只要收到一个或以上的有效信息则继续保留在中继组中，否则推出中继组。</p>
</li>
<li><p>若中继$R_i^{ETX}$对DU1和DU2来说均为无效中继，则该中继在下一轮通信中移除中继组不再参与数据转发；若对DU1和DU2来说中继$R_i^{ETX}$是有效的，那么可保留该中继用户至D2D通信结束。</p>
</li>
</ol>
<h2 id="多跳D2D通信系统性能分析"><a href="#多跳D2D通信系统性能分析" class="headerlink" title="多跳D2D通信系统性能分析"></a>多跳D2D通信系统性能分析</h2><p>上节介绍了D2D多跳通信系统的运行流程以及中继策略选择的过程，本节将继续对该系统进行性能分析。假设DU1与DU2到$R_i^{ETX}$的数据传输速率为$R_{R_i1},R_{R_i1}$，$P$为用户发射功率，$N$为高斯白噪声功率，$I$为邻居小区和蜂窝用户CUE产生的干扰功率均值。由香农公式$R=B\log_2(1+\gamma)$，其中$\gamma =\frac{P}{N+I}$，为通信系统的信噪比。可知在第一个通信阶段的单位时隙内，中继用户$R_i^{ETX}$的可编码信息量为：</p>
<script type="math/tex; mode=display">
r_i=\max \{R_{R_i1},R_{2R_i}\}</script><p>第二个通信阶段，DU1和DU2接收速率为：</p>
<script type="math/tex; mode=display">
r_1=\min\{R_{R_i1},r_i\}\\
r_2=\min\{R_{R_i2},r_i\}</script><p>则在第$t$轮通信后，DU1和DU2可解码得到的信息量分别为：</p>
<script type="math/tex; mode=display">
c_1^t = \sum_ir_1t\\
c_2^t = \sum_i r_2t</script><p>对于双向的多跳D2D通信，如果使用传统的存储转发方式，需要4个时隙才可完成通信（发送方发送到中间节点、中间节点再转发占用两个时隙，双向通信再将这个时隙数乘二），而使用随机线性网络编码方式仅需使用3个时隙，在中间节点可以同时转发接收发送方和接收方的信息以减少一次到中间节点的时隙。==图==给出了网络编码对提升多跳D2D通信系统容量的性能，可见网络编码可明显提升D2D通信的系统容量。</p>
<p><img src="https://s2.loli.net/2022/11/14/tIQiZqwSoY5XfcG.png" style="zoom:67%;" /></p>
<p>==图==是在编码域为$GF(2^8)$ 和$GF(2^3)$时，在不同的链路丢包率情况下，DU1 解码吞吐量的仿真结果。仿真环境共有5个节点，包含2个终端节点DU1和DU2以及三个中继节点；网络中共有1000个缓存数据包，每10个数据包组成一个分代，即通过随机系数将10个数据包及逆行线性组合形成一个编码包，每一个分代设置一个冗余的数据包，因此网络编码率为0.9。</p>
<p><img src="https://s2.loli.net/2022/11/14/rW8zpBEAs5lVt3g.png" style="zoom:67%;" /></p>
<p>可见选择的有限域越大，编码系数的无关性越强，解码吞吐量越大。 </p>
<p>==等==给出了随机线性网络编码与即时译码网络编码在D2D通信系统中的应用性能对比，如==图==所示。</p>
<p><img src="https://s2.loli.net/2022/11/14/kCYJ1KHrIEU7Wjs.png" style="zoom:67%;" /></p>
<p>从图中可看出，设备端到端的损失概率随着使用网络编码技术可以大幅地降低，并且使用线性网络编码对D2D通信系统的端到端之间的损失降低效果更为显著，因此在D2D通信中使用RLNC是更有效的，==同时==也给出了两种网络编码技术的编/解码效率对比，如==图==所示。</p>
<p><img src="https://s2.loli.net/2022/11/14/UKW4J6oOMbtgm8c.png" style="zoom: 50%;" /></p>
<p><img src="https://s2.loli.net/2022/11/14/UBMlNqQm4bXCTWR.png" style="zoom:50%;" /></p>
<p>可见尽管RLNC对信息的编解码消耗时间更久，但与IDNC编码在小数量包传输时几乎无太大差异；并且在解码过程中，RLNC的解码效率是更优于IDNC的。因此，RLNC更适合作为D2D通信的网络编码技术。</p>
<h2 id="总结与展望"><a href="#总结与展望" class="headerlink" title="总结与展望"></a>总结与展望</h2><p>D2D通信技术使得常见的用户终端设备可作为一般通信系统的中间节点对传输的数据进行处理，降低了传统通信对中间节点的硬件设施门槛，使得“万物互联”更进一步；而随之而来的海量数据无疑是一个巨大的挑战，网络编码技术通过在每个节点对数据进行编码重组可以大量降低冗余以提升通信系统的性能，且其依赖节点的编码这一核心思想很好地适配D2D技术。本文主要调查了多跳D2D技术与随机线性网络编码技术的结合，通过调研相关文献以及研究成果发现使用随机线性网络编码与多跳D2D通信能大幅改善一般D2D通信的丢包情况，同时也增加了系统的容量使得数据能在用户终端之间更好地传输。</p>
<p>然而多跳D2D的技术与随机线性网络编码技术还是有一定问题需要解决。首先是中继策略选择的问题，本文介绍的中继策略是基于预期传输次数最小原则下的选择策略，然而这种策略在面对需要高可靠通信时的效果可能就表现一般，如灾区临时搭建用于广播救灾信息相关的通信系统依靠这种中继策略可能导致部分用户的接收无法保障；其次，假若能平衡可靠性与有效性后，随机线性网络编码技术在传输过程中的参数选择也是一个需要考虑的指标。考虑到中继设备在进入第5代移动通信后不再是通信设备厂商提供的专用设备而可以是不同的用户终端设备，需要对不同中继设备的硬件性能进行编解码的参数、有限域大小等的选择。</p>
<p>综上所述，D2D技术与网络编码技术的结合无疑会为未来的移动通信网络带来巨大便利，但依然还有一段很长的路要走。</p>
]]></content>
      <categories>
        <category>学习记录</category>
        <category>网络编码</category>
      </categories>
      <tags>
        <tag>D2D通信</tag>
        <tag>RLNC</tag>
        <tag>网络编码</tag>
        <tag>5G</tag>
      </tags>
  </entry>
  <entry>
    <title>Polar码编码及SC译码Matlab仿真</title>
    <url>/2022/07/29/G1831/</url>
    <content><![CDATA[<p>2016年11月18日，在美国内华达州里诺召开的3GPP RAN1 #87次会议，确定Polar Code作为5G eMBB（增强移动宽带）场景下控制信道编码方案。极化码具有确定性的构造方法，并且是已知的唯一一种能够被严格证明“达到”信道容量的信道编码方法，因此我们将其作为研究对象，研究其编码/译码的实现。</p>
<p><img src="https://s2.loli.net/2022/05/27/t4Gi5PnegJYhRkv.png" alt=""></p>
<span id="more"></span>
<h1 id="研究讨论"><a href="#研究讨论" class="headerlink" title="研究讨论"></a>研究讨论</h1><h3 id="研究现状"><a href="#研究现状" class="headerlink" title="研究现状"></a>研究现状</h3><p>在针对时延扩展较长的信道时，频域选择性严重衰落，会出现残留冗余造成带宽浪费，通过采用以信源状态转移关系为基础构建信源信道联合译码网格图，综合信源转移概率和信道转移概率计算统一的序列后验概率的方式，可以实现了信源译码和信道译码的一体化联合优化，进而在不降低通信速率的情况下提高传输可靠性，基本实现无误码通信。不仅如此，在对6G$^{[1]}$的展望中，消除冗余的Polar码仍具有较LDPC码更优的BER性能，对于高阶调制的Polar码和多核Polar码设计也处于研究阶段，但纠错性能有一定的局限性，因此，具有较高纠错性能的多核Polar码的设计仍在发展中，也许成功的研究会应用于6G的信道编码技术。不过本次我们的仿真旨在理解Polar Code的基础原理，因此采用最基础的原始理论进行编写。</p>
<h3 id="研究意义"><a href="#研究意义" class="headerlink" title="研究意义"></a>研究意义</h3><p>作为一种新兴的码种，极化码在推出之时就获得学术界的广泛关注。它是第一个能达到香农极限的编码方式，因此在推动通信系统的性能发展中有不可限量的应用前途。作为通信系的学生，尝试研读、复现论文成果一来能锻炼科研的理解能力、实践能力，同时也能从中汲取到通信这一学科的前沿知识，能获得较高的实用价值。极化码的编码、译码是极化码的核心部分，也是小组成员拟研究的方向。</p>
<h3 id="研究计划"><a href="#研究计划" class="headerlink" title="研究计划"></a>研究计划</h3><ul>
<li>研读极化码的原始论文《Channel polarization: A method for constructing capacity-achieving codes for symmetric binary-input memoryless channels》，掌握信道极化的思想以及编码/译码思路；</li>
<li>在Matlab中搭建仿真平台，完成极化码编码、译码实现；</li>
<li>对比其他编码方式以及译码方式，对极化码实用性进行评估，并针对仿真结果，对编码译码方式进行考量并做出评价。</li>
</ul>
<h2 id="实现过程"><a href="#实现过程" class="headerlink" title="实现过程"></a>实现过程</h2><h3 id="编码部分"><a href="#编码部分" class="headerlink" title="编码部分"></a>编码部分</h3><h4 id="编码原理"><a href="#编码原理" class="headerlink" title="编码原理"></a>编码原理</h4><p>Polar Code是通过引入信道极化概念而构建的。</p>
<p>信道极化分为两个阶段，分别是信道联合和信道分裂。通过信道的联合与分裂，各个子信道的对称容量将呈现两级分化的趋势：随着码长（即联合信道数）N的增加，一部分子信道的容量趋于1，而其余子信道的容量趋于0。Polar Code正是利用这一信道极化的现象，在容量趋于1的K个子信道上传输消息比特，在其余子信道上传输冻结比特（即收发双方已知的固定比特，通常设置为全零）。由此构成的编码即为Polar Code，码率为$K/N$。</p>
<p>可以看出，编码问题的关键在于生成矩阵和信息位、冻结位的判决选取。最终的编码输出结果，可以简化为矩阵运算：</p>
<script type="math/tex; mode=display">
u^N=c_{i}^N·G_N</script><p>其中，$u^N$代表编码结果，$c_{i}^N$代表了输入数据，$G_N$为生成矩阵，$N$代表输入码长，且该值规定为2的正整数幂。</p>
<h4 id="生成矩阵的产生"><a href="#生成矩阵的产生" class="headerlink" title="生成矩阵的产生"></a>生成矩阵的产生</h4><p>首先先引入<strong>克罗内克积($\otimes$)</strong>运算：</p>
<p> 如果<em>A</em>是一个<em>m</em>×<em>n</em>的矩阵，而<em>B</em>是一个<em>p</em>×<em>q</em>的矩阵，则它们的克罗内克积则是一个<em>mp</em>×<em>nq</em>的分块矩阵，记为：</p>
<script type="math/tex; mode=display">
\mathrm{A} \otimes \mathrm{B}=\left[\begin{array}{ccc}
a_{11} B & \cdots & a_{1 n} B \\
\vdots & \ddots & \vdots \\
a_{1 n} B & \cdots & a_{n n} B
\end{array}\right]</script><p>以下举A，B为二阶矩阵时运算克罗内克积为例：</p>
<script type="math/tex; mode=display">
\left[\begin{array}{ll}
a_{11} & a_{12} \\
a_{21} & a_{22}
\end{array}\right] \otimes\left[\begin{array}{ll}
b_{11} & b_{12} \\
b_{21} & b_{22}
\end{array}\right]=\left[\begin{array}{llll}
a_{11} b_{11} & a_{11} b_{12} & a_{12} b_{11} & a_{12} b_{12} \\
a_{11} b_{21} & a_{11} b_{22} & a_{12} b_{21} & a_{12} b_{22} \\
a_{21} b_{11} & a_{21} b_{12} & a_{22} b_{11} & a_{22} b_{12} \\
a_{21} b_{21} & a_{21} b_{22} & a_{22} b_{21} & a_{22} b_{22}
\end{array}\right]</script><p>下图为文献$^{[1]}$中的编码示意图：</p>
<p><img src="https://i.loli.net/2021/09/03/sohiuSG6P1JtvKw.png" alt="image-20210903221730402" style="zoom: 80%;" /></p>
<p>该过程可以简化为如下流程：</p>
<p>首先输入的码字经过了向量元素的重排操作，即通过图中的$R_N$矩阵相乘运算，然后将翻转后的码字经过信道进行联合、分裂。</p>
<p>同时，也可以将整个生成矩阵的产生过程可以简化为如下运算：</p>
<script type="math/tex; mode=display">
G_{N}=B_{N} F^{\otimes n}</script><p>下面对该表达式进行说明：</p>
<ul>
<li><p>$B_N$为元素经过扩展重排后的结果，定义为：</p>
<script type="math/tex; mode=display">
B_{N}=R_{N}\left(I_{2} \otimes B_{N / 2}\right)</script><p>其中：</p>
<ul>
<li><p>$I_2$为二阶单位矩阵。从定义式可以看出，$B_N$的生成为一递归过程，给定递归初值为$B_2=I_2$。</p>
</li>
<li><p>$R_N$为置换矩阵，即将输入序列完成奇序元素和偶序元素的分离。用符号表示为：</p>
<script type="math/tex; mode=display">
\left(u_{1}, u_{2}, u_{3}, u_{4}, \cdots, u_{N}\right) \times R_{N}=u_{1}, u_{3}, u_{5}, \cdots, u_{N-1}, u_{2}, u_{4}, u_{6}, \cdots, u_{N}</script></li>
</ul>
<p>经过上述操作后，$B_N$完成了比特反序重排。即将每个原序列的十进制序号$i \in\{1,2,3,…,N\}$先减一得到$i-1$，再将$i-1$按二进制表示，随后将该二进制的高低位进行倒叙排列，将得到的一串二进制重新转化为十进制数$j-1$，然后将第$j$位对应的数变成原来的第$i$位数。以元素$u_7$举例如下：</p>
<script type="math/tex; mode=display">
u_{7} \stackrel{7-1}{\longrightarrow} u_{6} \stackrel{\text { 十进制转二进制 }}{\longrightarrow} 110 \stackrel{\text { reverse }}{\longrightarrow} 011 \stackrel{\text { 二进制转十进制 }}{\longrightarrow} 3 \stackrel{3 * 1}{\rightarrow} 4 \rightarrow u_7^*=u_{4}</script><p>其他元素可依次依照此流程重新排序，这里不再赘述。</p>
</li>
<li><p>$F^{\otimes n}$为F的n次克罗内克积,即对矩阵$F$进行n次克罗内克积运算。文献$^{[1]}$中给出的$F$矩阵定义为：</p>
</li>
</ul>
<script type="math/tex; mode=display">
F=\left[\begin{array}{ll}
1 & 0 \\
1 & 1
\end{array}\right]</script><h4 id="信息位与冻结位的选取"><a href="#信息位与冻结位的选取" class="headerlink" title="信息位与冻结位的选取"></a>信息位与冻结位的选取</h4><p>信道极化过程中，有一部分信道的信道容量$I(W)$可以到达1，另一部分则趋近于0。引入文献$^{[1]}$的巴氏参数$Z(W)$来衡量信道容量的趋向性：</p>
<script type="math/tex; mode=display">
Z\left(W_{N}^{(i)}\right)=\sum_{y_{1}^{N} \in Y^{N}} \sum_{u_{1}^{i-1} \in X^{i-1}} \sqrt{W_{N}^{(i)}\left(y_{1}^{N}, u_{1}^{i-1} \mid 0\right) W_{N}^{(i)}\left(y_{1}^{N}, u_{1}^{i-1} \mid 1\right)}</script><p>式中的$W_N^{i}(y,u|x)$表示第i个信道的条件转移概率。</p>
<p>对于一个给定信道，巴氏参数越大说明该信道越不可靠。因此我们只需计算出联合、分裂后信道的巴氏参数，并对它们进行排序，然后根据码率选择巴氏参数较小的信道作为信息位，剩余信道作为冻结位。</p>
<h4 id="编码输出"><a href="#编码输出" class="headerlink" title="编码输出"></a>编码输出</h4><p>得到巴氏参数的序列后，将该序列从小到大进行排列，前一半作为信息位，后一半为冻结位。即将原始的输入$u$重新排序为$c_i$。最后将排序后的信息$c_i$与生成矩阵相乘：</p>
<script type="math/tex; mode=display">
u^N=c_{i}^N·G_N</script><h3 id="信道部分"><a href="#信道部分" class="headerlink" title="信道部分"></a>信道部分</h3><p>我们在常见的高斯加性白噪声信道中进行模拟。将编码结果经过BPSK调制，即将$\{0,1\}$符号映射为$\{1,-1\}$，随后用不同信噪比的高斯加性白噪声与调制结果叠加。</p>
<h3 id="译码部分"><a href="#译码部分" class="headerlink" title="译码部分"></a>译码部分</h3><h4 id="译码原理"><a href="#译码原理" class="headerlink" title="译码原理"></a>译码原理</h4><p>由之前提到的编码可以看出极化码的构造就是一个信道选择的过程，而极化信道的选择实际上就是按照最优SC译码性能为标准的。因此对极化码而言，最合适的译码算法应当是基于SC译码的，只有这类译码算法才能充分利用极化码的结构，并且同时保证在码长足够长时容量可达。</p>
<p>SC译码全称为successive cancellation decoder即连续消除译码，采用蝶形算法，通过递归的方式来进行串行解码。而根据蝶形算法的特性，从右向左进行计算，因此在解码时我们首先要确定最右端所判决得到的近似值。</p>
<h4 id="近似判决"><a href="#近似判决" class="headerlink" title="近似判决"></a>近似判决</h4><p>先对信息位和冻结位进行判决：</p>
<script type="math/tex; mode=display">
\hat{\mathrm{u}}_{1}^{(\mathrm{i})}\left\{\begin{array}{c}
\mathrm{h}_{\mathrm{i}}\left(\mathrm{y}_{\mathrm{N}}^{(\mathrm{i})}, \hat{\mathrm{u}}_{1}^{(\mathrm{i}-1)}\right), \text { if } \mathrm{i} \in \mathrm{A} \\
\mathrm{u}_{\mathrm{i}}, \text { if } \mathrm{i} \in \mathrm{A}^{\mathrm{c}}
\end{array}\right.</script><p>其中$\mathrm{i} \in \mathrm{A}^{\mathrm{c}}$表明该比特为冻结比特，$\mathrm{i} \in \mathrm{A}$表明该比特为承载信息的比特。</p>
<p>随后是对信息位进行判决：</p>
<script type="math/tex; mode=display">
\widehat{\mathrm{h}}_{1}^{(\mathrm{i})}\left\{\begin{array}{l}
0, \text { if } \mathrm{L}_{\mathrm{N}}^{(\mathrm{i})}\left(\mathrm{y}_{1}^{(\mathrm{i})}, \hat{\mathrm{u}}_{1}^{(\mathrm{i}-1)}\right) \geq 0 \\
1, \text { if if } \mathrm{L}_{\mathrm{N}}^{(\mathrm{i})}\left(\mathrm{y}_{1}^{(\mathrm{i})}, \hat{\mathrm{u}}_{1}^{(\mathrm{i}-1)}\right)<0
\end{array}\right.</script><p>其中$\mathrm{L}_{\mathrm{N}}^{(\mathrm{i})}\left(\mathrm{y}_{1}^{(\mathrm{i})}, \widehat{\mathrm{u}}_{1}^{(\mathrm{i}-1)}\right)$为对数似然比（Log-Likelihood Ratio）：</p>
<script type="math/tex; mode=display">
\mathrm{L}_{\mathrm{N}}^{(\mathrm{i})}\left(\mathrm{y}_{1}^{(\mathrm{i})}, \widehat{\mathrm{u}}_{1}^{(\mathrm{i}-1)}\right) \triangleq \ln \left(\frac{\mathrm{W}_{\mathrm{N}}^{(\mathrm{i})}\left(\mathrm{y}_{1}^{(\mathrm{i})}, \widehat{\mathrm{u}}_{1}^{(\mathrm{i}-1)} \mid 0\right)}{\mathrm{W}_{\mathrm{N}}^{(\mathrm{i})}\left(\mathrm{y}_{1}^{(\mathrm{i})}, \hat{\mathrm{u}}_{1}^{(\mathrm{i}-1)} \mid 1\right)}\right)</script><p>该式说明LLR的值为在接收端得到$\left(\mathrm{y}_{1}^{(\mathrm{i})}, \widehat{\mathrm{u}}_{1}^{(\mathrm{i}-1)}\right)$发送端原本的发送”0”和”1”的比值取对数，当该对数值大于等于0时，说明原本发送”0”的概率要大，因此我们可以将其判决为接收端收到的应该为”0”，反之则为”1”。</p>
<h4 id="递归求解"><a href="#递归求解" class="headerlink" title="递归求解"></a>递归求解</h4><p>给定递归求解的公式：</p>
<script type="math/tex; mode=display">
\begin{gathered}
\mathrm{L}_{\mathrm{N}}^{(2 \mathrm{i}-1)}\left(\mathrm{y}_{1}^{(\mathrm{N})}, \widehat{\mathrm{u}}_{1}^{(2 \mathrm{i}-2)}\right)=\mathrm{f}\left(\mathrm{L}_{\mathrm{N} / 2}^{(\mathrm{i})}\left(\mathrm{y}_{1}^{(\mathrm{N} / 2)}, \widehat{\mathrm{u}}_{1,0}^{(2 \mathrm{i}-2)} \oplus \hat{\mathrm{u}}_{1, \mathrm{e}}^{(2 \mathrm{i}-2)}\right), \mathrm{L}_{\mathrm{N} / 2}^{(\mathrm{i})}\left(\mathrm{y}_{\mathrm{N} / 2+1}^{(\mathrm{N}}, \hat{\mathrm{u}}_{1, \mathrm{e}}^{(2 \mathrm{i}-2)}\right)\right. \\
\mathrm{L}_{\mathrm{N}}^{(2 \mathrm{i})}\left(\mathrm{y}_{1}^{(\mathrm{N})}, \hat{\mathrm{u}}_{1}^{(2 \mathrm{i}-1)}\right)=\mathrm{g}\left(\mathrm{L}_{\mathrm{N} / 2}^{(\mathrm{i})}\left(\mathrm{y}_{1}^{(\mathrm{N} / 2)}, \hat{\mathrm{u}}_{1,0}^{(2 \mathrm{i}-2)} \oplus \hat{\mathrm{u}}_{1, \mathrm{e}}^{(2 \mathrm{i}-2)}\right), \mathrm{L}_{\mathrm{N} / 2}^{(\mathrm{i})}\left(\mathrm{y}_{\mathrm{N} / 2+1}^{(\mathrm{N}} \hat{\mathrm{u}}_{1, \mathrm{e}}^{(2 \mathrm{i}-2)}\right), \hat{\mathrm{u}}_{2 \mathrm{i}-1}\right).
\end{gathered}</script><p>其中：</p>
<script type="math/tex; mode=display">
\begin{gathered}
f(a, b)=\ln \left(\frac{1+e^{a+b}}{e^{a}+e^{b}}\right) \\
g\left(a, b, u_{s}\right)=(-1)^{u_{s}} a+b
\end{gathered}</script><p>上述递归的的终止条件为$N=1$,即递归到达了最左端的$W$端。此时：</p>
<script type="math/tex; mode=display">
\mathrm{L}_{1}^{1}\left(\mathrm{y}_{\mathrm{j}}\right)=\ln \frac{\mathrm{W}\left(\mathrm{y}_{\mathrm{j}} \mid 0\right)}{\mathrm{W}\left(\mathrm{y}_{\mathrm{j}} \mid 1\right)}</script><p>由于我们在高斯信道下进行仿真，因此：</p>
<script type="math/tex; mode=display">
\mathrm{W}(\mathrm{y} \mid \mathrm{x})=\frac{1}{\sqrt{2 \pi} \sigma} \exp \left(-\frac{(\mathrm{y}-\mathrm{x})^{2}}{2 \sigma^{2}}\right)</script><p>给定递归出口：</p>
<script type="math/tex; mode=display">
\mathrm{L}_{1}^{1}\left(\mathrm{y}_{\mathrm{j}}\right)=\frac{2 \mathrm{y}}{\sigma^{2}}</script><h4 id="译码结果"><a href="#译码结果" class="headerlink" title="译码结果"></a>译码结果</h4><p>循环求出最后一列所有节点的似然值，然后倒推计算之前各个节点的似然值，重复该过程直到最右端即可完成译码。</p>
<h2 id="实现结果"><a href="#实现结果" class="headerlink" title="实现结果"></a>实现结果</h2><h3 id="结果评估"><a href="#结果评估" class="headerlink" title="结果评估"></a>结果评估</h3><p>我们在信噪比为5-20dB的情况下进行不同码长的极化码编码译码仿真，并统计了误码率，结果如下所示：</p>
<p><img src="https://i.loli.net/2021/09/06/OkXdnBWDjHc1oRS.jpg" style="zoom:50%;" /></p>
<center>码长为8时SNR-BER</center>

<p><img src="https://i.loli.net/2021/09/09/rbHnPJFvyMx7a1f.jpg" style="zoom:50%;" /></p>
<center>码长为16时SNR-BER</center>

<p>信噪比提高时时，误码率也在减小。码长增大时，抗噪性能越好。</p>
<h3 id="改进以及探究"><a href="#改进以及探究" class="headerlink" title="改进以及探究"></a>改进以及探究</h3><h4 id="巴氏参数的递归求解"><a href="#巴氏参数的递归求解" class="headerlink" title="巴氏参数的递归求解"></a>巴氏参数的递归求解</h4><p>在文献$^{[1]}$中，给定的巴氏参数计算方法较为复杂。且考虑条件转移概率和信道特性后，我们可以将该过程用递归过程实现：</p>
<script type="math/tex; mode=display">
\begin{gathered}
\mathrm{Z}\left(\mathrm{W}_{\mathrm{N}}^{(2 \mathrm{j}-1)}\right)=2 \mathrm{Z}\left(\mathrm{W}_{\mathrm{N} / 2}^{(\mathrm{j})}\right)-\mathrm{Z}\left(\mathrm{W}_{\mathrm{N} / 2}^{(\mathrm{j})}\right)^{2} \\
\mathrm{Z}\left(\mathrm{W}_{\mathrm{N}}^{(2 \mathrm{j})}\right)=\mathrm{Z}\left(\mathrm{W}_{\mathrm{N} / 2}^{(\mathrm{j})}\right)^{2}
\end{gathered}</script><h4 id="近似LLR硬件实现优化"><a href="#近似LLR硬件实现优化" class="headerlink" title="近似LLR硬件实现优化"></a>近似LLR硬件实现优化</h4><p>文献$^{[2]}$中指出，同时含有指数运算以及对数运算的过程不利于硬件实现，因此我们做出如下近似：</p>
<p>$$<br>f(a, b)=\ln \left(\frac{1+e^{a+b}}{e^{a}+e^{b}}\right)\thickapprox sgn(a·b)·\min\</p>
]]></content>
      <categories>
        <category>通信技术</category>
      </categories>
      <tags>
        <tag>5G通信</tag>
        <tag>极化码</tag>
      </tags>
  </entry>
  <entry>
    <title>LSTM初探</title>
    <url>/2022/10/14/LSTM%E5%88%9D%E6%8E%A2/</url>
    <content><![CDATA[<p><img src="https://pic4.zhimg.com/v2-03c41f0aaee75d920c1ba7bd756ae207.png" alt="preview" style="zoom:50%;" /></p>
<p>长短期记忆（Long Short Term Memory）在一般的循环神经网络的基础上补充完善了对信息的记忆机制，对时序信息有更好的处理能力，不但在NLP任务中大放光彩，甚至在一些视频、医学重建任务中也能发挥作用。下面则是我对LSTM的一个学习记录。</p>
<span id="more"></span>
<h2 id="RNN的简单回顾"><a href="#RNN的简单回顾" class="headerlink" title="RNN的简单回顾"></a>RNN的简单回顾</h2><p>RNN的一般结构如下：</p>
<p><img src="https://s2.loli.net/2022/10/14/BAHdpuG2mlFzkqc.jpg" alt="img" style="zoom: 50%;" /></p>
<p>其中黑色方框的$x^t$为输入，$h^{t-1}$为上一次输入时隐藏层的输出信息，也可以理解为被高度抽象化的特征，$y^{t}$为目标输出，以及当前的隐藏层状态$h^{t}$输出。可以看到不管在哪个时刻的输入，都会有上一个输入产生的输出的影响$h^{t-1}$，理论上RNN是可以保留从第一次输入到当前输入这段时期的所有序列信息（对于第一次输入，我们可以将$h^{t_0}$设为全零），那么我们为什么还需要引入长短期记忆呢？</p>
<p>答案很简单：因为不是过往所有的信息都是我们需要关心的。好比一个对话机器人bot，他不会去对用户一个月前的输入产生兴趣并揪着这个问题不断地询问用户。因此，我们需要一种“遗忘”的机制，以更加真实地去贴近人类处理时序信息地方式。</p>
<p>另一个更细节的问题就是：输入是随机的，但是随机的信息也会作为一个输入存留在RNN里，它带来的问题不只是简单的像通信领域用滤波器滤掉噪声这么单纯，它还会带来梯度爆炸或者梯度消失的问题。这两个问题在上了很深的网络上无疑是致命的，所以我们需要对过往信息的处理，而处理的最好方式就是“遗忘”。</p>
<h2 id="LSTM的引入"><a href="#LSTM的引入" class="headerlink" title="LSTM的引入"></a>LSTM的引入</h2><p>LSTM的基本结构如图所示，可以看出相比于一般的RNN，LSTM的输入中多了一个$c^{t-1}$变成了三个。</p>
<p><img src="https://s2.loli.net/2022/10/14/9amJuXiEDCSTdPb.jpg" alt="img" style="zoom:50%;" /></p>
<p>新加进来的这个的状态$c^t$叫做<code>cell state</code>，原来的$h^t$我们称为叫做<code>hidden state</code>。其中对于传递下去的$c^t$改变得很慢，通常输出的$c^t$是上一个状态传过来的 $c^{t-1}$加上一些数值，而$h^t$在不同节点下通常有很大区别。</p>
<h3 id="LSTM的层次结构与功能关系"><a href="#LSTM的层次结构与功能关系" class="headerlink" title="LSTM的层次结构与功能关系"></a>LSTM的层次结构与功能关系</h3><p><img src="https://s2.loli.net/2022/10/14/YXLjJ1dcvhRbeAV.jpg" alt="img" style="zoom:50%;" /></p>
<p>这张图比上一个图看上去更复杂点，但是其实它的本质还是一般的神经网络运算过程，和普通的MLP的单一$\mathrm y=\mathrm W \mathrm x+\mathrm b$区别在于多了几个需要运算的状态。我们先看看中间的$z$状态是怎么来的：</p>
<center><img src = 'https://s2.loli.net/2022/10/14/X9bugtqRQGONCe5.webp' style = "zoom:35%"><img src = 'https://s2.loli.net/2022/10/14/NOZ3IwRkCmcbpVY.jpg' style = "zoom:35%"></center>

<p>可以看到这四个玩意都是通过拼接两个输入状态然后与矩阵相乘后通过激活函数得到的。其中$\sigma$代表的是sigmoid函数（映射到(0,1)区间），把输入映射到<code>(0，1)</code>区间是一种类似门控的作用：</p>
<script type="math/tex; mode=display">
S(x)=\frac{1}{1+e^{-x}}</script><p>tanh代表的是双曲正切函数（映射到(1，1)区间），映射到<code>(-1,1)</code>理解成将其作为输入数据，而不是门控信息。：</p>
<script type="math/tex; mode=display">
tanh(x) = \frac{e^{x}-e^{-x}}{e^{x}+e^{-x}}</script><p>那么LSTM的工作如下所示：</p>
<script type="math/tex; mode=display">
c^t = z^f\odot c^{t-1} + z^i\odot z\\
h^t = z^o\odot tanh(c^t)\\
y^t =\sigma(W'h^t)</script><h3 id="LSTM运行原理"><a href="#LSTM运行原理" class="headerlink" title="LSTM运行原理"></a>LSTM运行原理</h3><p>LSTM内部有三个阶段：遗忘段、选择记忆段以及输出段。</p>
<ul>
<li><p>这个阶段主要是对上一个节点传进来的输入进行<strong>选择性</strong>忘记。简单来说就是会 “忘记不重要的，记住重要的”。</p>
<p>具体来说是通过计算得到的 $z^f$（f表示forget）来作为忘记门控，来控制上一个状态的$c^{t-1}$哪些需要留哪些需要忘。</p>
</li>
<li><p>选择记忆阶段：这个阶段将这个阶段的输入有选择性地进行“记忆”。主要是会对输入$x^t$进行选择记忆。哪些重要则着重记录下来，哪些不重要，则少记一些。当前的输入内容由前面计算得到的$z$表示。而选择的门控信号则是由$z^i$（i代表information）来进行控制。把上述两个阶段的结果相加即可得到输出阶段需要的$c^t$，也就是上面的第一个公式。</p>
</li>
<li><p>这个阶段将决定哪些将会被当成当前状态的输出。主要是通过$z^o$来进行控制的。并且还对上一阶段得到的$c^0$进行了放缩（通过一个tanh激活函数进行变化）。</p>
</li>
</ul>
<p>可以看到，在输出阶段$z^o$起到门限控制作用，对进行了映射后的融合信息$h^t$进行控制输出。</p>
<h2 id="Pytorch中的LSTM使用"><a href="#Pytorch中的LSTM使用" class="headerlink" title="Pytorch中的LSTM使用"></a>Pytorch中的LSTM使用</h2><p><a href="https://pytorch.org/docs/stable/generated/torch.nn.LSTM.html">官方文档</a>可以看到详细的参数设定。我们一般关注以下几个参数：</p>
<ul>
<li><code>input_size</code>：输入数据的特征维数。</li>
<li><code>hidden_size</code>：LSTM中隐层的维度。</li>
<li><code>num_layers</code>：循环神经网络的层数。</li>
</ul>
<p>把网络看成一个黑箱，我们在用是肯定是输入一个向量，然后网络处理后输出一个向量，所以我们必须要告诉网络输入的向量是多少维，输出的为多少维，因此前两个参数就决定了输入和输出向量的维度。当然，<code>hidden_size</code>只是指定从LSTM输出的向量的维度，并不是最后的维度，因为LSTM层之后可能还会接其他层，如全连接层（FC），因此<code>hidden_siz</code>e对应的维度也就是FC层的输入维度。第三个参数<code>num_layers</code>为隐藏层的层数，这个比较好理解，官方的例程里面建议一般设置为1或者2.</p>
<p><img src="https://s2.loli.net/2022/10/14/vuUZE39CXFdTVxi.png" alt="image-20221014111604955" style="zoom: 50%;" /></p>
<p>下面给出一个应用的案例：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> torch.nn <span class="keyword">as</span> nn</span><br><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">lstm</span>(nn.Module):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="built_in">super</span>(lstm, self).__init__()</span><br><span class="line">        <span class="comment"># 定义LSTM</span></span><br><span class="line">        self.rnn = nn.LSTM(input_size, hidden_size, hidden_num_layers)</span><br><span class="line">        <span class="comment"># 定义回归层网络，输入的特征维度等于LSTM的输出，输出维度为1</span></span><br><span class="line">        self.reg = nn.Sequential(</span><br><span class="line">            nn.Linear(hidden_size, <span class="number">1</span>)</span><br><span class="line">        )</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, x</span>):</span><br><span class="line">        x, (ht,ct) = self.rnn(x)</span><br><span class="line">        seq_len, batch_size, hidden_size= x.shape</span><br><span class="line">        x = x.view(-<span class="number">1</span>, hidden_size)</span><br><span class="line">        x = self.reg(x)</span><br><span class="line">        x = x.view(seq_len, batch_size, -<span class="number">1</span>)</span><br><span class="line">        <span class="keyword">return</span> x</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">output,(h_n,c_n) = lstm (x, [ht_1, ct_1])</span><br></pre></td></tr></table></figure>
]]></content>
      <categories>
        <category>深度学习</category>
      </categories>
      <tags>
        <tag>Pytorch</tag>
        <tag>计算机视觉</tag>
        <tag>时序分析</tag>
        <tag>LSTM</tag>
      </tags>
  </entry>
  <entry>
    <title>MD5加密算法的Python实现流程</title>
    <url>/2022/07/29/MD5/</url>
    <content><![CDATA[<p><strong>MD5信息摘要算法</strong>（英语：MD5 Message-Digest Algorithm），一种被广泛使用的<a href="https://baike.baidu.com/item/密码散列函数/14937715">密码散列函数</a>，可以产生出一个128位（16<a href="https://baike.baidu.com/item/字节/1096318">字节</a>）的散列值（hash value），用于确保信息传输完整一致。MD5由美国密码学家<a href="https://baike.baidu.com/item/罗纳德·李维斯特/700199">罗纳德·李维斯特</a>（Ronald Linn Rivest）设计，于1992年公开，用以取代<a href="https://baike.baidu.com/item/MD4/8090275">MD4</a>算法。这套算法的程序在 RFC 1321 标准中被加以规范。1996年后该算法被证实存在弱点，可以被加以破解，对于需要高度安全性的数据，专家一般建议改用其他算法，如<a href="https://baike.baidu.com/item/SHA-2/22718180">SHA-2</a>。2004年，证实MD5算法无法防止碰撞（collision），因此不适用于安全性认证，如<a href="https://baike.baidu.com/item/SSL/320778">SSL</a>公开密钥认证或是<a href="https://baike.baidu.com/item/数字签名/212550">数字签名</a>等用途。</p>
<span id="more"></span>
<p>首先先要对MD5使用的初始数据进行初始化：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">A=<span class="number">0x67452301</span></span><br><span class="line"></span><br><span class="line">B=<span class="number">0xEFCDAB89</span></span><br><span class="line"></span><br><span class="line">C=<span class="number">0x98BADCFE</span></span><br><span class="line"></span><br><span class="line">D=<span class="number">0x10325476</span></span><br><span class="line">T = [<span class="number">0xD76AA478</span>,<span class="number">0xE8C7B756</span>,<span class="number">0x242070DB</span>,<span class="number">0xC1BDCEEE</span>,<span class="number">0xF57C0FAF</span>,<span class="number">0x4787C62A</span>,<span class="number">0xA8304613</span>,<span class="number">0xFD469501</span>,</span><br><span class="line">    <span class="number">0x698098D8</span>,<span class="number">0x8B44F7AF</span>,<span class="number">0xFFFF5BB1</span>,<span class="number">0x895CD7BE</span>,<span class="number">0x6B901122</span>,<span class="number">0xFD987193</span>,<span class="number">0xA679438E</span>,<span class="number">0x49B40821</span>,</span><br><span class="line">    <span class="number">0xF61E2562</span>,<span class="number">0xC040B340</span>,<span class="number">0x265E5A51</span>,<span class="number">0xE9B6C7AA</span>,<span class="number">0xD62F105D</span>,<span class="number">0x02441453</span>,<span class="number">0xD8A1E681</span>,<span class="number">0xE7D3FBC8</span>,</span><br><span class="line">    <span class="number">0x21E1CDE6</span>,<span class="number">0xC33707D6</span>,<span class="number">0xF4D50D87</span>,<span class="number">0x455A14ED</span>,<span class="number">0xA9E3E905</span>,<span class="number">0xFCEFA3F8</span>,<span class="number">0x676F02D9</span>,<span class="number">0x8D2A4C8A</span>,</span><br><span class="line">    <span class="number">0xFFFA3942</span>,<span class="number">0x8771F681</span>,<span class="number">0x6D9D6122</span>,<span class="number">0xFDE5380C</span>,<span class="number">0xA4BEEA44</span>,<span class="number">0x4BDECFA9</span>,<span class="number">0xF6BB4B60</span>,<span class="number">0xBEBFBC70</span>,</span><br><span class="line">    <span class="number">0x289B7EC6</span>,<span class="number">0xEAA127FA</span>,<span class="number">0xD4EF3085</span>,<span class="number">0x04881D05</span>,<span class="number">0xD9D4D039</span>,<span class="number">0xE6DB99E5</span>,<span class="number">0x1FA27CF8</span>,<span class="number">0xC4AC5665</span>,</span><br><span class="line">    <span class="number">0xF4292244</span>,<span class="number">0x432AFF97</span>,<span class="number">0xAB9423A7</span>,<span class="number">0xFC93A039</span>,<span class="number">0x655B59C3</span>,<span class="number">0x8F0CCC92</span>,<span class="number">0xFFEFF47D</span>,<span class="number">0x85845DD1</span>,</span><br><span class="line">    <span class="number">0x6FA87E4F</span>,<span class="number">0xFE2CE6E0</span>,<span class="number">0xA3014314</span>,<span class="number">0x4E0811A1</span>,<span class="number">0xF7537E82</span>,<span class="number">0xBD3AF235</span>,<span class="number">0x2AD7D2BB</span>,<span class="number">0xEB86D391</span>]</span><br><span class="line"></span><br><span class="line">s = [<span class="number">7</span>,<span class="number">12</span>,<span class="number">17</span>,<span class="number">22</span>,<span class="number">7</span>,<span class="number">12</span>,<span class="number">17</span>,<span class="number">22</span>,<span class="number">7</span>,<span class="number">12</span>,<span class="number">17</span>,<span class="number">22</span>,<span class="number">7</span>,<span class="number">12</span>,<span class="number">17</span>,<span class="number">22</span>,</span><br><span class="line">    <span class="number">5</span>,<span class="number">9</span>,<span class="number">14</span>,<span class="number">20</span>,<span class="number">5</span>,<span class="number">9</span>,<span class="number">14</span>,<span class="number">20</span>,<span class="number">5</span>,<span class="number">9</span>,<span class="number">14</span>,<span class="number">20</span>,<span class="number">5</span>,<span class="number">9</span>,<span class="number">14</span>,<span class="number">20</span>,</span><br><span class="line">    <span class="number">4</span>,<span class="number">11</span>,<span class="number">16</span>,<span class="number">23</span>,<span class="number">4</span>,<span class="number">11</span>,<span class="number">16</span>,<span class="number">23</span>,<span class="number">4</span>,<span class="number">11</span>,<span class="number">16</span>,<span class="number">23</span>,<span class="number">4</span>,<span class="number">11</span>,<span class="number">16</span>,<span class="number">23</span>,</span><br><span class="line">    <span class="number">6</span>,<span class="number">10</span>,<span class="number">15</span>,<span class="number">21</span>,<span class="number">6</span>,<span class="number">10</span>,<span class="number">15</span>,<span class="number">21</span>,<span class="number">6</span>,<span class="number">10</span>,<span class="number">15</span>,<span class="number">21</span>,<span class="number">6</span>,<span class="number">10</span>,<span class="number">15</span>,<span class="number">21</span>]</span><br><span class="line"></span><br><span class="line">m = [<span class="number">0</span>,<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>,<span class="number">4</span>,<span class="number">5</span>,<span class="number">6</span>,<span class="number">7</span>,<span class="number">8</span>,<span class="number">9</span>,<span class="number">10</span>,<span class="number">11</span>,<span class="number">12</span>,<span class="number">13</span>,<span class="number">14</span>,<span class="number">15</span>,</span><br><span class="line">    <span class="number">1</span>,<span class="number">6</span>,<span class="number">11</span>,<span class="number">0</span>,<span class="number">5</span>,<span class="number">10</span>,<span class="number">15</span>,<span class="number">4</span>,<span class="number">9</span>,<span class="number">14</span>,<span class="number">3</span>,<span class="number">8</span>,<span class="number">13</span>,<span class="number">2</span>,<span class="number">7</span>,<span class="number">12</span>,</span><br><span class="line">    <span class="number">5</span>,<span class="number">8</span>,<span class="number">11</span>,<span class="number">14</span>,<span class="number">1</span>,<span class="number">4</span>,<span class="number">7</span>,<span class="number">10</span>,<span class="number">13</span>,<span class="number">0</span>,<span class="number">3</span>,<span class="number">6</span>,<span class="number">9</span>,<span class="number">12</span>,<span class="number">15</span>,<span class="number">2</span>,</span><br><span class="line">    <span class="number">0</span>,<span class="number">7</span>,<span class="number">14</span>,<span class="number">5</span>,<span class="number">12</span>,<span class="number">3</span>,<span class="number">10</span>,<span class="number">1</span>,<span class="number">8</span>,<span class="number">15</span>,<span class="number">6</span>,<span class="number">13</span>,<span class="number">4</span>,<span class="number">11</span>,<span class="number">2</span>,<span class="number">9</span>]</span><br></pre></td></tr></table></figure>
<h2 id="实现思路"><a href="#实现思路" class="headerlink" title="实现思路"></a>实现思路</h2><p>MD5加密需要经过输入转换、填充、四轮循环操作、置换以及最后的拼接等步骤。其中为了方便循环操作中的值的读取与置换，可以定义一个<code>MD5</code>类，并赋予此类一些初始的属性与函数简化后续的函数操作。现将类定义如下：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">md5</span>(<span class="title class_ inherited__">object</span>):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, message</span>):</span><br><span class="line">        self.message = message</span><br><span class="line">        self.A = A</span><br><span class="line">        self.B = B</span><br><span class="line">        self.C = C</span><br><span class="line">        self.D = D</span><br><span class="line">        self.init_A = A</span><br><span class="line">        self.init_B = B</span><br><span class="line">        self.init_C = C</span><br><span class="line">        self.init_D = D</span><br><span class="line">        self.temptext=<span class="string">&#x27;&#x27;</span></span><br><span class="line">        self.s=s</span><br><span class="line">        self.m=m</span><br><span class="line">        self.T=T</span><br></pre></td></tr></table></figure>
<p>对于一个MD5对象，其拥有如下几个主要属性：</p>
<ul>
<li>message：  输入的明文</li>
<li>A,B,C,D：  四轮循环中的操作对象</li>
<li>temptext： 暂存的结果，用于缓冲与临时存放</li>
<li>s,m,T:    均为MD5加密时用到的操作参数，以列表的形式存储</li>
</ul>
<h2 id="填充"><a href="#填充" class="headerlink" title="填充"></a>填充</h2><ul>
<li>将输入的明文转换成ASCII码，并按照规则进行填充。填充规则如下：</li>
<li>当转换的ASCII码的长度的二进制长度不为$512*n+448$的整数倍时，先在末尾补一个“1”；</li>
<li>当此时的长度依然不为$512<em>n+448$时，继续在末尾补“0”直至长度为$512</em>n+448$</li>
<li>将输入密文的长度转换成64位的二进制数，若输入字符串的长度大于$2^{64}$，则取最后的64位。</li>
<li>将得到的64位进行小端排序，即按8bit/组进行倒序排列</li>
<li>将小端排序得到的结果拼接在步骤3得到的字符后，完成填充</li>
</ul>
<p>完成此项工作需要一个函数将输入的十进制字符串转换城标准长度的二进制数，代码如下：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">decToBin</span>(<span class="params">num</span>):  <span class="comment"># 十进制转标准4位二或8位进制字符串函数 注意此为专用函数不要用于其他程序中</span></span><br><span class="line">    arry = []</span><br><span class="line">    <span class="keyword">while</span> <span class="literal">True</span>:</span><br><span class="line">        arry.append(<span class="built_in">str</span>(num % <span class="number">2</span>))</span><br><span class="line">        num = num // <span class="number">2</span></span><br><span class="line">        <span class="keyword">if</span> num == <span class="number">0</span>:</span><br><span class="line">            <span class="keyword">break</span></span><br><span class="line">    <span class="keyword">while</span> <span class="built_in">len</span>(arry)%<span class="number">4</span>!=<span class="number">0</span>:</span><br><span class="line">        arry.append(<span class="string">&#x27;0&#x27;</span>)</span><br><span class="line">    <span class="keyword">return</span> <span class="string">&quot;&quot;</span>.join(arry[::-<span class="number">1</span>])  <span class="comment"># 列表切片倒叙排列后再用join拼接</span></span><br></pre></td></tr></table></figure>
<p>下面进行填充的操作。将填充的方法归属于MD5对象专用，以防意外调用：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">fill</span>(<span class="params">self</span>):</span><br><span class="line">    bininput = <span class="string">&#x27;&#x27;</span></span><br><span class="line">    raw_input=self.message</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(raw_input)):</span><br><span class="line">        c = decToBin(<span class="built_in">ord</span>(raw_input[i]))</span><br><span class="line">        bininput += c</span><br><span class="line">    <span class="keyword">if</span> (<span class="built_in">len</span>(bininput) % <span class="number">512</span> != <span class="number">448</span>):</span><br><span class="line">        <span class="keyword">if</span> ((<span class="built_in">len</span>(bininput) + <span class="number">1</span>) % <span class="number">512</span> != <span class="number">448</span>):</span><br><span class="line">            bininput += <span class="string">&#x27;1&#x27;</span>  <span class="comment"># 补1</span></span><br><span class="line">        <span class="keyword">while</span> (<span class="built_in">len</span>(bininput) % <span class="number">512</span> != <span class="number">448</span>):</span><br><span class="line">            bininput += <span class="string">&#x27;0&#x27;</span>  <span class="comment"># 其余位补0直到满足长度为512*n+448</span></span><br><span class="line">    length = <span class="built_in">len</span>(raw_input) * <span class="number">8</span>  <span class="comment"># ASCII码位数</span></span><br><span class="line">    <span class="keyword">if</span> length &lt;= <span class="number">255</span>:</span><br><span class="line">        length = decToBin(length)  <span class="comment"># 二进制转换，此时length保留位数为8</span></span><br><span class="line">        <span class="keyword">while</span> <span class="built_in">len</span>(length) &lt; <span class="number">8</span>:</span><br><span class="line">            length = <span class="string">&#x27;0&#x27;</span> + length</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        temp = decToBin(length)</span><br><span class="line">        <span class="keyword">while</span> <span class="built_in">len</span>(length) &lt; <span class="number">16</span>:</span><br><span class="line">            length = <span class="string">&#x27;0&#x27;</span> + length</span><br><span class="line">        length = length[<span class="number">8</span>:<span class="number">12</span>] + length[<span class="number">12</span>:<span class="number">16</span>] + length[<span class="number">0</span>:<span class="number">4</span>] + length[<span class="number">4</span>:<span class="number">8</span>]</span><br><span class="line">    bininput += length</span><br><span class="line">    <span class="keyword">while</span> <span class="built_in">len</span>(bininput) % <span class="number">512</span> != <span class="number">0</span>:</span><br><span class="line">        bininput += <span class="string">&#x27;0&#x27;</span></span><br><span class="line">    self.temptext=bininput</span><br></pre></td></tr></table></figure>
<h2 id="4轮循环"><a href="#4轮循环" class="headerlink" title="4轮循环"></a>4轮循环</h2><h3 id="分解消息子块"><a href="#分解消息子块" class="headerlink" title="分解消息子块"></a>分解消息子块</h3><p>下面将得到的临时变量进行分组。将其分解成$16*32$的矩阵，并将其存放于<code>Mlist</code>中。后续将配合MD5类中的m矩阵进行操作。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">Cycolyce</span>(<span class="params">self</span>):</span><br><span class="line">    Mlist=[]<span class="comment">#分16组</span></span><br><span class="line">    bininput=self.temptext</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">0</span>,<span class="number">512</span>,<span class="number">32</span>):<span class="comment">#16</span></span><br><span class="line">        sym=<span class="string">&#x27;&#x27;</span></span><br><span class="line">        <span class="keyword">for</span> j <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">0</span>,<span class="built_in">len</span>(bininput[i:i+<span class="number">32</span>]),<span class="number">4</span>):</span><br><span class="line">            temp=<span class="built_in">hex</span>(<span class="built_in">int</span>((bininput[i:i+<span class="number">32</span>][j:j+<span class="number">4</span>]),<span class="number">2</span>))<span class="comment">#取十六进制</span></span><br><span class="line">            sym+=temp[<span class="number">2</span>]<span class="comment">#只取字母 忽略前面的0x 为下面的小端排序做准备</span></span><br><span class="line"></span><br><span class="line">        sym_tmp=<span class="string">&#x27;&#x27;</span></span><br><span class="line">        <span class="keyword">for</span> j <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">8</span>,<span class="number">0</span>,-<span class="number">2</span>):<span class="comment">#小端排序</span></span><br><span class="line">            temp=sym[j-<span class="number">2</span>:j]</span><br><span class="line">            sym_tmp+=temp</span><br><span class="line"></span><br><span class="line">        fn_sym=<span class="string">&#x27;&#x27;</span></span><br><span class="line">        <span class="keyword">for</span> j <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(sym_tmp)):</span><br><span class="line">            fn_sym+=decToBin(<span class="built_in">int</span>(sym_tmp[j], <span class="number">16</span>))<span class="comment">#再次转换成二进制</span></span><br><span class="line">        Mlist.append(fn_sym)</span><br></pre></td></tr></table></figure>
<h3 id="四轮循环的操作"><a href="#四轮循环的操作" class="headerlink" title="四轮循环的操作"></a>四轮循环的操作</h3><p>我们需要定义如下四个函数：</p>
<script type="math/tex; mode=display">
F(x,y,z)=(x\land y)\lor (\overline x \land z)\\
G(x,y,z)=(x\land z)\lor (y \lor \overline z)\\
H(x,y,z)=x\oplus y \oplus z\\
I(x,y,z)=y\oplus(x\lor \overline z)</script><p>以及定义四个操作：</p>
<script type="math/tex; mode=display">
FF(a,b,c,d,Mj,s,Ti)=(F(b,c,d)+a+mj+Ti)<<s\\
GG(a,b,c,d,Mj,s,Ti)=(G(b,c,d)+a+mj+Ti)<<s\\
HH(a,b,c,d,Mj,s,Ti)=(H(b,c,d)+a+mj+Ti)<<s\\
II(a,b,c,d,Mj,s,Ti)=(I(b,c,d)+a+mj+Ti)<<s\\</script><p>其中，$&lt;&lt;$是循环左移，$\oplus$是异或操作。在程序实现中，将四个函数定义在MD5类外，四个操作定义在MD5类以内。如此操作有两个原因：</p>
<ul>
<li>定义在外部的函数可以根据需求进行更改，对于封装后的类调用而言更具操作性</li>
<li>定义在类内部的操作是MD5的专用函数，必须专类专用</li>
<li>二者分离有助于设置断点、检查中间结果进行调试分析</li>
</ul>
<p>定义完函数以及相关操作后，我们将进行如下操作：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">for</span> j <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">0</span>, <span class="number">16</span>, <span class="number">4</span>):</span><br><span class="line">    self.FF(Mlist[m[j]], s[j], T[j])</span><br><span class="line">    self.FF(Mlist[m[j+<span class="number">1</span>]], s[j+<span class="number">1</span>], T[j+<span class="number">1</span>])</span><br><span class="line">    self.FF(Mlist[m[j+<span class="number">2</span>]], s[j+<span class="number">2</span>], T[j+<span class="number">2</span>])</span><br><span class="line">    self.FF(Mlist[m[j+<span class="number">3</span>]], s[j+<span class="number">3</span>], T[j+<span class="number">3</span>])</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> j <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">0</span>, <span class="number">16</span>, <span class="number">4</span>):</span><br><span class="line">    self.GG(Mlist[m[<span class="number">16</span>+j]], s[<span class="number">16</span>+j], T[<span class="number">16</span>+j])</span><br><span class="line">    self.GG(Mlist[m[<span class="number">16</span>+j+<span class="number">1</span>]], s[<span class="number">16</span>+j+<span class="number">1</span>], T[<span class="number">16</span>+j+<span class="number">1</span>])</span><br><span class="line">    self.GG(Mlist[m[<span class="number">16</span>+j+<span class="number">2</span>]], s[<span class="number">16</span>+j+<span class="number">2</span>], T[<span class="number">16</span>+j+<span class="number">2</span>])</span><br><span class="line">    self.GG(Mlist[m[<span class="number">16</span>+j+<span class="number">3</span>]], s[<span class="number">16</span>+j+<span class="number">3</span>], T[<span class="number">16</span>+j+<span class="number">3</span>])</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> j <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">0</span>, <span class="number">16</span>, <span class="number">4</span>):</span><br><span class="line">    self.HH(Mlist[m[<span class="number">32</span>+j]], s[<span class="number">32</span>+j], T[<span class="number">32</span>+j])</span><br><span class="line">    self.HH(Mlist[m[<span class="number">32</span>+j+<span class="number">1</span>]], s[<span class="number">32</span>+j+<span class="number">1</span>], T[<span class="number">32</span>+j+<span class="number">1</span>])</span><br><span class="line">    self.HH(Mlist[m[<span class="number">32</span>+j+<span class="number">2</span>]], s[<span class="number">32</span>+j+<span class="number">2</span>], T[<span class="number">32</span>+j+<span class="number">2</span>])</span><br><span class="line">    self.HH(Mlist[m[<span class="number">32</span>+j+<span class="number">3</span>]], s[<span class="number">32</span>+j+<span class="number">3</span>], T[<span class="number">32</span>+j+<span class="number">3</span>])</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> j <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">0</span>, <span class="number">16</span>, <span class="number">4</span>):</span><br><span class="line">    self.II(Mlist[m[<span class="number">48</span>+j]], s[<span class="number">48</span>+j], T[<span class="number">48</span>+j])</span><br><span class="line">    self.II(Mlist[m[<span class="number">48</span>+j+<span class="number">1</span>]], s[<span class="number">48</span>+j+<span class="number">1</span>], T[<span class="number">48</span>+j+<span class="number">1</span>])</span><br><span class="line">    self.II(Mlist[m[<span class="number">48</span>+j+<span class="number">2</span>]], s[<span class="number">48</span>+j+<span class="number">2</span>], T[<span class="number">48</span>+j+<span class="number">2</span>])</span><br><span class="line">    self.II(Mlist[m[<span class="number">48</span>+j+<span class="number">3</span>]], s[<span class="number">48</span>+j+<span class="number">3</span>], T[<span class="number">48</span>+j+<span class="number">3</span>])</span><br></pre></td></tr></table></figure>
<h2 id="初值相加与拼接输出"><a href="#初值相加与拼接输出" class="headerlink" title="初值相加与拼接输出"></a>初值相加与拼接输出</h2><p>完成四轮循环后，需要将此时的ABCD与初始的ABCD相加，并进行小端排序。将小端排序后的结果拼接即可得到MD5加密的结果。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">self.A = (self.A+self.init_A)%<span class="built_in">pow</span>(<span class="number">2</span>, <span class="number">32</span>)</span><br><span class="line">        <span class="built_in">print</span>(self.A)</span><br><span class="line">        self.B = (self.B+self.init_B)%<span class="built_in">pow</span>(<span class="number">2</span>, <span class="number">32</span>)</span><br><span class="line">        <span class="built_in">print</span>(self.B)</span><br><span class="line">        self.C = (self.C+self.init_C)%<span class="built_in">pow</span>(<span class="number">2</span>, <span class="number">32</span>)</span><br><span class="line">        <span class="built_in">print</span>(self.C)</span><br><span class="line">        self.D = (self.D+self.init_D)%<span class="built_in">pow</span>(<span class="number">2</span>, <span class="number">32</span>)</span><br><span class="line">        <span class="built_in">print</span>(self.D)</span><br><span class="line"></span><br><span class="line">        answer = <span class="string">&quot;&quot;</span></span><br><span class="line">        <span class="keyword">for</span> each <span class="keyword">in</span> [self.A, self.B, self.C, self.D]:</span><br><span class="line">            each = <span class="built_in">hex</span>(each)[<span class="number">2</span>:]</span><br><span class="line">            <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">8</span>, <span class="number">0</span>, -<span class="number">2</span>):</span><br><span class="line">                answer += <span class="built_in">str</span>(each[i - <span class="number">2</span>:i])</span><br><span class="line">        <span class="keyword">return</span> answer</span><br></pre></td></tr></table></figure>
<p>我们可以运行一下检验成果：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">MD=md5(<span class="string">&#x27;abc&#x27;</span>)</span><br><span class="line">MD.fill()</span><br><span class="line">result=MD.Cycolyce()</span><br><span class="line"><span class="built_in">print</span>(result)</span><br></pre></td></tr></table></figure>
]]></content>
      <categories>
        <category>通信技术</category>
        <category>加密技术</category>
      </categories>
      <tags>
        <tag>数字签名</tag>
        <tag>Python</tag>
        <tag>MD5</tag>
      </tags>
  </entry>
  <entry>
    <title>Typora新建文件时使用模板</title>
    <url>/2022/08/28/Markdown%20%E6%A8%A1%E6%9D%BF/</url>
    <content><![CDATA[<p align="center">
    <img src="https://s2.loli.net/2022/08/20/oxvPZeT8G7ydzct.png" alt="banner" width=200 height=200 />
</p>
<h1 align="center">这是文章模板的标题</h1>
<p align="center">
    <em>这是文章模板的副标题</em>
</p>




<p>经常写日记/博客/ToDo的朋友应该会对每次新建md文件时都要从以前的文档里复制粘贴一份修改感到厌倦，但是我们完全可以使用Typora在新建文档的时候直接搬用模板！&gt;&gt;&gt;</p>
<span id="more"></span>
<h2 id="模板文件参考"><a href="#模板文件参考" class="headerlink" title="模板文件参考"></a>模板文件参考</h2><p>你可以参考我的模板文件，我常用的Typora写作场景是博客博文写作(Next主题)和项目说明书，所以我的模板就如上所示，你可以根据自己的需求更改。</p>
<figure class="highlight markdown"><table><tr><td class="code"><pre><span class="line">---</span><br><span class="line">title: Typora新建文件时使用模板</span><br><span class="line">mathjax: false</span><br><span class="line">tags:</span><br><span class="line"><span class="bullet">-</span> tag1</span><br><span class="line">categories:</span><br><span class="line"><span class="section">- category1</span></span><br><span class="line"><span class="section">---</span></span><br><span class="line"><span class="language-xml"><span class="tag">&lt;<span class="name">p</span> <span class="attr">align</span>=<span class="string">&quot;center&quot;</span>&gt;</span></span></span><br><span class="line"><span class="code">    &lt;img src=&quot;https://s2.loli.net/2022/08/20/oxvPZeT8G7ydzct.png&quot; alt=&quot;pyecharts logo&quot; width=200 height=200 /&gt;</span></span><br><span class="line"><span class="code">&lt;/p&gt;</span></span><br><span class="line"><span class="code">&lt;h1 align=&quot;center&quot;&gt;Type Your Title here&lt;/h1&gt;</span></span><br><span class="line"><span class="code">&lt;p align=&quot;center&quot;&gt;</span></span><br><span class="line"><span class="code">    &lt;em&gt;type your subtitle here&lt;/em&gt;</span></span><br><span class="line"><span class="code">&lt;/p&gt;</span></span><br><span class="line"><span class="code"></span></span><br><span class="line">经常写日记/博客/ToDo的朋友应该会对每次新建md文件时都要从以前的文档里复制粘贴一份修改感到厌倦，但是我们完全可以使用Typora在新建文档的时候直接搬用模板！看看我是怎么操作的&gt;&gt;&gt;</span><br><span class="line"></span><br><span class="line">&lt;!--more--&gt;</span><br></pre></td></tr></table></figure>
<p>将以上内容或者你的模板内容保存为一个<code>.md</code>文件，我的是<code>Template.md</code>，然后就需要管理员权限来到<code>C:\Windows\ShellNew</code>的目录，如果没有的就新建一个，把我们的模板文件复制到这里：</p>
<p><img src="https://s2.loli.net/2022/08/28/adlH7VxifLpM3cX.png" alt="image-20220828174923586"></p>
<h2 id="新建文件行为写入注册表"><a href="#新建文件行为写入注册表" class="headerlink" title="新建文件行为写入注册表"></a>新建文件行为写入注册表</h2><p>按下<code>win+R</code>进入运行窗口，输入<code>regedit</code>后回车进入注册表。然后在<code>\HKEY_CLASSES_ROOT\.md\ShellNew</code>的目录新建项：</p>
<p><img src="https://s2.loli.net/2022/08/28/HMKxZzArsbhUv6S.png" alt="image-20220828174613056"></p>
<p>新建的项将其命名为<code>FileName</code>（注意大小写），然后修改它的值为我们的模板文件的目录：</p>
<p><img src="C:\Users\cybercolyce\AppData\Roaming\Typora\typora-user-images\image-20220828174728373.png" alt="image-20220828174728373"></p>
<p>然后重启下Typora就可以啦！</p>
<h2 id="右键菜单新建-md文件-可选"><a href="#右键菜单新建-md文件-可选" class="headerlink" title="右键菜单新建.md文件(可选)"></a>右键菜单新建<code>.md</code>文件(可选)</h2><p>为了更方便地不打开Typora而是直接右键新建<code>.md</code>文件，可以在注册表注册一个右键的新建选项。打开笔记本，然后将以下内容复制粘贴进去：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">Windows Registry Editor Version 5.00</span><br><span class="line"></span><br><span class="line">[HKEY_CLASSES_ROOT\.md]</span><br><span class="line">@=&quot;Typora.md&quot;</span><br><span class="line">&quot;Content Type&quot;=&quot;text/markdown&quot;</span><br><span class="line">&quot;PerceivedType&quot;=&quot;text&quot;</span><br><span class="line"></span><br><span class="line">[HKEY_CLASSES_ROOT\.md\ShellNew]</span><br><span class="line">&quot;NullFile&quot;=&quot;&quot;</span><br></pre></td></tr></table></figure>
<p>然后将它保存为<code>.reg</code>文件，直接运行就好。这个需要重启计算机才能在右键看到新增了Markdown文件选项。</p>
]]></content>
      <categories>
        <category>学习记录</category>
      </categories>
      <tags>
        <tag>Typora</tag>
      </tags>
  </entry>
  <entry>
    <title>PDU会话过程的建立过程</title>
    <url>/2022/08/28/PDU%E4%BC%9A%E8%AF%9D/</url>
    <content><![CDATA[<p>PDU会话是UE和指定DN之间的一条逻辑连接，为UE提供到DN的用户面连接。那么他的建立过程是怎样的呢?</p>
<span id="more"></span>
<p>PDU会话的建立简化过程如下：</p>
<p><img src="https://s2.loli.net/2022/08/27/89RuGbNqwKJjI6A.png" alt="image-20220827155413747"></p>
<p>完整过程可以参考下图：</p>
<p><img src="https://s2.loli.net/2022/08/27/LM8gxfRhF4NydK7.png" alt="img"></p>
]]></content>
      <categories>
        <category>学习记录</category>
      </categories>
      <tags>
        <tag>通信技术</tag>
      </tags>
  </entry>
  <entry>
    <title>【文献翻译】神经网络的有趣特性</title>
    <url>/2023/02/18/CN-Intriguing%20properties%20of%20neural%20networks/</url>
    <content><![CDATA[<p><img src="https://s2.loli.net/2023/01/08/GZXH6pI9rywmhCW.png" alt="image-20230108121329642"></p>
<span id="more"></span>
<h2 id="摘要"><a href="#摘要" class="headerlink" title="摘要"></a>摘要</h2><p>深度神经网络是一种高度表达的模型，并且在最近在语音和视觉识别任务上取得了最佳性能效果。尽管他们的表现力是他们成功的原因，但也造成他们可能学习到具有反直觉属性的难以解释的解决方法。在本文中，我们报告了两种这样的属性。</p>
<p>首先我们通过一系列的单元分析方法发现在各个高级单元和高级单元的随即线性组合之间没有区别。这说明，其实是空间而非是单个神经元保留了神经网络的高维层次结构的语义信息。</p>
<p>其次，我们发现深度神经网络学习到的输入-输出映射在很大程度上是不连续的。我们可以通过应用某些难以感知的扰动使网络对图像进行错误的分类，这些扰动使通过最大化网络的预测误差发现的。除此之外，这些扰动的特定性质不是学习的随机产物，相同的扰动会导致在数据集的不同子集上训练的不同网络对相同输入进行错误的分类。</p>
<h2 id="1-引言"><a href="#1-引言" class="headerlink" title="1. 引言"></a>1. 引言</h2><p>深度神经网络使功能强大的学习模型，可以在视觉和语音识别问题上表现出出色的性能。神经网络之所以可以达到高性能是因为它们可以表达任意的计算，这些计算由适量的大量的并行非线性步骤组成。但是由于结果计算是通过监督学习的反向传播机制发现的，因此可能很难解释并且拥有反直觉的特性。（注：这里说的反直觉特性指的是网络，而不是指的反向传播机制）在本文中我们讨论了深度神经网络两个反直觉特性。</p>
<p>第一个属性与单个单元的语义有关。先前的工作通过找到最大程度地激活给定单元的输入集来分析各种单元的语义含义。对单个单元的检查隐含了一个假设，即最后一个特征层的单元形成了一个可区分的基础，这对于提取语义信息特别有用。我们将在第三部分证明$\phi(x)$的随机投影和$\phi(x)$的坐标在语义上是不可区分的，这使人们对神经网络解开坐标间变化因素的猜想提出了质疑。一般来说，是整个激活的空间而不是单个的神经元包含了语义信息。Mikolov等人最近对单词的表示得出了一个相似但强的结论，他们发现单词的表征在矢量空间的各个方向上拥有令人惊讶的丰富的语义编码的关系和类比。同时，向量表示在空间旋转之前都是稳定的，因此矢量表示的各个单元不太可能包含语义信息。</p>
<p>第二个属性和神经网络对输入的微扰的稳定性相关。考虑一个性能优异的深度神经网络，它的泛化性能优秀并且在物体识别任务上取得良好性能。我们期望这样的神经网络能在输入由微小扰动的情况下依然具备鲁棒性，因为小的扰动不会图像的对象类别。但是我们发现将不可察觉的非随机扰动应用于测试图像后，就可以任意地干预到网络的预测结果。这些扰动是通过优化输入后最大化预测误差得到的，我们把这些干扰的样本称为“对抗性样本”。</p>
<p>我们很自然地期望最小的必要干扰的精确配置实在反向传播学习中不同的运行过程下出现的正常变异性的随机伪像。然而我们发现对抗性样本是相当鲁棒的，并且在具有不同层数、激活次数或在训练数据的子集上训练的神经网络上都能干扰。也就是说，如果我们使用一个神经网络生成一组对抗样本，则会发现这些样本对于另一个神经网络在统计学的角度上看依然被很难被正确分类，尽管其他的神经网络使用了不同的超参数、不同的样本数据训练。</p>
<p>这些结果表明，通过反向传播学习的神经网络具有非直觉特性和固有盲点，其结构与数据分布相关，只不过这种分布不能被显示地观察到。</p>
<h2 id="2-框架"><a href="#2-框架" class="headerlink" title="2. 框架"></a>2. 框架</h2><p>定义： 我们使用$x\in\mathbb{R}^m$表示输入图像，$\phi(x)$表示某层的激活值。我们首先检查$\phi(x)$的属性，然后搜索其盲点。我们在不同的网络上对三个数据集进行了实验：</p>
<ul>
<li>对于<code>MNIST</code>数据集，我们使用了如下的配置：<ul>
<li>具有一个或多个隐藏层和softmax的分类器的简单的全连接网络。我们称其为<code>FC</code>。<ul>
<li>一个自动编码器上训练的分类器，我们称其为<code>AE</code>。</li>
</ul>
</li>
</ul>
</li>
<li><code>ImageNet</code>数据集：<ul>
<li>使用了Krizhevsky的架构。我们称其为`AlexNet`。</li>
</ul>
</li>
<li>~10M的<code>Youtube</code>样本：<ul>
<li>无监督的训练网络，大约有10亿可学习参数。我们称其为<code>QuocNet</code>。</li>
</ul>
</li>
</ul>
<p>对于<code>MNIST</code>数据集上的实验，我们使用了权重衰减为$\lambda$的正则化方法。此外，在一些实验中，我们将<code>MNIST</code>上训练的数据集分为两个子集$P_1$和$P_2$，每一个子集都有30,000个样本。</p>
<h2 id="3-phi-x-的单元"><a href="#3-phi-x-的单元" class="headerlink" title="3. $\phi(x)$的单元"></a>3. $\phi(x)$的单元</h2><p>传统的计算机视觉系统依赖于特征提取：通常单个特征很容易解释，比如说颜色的直方图或量化的局部导数。这允许研究者去检查特征空间中的每一个体的坐标，并将它们与语义丰富的原始图像进行连接。先前的工作在分析应用神经网络解决计算机视觉问题时使用了相似的机理。这些工作将一个激活的隐藏层单元作为一个有意义的特征，他们寻找一种一种使该单一特征激活值最大化的输入图形。</p>
<p>前面提及的这种技术可以正式表述为图像$x’$的视觉检查，这些图像满足(或接近最大可到达值)：</p>
<script type="math/tex; mode=display">
\begin{equation}
x'={\arg\max_{x\in \mathcal{I}}}<\phi(x),e_i>
\end{equation}</script><p>其中，$I$为未接受网络训练的数据分布的图像集，$e_i$为第$i$个隐藏单元关联的自然基向量。我们的实验表明，任何随机方向$v\in\mathbb{R}^n$都会产生相似的可解释性的语义属性。更正式地说，我们发现图像$x’$在语义上彼此相关，对于许多$x’$:</p>
<script type="math/tex; mode=display">
\begin{equation}
x'=\arg\max_{x\in\mathcal{I}}<\phi(x),v>
\end{equation}</script><p>这说明对于检查$\phi(x)$的属性而言，自然基向量并不会比随机的基向量效果更好。这使人们对神经网络解开坐标间变化因素的猜想提出了质疑。（注：我也没看太懂，原文是’This puts into question the notion that neural networks disentangle variation factors across coordinates.‘）</p>
<p>首先，我们在<code>MNIST</code>数据集上训练卷积神经网络以评估我们上述的想法。我们使用MNIST的测试集作为$\mathcal{I}$。图1展示了自然基础上的最大化的激活图像，图2展示了在随机方向上的最大化激活图像。在这两种情况下，两种图像都有许多高层的相似性。</p>
<p><img src="https://s2.loli.net/2023/01/08/8Ijb64hRkMZitQE.png" alt="image-20230108121431769"></p>
<p><img src="https://s2.loli.net/2023/01/08/s7i6oE4DayCWmJ1.png" alt="image-20230108121445747"></p>
<p>接着我们在<code>AlexNet</code>上重复了我们的实验，我们使用了验证集作为$\mathcal{I}$。图3和图4对比了训练网络上的随机和自然基向量。对于单个单元以及单元的组合，每行所展示的语义似乎都是有意义的。</p>
<p><img src="https://s2.loli.net/2023/01/08/y2CkhfwdpJVL4va.png" alt="image-20230108121616692"></p>
<p><img src="https://s2.loli.net/2023/01/08/apkgcMl8CFHZeAq.png" alt="image-20230108121636897"></p>
<p>尽管这种分析提供了关于$\phi$在输入分布的特定子集上生成不变性的能力的见解，但它并未解释其其余域的行为。在下一节中，我们将看到$\phi$在几乎每个点形式的数据分布附近都具有违反直觉的特性。</p>
<h2 id="4-神经网络的盲点"><a href="#4-神经网络的盲点" class="headerlink" title="4. 神经网络的盲点"></a>4. 神经网络的盲点</h2><p>到目前为止，除了确认有关由深度神经网络学习的表示的复杂性的某些直觉之外，单元级检查方法的实用性相对较小。全局的网络级别检查方法在解释模型做出的分类决策时可能很有用，并且可以用于例如识别导致对给定视觉输入实例进行正确分类的输入部分。换句话说，可以使用经过训练的模型进行弱监督定位。这样的全局分析很有用，因为它们可以使我们更好地理解受过训练的网络所代表的输入到输出映射。</p>
<p>一般来说，神经网络的输出层单元是其输入的高度非线性函数。当使用交叉熵损失对其进行训练时（使用Softmax激活函数），它表示给定输入（以及到目前为止提供的训练集）的标签的条件分布。有人认为，在神经网络的输入和输出单元之间的非线性层的深层堆栈是模型在输入空间上编码非局部泛化先验的一种方法。换句话说，假设输出单元可以为输入空间的各个区域分配非重要（可能是非$\varepsilon$）概率，而未训练的样本就在这个邻域中。例如，这些区域是可以从不同的角度对相同的对象及逆行表示，这些对象在像素空间中相对较远，但是以他们共享原始输入的标签和统计特性。</p>
<p>如上的想法意味着局部的泛化在训练过程中可以如期地工作。尤其是在给定训练输入$x$时添加的一个足够小的半径$\varepsilon&gt;0$(注：这个半径我的理解是某些语义弱相关的信息或者无关信息的延伸)，满足$||r||&lt;\varepsilon$的的样本$x+r$将会被模型输出到一个较高的正确类别的概率。这种平滑的先验通常对计算机视觉的问题有效，因为通常来说，给定图像细微的扰动不会改变其基础的类别。</p>
<p>我们的主要结果是，对于深度的神经网络，许多核方法在平滑假设阶段就不成立了。具体而言，我们通过使用简单的优化方法找到了对抗样本，这些样本时通过对正确分类的输入图像进行不明显的微小扰动获得的，所以将不再被正确分类。</p>
<p>从某种意义上说，我们所描述的是一种以有效方式（通过优化）遍历网络所表示的流形(注：Manifolds)并在输入空间中找到对抗样本的方法。对抗样本代表的就是流形中的低概率（但是高维的）的”口袋“，他们很难仅通过围绕给定的样本随机地对输入进行采样得到。目前，各种最新的计算机视觉模型都在训练过程中采用了输入变换，以提高模型的鲁棒性和收敛速度。但是对于给定的样本，这些变换在统计上效率低下：因为他们高度相关，并且在整个模型训练过程中都是从相同的分布中得出的（？也许说的是数据增强）。我们提出了一种使该过程具有自适应性的方案，该方案利用了模型及其在训练数据的局部空间建模中的缺陷。</p>
<p>我们在本质上很接近难负样本挖掘，这与它密切相关：在计算机视觉中，难负样本挖掘包括识别训练集示例（或其中的一部分），这些示例被模型赋予了较低的概率，但是应该相反，为高概率。然后更改训练集分布，以强调这种难负样本，并执行下一轮模型训练。如将要描述的那样，这项工作中提出的最优化问题也可以以建设性的方式使用，类似于难负样本挖掘原理。</p>
<h3 id="4-1-规范表述"><a href="#4-1-规范表述" class="headerlink" title="4.1 规范表述"></a>4.1 规范表述</h3><p>我们用$f:\mathbb{R}^M\rightarrow\{1\dots k\}$表示一个将图像像素值向量到离散标签集的分类器。我们假设$f$有一个相关的连续损失函数$loss_f:\mathbb{R}^m\times \{1\dots k\}\rightarrow \mathbb{R}^+$。对于一个给定的$x\in \mathbb{R}^m$的图像和标签$l\in \{1\dots k\}$，我们旨在解决如下盒约束的优化问题：</p>
<ul>
<li>最小化$||r||_2$，使得<ol>
<li>$f(x+r)=l$;</li>
<li>$x+r\in[0,1]^m$</li>
</ol>
</li>
</ul>
<p>最小化器 $r$可能不是唯一的，但是我们将其定义为从$D(x,l)$随机抽取的一个并将其用于表示$x+r$。不正式地说，$x+r$就是一张能被$f$分类为$l$的最接近的图片。显然，$D(x,f(x))=f(x)$，因此这个任务只有当$f(x)\neq l$的时候才有意义。(D的定义在4.2部分，它是一个（率？）失真函数)通常来说，$D(x,l)$的精准计算是一个困难的问题，因此我们使用盒约束的L-BFGS方法进行近似。具体来说就是，我们通过线性搜索找到一个最小的$c&gt;0$来找到$D(x,l)$的近似。对于这个最小值，下面问题的$r$需要满足$f(x+r)=l$：</p>
<ul>
<li>最小化 $c|r|+loss_f(x+r,l)$，同时满足约束$x+r\in [0,1]^m$</li>
</ul>
<p>在凸损失的情况下，这种惩罚函数方法将给出$D(x,l)$的精确解，但是神经网络通常是非凸的，因此这种情况下我们一般只能得到一个近似值。</p>
<h3 id="4-2-实验结果"><a href="#4-2-实验结果" class="headerlink" title="4.2 实验结果"></a>4.2 实验结果</h3><p>我们的最小失真函数$D$具有如下有趣的属性，我们将在本节通过非正式的证据和定量实验支撑我们的观点：</p>
<ol>
<li><p>对于我们研究的所有网络（MNIST，QuocNet，AlexNet），对于每个样本，我们都能生成非常接近、在视觉上难以区分的对抗样本，这些样本被上述网络错误分类。</p>
<p><img src="https://s2.loli.net/2023/01/08/EiKWRVOqC1om9uj.png" alt="image-20230108121907193"></p>
<p><img src="https://s2.loli.net/2023/01/08/7T5RlWgpLyrKbeN.png" alt="image-20230108122008696"></p>
</li>
<li><p>对抗样本具有跨模型的泛化能力：在A模型上产生的对抗样本，有很大一部分在B模型（和A模型结构相同，超参数不同）上也有效（也能是B模型错误分类）；</p>
</li>
<li><p>跨训练数据的泛化能力：相当大的一部分样本就会被网络错误地输出分类，这些网络都是从给定训练集的子集中训练得到的。</p>
</li>
</ol>
<p>上述观察结果表明，对抗样本在某种程度上是普遍的，而不仅仅是过度拟合特定模型或特定选择训练集的结果。这些结果还表明，将对抗样本用于训练可能会提高结果模型的通用性。我们的初步实验也为<code>MNIST</code>提供了积极的证据来支持这一假设：我们通过保留一组对抗样本作为随机子集，成功地训练了两层100-100-10非卷积神经网络，其测试误差低于1.2％其中不断被新生成的对抗样本所取代，并始终与原始训练集中混合。我们使用了权重衰减，但该网络没有dropout。为了进行比较，如果仅通过权重衰减对其进行调整，则该大小的网络的误差为1.6％，并且可以通过使用精心应用的dropout将其提高到1.3％左右。一个微妙但必不可少的细节是，我们仅通过为每层输出生成对抗样本来进行改进，这些示例用于训练以上所有层。该网络以交替的方式进行了训练，除了原始训练集之外，还分别维护和更新了每一层的对抗样本库。根据我们的初步观察，高层的对抗样本似乎比输入层或较低层的对抗样本有用得多。在未来的工作中，我们计划系统地比较这些影响。</p>
<p>出于空间考虑，我们只介绍我们执行的<code>MNIST</code>实验的代表性子集（参见下表）的结果，此处显示的结果与各种非卷积模型的结果一致。 </p>
<p><img src="https://s2.loli.net/2023/01/08/Ibknxtr9aq1CXfe.png" alt="image-20230108121754870"></p>
<p>对于<code>MNIST</code>，我们尚无卷积模型的结果，但我们与<code>AlexNet</code>进行的首次定性实验使我们有理由相信卷积网络的行为也可能相似。我们的每个模型都经过L-BFGS训练，直到收敛为止。前三个模型是线性的分类器，他们工作在具有各种权重衰减参数$\lambda$上。</p>
<p>我们证明了深度神经网络在单个单元的语义含义和不连续性方面都具有违反直觉的属性。 对抗性负面因素的存在似乎与该网络实现高泛化性能的能力相矛盾。的确，如果网络能够很好地推广，那么如何将这些对抗性的否定与常规的例子区分开来呢？可能的解释是，对抗性否定集的可能性极低，因此从未（或很少）在测试集中观察到，但是它很密集（很像有理数），因此几乎在每个测试用例中都可以找到它。但是，我们对对抗性否定出现的频率没有深刻的了解，因此应该在以后的研究中解决这个问题。我们所有的样本都使用了二次权重衰减：即$loss_{decay}=\lambda\sum w_i^2/k$将被添加到总的损失中，其中$k$是每层的单元数量。我们的三个模型都是简单的线性(softmax)的分类器，没有任何的隐藏单元$(\mathrm{FC10(\lambda))}$。其中的一个$\mathrm{FC10(1)}$使用了很高的衰减，即$\lambda=1$的值训练以用于测试是否仍可能在极端的训练条件下产生对抗样本。另外两个模型是简单的sigmoid神经网络，由两个隐藏层和一个分类器组成。最后一个模型，$\mathrm{AE400-10}$由单层的稀疏编码器和sigmoid激活函数以及400个节点的Softmax分类器组成。这个网络已经被训练好，在第一层已经具备了高质量的过滤器，并且这层并没有微调。最后一列测量了训练集上达到0%准确率的最小平均像素失真情况。失真的测量使用了$\sqrt{\frac{\sum(x’_i-x_i)^2}{n}}$以衡量原始的$x$和失真的$x’$程度，其中$n=784$代表的是图像像素的大小。像素值被缩放到了$[0,1]$区间。</p>
<p>在我们的第一个实验中，我们为给定的网络生成了一组对抗样本，并为每个其他网络提供了这些实例，以衡量误分类实例的比例。最后一列显示在整个训练集上达到0％准确度所需的平均最小失真。实验结果显示在下表中。</p>
<p>表7的列展示了这种失真的训练集上的错误（错误分类实例的比例）。最后两行作为参考，展示了当给定量的高斯噪声而失真时引起的误差。</p>
<p><img src="https://s2.loli.net/2023/01/08/C98QaESgJ3plsjn.png" alt="image-20230108122229083"></p>
<p>值得注意的是，对于除其中一个模型以外的所有模型，即使标准差为0.1的噪声也大于我们对抗性噪声的标准差。图7展示了该实验中使用的两个网络生成的对抗样本的可视化。总的结论是，即使对于使用不同超参数训练的模型，对抗样本也趋于困难。尽管基于自动编码器的版本似乎可以克服对抗样本的攻击，但也不能完全免疫。</p>
<p><img src="https://s2.loli.net/2023/01/08/ElZQVaXiNGxFq39.png" alt="image-20230108122103098"></p>
<p>尽管如此，实验仍有问题没有解决，这些问题来自训练集。生成的样本的难度是否仅取决于我们从训练集中特定选择的样本，还是这种效果甚至可以泛化到在完全不同的训练集上训练的模型？</p>
<p>为了研究交叉训练集的泛化性能，我们将60000个MNIST训练图像划分为大小分别为30000的两个部分$P_1$和$P_2$，并训练了三个具有Sigmod型激活的非卷积网络：两个网络FC100-100-10和FC123-456-10在$P_1$上训练以及一个网络FC100-100-10在$P_2$上训练。我们为$P_1$训练两个网络的原因是要研究同时更改超参数和训练集的累积效果。FC100-100-10和FC100-100-10共享相同的超参数：它们都是100-100-10网络，而FC123-456-10具有不同数量的隐藏单元。在这个实验中，失真的对象是测试集的样本而非训练集的样本。表3总结了有关这些模型的基本情况。</p>
<p>在为测试集生成具有100％错误率且失真最小的对抗样本之后，我们将这些样本输入给每个模型。表4上部的相应栏中显示每个模型对应的错误率。最后的实验中我们使用了失真程度为$x+0.1\frac{x’-x}{||x’-x||_2}$的样本而不是单纯的$x’$。这种变化使得是真成都提高了40%，标准差从0.06扩大到0.1。这种失真的样本将反馈到每个模型，对应的错误率也显示在表4的下部。</p>
<p><img src="https://s2.loli.net/2023/01/08/GZhxJKWU8b5IpDm.png" alt="image-20230108122316335"></p>
<p>有趣的结论是，即便在不相交的训练集上训练的模型，对抗样本依然很难找到，但他们的有效性也大大降低。</p>
<h3 id="4-3-不稳定性的谱分析"><a href="#4-3-不稳定性的谱分析" class="headerlink" title="4.3 不稳定性的谱分析"></a>4.3 不稳定性的谱分析</h3><p>前一节中我们展示了纯监督训练得到的深度神经网络的样例在某些微小的扰动下是不稳定的。对抗样本展示了存在一种微小的加性(欧几里得意义上的)输入干扰可以在网络的最后一层的输出中产生较大的扰动，这种特性独立于训练集和网络。本节将描述一种简单的方法，通过测量每一矫正后的层的测量以控制网络的额外稳定性。（注：不知道这个矫正是怎么矫正的，文中也没提及）</p>
<p>从数学的角度来讲，如果$\phi(x)$表示拥有训练参数$W$的对输入为$x$时的$K$层网络的输出，我们将其写为：</p>
<script type="math/tex; mode=display">
\phi(x)=\phi_K(\phi_{K-1}(\dots\phi_1(x;W_1);W_2)\dots;W_K)</script><p>其中，$\phi_k$表示了第$k-1$层到第$k$层的映射。$\phi(x)$的稳定性可以通过检查每一层 $k=1\dots K$的<a href="https://encyclopediaofmath.org/wiki/Lipschitz_constant">Lipschitz常数</a>上半部分进行表征，定义这个常数$L_K&gt;0$为：</p>
<script type="math/tex; mode=display">
\forall x,r,||\phi_k(x;W_k)-\phi_k(x+r;W_k)||\leq L_k||r||</script><p>这样训练得到的网络将因此满足$||\phi(x)-\phi(x+r)||\leq L||r||$，其中$L=\prod_{k=1}^{K}L_k$。</p>
<p>一个半矫正后的层（无论是卷积层还是全连接层）都通过映射$\phi_k(x;W_k,b_k)=\max (0,W_kx+b_k)$定义。令$||W||$表示$W$的算子范数（比如说它的极大值）。由于非线性函数$\rho(x)=\max(0,x)$是有界的，比如说它对于所有的$x,r$都满足$||\rho(x)-\rho(x+r)||\leq|r|$。同时也遵循：</p>
<script type="math/tex; mode=display">
||\phi_k(x;W_k)-\phi_k(x+r;W_k)||=||\max(0,W_kx+b_k)-\max(0,W_k(x+r)+b_k)||\leq||W_kr||\leq||W_k||||r||</script><p>因此满足$L_k\leq||W_k||$。另一方面，最大池化层的$\phi_k$也是有界的：</p>
<script type="math/tex; mode=display">
\forall x,r, ||\phi_k(x)-\phi_k(x+r)||\leq||r||</script><p>由于其雅各比矩阵就是输入坐标子集的一个投影，并因此不会扩张其梯度。最后，如果$\phi_k$是一个对比归一化层</p>
<script type="math/tex; mode=display">
\phi_k(x)\frac{x}{(\varepsilon+||x||^2)^\gamma}</script><p>那么可以证明，对于任意的$\gamma\in[0.5,1]$均有：</p>
<script type="math/tex; mode=display">
\forall x,r, ||\phi_k(x)-\phi_k(x+r)||\leq\varepsilon^{-\gamma}||r||</script><p>其中$\gamma$的取值可以对应到大部分的网络层处理方式。</p>
<p>下面我们就可以通过简单的计算每一全连接层和卷积层的算子范数得到一个测量网络不稳定性的保守测量。全连接层的计算很简单，因为其范数通过全连接矩阵的的极大值直接给出，我们主要探究卷积层的情况。假设$W$是一个普通的4维张量，输入特征数为$C$，输出特征数为$D$，支持$N\times N$大小以及空间步长为$\Delta$的运算，有：</p>
<script type="math/tex; mode=display">
W_x=\{\sum_{c=1}^{C}x_c\star w_{c,d}(n_1\Delta,n_2\Delta);d=1\dots,D\}</script><p>其中，$x_c$表示第$c$个输入特征图像，$w_{c,d}$表示对应输入特征为$c$以及输出特征为$d$ 的空间卷积核，使用帕斯瓦尔公式我们可以饿到他的操作算子为：</p>
<script type="math/tex; mode=display">
||W||=\sup_{\xi\in[0,N\Delta ^{-1})^2}||A(\xi)||</script><p>其中，$A(\xi)$是一个$D\times (C\cdot \Delta^2)$的矩阵，它的行表示为：</p>
<script type="math/tex; mode=display">
\forall d=1\dots D,A(\xi)_d=(\Delta^{-2}\widehat{w_{c,d}}(\xi+l\cdot N\cdot \Delta^{-1});c=1\dots C,l=(0\dots \Delta-1)^2)</script><p>其中，$\widehat{w_{c,d}}$为$w_{c,d}$二维傅里叶变换：</p>
<script type="math/tex; mode=display">
\widehat{w_{c,d}}(\xi)-=\sum_{u\in[0,N)^2}w_{c,d}(u)e^{-2\pi i (u\cdot \xi)/N^2}</script><p>表5展示了从<code>ImageNet</code>训练的深度神经网络（即<code>AlexNet</code>）使用式(1)计算的Lipschitz常数的上边界。它表明不稳定性可以在很快得再第一层卷积层就出现了。</p>
<p>这些结果与上一节中构造的盲点的出现是一致的，但是它们并没有试图解释为什么这些对抗样本会针对不同的超参数或训练集有泛化效果。 我们强调我们计算上限：大的界限并不会是对抗性示例的存在的原因； 但是，小的边界范围可保证不会出现此类对抗性样本。 这表明可以对参数进行简单的正则化，包括对每个利普希茨上界进行惩罚，这可能有助于改善网络的泛化误差。</p>
<h2 id="5-讨论"><a href="#5-讨论" class="headerlink" title="5. 讨论"></a>5. 讨论</h2><p>我们证明了深度神经网络在单个单元的语义含义和不连续性方面都具有违反直觉的属性。 对抗性负面因素的存在似乎与该网络实现高泛化性能的能力相矛盾。的确，如果网络能够很好地推广，那么如何将这些对抗性的否定与常规的例子区分开来呢？可能的解释是，对抗性否定集的可能性极低，因此从未（或很少）在测试集中观察到，但是它很密集（很像有理数），因此几乎在每个测试用例中都可以找到它。但是，我们对对抗性否定出现的频率没有深刻的了解，因此应该在以后的研究中解决这个问题。</p>
<h2 id="参考文献"><a href="#参考文献" class="headerlink" title="参考文献"></a>参考文献</h2><p>略</p>
]]></content>
      <categories>
        <category>学习记录</category>
      </categories>
      <tags>
        <tag>文献翻译</tag>
        <tag>神经网络</tag>
        <tag>对抗攻击</tag>
      </tags>
  </entry>
  <entry>
    <title>Python装饰器解析与使用场景</title>
    <url>/2022/10/15/Python%E8%A3%85%E9%A5%B0%E5%99%A8/</url>
    <content><![CDATA[<p><img src="https://s2.loli.net/2022/10/15/EwZH8YS1Nkt67mr.jpg" alt="img"></p>
<p>如果你是开发人员，那装饰器对你开发调试有很大帮助。装饰器作为python这门语言特有的一个东西，和其他语言的东西很不一样，而且网上的例子又很让人退却三步，所以我看了一位B站up主的<a href="https://www.bilibili.com/video/BV1Gu411Q7JV/?spm_id_from=333.999.0.0&amp;vd_source=ab34db443b112b108b42c31ac575fd1f">视频</a>后就大概理清楚了，也推荐大家关注一下。</p>
<span id="more"></span>
<h2 id="函数是什么"><a href="#函数是什么" class="headerlink" title="函数是什么"></a>函数是什么</h2><p>函数就是一段可以复用的代码段，这是每门语言都有的东西。但是python中的函数与其他语言中的函数的区别，或者说python这门语言和其他语言的本质区别就在于，python中的任何东西都是一个<code>object</code>：</p>
<p><img src="https://s2.loli.net/2022/10/15/Fv1QB8wEZpCPKus.png" alt="image-20221015211022717"></p>
<center><small>编译后的字节码，摘自Up主@码农高天 视频</small></center>

<p>我们可以看到整个过程就是1.先把<code>code object</code>加载进来2.加载函数名称<code>double</code>3.制作了一个<code>function obeject</code>4.将function object保存到double里面。因此定义函数的整个过程就是：新建一个变量，然后在变量里面保存一个<code>function object</code>。</p>
<h3 id="函数作为参数"><a href="#函数作为参数" class="headerlink" title="函数作为参数"></a>函数作为参数</h3><p>python中的函数对象有一个特点，那就是<code>callable</code>的，这意味着你可以调用它。到这里你也能理解了所谓的函数对象也只不过是一个普通的对象而已，它也可以作为参数传入其他函数：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">double</span>(<span class="params">x</span>):</span><br><span class="line">    <span class="keyword">return</span> x * <span class="number">2</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">triple</span>(<span class="params">x</span>):</span><br><span class="line">    <span class="keyword">return</span> x * <span class="number">3</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">cal_number</span>(<span class="params">func,x</span>):</span><br><span class="line">    <span class="built_in">print</span>(func(x))</span><br><span class="line">    </span><br><span class="line">cal_number(double,<span class="number">3</span>)</span><br><span class="line">cal_number(triple,<span class="number">3</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment">#6 9</span></span><br></pre></td></tr></table></figure>
<h3 id="函数作为返回值"><a href="#函数作为返回值" class="headerlink" title="函数作为返回值"></a>函数作为返回值</h3><p>作为参数和作为返回值都体现着函数只不过是一个普通的对象这一事实，因此我们可以这样定一个函数：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">triplet_loss</span>(<span class="params">alpha = <span class="number">0.2</span></span>):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">_triplet_loss</span>(<span class="params">y_pred,Batch_size</span>):</span><br><span class="line">        anchor, positive, negative = y_pred[:<span class="built_in">int</span>(Batch_size)], y_pred[<span class="built_in">int</span>(Batch_size):<span class="built_in">int</span>(<span class="number">2</span>*Batch_size)], y_pred[<span class="built_in">int</span>(<span class="number">2</span>*Batch_size):]</span><br><span class="line"></span><br><span class="line">        pos_dist = torch.sqrt(torch.<span class="built_in">sum</span>(torch.<span class="built_in">pow</span>(anchor - positive,<span class="number">2</span>), axis=-<span class="number">1</span>))</span><br><span class="line">        neg_dist = torch.sqrt(torch.<span class="built_in">sum</span>(torch.<span class="built_in">pow</span>(anchor - negative,<span class="number">2</span>), axis=-<span class="number">1</span>))</span><br><span class="line">        </span><br><span class="line">        keep_all = (neg_dist - pos_dist &lt; alpha).cpu().numpy().flatten()</span><br><span class="line">        hard_triplets = np.where(keep_all == <span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">        pos_dist = pos_dist[hard_triplets]</span><br><span class="line">        neg_dist = neg_dist[hard_triplets]</span><br><span class="line"></span><br><span class="line">        basic_loss = pos_dist - neg_dist + alpha</span><br><span class="line">        loss = torch.<span class="built_in">sum</span>(basic_loss) / torch.<span class="built_in">max</span>(torch.tensor(<span class="number">1</span>), torch.tensor(<span class="built_in">len</span>(hard_triplets[<span class="number">0</span>])))</span><br><span class="line">        <span class="keyword">return</span> loss</span><br><span class="line">    <span class="keyword">return</span> _triplet_loss</span><br></pre></td></tr></table></figure>
<p>这是我在做人脸识别的时候写的一个损失函数。它的使用过程是这样的：传入一个alpha的参数然后返回一个<code>_triplet_loss</code>函数，这个<code>_triplet_loss</code>函数的具体返回值就是<code>loss</code>。使用时是这样的：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">loss_fn = triplet_loss()</span><br><span class="line">loss = loss_fn(y_hat,batch_size)</span><br><span class="line"></span><br><span class="line"><span class="comment">#0.012</span></span><br></pre></td></tr></table></figure>
<p>注意一点：这和<code>Pytroch</code>里面常用的那几个损失函数不一样，尽管他们的使用语法很相近：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> torch.nn <span class="keyword">as</span> nn</span><br><span class="line"></span><br><span class="line">loss_fn = nn.CrossEntropyLoss()</span><br><span class="line">loss = loss_fn(output, target)</span><br></pre></td></tr></table></figure>
<p>但是他们的本质是一样的。<code>Pytorch</code>中的<code>loss_fn</code>是一个对象的实例化，然后通过重写对象的<code>__call__</code>方法调用<code>nn</code>模块的标准<code>foward()</code>函数进行运算，所以是在函数中调用函数，调用<code>__call__</code>方法的就是类装饰器中执行的函数。</p>
<h2 id="假如我要测个时间"><a href="#假如我要测个时间" class="headerlink" title="假如我要测个时间"></a>假如我要测个时间</h2><p>其实也不用假如，因为按现在这个就业形式迟早都会变成开发…言归正传，在刚刚看完罗里吧嗦一大堆之后我们放松下设想一个场景：</p>
<p>你需要测试一个函数<code>Deny996()</code>的运行时间，你怎么办？你二话不说：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">Deny996</span>()():</span><br><span class="line">	<span class="keyword">return</span> <span class="literal">None</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> time</span><br><span class="line">start = time.time()</span><br><span class="line">Deny996()</span><br><span class="line"><span class="built_in">print</span>(time.time()-start)</span><br><span class="line"><span class="comment"># 0.0</span></span><br></pre></td></tr></table></figure>
<p>非常的简单！但是问题来了，下面你老板让你继续测其他的函数运行时间：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">Deny997</span>():</span><br><span class="line">    <span class="keyword">return</span> <span class="literal">None</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">Deny007</span>():</span><br><span class="line">    <span class="keyword">return</span> <span class="literal">None</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">Deny667</span>():</span><br><span class="line">    <span class="keyword">return</span> <span class="literal">None</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">Deny887</span>():</span><br><span class="line">    <span class="keyword">return</span> <span class="literal">None</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">Deny995</span>():</span><br><span class="line">    <span class="keyword">return</span> <span class="literal">None</span></span><br><span class="line">...</span><br></pre></td></tr></table></figure>
<p>你说这简单，就是废我的<code>ctrl</code>键和<code>c</code>键<code>v</code>键。为了避免这种低效的方法，我们使用了装饰器：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">Deny996</span>():</span><br><span class="line">    <span class="keyword">return</span> <span class="literal">None</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">count_time</span>(<span class="params">func</span>):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">wrapper</span>():</span><br><span class="line">        start = time.time()</span><br><span class="line">        func()</span><br><span class="line">        <span class="built_in">print</span>(time.time()-start)</span><br><span class="line">    <span class="keyword">return</span> wrapper</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&quot;__main__&quot;</span>:</span><br><span class="line">    func = count_time(Deny996)</span><br><span class="line">    func()	<span class="comment">#相当于执行wrapper()</span></span><br></pre></td></tr></table></figure>
<p>这里面的<code>count_time</code>就是一个装饰器，这里面又定义了一个函数<code>wrapper</code>，并把<code>func</code>作为参数放进来运行。当然啦<code>wrapper</code>的名字可以随便起，只要符合变量命名规则就行。</p>
<h2 id="装饰器的语法糖"><a href="#装饰器的语法糖" class="headerlink" title="装饰器的语法糖"></a>装饰器的语法糖</h2><p>其实大家对装饰器的语法糖更熟悉，它的符号是<code>@</code>。上面的那段代码可以用这样来等价替代：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">count_time</span>(<span class="params">func</span>):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">wrapper</span>():</span><br><span class="line">        start = time.time()</span><br><span class="line">        func()</span><br><span class="line">        <span class="built_in">print</span>(time.time()-start)</span><br><span class="line">    <span class="keyword">return</span> wrapper</span><br><span class="line"></span><br><span class="line"><span class="meta">@count_time</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">Deny996</span>():</span><br><span class="line">    <span class="keyword">return</span> <span class="literal">None</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&quot;__main__&quot;</span>:</span><br><span class="line">    Deny996()</span><br></pre></td></tr></table></figure>
<h2 id="但是我的函数需要传入参数…"><a href="#但是我的函数需要传入参数…" class="headerlink" title="但是我的函数需要传入参数…?"></a>但是我的函数需要传入参数…?</h2><p>很明显我写的装饰器只考虑了固定形式的参数，但是万一我有一个装饰器是对不同参数设置的函数进行测试呢？或者说我希望我的装饰器也能通过参数更改功能怎么办？</p>
<h3 id="装饰器传参"><a href="#装饰器传参" class="headerlink" title="装饰器传参"></a>装饰器传参</h3><p>我们先看装饰器传入参数。Python中对不定参数传入有个办法：<code>*args</code>和<code>**kwargs</code>。前者是传入非键值对参数，后者是传入键值对函数比如说字典类型的变量。给个例子：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> time</span><br><span class="line"> </span><br><span class="line"><span class="keyword">def</span> <span class="title function_">count_time</span>(<span class="params">func</span>):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">wrapper</span>(<span class="params">*args, **kwargs</span>):</span><br><span class="line">        t1 = time.time()</span><br><span class="line">        func(*args, **kwargs)</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&quot;执行时间为：&quot;</span>, time.time() - t1)</span><br><span class="line"> </span><br><span class="line">    <span class="keyword">return</span> wrapper</span><br><span class="line"></span><br><span class="line"><span class="meta">@count_time</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">Deny996</span>(<span class="params">name1,name2</span>):</span><br><span class="line">    <span class="built_in">print</span>(name1,name2)</span><br><span class="line">    </span><br><span class="line"><span class="meta">@count_time</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">Deny997</span>(<span class="params">name</span>):</span><br><span class="line">    <span class="built_in">print</span>(name)</span><br><span class="line">    </span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&quot;__main__&quot;</span>:</span><br><span class="line">    Deny996(<span class="string">&quot;hello&quot;</span>,<span class="string">&quot;world&quot;</span>)</span><br><span class="line">    Deny997(<span class="string">&quot;Capitalism&quot;</span>)</span><br></pre></td></tr></table></figure>
<h3 id="装饰器带参"><a href="#装饰器带参" class="headerlink" title="装饰器带参"></a>装饰器带参</h3><p>很简单，就是用装饰器去装饰装饰器：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> time</span><br><span class="line"> </span><br><span class="line"><span class="keyword">def</span> <span class="title function_">count_time_args</span>(<span class="params">msg = <span class="literal">None</span></span>)：</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">count_time</span>(<span class="params">func</span>):</span><br><span class="line">        <span class="keyword">def</span> <span class="title function_">wrapper</span>(<span class="params">*args, **kwargs</span>):</span><br><span class="line">            t1 = time.time()</span><br><span class="line">            func(*args, **kwargs)</span><br><span class="line">            <span class="built_in">print</span>(<span class="string">&quot;&#123;&#125;执行时间为：&quot;</span>.<span class="built_in">format</span>(msg), time.time() - t1)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> wrapper</span><br><span class="line">    <span class="keyword">return</span> count_time</span><br><span class="line"></span><br><span class="line"><span class="meta">@count_time_args(<span class="params">msg=<span class="string">&quot;996&quot;</span></span>)</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">Deny996</span>(<span class="params">name1,name2</span>):</span><br><span class="line">    <span class="built_in">print</span>(name1,name2)</span><br><span class="line">    </span><br><span class="line"><span class="meta">@count_time_args(<span class="params">msg=<span class="string">&quot;997&quot;</span></span>)</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">Deny997</span>(<span class="params">name</span>):</span><br><span class="line">    <span class="built_in">print</span>(name)</span><br><span class="line">    </span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&quot;__main__&quot;</span>:</span><br><span class="line">    Deny996(<span class="string">&quot;hello&quot;</span>,<span class="string">&quot;world&quot;</span>)</span><br><span class="line">    Deny997(<span class="string">&quot;Capitalism&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># hello world</span></span><br><span class="line"><span class="comment"># 996执行时间为： 0.0009996891021728516</span></span><br><span class="line"><span class="comment"># Capitalism</span></span><br><span class="line"><span class="comment"># 997执行时间为： 0.0</span></span><br></pre></td></tr></table></figure>
<h2 id="类装饰器到底是不是装饰器？"><a href="#类装饰器到底是不是装饰器？" class="headerlink" title="类装饰器到底是不是装饰器？"></a>类装饰器到底是不是装饰器？</h2><p>虽然我在前面说了一嘴<code>Pytorch</code>中的损失函数和一般的装饰器运行过程不太一样，但也不要否认人家是装饰器这一事实！我们可以看看<code>Pytorch.nn.CrossEntropyLoss</code>类：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">CrossEntropyLoss</span>(<span class="title class_ inherited__">_WeightedLoss</span>):</span><br><span class="line">    __constants__ = [<span class="string">&#x27;ignore_index&#x27;</span>, <span class="string">&#x27;reduction&#x27;</span>, <span class="string">&#x27;label_smoothing&#x27;</span>]</span><br><span class="line">    ignore_index: <span class="built_in">int</span></span><br><span class="line">    label_smoothing: <span class="built_in">float</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, weight: <span class="type">Optional</span>[Tensor] = <span class="literal">None</span>, size_average=<span class="literal">None</span>, ignore_index: <span class="built_in">int</span> = -<span class="number">100</span>,reduce=<span class="literal">None</span>, reduction: <span class="built_in">str</span> = <span class="string">&#x27;mean&#x27;</span>, label_smoothing: <span class="built_in">float</span> = <span class="number">0.0</span></span>) -&gt; <span class="literal">None</span>:</span><br><span class="line">        <span class="built_in">super</span>(CrossEntropyLoss, self).__init__(weight, size_average, reduce, reduction)</span><br><span class="line">        self.ignore_index = ignore_index</span><br><span class="line">        self.label_smoothing = label_smoothing</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, <span class="built_in">input</span>: Tensor, target: Tensor</span>) -&gt; Tensor:</span><br><span class="line">        <span class="keyword">return</span> F.cross_entropy(<span class="built_in">input</span>, target, weight=self.weight,</span><br><span class="line">                               ignore_index=self.ignore_index, reduction=self.reduction,</span><br><span class="line">                               label_smoothing=self.label_smoothing)</span><br></pre></td></tr></table></figure>
<p>你会说这也没写那个<code>__call__</code>方法啊？倒是<code>forward()</code>函数写了。别急，我们看看这个类的继承关系：</p>
<p><code>CrossEntropyLoss -&gt; _WeightedLoss -&gt; _Loss -&gt; Module</code>。点开<code>Module</code>类，在1176行有这么一条：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">__call__ : Callable[..., Any] = _call_impl</span><br></pre></td></tr></table></figure>
<p>我们再点开<code>_call_impl</code>：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">_call_impl</span>(<span class="params">self, *<span class="built_in">input</span>, **kwargs</span>):</span><br><span class="line">        forward_call = (self._slow_forward <span class="keyword">if</span> torch._C._get_tracing_state() <span class="keyword">else</span> self.forward)</span><br><span class="line">        <span class="comment"># If we don&#x27;t have any hooks, we want to skip the rest of the logic in</span></span><br><span class="line">        <span class="comment"># this function, and just call forward.</span></span><br><span class="line">        <span class="keyword">if</span> <span class="keyword">not</span> (self._backward_hooks <span class="keyword">or</span> self._forward_hooks <span class="keyword">or</span> self._forward_pre_hooks <span class="keyword">or</span> _global_backward_hooks</span><br><span class="line">                <span class="keyword">or</span> _global_forward_hooks <span class="keyword">or</span> _global_forward_pre_hooks):</span><br><span class="line">            <span class="keyword">return</span> forward_call(*<span class="built_in">input</span>, **kwargs)</span><br><span class="line">        <span class="comment"># Do not call functions when jit is used</span></span><br><span class="line">        full_backward_hooks, non_full_backward_hooks = [], []</span><br><span class="line">        <span class="keyword">if</span> self._backward_hooks <span class="keyword">or</span> _global_backward_hooks:</span><br><span class="line">            full_backward_hooks, non_full_backward_hooks = self._get_backward_hooks()</span><br><span class="line">        <span class="keyword">if</span> _global_forward_pre_hooks <span class="keyword">or</span> self._forward_pre_hooks:</span><br><span class="line">            <span class="keyword">for</span> hook <span class="keyword">in</span> (*_global_forward_pre_hooks.values(), *self._forward_pre_hooks.values()):</span><br><span class="line">                result = hook(self, <span class="built_in">input</span>)</span><br><span class="line">                <span class="keyword">if</span> result <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span>:</span><br><span class="line">                    <span class="keyword">if</span> <span class="keyword">not</span> <span class="built_in">isinstance</span>(result, <span class="built_in">tuple</span>):</span><br><span class="line">                        result = (result,)</span><br><span class="line">                    <span class="built_in">input</span> = result</span><br><span class="line"></span><br><span class="line">        bw_hook = <span class="literal">None</span></span><br><span class="line">        <span class="keyword">if</span> full_backward_hooks:</span><br><span class="line">            bw_hook = hooks.BackwardHook(self, full_backward_hooks)</span><br><span class="line">            <span class="built_in">input</span> = bw_hook.setup_input_hook(<span class="built_in">input</span>)</span><br><span class="line"></span><br><span class="line">        result = forward_call(*<span class="built_in">input</span>, **kwargs)</span><br><span class="line">        <span class="keyword">if</span> _global_forward_hooks <span class="keyword">or</span> self._forward_hooks:</span><br><span class="line">            <span class="keyword">for</span> hook <span class="keyword">in</span> (*_global_forward_hooks.values(), *self._forward_hooks.values()):</span><br><span class="line">                hook_result = hook(self, <span class="built_in">input</span>, result)</span><br><span class="line">                <span class="keyword">if</span> hook_result <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span>:</span><br><span class="line">                    result = hook_result</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> bw_hook:</span><br><span class="line">            result = bw_hook.setup_output_hook(result)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># Handle the non-full backward hooks</span></span><br><span class="line">        <span class="keyword">if</span> non_full_backward_hooks:</span><br><span class="line">            var = result</span><br><span class="line">            <span class="keyword">while</span> <span class="keyword">not</span> <span class="built_in">isinstance</span>(var, torch.Tensor):</span><br><span class="line">                <span class="keyword">if</span> <span class="built_in">isinstance</span>(var, <span class="built_in">dict</span>):</span><br><span class="line">                    var = <span class="built_in">next</span>((v <span class="keyword">for</span> v <span class="keyword">in</span> var.values() <span class="keyword">if</span> <span class="built_in">isinstance</span>(v, torch.Tensor)))</span><br><span class="line">                <span class="keyword">else</span>:</span><br><span class="line">                    var = var[<span class="number">0</span>]</span><br><span class="line">            grad_fn = var.grad_fn</span><br><span class="line">            <span class="keyword">if</span> grad_fn <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span>:</span><br><span class="line">                <span class="keyword">for</span> hook <span class="keyword">in</span> non_full_backward_hooks:</span><br><span class="line">                    wrapper = functools.partial(hook, self)</span><br><span class="line">                    functools.update_wrapper(wrapper, hook)</span><br><span class="line">                    grad_fn.register_hook(wrapper)</span><br><span class="line">                self._maybe_warn_non_full_backward_hook(<span class="built_in">input</span>, result, grad_fn)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> result</span><br></pre></td></tr></table></figure>
<p>好长一大段是吧？别急，我们只需关注第一行最后面那个<code>self.foward</code>就行了：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">forward_call = (self._slow_forward <span class="keyword">if</span> torch._C._get_tracing_state() <span class="keyword">else</span> self.forward)</span><br></pre></td></tr></table></figure>
<p>现在应该懂了<code>__call__()</code>是干啥的了吧？总之通过复杂的继承关系，让最后的<code>CrossEntropyLoss</code>的<code>__call__()</code>调用了当前类里定义的<code>foward()</code>函数。所以这也是一种装饰器！</p>
<h2 id="装饰器顺序"><a href="#装饰器顺序" class="headerlink" title="装饰器顺序"></a>装饰器顺序</h2><p>结论就是离函数最近的装饰器最先执行。可以这么理解：装饰器包裹着一个函数，然后又被另一个装饰器包裹，然后在执行函数的时候最先完成执行的是函数，随后才是函数外第一层的装饰器，然后到第二层，第三层…</p>
<h2 id="装饰器用在哪？"><a href="#装饰器用在哪？" class="headerlink" title="装饰器用在哪？"></a>装饰器用在哪？</h2><p>以上就是装饰器的所有用法啦！除了我们用来测时间的应用场景，我们还可以通过装饰器来设定参数传入函数，比如说你在测试用户权限啥的，你可以写一个用户等级的函数，然后在测试的时候调用这个等级函数作为装饰器去测试你的业务；总之这个装饰器的用法很多，恰当使用的话可以提高开发效率。</p>
]]></content>
      <categories>
        <category>python技巧</category>
      </categories>
      <tags>
        <tag>python</tag>
        <tag>装饰器</tag>
      </tags>
  </entry>
  <entry>
    <title>Pytorch训练神经网络的一般过程</title>
    <url>/2022/08/04/Pytorch%E8%AE%AD%E7%BB%83%E6%A8%A1%E5%9E%8B%E7%9A%84%E5%9F%BA%E6%9C%AC%E8%BF%87%E7%A8%8B/</url>
    <content><![CDATA[<p>这个是我在使用<code>Pytorch</code>进行图像相关任务的神经网络构建和训练过程中的一个记录，没有什么参考价值的，可以忽略~</p>
<p><img src="https://s2.loli.net/2022/08/20/oxvPZeT8G7ydzct.png" alt="avata1r.png" style="zoom:25%;" /></p>
<span id="more"></span>
<h1 id="整体流程"><a href="#整体流程" class="headerlink" title="整体流程"></a>整体流程</h1><p><code>Pytorch</code>中构建神经网络训练自己的数据集是个挺繁琐的事情，主要流程分为数据集的构建、网络构建、训练调参以及结果测试四个部分。数据集的构建最好是使用<code>DataLoader</code>类进行构造，这是<code>Pytorch</code>写好的一个类别，我们只需要简单了解下接口即可顺利地在有监督学习中使用。网络构建则是一个比较中规中矩的过程，写法比较固定，比较好上手；训练调参包含的东西比较繁琐，包括模型参数的调整、加载，以及包含<code>Tensorboard</code>对训练结果的可视化(可选)；最后则是测试部分，这个相对也比较简单。</p>
<h1 id="数据加载"><a href="#数据加载" class="headerlink" title="数据加载"></a>数据加载</h1><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> torch.utils.data.DataLoader <span class="keyword">as</span> DataLoader</span><br><span class="line"></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">torch.utils.data.DataLoader(dataset, batch_size=1, shuffle=False, sampler=None,</span></span><br><span class="line"><span class="string">batch_sampler=None, num_workers=0, collate_fn=None,</span></span><br><span class="line"><span class="string">pin_memory=False, drop_last=False, timeout=0,</span></span><br><span class="line"><span class="string">worker_init_fn=None)</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br></pre></td></tr></table></figure>
<p>下面对几个重要的参数进行解析。</p>
<h2 id="dataset"><a href="#dataset" class="headerlink" title="dataset"></a>dataset</h2><p>dataset只接受两种类型的输入，分别是<code>map-style datasets</code>和<code>iterable-style datasets</code>。</p>
<h3 id="map-style-datasets"><a href="#map-style-datasets" class="headerlink" title="map-style datasets"></a>map-style datasets</h3><p>是一个类，需自行构建两个魔术方法<code>__getitem__()</code>和<code>__len__()</code>，用于表示数据的索引到数据的内容的映射。</p>
<p>其中：</p>
<ul>
<li><code>__getitem__()</code>用于根据索引遍历全部数据</li>
<li><code>__len__()</code>用于返回数据集长度</li>
<li>创建dataset类时可以对数据进行预处理，预处理的函数可以夹杂在<code>__getitem__()</code>方法中进行调用，或者直接在<code>__init__()</code>或<code>__getitem__()</code>中进行编写，但<code>__getitem__()</code>必须根据<code>index</code>返回响应值，因为该值会通过index传到DataLoader类中后续处理。</li>
</ul>
<p>这里给出一个基本的模板：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">Dataset</span>(<span class="title class_ inherited__">object</span>):</span><br><span class="line">    <span class="string">&quot;&quot;&quot;An abstract class representing a :class:`Dataset`.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    All datasets that represent a map from keys to data samples should subclass</span></span><br><span class="line"><span class="string">    it. All subclasses should overwrite :meth:`__getitem__`, supporting fetching a</span></span><br><span class="line"><span class="string">    data sample for a given key. Subclasses could also optionally overwrite</span></span><br><span class="line"><span class="string">    :meth:`__len__`, which is expected to return the size of the dataset by many</span></span><br><span class="line"><span class="string">    :class:`~torch.utils.data.Sampler` implementations and the default options</span></span><br><span class="line"><span class="string">    of :class:`~torch.utils.data.DataLoader`.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    .. note::</span></span><br><span class="line"><span class="string">      :class:`~torch.utils.data.DataLoader` by default constructs a index</span></span><br><span class="line"><span class="string">      sampler that yields integral indices.  To make it work with a map-style</span></span><br><span class="line"><span class="string">      dataset with non-integral indices/keys, a custom sampler must be provided.</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__getitem__</span>(<span class="params">self, index</span>):</span><br><span class="line">        <span class="keyword">raise</span> NotImplementedError</span><br><span class="line">        </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__len__</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="keyword">raise</span> NotImplementedError</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<p>给出几种常用的Dataset构造：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">from</span> torch <span class="keyword">import</span> nn</span><br><span class="line"><span class="keyword">from</span> torch.utils.data <span class="keyword">import</span> Dataset, DataLoader</span><br><span class="line"></span><br><span class="line"><span class="comment"># 数值类型的数据构造</span></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">Num_dataset</span>(<span class="title class_ inherited__">Dataset</span>):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="built_in">super</span>().__init__()</span><br><span class="line">    	<span class="comment"># 注意这里输入进来的每个数据是Tensor类型的，承载的部分随便</span></span><br><span class="line">        self.x = torch.randn(<span class="number">1000</span>,<span class="number">3</span>)</span><br><span class="line">        self.y = self.x.<span class="built_in">sum</span>(axis=<span class="number">1</span>)</span><br><span class="line">        self.src,  self.trg = [], []</span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">1000</span>):</span><br><span class="line">            self.src.append(self.x[i])</span><br><span class="line">            self.trg.append(self.y[i])</span><br><span class="line">           </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__getitem__</span>(<span class="params">self, index</span>):</span><br><span class="line">        <span class="keyword">return</span> self.src[index], self.trg[index]</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__len__</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="keyword">return</span> <span class="built_in">len</span>(self.src) </span><br><span class="line">    </span><br><span class="line"><span class="comment"># 图片类型的数据构造</span></span><br><span class="line"><span class="comment"># 还不完善 等我修补下</span></span><br><span class="line">train_dir = <span class="string">&quot;../data/hotdog/train&quot;</span></span><br><span class="line">test_dir = <span class="string">&quot;../data/hotdog/test&quot;</span></span><br><span class="line"></span><br><span class="line">mean = [<span class="number">0.485</span>, <span class="number">0.456</span>, <span class="number">0.406</span>]</span><br><span class="line">std = [<span class="number">0.229</span>, <span class="number">0.224</span>, <span class="number">0.225</span>]</span><br><span class="line"><span class="keyword">class</span> <span class="title class_">Img_dataset</span>(<span class="title class_ inherited__">Dataset</span>):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, path</span>):</span><br><span class="line">        data_root = pathlib.Path(path)</span><br><span class="line">        all_image_paths = <span class="built_in">list</span>(data_root.glob(<span class="string">&#x27;*/*&#x27;</span>))</span><br><span class="line">        self.all_image_paths = [<span class="built_in">str</span>(path) <span class="keyword">for</span> path <span class="keyword">in</span> all_image_paths]</span><br><span class="line">        label_names = <span class="built_in">sorted</span>(item.name <span class="keyword">for</span> item <span class="keyword">in</span> data_root.glob(<span class="string">&#x27;*/&#x27;</span>) <span class="keyword">if</span> item.is_dir())</span><br><span class="line">        label_to_index = <span class="built_in">dict</span>((label, index) <span class="keyword">for</span> index, label <span class="keyword">in</span> <span class="built_in">enumerate</span>(label_names))</span><br><span class="line">        self.all_image_labels = [label_to_index[path.parent.name] <span class="keyword">for</span> path <span class="keyword">in</span> all_image_paths]</span><br><span class="line">        self.mean = np.array(mean).reshape((<span class="number">1</span>, <span class="number">1</span>, <span class="number">3</span>))</span><br><span class="line">        self.std = np.array(std).reshape((<span class="number">1</span>, <span class="number">1</span>, <span class="number">3</span>))</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__getitem__</span>(<span class="params">self, index</span>):</span><br><span class="line">        img = cv.imread(self.all_image_paths[index])</span><br><span class="line">        img = cv.resize(img, (<span class="number">224</span>, <span class="number">224</span>))</span><br><span class="line">        img = img / <span class="number">255.</span></span><br><span class="line">        img = (img - self.mean) / self.std</span><br><span class="line">        img = np.transpose(img, [<span class="number">2</span>, <span class="number">0</span>, <span class="number">1</span>])</span><br><span class="line">        label = self.all_image_labels[index]</span><br><span class="line">        img = torch.tensor(img, dtype=torch.float32)</span><br><span class="line">        label = torch.tensor(label)</span><br><span class="line">        <span class="keyword">return</span> img, label</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__len__</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="keyword">return</span> <span class="built_in">len</span>(self.all_image_paths)</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<h3 id="Iterable-style-datasets"><a href="#Iterable-style-datasets" class="headerlink" title="Iterable-style datasets"></a>Iterable-style datasets</h3><p>可迭代样式的数据集是IterableDataset的一个实例，该实例必须重写<strong>iter</strong>方法,该方法用于对数据集进行迭代。这种类型的数据集特别适合随机读取数据不太可能实现的情况，并且批处理大小batchsize取决于获取的数据。比如读取数据库，远程服务器或者实时日志等数据的时候，可使用该样式，一般时序数据不使用这种样式。我就摸了~</p>
<h2 id="batchsize"><a href="#batchsize" class="headerlink" title="batchsize"></a>batchsize</h2><p>一次抽取的数据多少，最好根据数据量的多少以及自己的设备的内存、GPU、显存进行选择，尽量选择2的正整数次幂作为batchsize。</p>
<h2 id="numworkers"><a href="#numworkers" class="headerlink" title="numworkers"></a>numworkers</h2><p>参与程序使用的CPU核心数，注意使用该参数后需要自写主函数入口：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&quot;__main__&quot;</span>:</span><br><span class="line">    main()</span><br></pre></td></tr></table></figure>
<h2 id="shuffle"><a href="#shuffle" class="headerlink" title="shuffle"></a>shuffle</h2><p>是否对数据进行打乱，一般都选True，因为数据的相关性会影响网络的训练泛化性能。</p>
<h1 id="网络构造"><a href="#网络构造" class="headerlink" title="网络构造"></a>网络构造</h1><p>所有的网络构造都需要继承<code>nn.Module</code>类，然后在构造函数<code>__init__()</code>中构造一些网络层的成员，然后重写<code>forward(self,x)</code>成员函数。下面给出LeNet的一个构造示例：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> torch.nn <span class="keyword">as</span> nn</span><br><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">LeNet</span>(nn.Module):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self</span>) -&gt; <span class="literal">None</span>:</span><br><span class="line">        <span class="built_in">super</span>().__init__()</span><br><span class="line"></span><br><span class="line">        self.conv1 = nn.Conv2d(<span class="number">1</span>,<span class="number">6</span>,<span class="number">3</span>)</span><br><span class="line">        self.pool1 = nn.MaxPool2d(<span class="number">2</span>,<span class="number">2</span>)</span><br><span class="line">        self.conv2 = nn.Conv2d(<span class="number">6</span>,<span class="number">16</span>,<span class="number">3</span>)</span><br><span class="line">        self.pool2 = nn.MaxPool2d(<span class="number">2</span>,<span class="number">2</span>)</span><br><span class="line">        self.fc1 = nn.Linear(<span class="number">16</span>*<span class="number">6</span>*<span class="number">6</span>, <span class="number">120</span>)</span><br><span class="line">        self.fc2 = nn.Linear(<span class="number">120</span>, <span class="number">84</span>)</span><br><span class="line">        self.fc3 = nn.Linear(<span class="number">84</span>,<span class="number">10</span>)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self,x</span>):</span><br><span class="line">        x = self.pool1(torch.relu(self.conv1(x)))</span><br><span class="line">        x = self.pool2(torch.relu(self.conv2(x)))</span><br><span class="line">        x = x.view(x.size(<span class="number">0</span>),-<span class="number">1</span>)</span><br><span class="line">        x = torch.relu(self.fc1(x))</span><br><span class="line">        x = torch.relu(self.fc2(x))</span><br><span class="line">        x = self.fc3(x)</span><br><span class="line">        <span class="keyword">return</span> x</span><br></pre></td></tr></table></figure>
<p><code>Pytorch</code>构造的网络使用方式比较直观，在实例化对象后，可以直接使调用输出结果：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&quot;__main__&quot;</span>:</span><br><span class="line">    model = LeNet()</span><br><span class="line">    ret = model(torch.randn(<span class="number">1</span>,<span class="number">1</span>,<span class="number">32</span>,<span class="number">32</span>))</span><br><span class="line">    <span class="built_in">print</span>(ret.shape)</span><br><span class="line">    <span class="comment">#torch.Size([1, 10])</span></span><br></pre></td></tr></table></figure>
<p>这是因为它继承了<code>nn.Module</code>中的<code>__call__()</code>方法，而默认的<code>__call__()</code>方法则是定义为调用<code>forward(self,x)</code>这个成员函数。</p>
<h1 id="模型训练"><a href="#模型训练" class="headerlink" title="模型训练"></a>模型训练</h1><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> torch.nn <span class="keyword">as</span> nn</span><br><span class="line"><span class="keyword">from</span> model <span class="keyword">import</span> LeNet</span><br><span class="line"></span><br><span class="line"><span class="comment">#Dataset</span></span><br><span class="line"><span class="keyword">from</span> torchvision.datasets <span class="keyword">import</span> MNIST</span><br><span class="line"><span class="keyword">import</span> torchvision.transforms <span class="keyword">as</span> transforms</span><br><span class="line"><span class="keyword">from</span> torch.utils.data <span class="keyword">import</span> DataLoader</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># Load Data</span></span><br><span class="line"></span><br><span class="line">data_train = MNIST(<span class="string">&#x27;./data&#x27;</span>, </span><br><span class="line">                    download = <span class="literal">True</span>, </span><br><span class="line">                    transform = transforms.Compose([transforms.Resize((<span class="number">32</span>,<span class="number">32</span>)),transforms.ToTensor()]))</span><br><span class="line"></span><br><span class="line">data_train_loader = DataLoader(data_train, batch_size = <span class="number">32</span>, shuffle= <span class="literal">True</span>, num_workers=<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Model</span></span><br><span class="line">model = LeNet()</span><br><span class="line"><span class="comment"># 切换状态</span></span><br><span class="line">model.train()</span><br><span class="line">lr = <span class="number">1e-2</span></span><br><span class="line">loss_func = nn.CrossEntropyLoss()</span><br><span class="line">optimizer = torch.optim.SGD(model.parameters(), lr = lr, momentum = <span class="number">0.9</span>, weight_decay = <span class="number">5e-4</span>)</span><br><span class="line"></span><br><span class="line">train_loss = <span class="number">0</span></span><br><span class="line">correct = <span class="number">0</span></span><br><span class="line">total = <span class="number">0</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&#x27;__main__&#x27;</span>:</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> batch_idx, (inputs, targets) <span class="keyword">in</span> <span class="built_in">enumerate</span>(data_train_loader):</span><br><span class="line"></span><br><span class="line">        optimizer.zero_grad()</span><br><span class="line">        outputs = model(inputs)</span><br><span class="line">        loss = loss_func(outputs, targets)</span><br><span class="line">        loss.backward()</span><br><span class="line">        optimizer.step()</span><br><span class="line"></span><br><span class="line">        train_loss += loss.item()</span><br><span class="line">        _, predicted = outputs.<span class="built_in">max</span>(<span class="number">1</span>)</span><br><span class="line">        total += targets.size(<span class="number">0</span>)</span><br><span class="line">        correct += predicted.eq(targets).<span class="built_in">sum</span>().item()</span><br><span class="line"></span><br><span class="line">        <span class="built_in">print</span>(batch_idx, <span class="built_in">len</span>(data_train_loader), <span class="string">&quot;Loss: %.3f | ACC: %.3f%% (%d/%d)&quot;</span> % (train_loss/(batch_idx+<span class="number">1</span>), <span class="number">100.</span>*correct/total, correct, total))</span><br><span class="line">        </span><br></pre></td></tr></table></figure>
<p>值得注意的是，这里的训练只训练了一个epoch，如果训练多个epoch则需要再套一层for循环。</p>
<p>如果要使用一些已经预训练好的模型的权重，则可以选择加载部分权重。分为几种情况：</p>
<h2 id="结构相同，某些层不加载"><a href="#结构相同，某些层不加载" class="headerlink" title="结构相同，某些层不加载"></a>结构相同，某些层不加载</h2><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">model = LeNet()</span><br><span class="line">model_dict = model.state_dict()<span class="comment">#新的模型结构</span></span><br><span class="line">pre_train = torch.load(<span class="string">&#x27;model.pth&#x27;</span>)</span><br><span class="line">pretrain_dict = pre_train.state_dict()<span class="comment">#已有的模型权重</span></span><br><span class="line"><span class="keyword">for</span> each <span class="keyword">in</span> pretrain_dict:</span><br><span class="line">    <span class="built_in">print</span>(each)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;--------------------&#x27;</span>)</span><br><span class="line"></span><br><span class="line">load_pretrained_dict = &#123;key: value <span class="keyword">for</span> key, value <span class="keyword">in</span> pretrain_dict.items() <span class="keyword">if</span> (key <span class="keyword">in</span> model_dict <span class="keyword">and</span> <span class="string">&#x27;fc1&#x27;</span> <span class="keyword">not</span> <span class="keyword">in</span> key)&#125;</span><br><span class="line"><span class="keyword">for</span> each <span class="keyword">in</span> load_pretrained_dict:</span><br><span class="line">    <span class="built_in">print</span>(each)</span><br><span class="line"></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">conv1.weight</span></span><br><span class="line"><span class="string">conv1.bias</span></span><br><span class="line"><span class="string">conv2.weight</span></span><br><span class="line"><span class="string">conv2.bias</span></span><br><span class="line"><span class="string">fc1.weight</span></span><br><span class="line"><span class="string">fc1.bias</span></span><br><span class="line"><span class="string">fc2.weight</span></span><br><span class="line"><span class="string">fc2.bias</span></span><br><span class="line"><span class="string">fc3.weight</span></span><br><span class="line"><span class="string">fc3.bias</span></span><br><span class="line"><span class="string">--------------------</span></span><br><span class="line"><span class="string">conv1.weight</span></span><br><span class="line"><span class="string">conv1.bias</span></span><br><span class="line"><span class="string">conv2.weight</span></span><br><span class="line"><span class="string">conv2.bias</span></span><br><span class="line"><span class="string">fc2.weight</span></span><br><span class="line"><span class="string">fc2.bias</span></span><br><span class="line"><span class="string">fc3.weight</span></span><br><span class="line"><span class="string">fc3.bias</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br></pre></td></tr></table></figure>
<h2 id="结构不同，不同层不加载"><a href="#结构不同，不同层不加载" class="headerlink" title="结构不同，不同层不加载"></a>结构不同，不同层不加载</h2><p>与上面类似，只不过把筛选语句修改以下就可以了：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">load_pretrained_dict = &#123;key: value <span class="keyword">for</span> key, value <span class="keyword">in</span> pretrain_dict.items() <span class="keyword">if</span> (key <span class="keyword">in</span> model_dict)&#125;</span><br></pre></td></tr></table></figure>
]]></content>
      <tags>
        <tag>Pytorch</tag>
        <tag>Python</tag>
      </tags>
  </entry>
  <entry>
    <title>在Ubuntu20.04 LTS中配置USRP B210</title>
    <url>/2022/09/20/usrp/</url>
    <content><![CDATA[<p>从实验室白嫖了SDR，是USRP B210，准备用作UE放在Ubuntu搭建的核心网里，记录一下配置的过程。</p>
<span id="more"></span>
<h2 id="软硬件平台"><a href="#软硬件平台" class="headerlink" title="软硬件平台"></a>软硬件平台</h2><p><img src="https://s2.loli.net/2022/09/20/Q1amF49NGo5n76H.png" alt="image-20220920160939401"></p>
<p>经测试本文内容在：</p>
<ul>
<li>Ubuntu 20.04 LTS</li>
<li>USRP B210</li>
</ul>
<p>可以成功运行。</p>
<h2 id="UHD依赖安装"><a href="#UHD依赖安装" class="headerlink" title="UHD依赖安装"></a>UHD依赖安装</h2><p>先更新软件索引：</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">sudo apt-get update</span><br></pre></td></tr></table></figure>
<p>随后安装依赖：</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">sudo apt-get -y install git swig cmake doxygen build-essential libboost-all-dev </span><br><span class="line">libtool libusb-1.0-0 libusb-1.0-0-dev libudev-dev libncurses5-dev libfftw3-bin </span><br><span class="line">libfftw3-dev libfftw3-doc libcppunit-1.15-0 libcppunit-dev libcppunit-doc ncurses-bin cpufrequtils python-numpy python-numpy-doc python-numpy-dbg python3-scipy python-docutils qt4-bin-dbg qt4-default qt4-doc libqt4-dev libqt4-dev-bin python-qt4 python-qt4-dbg python-qt4-dev python-qt4-doc python-qt4-doc libqwt6abi1 libfftw3-bin libfftw3-dev libfftw3-doc ncurses-bin libncurses5 libncurses5-dev libncurses5-dbg libfontconfig1-dev libxrender-dev libpulse-dev swig g++ automake autoconf libtool python-dev libfftw3-dev libcppunit-dev libboost-all-dev libusb-dev libusb-1.0-0-dev fort77 libsdl1.2-dev python-wxgtk3.0 git libqt4-dev python-numpy ccache python-opengl libgsl-dev python-cheetah python-mako python-lxml doxygen qt4-default qt4-dev-tools libusb-1.0-0-dev libqwtplot3d-qt5-dev pyqt4-dev-tools python-qwt5-qt4 cmake git wget libxi-dev gtk2-engines-pixbuf r-base-dev python-tk liborc-0.4-0 liborc-0.4-dev libasound2-dev python-gtk2 libzmq3-dev libzmq5 python-requests python-sphinx libcomedi-dev python-zmq libqwt-dev libqwt6abi1 python-six libgps-dev libgps23 gpsd gpsd-clients python-gps python-setuptools</span><br></pre></td></tr></table></figure>
<h2 id="下载编译UHD-v3-15"><a href="#下载编译UHD-v3-15" class="headerlink" title="下载编译UHD v3.15"></a>下载编译UHD v3.15</h2><h3 id="下载源码"><a href="#下载源码" class="headerlink" title="下载源码"></a>下载源码</h3><p>先创建<code>UHD</code>文件夹作为UHD源码存放地：</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="built_in">cd</span></span><br><span class="line"><span class="built_in">mkdir</span> UHD</span><br><span class="line"><span class="built_in">cd</span> UHD</span><br><span class="line">git <span class="built_in">clone</span> https://github.com/EttusResearch/uhd</span><br></pre></td></tr></table></figure>
<p>随后进入文件夹并检出<code>v3.15</code>版本的UHD：</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="built_in">cd</span> uhd</span><br><span class="line">git tag -l	<span class="comment">#查看标签</span></span><br><span class="line">git checkout v3.15.0.0	<span class="comment">#检出标签</span></span><br></pre></td></tr></table></figure>
<h3 id="编译源码"><a href="#编译源码" class="headerlink" title="编译源码"></a>编译源码</h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="built_in">cd</span> host <span class="comment">#该指令执行前目录应该为 UHD/uhd</span></span><br><span class="line"><span class="built_in">mkdir</span> build</span><br><span class="line"><span class="built_in">cd</span> build</span><br><span class="line">cmake ../</span><br><span class="line">make	</span><br></pre></td></tr></table></figure>
<h3 id="安装并验证UHD"><a href="#安装并验证UHD" class="headerlink" title="安装并验证UHD"></a>安装并验证UHD</h3><p>验证编译结果可使用如下命令：</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">make <span class="built_in">test</span></span><br></pre></td></tr></table></figure>
<p>输出内容大致如下：</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">Running tests...</span><br><span class="line">Test project /home/zxhui/workspace/uhd/host/build</span><br><span class="line">      Start  1: addr_test</span><br><span class="line"> 1/50 Test  <span class="comment">#1: addr_test ........................   Passed    0.05 sec</span></span><br><span class="line">      Start  2: buffer_test</span><br><span class="line"> 2/50 Test  <span class="comment">#2: buffer_test ......................   Passed    0.03 sec</span></span><br><span class="line">      Start  3: byteswap_test</span><br><span class="line"> 3/50 Test  <span class="comment">#3: byteswap_test ....................   Passed    0.01 sec</span></span><br><span class="line">      Start  4: cast_test</span><br><span class="line">									... </span><br><span class="line">									...</span><br><span class="line">                                    ...</span><br><span class="line">      Start 50: paths_test</span><br><span class="line">50/50 Test <span class="comment">#50: paths_test .......................   Passed    0.01 sec</span></span><br><span class="line"></span><br><span class="line">100% tests passed, 0 tests failed out of 50</span><br><span class="line"></span><br><span class="line">Total Test time (real) =   0.20 sec</span><br></pre></td></tr></table></figure>
<p>如果测试全通过了则编译成功。下面进行安装：</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">sudo make install</span><br><span class="line">sudo ldconfig</span><br></pre></td></tr></table></figure>
<p>随后修改<code>$HOME/.bashrc</code>文件，在最后一行添加环境变量：</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="built_in">export</span> LD_LIBRARY_PATH=/usr/local/lib</span><br></pre></td></tr></table></figure>
<p>然后下载UHD FPGA的镜像文件：</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">sudo uhd_images_downloader</span><br></pre></td></tr></table></figure>
<p>随后将USRP通过数据线与Ubuntu的USB接口连接，并在当前终端输入：</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">sudo uhd_find_devices</span><br></pre></td></tr></table></figure>
<p>如果安装成功的话应该会有设备信息的显示：</p>
<p><img src="https://s2.loli.net/2022/09/20/eIKa1xmqSO8G6ct.png" alt="image-20220920152330263"></p>
]]></content>
      <categories>
        <category>学习记录</category>
      </categories>
      <tags>
        <tag>SDR</tag>
      </tags>
  </entry>
  <entry>
    <title>一种用于路径规划的栅格地图简易生成方法</title>
    <url>/2022/07/29/%E4%B8%80%E7%A7%8D%E6%A0%85%E6%A0%BC%E5%9C%B0%E5%9B%BE%E7%9A%84%E7%94%9F%E6%88%90%E6%96%B9%E6%B3%95/</url>
    <content><![CDATA[<h2 id="引言"><a href="#引言" class="headerlink" title="引言"></a>引言</h2><p>做机器人路径规划还有避碰方面的应该都离不开栅格地图环境。最近一个项目是要使用N*N大小的栅格地图生成可视障碍物，并要保证在动作空间$\mathcal A=\{up,down.left,right\}$时，从起点到终点有至少一条可行的道路。所有的障碍物用黑色表示，可行区域用白色表示。栅格地图的生成我看网上大多数的文章是基于matlab生成的，使用python的比较少，即使有也是使用gym这个强化学习测试平台进行搭建的，它是强化学习中一个公认的标准测试平台是，用户可以通过自定义环境或修改现有环境构建一个符合自己需要的模型，但是开发文档太长了…它的内核是pygame，有些规范化的东西其实我不太喜欢，而且代码也忒长了。我参考了这位<a href="https://www.ihawo.com/archives/85.html">大佬的文章</a>尝试搭了一下，奈何发现修改起来太麻烦了。gym其实还有一个问题就是，它的环境是固定死的，也就是说你想调整栅格地图的大小和精度就必须重新编写程序，这样其实对需要做大量对比实验的人来说非常不友好，因此我构想了一种更快更容易修改的栅格地图生成法。</p>
<span id="more"></span>
<h2 id="问题分析"><a href="#问题分析" class="headerlink" title="问题分析"></a>问题分析</h2><p>算法的核心其实就是构建一个矩阵，以0标识为可行区域，以1标识障碍区域。矩阵的构建约束为在每一个标识为0的区域在其四个方向的单步延拓至少有一个标识为0的区域，且对于设定的起点与终点均需保证他们的标识为0。我的想法是将可视化工作用热力图来表示，seaborn的热力图比plt的好看多了就选择了seaborn。可以先进行一个简单的<code>5*5</code>大小的生成测试观察可视化结果：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> seaborn <span class="keyword">as</span> sns</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">import</span> random</span><br><span class="line"></span><br><span class="line">a = np.array([[<span class="number">0</span>,<span class="number">0</span>,<span class="number">1</span>,<span class="number">1</span>,<span class="number">0</span>],</span><br><span class="line">              [<span class="number">0</span>,<span class="number">1</span>,<span class="number">1</span>,<span class="number">1</span>,<span class="number">1</span>],</span><br><span class="line">              [<span class="number">0</span>,<span class="number">0</span>,<span class="number">1</span>,<span class="number">1</span>,<span class="number">0</span>],</span><br><span class="line">              [<span class="number">1</span>,<span class="number">0</span>,<span class="number">0</span>,<span class="number">1</span>,<span class="number">1</span>],</span><br><span class="line">              [<span class="number">1</span>,<span class="number">1</span>,<span class="number">0</span>,<span class="number">0</span>,<span class="number">0</span>]])</span><br><span class="line"></span><br><span class="line">fig, ax = plt.subplots(figsize = (<span class="number">9</span>,<span class="number">9</span>))</span><br><span class="line"><span class="comment">#二维的数组的热力图，横轴和数轴的ticklabels要加上去的话，既可以通过将array转换成有column</span></span><br><span class="line"><span class="comment">#和index的DataFrame直接绘图生成，也可以后续再加上去。后面加上去的话，更灵活，包括可设置labels大小方向等。</span></span><br><span class="line">sns.heatmap(pd.DataFrame(np.<span class="built_in">round</span>(a,<span class="number">2</span>), columns = [<span class="string">&#x27;0&#x27;</span>, <span class="string">&#x27;1&#x27;</span>, <span class="string">&#x27;2&#x27;</span>,<span class="string">&#x27;3&#x27;</span>,<span class="string">&#x27;4&#x27;</span>], index = [<span class="string">&#x27;0&#x27;</span>, <span class="string">&#x27;1&#x27;</span>, <span class="string">&#x27;2&#x27;</span>,<span class="string">&#x27;3&#x27;</span>,<span class="string">&#x27;4&#x27;</span>]), linecolor=<span class="string">&#x27;gray&#x27;</span>,linewidths=<span class="number">1</span>,</span><br><span class="line">                annot=<span class="literal">True</span>, vmax=<span class="number">1</span>,vmin = <span class="number">0</span>, xticklabels= <span class="literal">True</span>, yticklabels= <span class="literal">True</span>, square=<span class="literal">True</span>,cmap=<span class="string">&quot;hot_r&quot;</span>, cbar= <span class="literal">False</span>)<span class="comment"># cmap=&quot;Blues&quot;</span></span><br><span class="line">plt.savefig(<span class="string">&#x27;5x5.png&#x27;</span>)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>
<p><img src="https://s2.loli.net/2022/05/30/4chvdXGm7U3RnfM.png" style="zoom: 33%;" /></p>
<p>这里我设定的起点是(0,0)和(4,4)。可以看到通过我人为的控制保证了一条路径生成。但是随着N的扩大，这种人为控制的方法显然是不现实的，而且这样生成的图也有明显的人为痕迹，因此我们需要进一步的拓展。我们可以先生成路径，再生成随机的地图，这样就能满足需求了。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">Function: Draw a grid map with the size of N*N</span></span><br><span class="line"><span class="string">Input: N -- the size of the grip map</span></span><br><span class="line"><span class="string">Output: None</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">drawGrid</span>(<span class="params">N</span>):</span><br><span class="line">    routedata = []	<span class="comment">#用于存储路径</span></span><br><span class="line">    alldata = []	<span class="comment">#用于存储栅格信息</span></span><br><span class="line">    a,b = <span class="number">0</span>,<span class="number">0</span>		<span class="comment">#路径的行与列索引</span></span><br><span class="line">    </span><br><span class="line">    <span class="comment"># 路径生成</span></span><br><span class="line">    <span class="keyword">while</span> a!= N-<span class="number">1</span> <span class="keyword">or</span> b!=N-<span class="number">1</span>:</span><br><span class="line">        judge = random.randint(<span class="number">0</span>,<span class="number">1</span>)	<span class="comment"># 栅格50%覆盖</span></span><br><span class="line">        <span class="keyword">if</span> a &lt; N-<span class="number">1</span> <span class="keyword">and</span> b&lt;N-<span class="number">1</span>:</span><br><span class="line">            <span class="keyword">if</span> judge==<span class="number">1</span>:</span><br><span class="line">                a += <span class="number">1</span></span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                b += <span class="number">1</span></span><br><span class="line"></span><br><span class="line">        <span class="keyword">elif</span> a&gt;=N-<span class="number">1</span> <span class="keyword">and</span> b&lt;N-<span class="number">1</span>:</span><br><span class="line">            b += <span class="number">1</span></span><br><span class="line">        </span><br><span class="line">        <span class="keyword">elif</span> a &lt; N-<span class="number">1</span> <span class="keyword">and</span> b &gt;= N-<span class="number">1</span>:</span><br><span class="line">            a+=<span class="number">1</span></span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            <span class="built_in">print</span>(<span class="string">&quot;error!&quot;</span>)</span><br><span class="line">        routedata.append([a,b])</span><br><span class="line">        </span><br><span class="line">	<span class="comment"># 栅格生成</span></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(N):</span><br><span class="line">        subdata = []</span><br><span class="line">        <span class="keyword">for</span> j <span class="keyword">in</span> <span class="built_in">range</span>(N):</span><br><span class="line">            a = random.randint(<span class="number">0</span>,<span class="number">1</span>)</span><br><span class="line">            subdata.append(a)</span><br><span class="line">        alldata.append(subdata)</span><br><span class="line"></span><br><span class="line">	<span class="comment"># 强行覆盖地图</span></span><br><span class="line">    <span class="keyword">for</span> each <span class="keyword">in</span> routedata:</span><br><span class="line">        alldata[each[<span class="number">0</span>]][each[<span class="number">1</span>]] = <span class="number">0</span></span><br><span class="line">        </span><br><span class="line">	<span class="comment"># 强行覆盖初始位置</span></span><br><span class="line">    alldata[<span class="number">0</span>][<span class="number">0</span>] = <span class="number">0</span></span><br><span class="line">    alldata[N-<span class="number">1</span>][N-<span class="number">1</span>] = <span class="number">0</span></span><br><span class="line"></span><br><span class="line">    data = np.array(alldata)</span><br><span class="line">    fig, ax = plt.subplots(figsize = (<span class="number">9</span>,<span class="number">9</span>))</span><br><span class="line">    sns.heatmap(pd.DataFrame(np.<span class="built_in">round</span>(data,<span class="number">2</span>)), linecolor=<span class="string">&#x27;gray&#x27;</span>,linewidths=<span class="number">1</span>,</span><br><span class="line">        annot=<span class="literal">True</span>, vmax=<span class="number">1</span>,vmin = <span class="number">0</span>, xticklabels= <span class="literal">True</span>, yticklabels= <span class="literal">True</span>, square=<span class="literal">True</span>,cmap=<span class="string">&quot;hot_r&quot;</span>, cbar= <span class="literal">False</span>)<span class="comment"># cmap=&quot;Blues&quot;</span></span><br><span class="line">    <span class="comment">#plt.savefig(&#x27;N*N.png&#x27;)</span></span><br><span class="line">    plt.show()</span><br></pre></td></tr></table></figure>
<p>测试一下<code>N=15</code>和<code>N=20</code>的情况：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">drawGrid(15)</span><br><span class="line">drawGrid(20)</span><br></pre></td></tr></table></figure>
<p><img src="https://s2.loli.net/2022/05/30/nQ2bdJofyCTG9V3.png" style="zoom: 33%;" /></p>
<center><small>10*10栅格地图</small></center>

<p><img src="https://s2.loli.net/2022/05/30/fl8qz47knpRu9O2.png" alt="20x20" style="zoom:33%;" /></p>
<center><small>20*20栅格地图</small></center>

<p>大功告成~</p>
<h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>如果使用gym去构建的话，我估计20*20的代码量大概要两三百行…但是这种方法生成的话应该会快一点。gym的代码量大其实可以理解，毕竟它还需要负责智体的交互部分，所以大家按需选择咯。我的方案是生成图片再使用像素值得差异进行路径规划算法的研究。</p>
]]></content>
      <categories>
        <category>强化学习</category>
      </categories>
      <tags>
        <tag>栅格地图</tag>
      </tags>
  </entry>
  <entry>
    <title>【文献翻译】Delay-Optimal Virtualized Radio Resource Scheduling in Software-Defined Vehicular Networks via Stochastic Learning</title>
    <url>/2022/09/24/%E3%80%90%E6%96%87%E7%8C%AE%E7%BF%BB%E8%AF%91%E3%80%91Delay-Optimal%20Virtualized%20Radio%20Resource%20Scheduling%20in%20Software-Defined%20Vehicular%20Networks%20via%20Stochastic%20Learning/</url>
    <content><![CDATA[<h1><center>摘要</center></h1>

<p>由于现有的车辆高密度和多样的车载服务需求，在当前的LTE网络使用效益最高的方法保证车载服务质量充满了挑战。很幸运的是，随着5G技术的发展，大量的蜂窝小区的建立被视为可达到车联网低延迟需求的场景下的一个可行方案。然而，这可能会导致大量的操作开销的产生以及由受限的回传容量以及爆发式增长的信号发射造成的移动网络操作的成本。本文提出一种把软件定义的网络和无线资源虚拟化整合到基于LTE系统的车联网络，比如说</p>
<p>，<strong>SoftdEfined heteRogeneous VehICular nEtwork</strong>。基于此系统框架，我们提出了基于stochastic Learning的时延最优虚拟无线电资源规划方法。延迟优化问题可以被建模成一个无限维度的平均损耗的部分可观测马尔可夫决策链的过程。然后，使用一个等价的贝尔曼方程来解决这个问题。我们提出的方法可以分成两部分，宏观虚拟资源分配MaVRA以及微观虚拟资源分配MiVRA。前者基于大尺度的时间段单元（交通密度的）而使用，后者通过小尺度的时间段单元履行职能（信道状态 队列状态）。仿真的结果显示了我们提出的方法比传统方法更有效。</p>
<span id="more"></span>
<h2 id="引言"><a href="#引言" class="headerlink" title="引言"></a>引言</h2><p>“链接的车辆”被视为能提高交通运势效率，保障交通安全，减少交通事故并降低交通拥塞影响的方法。智能交通系统通过V2V以及V2I的通信为交通安全与效率提供了支持，车辆的无线连接已经称为多方追逐社会与经济效益的目标。同时，大量的服务被设计来保证交通安全，提高交通质量并满足乘客娱乐需求（？），要做到这些就需要达到严格的服务质量QoS需求。通常，安全服务的最大容许延迟时间是需要小于100ms的，对于特殊服务，比如说碰撞预测警报，最大允许的时延是50ms，其他的非安全相关服务的最大允许时延时间是500ms。</p>
<p>多样的无线通信技术已经被考虑纳入支持ITS服务。1999年DSRC技术取得发展，它最广为人知的叫法是IEEE 802</p>
<p>.11p。DSRC从它的特性中受益许多，比如说易于开发，低成本，以及传播支持的原生信息的能力。然而扩展性问题、无边界的延迟以及缺少确定性QoS保障都极大地阻碍了其发展和DSRC系统的市场化。比如说，在[4]中，分析指出一种增强的分布信道接入EDCA在高密度的车联网场景下会受到严重影响。<strong>[5]研究了切换CCH和SCH的方法的性能，并得出aware的应用如果使在UTC时间上是对齐的，那么出于改变信道的切换的原因，这些应用必须妥善处理。（？）</strong>同时 由与DSRC 一开始设计之时是针对短距离通信的，并没由考虑到路边设施的需要大量的接入问题，因此它并不能提供广阔的通信覆盖范围和长久的V2I连接。再者，DSRC的部署是一个耗时耗财的工作，并且面临了鸡蛋和鸡的问题。一方面汽车制造商并不愿意投资开发安装车载设备（DSRC无线设备），因为没有任何东西保证他们制造的东西以后可以去连接。另一方面，当局也不想在毫无车载服务保证的情况下投入资金成本来建立供DSRC接入的设备。</p>
<p>同时，一些汽车制造商和通信运营商在考虑基于蜂窝网络的解决方法。比如说，LTE是最具潜力的无线技术，它可以对车载用户提供高速率的低延时的传输，同时他也满足了QoS对宽带的高要求的要给子类——信息娱乐，比方说社交网络。然而，LTE对车载安全应用的指出非常有限，并且网络几百年实在理想情况下也非常容易过载。因此，未来的车联网趋势已经从关注单一技术转向设计异构网络，比如说HetVNETs。</p>
<p>HetVNETS当前正处基础信息平台建设过程中，最终他将成为适配车联网的网络。未来的HetVNETS不仅仅可以支持大面积覆盖、高宽带以及非强时效性的车联网服务，同时也能保障安全服务的QoS需求。然而，HevNETS用于车联网服务依然面临几个问题。HetVNETs存在多种不同的无线技术，在传统的网络架构下这些技术很难相互连通，在设备中集成大量的无线技术是一个难题；再者，大量的无线网络设施和频谱资源会被浪费并且会导致车联网用户的糟糕的用户体验。因此，HetVNETs在车联网领域的发展需要一个新的架构。就如前文所提及的，一个成功的HetVNETs的架构必须达成以下严格的标准：</p>
<ul>
<li>架构能扩展、改进，并且与新发展的技术能有效融合</li>
<li>在掌握架构配置和交互面的定义后，第三方公司可以开发新的尚未出现充满前景的应用</li>
</ul>
<p>最近，大量的解决车联网面临的挑战创新想法被提出。一种紧急信息传播的时/地严格的框架被提出，且很好地适配了即时碰撞避让与路径规划功能。车联网使用的协同通信可以提高车联网的性能，V2V通信被用于中继V2I通信的信息。在[16]中，车联传感网络被用于监测城市交通，同时巡逻控制算法也被提出以提升检测性能，并为传感器网络设计了一种基于动态感知和路由的数据采集优化算法。然而，大多数的现有成果只能在特定场景下发挥作用。再者，随着5G技术的提升，软件定义网络可以被用于设计高效和拓展网络。因此为了满足需求，我们将SDN与虚拟无线资源集成到HevNETs中，在先前的论文中我们将它称为SERVICVE。在[12]中提到，大量的虚拟无线资源不能被充分地被利用以及大量的信号开销引入和浪费，导致严格的延迟要求不能被保障。为了解决这些问题，我们再者提出了一种时延最优的虚拟无线电资源规划方法，它分为两个部分：MaVRA和MiVRA。两者分别在大的时间段单元（比如说交通密度）和小的时间段单元（队列状态、信道状态）履行职能。他们的特点总结如下：</p>
<ul>
<li>提出一个用于SERVICE的两步的延迟优化动态虚拟无线电资源优化方法，将大的时间单元以及小的时间单元作为变量进行考察分析</li>
<li>将时延最优的动态虚拟化无线电资源分配问题建模成受限于部分可观马尔可夫决策过程的时域无穷的的平均开销，并且通过使用贝尔曼方程解决该问题，同时：</li>
<li>通过对每一车辆势函数求和来拟合MaVRA选择Q-因子，和分布的在线随机学习算法评估每辆车的势函数，这样能减少大量的控制面上的信号收发。</li>
</ul>
<p>马尔可夫决策过程是一种解决延迟优化的资源分配问题的系统建模理论，唯一需要考虑的问题就是由于维度的问题解决MDP没有简单的方法。最近MDP被用于解决各个领域的延迟优化无线电资源分配问题。比如说，在[21]中OFDMA中使用了一种时延最优的功率和子载波分配方法，将问题转为时域有限的马尔可夫决策过程的平均奖励问题。在MIMO系统网络中，双时间尺度的时延优化的动态集束和资源分配方法被应用在下行链路的传输过程中。在[23]中，端到端通信的时延最优模式选择和资源分配同样使用了MDP的理论。更有甚者，移动云计算的优化同样可以建模成MDP问题。在[24]中，提出了基于半MDP的移动云信息娱乐服务模型，旨在通过最小化服务概率来最大化云系统和用户的奖励。据我们所知，这是首次将交通行为纳入资源分配的马尔可夫决策过程中。</p>
<p>本文剩下部分结构如下。第二部分将给出SERVCICE架构的简要介绍，第三部分展示了时延优化问题的系统模型，第四部分展示了问题的建模。第五部分给出了一种低复杂度的时延优化问题的解决方案，第六部分则提供了两条baseline并与提出的MDP方法进行了性能对比，同时还有数值和模拟结果的讨论，最后则是结论部分。</p>
<h2 id="软件定义网络"><a href="#软件定义网络" class="headerlink" title="软件定义网络"></a>软件定义网络</h2><p>SDN已成为提升网络资源管理的网络性能的最有前景的一种方法。SDN的主要特征包括控制层和信息层的分离，控制层和数据层的开放接口以及集中的控制功能、可编程网络。基于可编程的SDN控制器，网络操作者可以轻松地定义新网络的设备配置并快速部署新应用。在这部分，我们给出SOTA的SDN，也就是我们之前的工作：SERVICE。</p>
<h3 id="SOTA"><a href="#SOTA" class="headerlink" title="SOTA"></a>SOTA</h3><p>SDN的概念原先是基于UCB、斯坦福、CMU、普林斯顿大学的研究提出的Nicira Network。曾有人在[25][26]做过OpenFlow/SDN的全面调查，包括基础的概念，应用，虚拟化，QoS，安全性等等，展示了SDN/OpenFlow的最新成果。ONF主导SDN改进与SDN框架的基本元素（如OpenFlow协议）的标准制定。另外，基于OpenFlow的SDN被用于解决高带宽、动态特性，使网络适应不断变化的业务需求，并显著降低了运营和管理的繁琐复杂。在[28]中作者提出了融合了SDN和NFV技术的SDNFV以到达更深层次的SDN。大量新兴的通信范式，比如说社交网络、移动云计算、物联网、车联网给当前的LTE网络带来了挑战。我们受这些启发，面向5G的软件定义移动网络去中心化架构得以提出，它能提升系统性能以达到更加性能与扩展性。</p>
<h3 id="SERVICE的结构"><a href="#SERVICE的结构" class="headerlink" title="SERVICE的结构"></a>SERVICE的结构</h3><p><img src="https://s2.loli.net/2022/09/21/hfYW52qV1MEF3G9.png" alt="image-20220921162447674"></p>
<p>在这个部分我们将简述SERVICE的框架（详细的介绍可以看文献[12]）。据我们所知，这是首次给HetVNETs的全面SDN框架。作为一个软件定义的网络，SERVICE可以按逻辑分成三个层：网络设施层，控制层和应用层。各层的细节描述如下：</p>
<ul>
<li>网络设施层：网络设施层位于SERVICE架构的最底层，对应SDN标准架构中的数据面。实际上，这一层主要由许多种不同的资源比如说通信资源，计算资源以及纯村资源。为了使所有的资源连通，需要高速率的回程链路并且可以受控制层的配置。</li>
<li>控制层：控制层位于网络架构的中层，它作为服务代理传达用户服务需求并控制，对虚拟资源进行资源控制，并未应用程序提供相关信息。由于车辆高机动性以及网络拓补的不稳定性，不同层间的信息交换和功能数量变得巨大，实时通信的性能难以保障。因此需要一种更有效的方式去保证SERVICE中的QoS服务，它可以对快速移动的车辆请求进行迅速响应。所以我们在SERVICE中提出了一种分层的控制层，它由主控制器（PCon）和次控制器（SCon）组成。<ul>
<li>主控制器：PCon位于SERVICE控制层的最顶层。PCON控制全局的SERVICE网络，因此PCON可以做出可行的优化决策。再者，PCon和SCon一样拥有直接和网络设施交互的功能。</li>
<li>次控制器：SCon位于PCon之下，它充当一个局部控制实体，是一个重要的组件。它其中一个重要的功能就是确保低延时的安全服务QoS需求，同时Scon可以通过虚拟资源池控制服务区内（intra-SA）的资源。</li>
</ul>
</li>
<li>应用层：应用层位于SERVICE架构的顶层。操作者可以通过设计不同的应用比如说动态资源分配、接入管理等功能配置并控制SERVICE。在这里我们以接入管理作为例子：<ul>
<li>接入管理：当接入管理应用运行时，SCon将监测网络负载和链路状态。一旦网络复杂超过了基站给定的某一等级，SCon将新的车辆接入请求转移到另一基站，这样不仅可以平衡负载同时也达到了现存车辆用户的QoS要求。</li>
</ul>
</li>
</ul>
<h3 id="Win-Lots机制"><a href="#Win-Lots机制" class="headerlink" title="Win-Lots机制"></a>Win-Lots机制</h3><p>基于如上所述的架构，软件定义的虚拟基站（vBSs）可以被用于向车辆用户提供符合要求的服务。通常来说，有两种虚拟基站，宏小区型虚拟基站（MvBS）和微小区型虚拟基站（SvBS）。基于此，我们可以设计更高效的虚拟无线资源分配方法。核心思想就是只有负责维持可靠性与覆盖的MvBS可以提供控制信道的功能，SvBS只负责高速率传输以达到广控制和局部传输的效果，这也是Win-Lots的由来。换句话说，不必去处理一个用户在SA覆盖范围内的移动接入问题，这可能会打破信号覆盖和传输能力之间的瓶颈。低频率的无线带宽更适合MvBS使用，因为他们传播路径损耗低。另一方面，高频段资源更应该被分配用于SvBS。基于这一原则，可以谨慎地设计无线资源管理（RRM）应用以最小化传输延迟。</p>
<h2 id="系统模型"><a href="#系统模型" class="headerlink" title="系统模型"></a>系统模型</h2><p>在这一部分，我们将阐述SERVICE系统的拓扑结构，包括其物理层模型，突发源模型以及流量模型，然后对SERVICE框架的时延优化控制问题进行建模。</p>
<h3 id="系统拓扑"><a href="#系统拓扑" class="headerlink" title="系统拓扑"></a>系统拓扑</h3><p>考虑基于包含一个MvBS和$M$个SvBS的SERVICE的无线车联网络，如图2所示。假设每一个SvBS都具备一根天线。设所有的SvBNS节点为集合$\mathcal B=\{1,2,3\dots,M\}$，考虑每一个SvBS节点只能为最大为$N_{max}$台车辆设备（VEs）服务，并且将VEs集合中与第$b$个SvBS相连的VE记作$V_b$。<img src="https://s2.loli.net/2022/09/21/TW7BfgAZrtO4ojJ.png" alt="image-20220921165830086"></p>
<p>如图2所示，SERVICE控制器将$M$个SvBS虚拟化以覆盖整个路边区域。每个SvBS可以本地测量本地的CSI和QSI。SERVICE控制器可以从每个分散的SvBS中获取全局的QSI。然后，每个VE可以报告其信息，比如说速度，状态，通过MvBS传输到控制器，这意味着控制器可以获取每个SvBS的交通密度。在P-GW中，存在许多与在控制器覆盖范围内的全部VE的流通信息序列。控制器将从每个SvBS收集的信息转发到RRM应用中。基于转发的信息，时延优化的无线资源分配方案会反馈到相应的车辆。在这里我们给出了详细的交通和我通信行为模型的假设：</p>
<ul>
<li><p>交通行为模型： 如图2所示，每个SvBS通信范围覆盖了长度为$d_C$长的子路段。假设车辆都处于畅通状态，在该条件下，根据文献p[30]，以下假设是合理的：</p>
<p>假设1：每辆车的速度是独立且均服从正态分布的随机变量，该概率分布密度表述为：</p>
<script type="math/tex; mode=display">
f_V(v)=\frac{\xi}{\sigma_V\sqrt{2 \pi}}e^{-(\frac{v-\bar V}{\sigma_V\sqrt{2}})^2},
v\in[V_{min},V_{max}]</script><p>其中，$\bar V$，$V_{max}$以及$V_{min}$分别为平均、最大、最小的车辆速度，$\sigma_V$是车辆速度的标准差，$\xi$是截断产生的归一化常数。</p>
<p>假设2：车辆的到达时间间隔构成一系列独立且服从指数分布的随机变量，概率分布密度表示为：</p>
<script type="math/tex; mode=display">
f_I(t)=\frac{1}{\mu}e^{-\frac{t}{\mu_v}},t\geq 0</script></li>
</ul>
<p>  其中，$\bar V$，$V_{max}$以及$V_{min}$分别为平均、最大、最小的车辆速度，$\sigma_V$是车辆速度的标准差，$\xi$是截断产生的归一化常数：</p>
<script type="math/tex; mode=display">
  \rho_v=\mu_v\bar V^{-1}</script><p>  基于前面的假设，可以得到车辆位置的稳定状态服从一般分布【？感觉是均匀分布】：</p>
<script type="math/tex; mode=display">
  g_l(r)=\frac{1}{R},0\leq r\leq R</script><p>  在SvBS中的车辆数分布则服从：</p>
<script type="math/tex; mode=display">
  Pr(N_b=n)=e^{-\phi_b}\frac{\phi_b^n}{n!}</script><ul>
<li>通信行为模型：为了简化通信行为模型，假设收端和发端的CSI处于完美状态。因此，车载设备（VE）$n$的最大可达速率可以被计算为：</li>
</ul>
<script type="math/tex; mode=display">
  \mu_{b.n}=\sum_{k=1}^{N_F}\mu_{(b,n),k}=\sum_{k=1}^{N_F}s_{(b,n),k}\log(1+\mathrm{SINR}_{n,k})</script><p>  其中$\mathrm{SINR}_{n,k}=\mathrm{SINR}_{(b,n),k},n\in V_b$是信号在第$k$个虚拟无线资源块传输时第$b$个VE的<strong>信号与干扰加噪声比（信噪比）</strong>。</p>
<p>  我们假设每个VE拥有一个长度为$N_Q$的有限长队列用于缓存到达的包数据。当前场景下的所有VE的队列长度可以用$Q(t)=\{Q_{b,n}\}_{n\in V_b,v\in\mathcal B}$表示，并且队列的状态转换按如下公式进行：</p>
<script type="math/tex; mode=display">
  Q_{b,n}(t+1)=\min\{[Q_{b,n}(t)-\mu_{b,n}(t)\Delta T]^{+}+A_{b,n}(t),N_Q\}</script><p>  其中，$A_{b,n}(t)$是在第t个时间间隔中第$n$个VE与SvBS $b$相连的随机新到达的包，并将其表述为$A(t)=\{A_{b,n}(t):b\in \mathrm V_b,b\in\mathcal B\}$</p>
<p>  假设3：包到达过程$A_{b,n}$在时隙规划时是独立同分布的，并且在与SvBS和VE相关时他们之间是独立的。</p>
<h3 id="虚拟无线资源管理策略"><a href="#虚拟无线资源管理策略" class="headerlink" title="虚拟无线资源管理策略"></a>虚拟无线资源管理策略</h3><p>在第t个时隙开始之时，SERVICE的控制器通过获取得到的交通密度条件决定了所有SvBS的MaVRA。然后每个SvBS对其无线资源进行分配，这个过程被定义为MiVRA在给定观测的CSI和QSI后的操作。MaVRA的定义如下：</p>
<ul>
<li><strong>*定义1</strong> MaVRA*：定义一个可行的MaVRA $V \in \mathcal V$是总的虚拟无线资源集合$\mathcal N_f$的一个子集，它的定义如下：<script type="math/tex; mode=display">
V=\{v_b\subseteq \mathcal N_f:v_b \cap v_{b'}=\O \quad\forall b\neq b',\bigcup_{b\in\mathcal B}v_b=\mathcal N_f\}</script></li>
</ul>
<p>  其中$\mathcal V$是所有可行的MaVRA的集合，$|\mathcal V| = I_V$，$|\mathcal N_f|=N_F$。</p>
<ul>
<li><strong>*定义2</strong> 虚拟无线资源管理策略*：虚拟无线资源管理策略包含了MaVRA和MiVRA，举例来说，$\Omega=(\Omega_v, \Omega_s)$就是系统状态$\chi \in X$到宏观与微观无线资源分配动作的一个映射，其中$\Omega_v(\mathrm T)=\mathrm V\in\mathcal V$，$\Omega_s(\chi)=\{s_{(b,n),k}:b\in\mathcal B,n\in \mathrm V_b,k\in v_b\}$。$\mathrm T$是交通状态，代表了当前的交通密度。</li>
</ul>
<p>如定义2所示，MaVRA是一个对交通密度的映射，这种映射仅为了如下原因而设立：首先，交通密度在时间尺度上与QSI和CSI相比是一个变化的量；其次，由于MaVRA是从SERVICE网络架构中以全局的视角进行功能执行的，所以需要在一个更大的时间尺度上进行决策，这不仅能降低应用与计算的复杂度，同时能减少大量的信号交互；最后，MiVRA在每个SvBS分布式地部署，他们产生的是局部的CSI和QSI。因此在考虑到过量的信号交互与计算复杂度后，可以短的时间单元内（通常是时隙级别）履行职能。</p>
<h2 id="问题建模"><a href="#问题建模" class="headerlink" title="问题建模"></a>问题建模</h2><h3 id="动态系统状态转移"><a href="#动态系统状态转移" class="headerlink" title="动态系统状态转移"></a>动态系统状态转移</h3><p>定义状态空间为$\chi(t)=(\mathrm T(t),\mathrm H(t), \mathrm Q(t))$，其中$\mathrm H(t)=\{|H_{(b,n),k}|:n\in\mathrm V_b,b\in\mathcal B\}$代表了系统每一个节点的CSI，$\mathrm T(t)=\{|T_b(t)|:b\in \mathcal B\}$是每一个节点的交通密度信息（TDI）。因此马尔科夫状态转移可表示为：</p>
<script type="math/tex; mode=display">
\begin{align}
&\mathrm {Pr}[\mathrm Q(t+1)|\chi(t),\Omega(\chi(t))]\\\\
=&\mathrm {Pr}[\mathrm A(t)+\mathrm Q(t+1)-[\mathrm Q(t)-\mathrm R(t)\Delta T]^{+}]\\\\
=&\prod_{b\in\mathcal B} \prod_{n\in\mathrm V_b}\mathrm {Pr}[A_{b,n}(t)=Q_{b,n}(t+1)
-[Q_{b,n}(t)-R_{b.n}(t)\Delta T]^{+}]
\end{align}</script><p>注意到$M\times N$的队列是通过控制策略$\Omega()$组合成的。引入的随机过程$\chi(t)=(\mathrm T(t),\mathrm H(t), \mathrm Q(t))$是遵循状态转移矩阵（见公式10）的马尔可夫链。</p>
<p>在公式10中，根据$\mathrm {Pr}[\mathrm H(t)]$和TDI的状态转移概率：</p>
<script type="math/tex; mode=display">
\begin{align}
&\mathrm {Pr}[\mathrm T(t+1)|\mathrm T(t)]\\
=&\prod_{b\in \mathcal B}\mathrm {Pr}[T_b(t+1)|T_b(t)]
\end{align}</script><p>我们假设信道状态服从一个离散的均匀分布。其中:</p>
<script type="math/tex; mode=display">
\mathrm {Pr}[\mathrm T(t+1)|\mathrm T(t)]
=\begin{cases}&
\begin{align}
p_1=\frac{\Delta T}{\mu_v}(1-T_b(t)\frac{\Delta T \bar V}{R})\quad &T_b(t+1)=T_b(t)+1\\    
p_2=T_b(t)\frac{\Delta T \bar V}{R}(1-\frac{\Delta T}{\mu_v})\quad &T_b(t+1)=T_b(t)-1\\
p_3 = 1-p_1-p_2 \quad &T_b(t+1)=T_b(t)
\end{align}
\end{cases}</script><h3 id="问题重述"><a href="#问题重述" class="headerlink" title="问题重述"></a>问题重述</h3><p>给定一个单链策略组$\Omega$，马尔可夫链是变脸的且拥有唯一的稳定状态分布$\pi_\chi$。因此，第b个SvBNS的平均成本为：</p>
<script type="math/tex; mode=display">
\begin{align}
\bar D_b (\Omega)&=\lim_{T\rightarrow \infty}\frac{1}{T}\sum_{t=1}^{T}\mathbb E^{\Omega}[\sum_{n\in \mathrm V_b}f(Q_{b,n}(t))]\\
&=\mathbb E_{\pi_\chi}[\sum_{n\in\mathrm V_b}f(Q_{b,n})]
\end{align}</script><p>在本文中，主要的目标是最小化传输延迟，因此我们设$f(Q_{b,k})=Q_{b,k}/\lambda_{b,k}$。现在，我们有：</p>
<ul>
<li><strong><em>问题一 SERVICE网络的时延最优控制</em></strong> ：为区分不同的服务优先级，我们给每一个队列设定了权重因子$\beta = \{\beta_{b,n}&gt;0:b\in\mathcal B,n\in \mathrm V_b\}$。时延最优的问题可以建模如下:</li>
</ul>
<script type="math/tex; mode=display">
  \begin{align}
  \min_{\Omega}J_{\beta}(\Omega)&=\sum_{b\in \mathcal B}\bar D_b(\Omega)\\
  &=\lim_{T\rightarrow \infty}\frac{1}{T}\sum_{t=1}^{T}\mathbb E^{\Omega}[g(\chi(t),\Omega(\chi(t)))]
  \end{align}</script><p>  其中:</p>
<script type="math/tex; mode=display">
  g(\chi(t),\Omega(\chi(t)))=\sum_{b\in \mathcal B}\sum_{n\in \mathrm V_b}\beta_{b,n}f(Q_{b,n}(t))</script><h3 id="POMDP"><a href="#POMDP" class="headerlink" title="POMDP"></a>POMDP</h3><p>根据公式12， 问题一是一个有限域中不受限的PODMP的平均成本问题。如前文所提，为了减少时间和空间复杂度，问题一的解决方法被分成了两部分：MaVRA和MiVRA。MaVRA基于系统的部分状态$\mathrm T$，后者则是在整个系统的状态$\chi=(\mathrm {T,H,Q})$上定义的。因此，POMDP的建模定义如下：</p>
<ul>
<li><p>状态空间：$\{(\mathrm {T,H,Q}:\forall\mathrm T\in\mathcal T,\mathrm H\in\mathcal H,\mathrm Q\in\mathcal Q)\}$。</p>
</li>
<li><p>动作空间：$\{\Omega(\chi)=(\Omega_v,\Omega_s)\}$，是定义2中给出的一个单链可达策略。</p>
</li>
<li><p>状态转移矩阵：$\mathrm {Pr}[\chi’|\chi,\Omega(\chi)]$，在公式10中定义。</p>
</li>
<li><p>每步损失函数：$g(\chi(t),\Omega(\chi(t))) = \sum_{b\in \mathcal B}\sum_{n\in \mathrm V_b}\beta_{b,n}f(Q_{b,n}(t))$。</p>
</li>
<li><p>观测：MaVRA的观测是交通密度，比如说$o_v=\mathrm T$，而MiVRA的观测则是整个系统状态，比如$o_s=\chi$。</p>
</li>
<li><p>观测函数：对于MaVRA来讲，观测函数$O_v$是：</p>
<script type="math/tex; mode=display">
O_v(o_v,\chi,(\Omega_v(\mathrm T'),\Omega_s(\chi')))=
\begin{cases}
\begin{align}
1\quad\quad &o_v=\mathrm T\\
0\quad\quad &otherwise\\
\end{align}
\end{cases}</script><p>对于MiVRA来说，观测函数$O_s$是：</p>
<script type="math/tex; mode=display">
O_s(o_s,\chi,(\Omega_v(\mathrm T'),\Omega_s(\chi')))=
\begin{cases}
\begin{align}
1\quad\quad &o_s=\chi\\
0\quad\quad &othersie
\end{align}
\end{cases}</script></li>
</ul>
<p>因此对应问题1中的的无约束的POMDP可以表述为：</p>
<script type="math/tex; mode=display">
J=\min_{\Omega}J_{\beta}(\Omega)</script><p>最优的动作$\Omega^*$可以通过解贝尔曼方程得到。很不幸的是，POMDP通常是一个非常难解决的问题，如果直接获得其解析解需要大量的计算。因此，我们使用了一个等价的贝尔曼方程来获取最优的控制策略。</p>
<h3 id="等价贝尔曼方程"><a href="#等价贝尔曼方程" class="headerlink" title="等价贝尔曼方程"></a>等价贝尔曼方程</h3><p>首先先定义条件MiVRA动作集：</p>
<ul>
<li><strong><em>定义3 条件MiVRA动作集</em></strong> 给定一个MiVRA的策略$\Omega_s$，我们定义条件无线资源分配动作集为$\Omega_s(\mathrm T)=\{s=\Omega_s(\chi):\chi=\mathrm{(T,H,Q),\forall H,Q}\}$作为给定$\mathrm T$时的所有可能CSI和QSI集合。</li>
</ul>
<p>基于定义3，POMDP转换成馋鬼的有限域平均成本MDP问题。除此之外，最优控制策略$\Omega^{*}$可通过如下的等价贝尔曼方程求解得到。</p>
<ul>
<li><strong><em>引理1 等价贝尔曼方程与MaVRA选择方法</em></strong> 问题1的时延最优化问题的最佳控制策略$\Omega^{<em>} = (\Omega_v^{</em>},\Omega_s^{*})$可以通过如下等价的贝尔曼方程求解得到：<script type="math/tex; mode=display">
\begin{align}
&\mathbb Q(\mathrm T,V)+\theta
\\=&\min_{\Omega_s(\mathrm T)}\{\bar{g}(\mathrm T,V,\Omega_s(\mathrm T))
\\&+\sum_{\mathrm T'}\mathrm{Pr}[\mathrm T'|\mathrm T,V, \Omega_s(\mathrm T)]\min_{V'}(\mathrm T',V')\},\forall\mathrm T \in \mathcal T, V\in \mathcal V
\end{align}\\</script></li>
</ul>
<p>​        其中$\mathbb Q(\mathrm T,V)$是MaVRA的选择的Q因子，$\bar g(\mathrm T,V,\Omega_s(\mathrm T))=\mathbb E[g(\chi,V,\Omega_s(\chi))|\mathrm T]$是每步执行的条件期望，$\mathrm {Pr}[\mathrm T’|\mathrm T,V,\Omega_s(\mathrm T)]=\mathbb E[\mathrm{Pr[\mathrm T’|\chi,\Omega_s(\chi)]}\mathrm T]$是条件转移概率的期望。问题1中的最优的平均损耗$\theta=\min_{\Omega}J_\beta(\Omega)$必须满足等式16所指出的贝尔曼方程。通过最小化最小化等式16的右侧并求$\Omega_v^{*}(\mathrm T)=\arg \min \mathbb Q(\mathrm T,V)$即可得到最优的控制策略。</p>
<p>​        等式16提出的等价贝尔曼方程只考虑交通密度信息$\mathrm T$。通过解等式16的方程，可以求得最优的MiVRA策略$\Omega_s^{\star}=\cup_{\mathrm T}\Omega_s^{\star}(\mathrm T)$，其中的$\Omega_s^{*}$已经在定义3中给出。然而这个定义可以对全局的CSI $\mathrm H$以及QSI $\mathrm Q$同样适用，因此，在下一部分，我们将使用线性拟合和随机学习来减少计算的复杂度。</p>
<h2 id="一般的低计算复杂度的解"><a href="#一般的低计算复杂度的解" class="headerlink" title="一般的低计算复杂度的解"></a>一般的低计算复杂度的解</h2><p>直接的暴力计算需要考虑指数级别的信道状态数和队列状态数的暴增带来的问题。而且由于部署位置位于整个系统的中心位置，因此大量的数据会不断回传。在这一部分，我们使用线性拟合和随机学习的分布式方法来估计的势函数。</p>
<h3 id="线性拟合MVRAS选择Q因子"><a href="#线性拟合MVRAS选择Q因子" class="headerlink" title="线性拟合MVRAS选择Q因子"></a>线性拟合MVRAS选择Q因子</h3><p>记$T_b\in\mathrm T$为第b个SvBS的交通密度值。为了减少状态空间的维数以及计算复杂度，同时为了把资源分配问题去中心化，我们通过线性累加每个SvBS的函数$q_b(T_b)$，如下所示：</p>
<script type="math/tex; mode=display">
\mathbb Q(\mathrm T,V)\approx\sum_{v_b\in V}q_b(T_b)</script><p>第b个SvbS的势函数$q_b(T_b)$满足如下贝尔曼等式：</p>
<script type="math/tex; mode=display">
\begin{align}
&q_b(T_b)+\theta_b\\
=&\min_{\Omega_{s_b}(\mathrm Q_b)}\{\bar g(T_b,\Omega_{s_b}(T_b))\\
&+\sum_{(T_b,\mathrm Q'_b)}\mathrm{Pr}[T_b'|T_b,\Omega_{s_b}(T_b)]q_b(T_b)
\}
\end{align}</script><p>其中：</p>
<script type="math/tex; mode=display">
\bar g(T_b,\Omega_{s_b}(T_b))=\mathbb E[\sum_{n\in\mathrm {V_b}}\beta_{b,n}f)Q_{B,n}],</script><script type="math/tex; mode=display">
\mathrm {Pr}[T_b'|T_b,\Omega_{s_b}(T_b)]\\
=\mathbb E[\mathrm{Pr}[T_b'|\chi_b,\Omega_{s_b}(\chi_b)]|T_b]</script><p>使用如上的线性拟合，SERVICE的控制器即可根据观测到的交通密度信息$\mathrm T$做出最优的MaVRA策略决策$\Omega_v^*$:</p>
<script type="math/tex; mode=display">
\Omega_v^*(\mathrm T)=\arg \min_{V}\sum_{v_b\in V}q_b(T_b)</script><p>基于每个SvBS观测得到的CSI和QSI，每个SvBS通过最优决策$\Omega_{s_b}^*(T_b)=\{\Omega_{s_b}(\chi_b):\chi_b \forall(\mathrm{H_b,Q_b})\}$来最小化等式18。随后我们即可得到全局的无线资源分配方法：</p>
<script type="math/tex; mode=display">
\Omega^*(\chi)=(\Omega_v^*(\chi),.\Omega_s^*(\chi))=(\Omega_v^*(\chi),\{\Omega_{s_b}^*(\chi):b\in \mathcal B\})</script><h3 id="每一SvBS势函数的分解"><a href="#每一SvBS势函数的分解" class="headerlink" title="每一SvBS势函数的分解"></a>每一SvBS势函数的分解</h3><p>每个SvBS的势函数$q_b(T_b)$可分解成每一车辆（或队列）势函数$q_b(T_b)=\sum_{n\in\mathrm V_b}q_b^n(T_b,\mathrm H_{b,n},Q_{b,n})$，这些势函数必须满足等式22，其中$\bar g_{b,n}(T_b,\Omega_{s_b},(T_b,Q_{b,n}))=\mathbb E[\beta_{b,n}f(Q_{b,n})]$，系统的状态转移如式23所示。</p>
<p>优化的目标是最小化等式22迭代中的R.H.S，然后让其变成等式24。</p>
<p><strong><em>引理2</em></strong> 最优MiVRA的闭式解：基于如上的分析，在给定系统状态$\chi_b=(T_b,\mathrm H_b, \mathrm Q_b)$和控制策略（式-18）下的MiVRA最优解如下：</p>
<script type="math/tex; mode=display">
s_{(b,n),k}=
\begin{cases}
\begin{align}
1,&\quad X_{(b,n),k}=\max_n\{X_{(b,n),k}\}\\
0,&\quad otherwise
\end{align}
\end{cases}</script><p>其中：</p>
<script type="math/tex; mode=display">
X_{(b,n),k}=\frac{\Delta T}{\bar N_{b,n}}(q^n(T_b,Q_{b,n}-1)-q^n(T_b,Q_{b,n}))\log(1+PH_{(b,n),k})</script><h3 id="随机拟合的在线分布式学习算法"><a href="#随机拟合的在线分布式学习算法" class="headerlink" title="随机拟合的在线分布式学习算法"></a>随机拟合的在线分布式学习算法</h3><p>在这个模块，我们使用了在线学习算法来预估势函数$q_b^n(T_b,Q_{b,n})$。$q_b^n(T_b,Q_{b,n})$的迭代公式在<strong><em>算法1</em></strong>中给出。</p>
<h3 id="计算复杂度与信号分析"><a href="#计算复杂度与信号分析" class="headerlink" title="计算复杂度与信号分析"></a>计算复杂度与信号分析</h3><p>在这个部分， 我们研究了暴力求解的计算复杂度以及信令开销。对于暴力求解的方法，由于是在集中模式进行处理，这就需要获取全局的CSI、全局的QSI和TDI。暴力求解的过程包含了解一个系统的非线性贝尔曼方程$I_V(N_Q+1)^{MN_{\max}}$。然而使用随机近似的方法时，我们可以得到一个低复杂度的解，它的时间复杂度是$\mathcal O(N_F(N_Q+1))$以及$\mathcal O((N_{Q}+1)(MN_{\max}))$的空间复杂度。除此之外，CSI和QSI的信息并不需要上传到SERVICE框架的应用层，因为它运行于分布模式，这能大量地减少信令开销。</p>
<h2 id="仿真结果与分析"><a href="#仿真结果与分析" class="headerlink" title="仿真结果与分析"></a>仿真结果与分析</h2><p>在这一部分，我们展示了一些仿真的结果，并评估了我们提出的虚拟无线资源分配方法的性能。为了证明我们的方法更加有效，我们还使用了两个参考的方法与我们的方法进行了对比。</p>
<h3 id="仿真实验设置"><a href="#仿真实验设置" class="headerlink" title="仿真实验设置"></a>仿真实验设置</h3><p>考虑一个长度为400米的高速公路的仿真场景。仿真实验的主要的参数以及配置已经列在了表格1中。在仿真中，有两个覆盖半径为200米的SvBS部署在路段。该仿真场景使用了Free-Flow模型，这个场景下每辆车不之间没有交互。车辆到达时间间隔服从等式2的指数分布，汽车的每秒的到达率$\mu_v$为取值为$[0.2,1.0]$。每辆车的速度服从等式2的截断正态分布，其中均值为$V=30 m/s$，最大速度为$V_{\max}=50m/s$，最小速度为$V_{\min}=10m/s$。我们假设每辆车辆在路段都保持其初始速度。</p>
<p><img src="https://s2.loli.net/2022/09/24/BdkJlFwh5HrQf6j.png" alt="image-20220924095830480"></p>
<p>车辆和SvBS的通信使用的是LTE-Advanced系统。在仿真中，无线虚拟资源块被设置成10，对应的是5MHZ的带宽。SvBS维持一个缓存对应车辆的到达数据包，其长度为$Q_{\max}=10$。报数据大小均值为50k比特，包达到速率为20个/s~120ge /s。所有的车辆都假设拥有过独立同分布的无线信道，并且信噪比的均值为12dB。为了对比性能，我们使用了如下两个方法作为参照：</p>
<ul>
<li><strong><em>基准1 Macro Resource Equipartition &amp; Round Robin (MaRE&amp;RR)方法</em></strong>： 这个方法中宏观的虚拟无线资源被平均地分配到每一个SvBS。基于这种分配方式，车辆能适应Round Robin 的方法，这意味着每辆车都有均等的使用无线资源的机会。</li>
<li><strong><em>基准2  Macro Resource Equipartition &amp; Channel Precedence (MaRE&amp;CP)方法</em></strong>： 宏观的虚拟无限资源分配方法如基准1，二者的唯一区别在于微观无线资源的分配方式，SvBS是通过信道的条件优劣为车辆分配无线资源。</li>
</ul>
<h3 id="结果分析"><a href="#结果分析" class="headerlink" title="结果分析"></a>结果分析</h3><p>图3、4给出了主要性能的对比。图3展示了每辆车在不同的到达率时的平均包延迟。随着车辆到达率的增加，所有方法的包延迟都在上升。基准2的方法（MaRE&amp;CP）比基准1（MaRE&amp;RR）的效果好，因为MaRE&amp;CP方法更倾向于选择更好信道条件的车辆。我们提出的方法都比这两种方法效果要好，因为其根据即时的交通情况动态的分给每个SvBS宏观虚拟无线资源。比如说，我们的方法和MaRE&amp;RR相比可以减少接近30%的平均延迟（包速率和车辆到达率分别为60/s和1/s）.最终，性能增益随着车辆到达率的增加而明显获得增幅，这是由于当交通密度较低时，无线资源对传输数据的支持都非常有效。因此，所有方法在车辆到达率较低时都能有较好的性能表现。</p>
<p><img src="https://s2.loli.net/2022/09/24/9MPw8Y7HIAbzaXD.png" alt="Fig.3  Average delay of total network versus different vehicle arrival rate."><img src="https://s2.loli.net/2022/09/24/JL8k6MH7CQoyXvI.png" alt="Fig. 4. Average delay of total network versus different data packet arrival rate."></p>
<p>图4展示了在不同数据包速率情况下不同算法的性能表现对比。每个SvBS的车辆到达率设成了低密度（每秒1辆车），数据到达率为20~120每秒。可以看到与图3近似的曲线，随着数据包到达率的增加，性能增益得益于宏无线资源得到提升。然而，当数据包到达率较低时，可能会有相反的情况出现。</p>
<p><img src="https://s2.loli.net/2022/09/24/RJxB8aoNlPnVXeZ.png" alt="Fig. 5. Average delay of total network under different data packet arrival rates and vehicle arrival rates."><img src="https://s2.loli.net/2022/09/24/UZYAVRLPKBkH26j.png" alt="ig. 6. Illustration of convergence property of the proposed scheme via stochastic approximation."></p>
<p>图5给出了在动态资源达到率和汽车到达率下的三维的平均时延图。可以看出平均延迟的增加受数据包到达率和车辆到达率的增加而增加。而且数据包到达率的增加对平均时延的影响比车辆到达率的影响更大。</p>
<p>图6表示MDP方法打的收敛性，给出了长度为10的队列状态$\{q_b^n(Q)\}$平均的势函数以及时隙槽的关系图。可以看到我们给出的方法收敛速度很快，而且随着队列状态空间越大，能更快收敛。这种现象的原因是和图六中所给出的在仿真条件下小长度序列拥有更多状态空间的队列的更新频率更快。</p>
<h2 id="结论"><a href="#结论" class="headerlink" title="结论"></a>结论</h2><p>本文提出了一种在SERVICE框架下的两步时延最优虚拟无线资源分配方法。这种方法可以建模成有限域中的平均成本POMDP问题，通过解一个等价的贝尔曼方程即可求解。为了减少计算复杂度以及信令开销，使用了1)分成MaVRA以及MiVRA两个从不同时间层面决策的决策步；2）通过累加每个用于估计系统势函数SvBS的势函数进行线性拟合，大量地减少了系统空间的维数，并且使用了在线分布学习的分布式算法去估计每个车辆的势函数，最终，我们证明了我么牛的方法可以收敛并且达到了一个不错的性能增益效果。</p>
]]></content>
      <categories>
        <category>学习记录</category>
        <category>文献翻译</category>
      </categories>
      <tags>
        <tag>车联网</tag>
        <tag>资源分配</tag>
      </tags>
  </entry>
  <entry>
    <title>光模块发展简易调研</title>
    <url>/2022/09/09/%E5%85%89%E6%A8%A1%E5%9D%97%E5%95%86%E7%94%A8/</url>
    <content><![CDATA[<h2 id="引言"><a href="#引言" class="headerlink" title="引言"></a>引言</h2><p>​        光模块是光通信中的核心器件，其核心功能是实现光电信号的相互转换。在数据流量爆发与网络需求升级的背景下，全球光模块市场成长动能强劲。从长期来看，光模块厂商未来有望迎来发展黄金时期，产品力的提升与工程师红利为光模块行业带来巨大潜能，国内龙头厂商如中际旭创、新易盛等在全球光模块竞争市场中逐渐崛起，近年来产品竞争力已赶超海外。本文试从商用光模块基本信息概述与光模块发展趋势两个维度对光模块发展进行简单的分析。</p>
<span id="more"></span>
<h2 id="商用光模块基本信息概述"><a href="#商用光模块基本信息概述" class="headerlink" title="商用光模块基本信息概述"></a>商用光模块基本信息概述</h2><p>​        本节将就光模块的基本结构、光模块在光通信市场产业链的位置以及光模块当前市场规模三个方面对商用光模块的基本信息进行简单概述。</p>
<h3 id="光模块基本结构"><a href="#光模块基本结构" class="headerlink" title="光模块基本结构"></a>光模块基本结构</h3><p>​        光模块是用于短中长据数据传输的核心器件。当前通信设备间通常使用光纤进行信息传输，而光模块就是实现信源设备与光纤之间进行光/电信号转换的核心器件，发送端把信源的电信号转换为光信号经由光纤传送，在接收端把光信号转换为电信号$^{[1]}$。</p>
<p><img src="https://s2.loli.net/2022/09/15/paklS4YoVq3LjOZ.png" alt="image-20220909095628572" style="zoom: 50%;" /></p>
<center><small>光模块结构示意<br>图源：<a href = 'https://www.elecfans.com/baike/buxian/guangqianshebei/20180309645014_a.html'>电子发烧友-光模块基础知识大全、分类及选用</a></small></center>

<p>​        光模块由光发射组件（含激光器）、光接收组件（含光探测器）、 驱动芯片与放大器等组成。在发送端，一定速率的电信号经驱动芯片处理后驱动激光器发射出相应速率的调制光信号。在接收端，一定速率 的光信号输入模块后由光探测器（PD）转换为电信号，经前置放大器后输出相应速率的电信号。</p>
<p>​        光模块产品品类繁多，一般以封装形式和光纤链路分类。下表给出光模块分类示意图$^{[2]}$。</p>
<p><img src="https://s2.loli.net/2022/09/15/9pXz6j3IEMYbcSD.png" alt="image-20220909101704664" style="zoom: 50%;" /></p>
<center><small>光模块分类示意图<br>资料来源：<a href = "http://legacy.frostchina.com/wp-content/uploads/2021/03/2.pdf">FROST& SULLIVAN</a></small></center>

<h3 id="光模块与光通信产业链"><a href="#光模块与光通信产业链" class="headerlink" title="光模块与光通信产业链"></a>光模块与光通信产业链</h3><p>​        光模块在光通信产业中处于中游的关键节点。上游产业是光芯片、光器件、电芯片厂商，下游是运营商、设备商以及云厂商等，如图$^{[3]}$所示。</p>
<p><img src="C:\Users\cybercolyce\AppData\Roaming\Typora\typora-user-images\image-20220909100857534.png" alt="image-20220909100857534"></p>
<center><small>光通信产业链<br>资料来源：<a href = "http://legacy.frostchina.com/wp-content/uploads/2021/03/2.pdf">FROST SULLIVAN</a></small></center>

<p>​        可以看到光模块处于链接产业上下游的关键节点，其产品应用覆盖了互联网服务、电信市场、云服务等行业，产业覆盖面广，在多个行业中承担了重要的技术支持角色。</p>
<h3 id="光模块市场规模"><a href="#光模块市场规模" class="headerlink" title="光模块市场规模"></a>光模块市场规模</h3><p>​        根据 Lightcounting 的统计数据，全球光模块市场规模在经历2016-2018年连续三年的停滞之后于 2019 恢复增长，2020年全球光模块市场规模达到81亿美元。Lightcounting 预计2026年全球光模块市场规模为176亿美元，2021-2026 年的复合年增长率为13.7%$^{[4]}$。下图给出了</p>
<p><img src="https://s2.loli.net/2022/09/15/zdsB86hlYD9fGZ3.png" alt="image-20220909105612572"></p>
<center><small>全球光模块出货量与全球光模块市场规模<br>资料来源：国联证券、Lightcounting</small></center>

<p>​        境内和海外的市场预期表现出很大的反差，其中 2022-2024 年，国内光模块市 场 增 长 率 分 别 为 0.8%/-0.1%/1.1% ， 而 境 外 光 模 块 市 场 增 长 率 分 别 为 24.7%/17.6%/17.1%，下图给出中外光模块发货量(2022年及以后为预测)以及中外光模块市场规模预测(单位为百万美元)$^{[5]}$。</p>
<p><img src="https://s2.loli.net/2022/09/15/ktSsBdeZv9x4WmU.png" alt="image-20220909110006587"></p>
<center><small>中外光模块发货量与中外光模块市场规模预测<br>资料来源：Lightcounting</small></center>

<h2 id="光模块发展趋势"><a href="#光模块发展趋势" class="headerlink" title="光模块发展趋势"></a>光模块发展趋势</h2><p>​        本节就光模块发展历程、光模块发展驱动、光模块性能突破方向三个方面对光模块发展趋势进行阐述与总结。</p>
<h3 id="光模块发展历程"><a href="#光模块发展历程" class="headerlink" title="光模块发展历程"></a>光模块发展历程</h3><p>下图给出了不同时期的不同封装光模块性能比较$^{[6]}$。</p>
<p>​        <img src="https://0.rc.xiniu.com/g1/M00/2C/D8/CgAGTF1f3geAehL4AANfSBQ5vzI153.png" alt="查看源图像"></p>
<center><small>光模块发展历程与以太网标准发布的横纵对比</small></center>

<p>​        在2000年以前GBIC是最主要的光模块封装，但由于其体积较大被后来的体积约为其一半的SFP取代，二者在功能上相近（都是千兆级别的），区别在于由于体积减少了一半，如下图$^{[7]}$所示。因此在同样的面板上可以配置多出一倍以上的端口数量；</p>
<p><img src="https://www.etulink.com/js/htmledit/kindeditor-en/attached/20170712/20170712093945_33495.png" alt="千兆位交换机_SFP光模块_SFP电口模块" style="zoom:50%;" /></p>
<p>​        随后光模块发展来到万兆级别，在此背景下诞生XFP与SFP+均为10G级别，但SFP+体积比XFP更紧凑，功耗也更小。随后的QSFP/QSFP+/QSFP28/QSFP28-DD根据速度可将QSFP分为4×10G QSFP+、4×25G QSFP28、8×25G QSFP28-DD光模块等，其性能的提升主要是通过增加通道数（以前都是单通道）。同时，采用了PAM4调制技术，区别于传统的PAM调制的NRZ编码，PAM4的编码提高了单通道的速率。</p>
<p><img src="https://img.expreview.com/news/2020/09/09/gddr6x/image-20200909101042207.png" alt="查看源图像" style="zoom:50%;" /></p>
<center><small>NRZ与PAM4对比</small></center>

<p>因此在多通道“乘法”与调制方式的“加法”的加持下，光模块的速率得以不断突破。</p>
<p>​        当前光模块的传输性能可达100-400Hbps，主要是以CFP/CFP2/CFP4/CFP8为主导$^{[8]}$。CFP、CFP2、CFP4的区别在于体积。CFP2的体积是CFP的二分之一，CFP4是CFP的四分之一。CFP8是专门针对400G提出的封装形式，其尺寸与CFP2相当。支持25Gbps和50Gbps的通道速率，通过16x25G或8x50电接口实现<strong>400Gbps</strong>模块速率。</p>
<p><img src="https://ts1.cn.mm.bing.net/th/id/R-C.48c1e779288b47694b91e15a83fb11ff?rik=YF5ixHZ1CJDJGQ&riu=http%3a%2f%2fwww.chinacablesbuy.com%2fwp-content%2fuploads%2f2017%2f03%2fCFP-CFP2-CFP4-QSFP28.jpg&ehk=Hc5Lmq7fNyTvka14uX2FRnfl96yCaaOYgegGWezKJvg%3d&risl=&pid=ImgRaw&r=0" alt="查看源图像" style="zoom:50%;" /></p>
<p>400G，是目前光通信产业的主要竞争方向。现在400G也是规模商用的初期阶段。目前的400G光模块，不管是哪种封装，价格都很昂贵，离用户的期望值还有很大差距。所以，暂时还无法快速进行全面普及。</p>
<h3 id="光模块的发展驱动"><a href="#光模块的发展驱动" class="headerlink" title="光模块的发展驱动"></a>光模块的发展驱动</h3><h4 id="电信市场"><a href="#电信市场" class="headerlink" title="电信市场"></a>电信市场</h4><p>​        5G引入了大带宽和低时延应用，承载网的架构、带宽、时延、同步精度等需求发生很大变化。5G将原4G无线接入网功能模块重新拆分。各级光传输节点之间光端口速率提升明显。随着网络步入大规模成熟部署期，中传、回传以及东西向流量的增加需要更多光模块。</p>
<p><img src="https://s2.loli.net/2022/09/15/X5htVeDRZk83nyu.png" alt="image-20220909151405593" style="zoom: 50%;" /></p>
<p>​        5G更高频段带来建站密度的提高，预计建站规模将是4G的1.5到2倍，光模块需求大大增加，室内小基站规模部署后，光模块用量还将更多。根据中国电子信息 产业发展研究院，到2030年，中国5G基站数量将达到1500万个$^{[8]}$。作为全球最早开始5G商用的国家之一，中国的5G基站数量将会高速增长，5G基站的建设需求将刺激运营商对光模块的需求，进一步提高光模块制造商的收入和产能。</p>
<h4 id="数通市场"><a href="#数通市场" class="headerlink" title="数通市场"></a>数通市场</h4><p>​        数据中心发展呈集中化大型化，中国拥有全球 最大的数据中心增量需求，网络基础设施的新 要求将拉动数据中心光模块需求增长。目前， 北美数据中心如谷歌、微软、亚马逊已陆续开 启400G网络升级进程。这些大型数据中心为 了满足带宽需求，每两到三年会对整体网络架 构进行一次升级。2015至2020年，全球超大型数据中心容量从 3,518MW增长到6,884MW，复合年增长率为 14.4%。同期国内超大 型数据中心容 量从 2017年的461MW增长至2020年的1,325MW， 并且增长还在呈现进一步加快态势。</p>
<p><img src="https://s2.loli.net/2022/09/15/ayzWhDPG59nZjrm.png" alt="image-20220909150616883" style="zoom: 33%;" /></p>
<p>​        2021 年，Facebook 宣布进军元宇宙，开启了元宇宙建设的新时代。同时 5G、云计 算、物联网、AI 等技术的发展，不断提高数据处理需求，科技巨头不断加大算力资 源投入，进一步推动高端光模块需求增长。数据中心大量的数据流通需要高速可靠的数据传输作为保障，这为光模块的技术进步提供了巨大的推动力。</p>
<h4 id="数通电信连携"><a href="#数通电信连携" class="headerlink" title="数通电信连携"></a>数通电信连携</h4><h3 id="光模块性能突破方向"><a href="#光模块性能突破方向" class="headerlink" title="光模块性能突破方向"></a>光模块性能突破方向</h3><p>​        从1998年发展至今，光模块一直朝着更高速率和更小封装与功耗两个方向不断升级。光模块的主要升级是速率升级，基本上3-4年进行一次迭代。</p>
<h4 id="更高速率的突破"><a href="#更高速率的突破" class="headerlink" title="更高速率的突破"></a>更高速率的突破</h4><p>​        从1.25Gbit/s发展到2.5Gbit/s，再到10Gbit/s、40Gbit/s、100Gbit/s、单波长100Gbit/s、400Gbit/s乃至1T，光模块的速率突破有以倍数增长的趋势。在3.2节中提到光模块提升带宽的思路有两种：</p>
<ul>
<li>1.提高每个通道的比特速率。</li>
<li>2.增加通道数。</li>
</ul>
<p>对于思路1，采取更高级、更巧妙的编/解码、调制/解调方式，提高传输速率；对于思路2，则是在硬件层面上进行改进，这应该也是最直接提升性能的最快方式$^{[9]}$。</p>
<h4 id="更小封装的突破"><a href="#更小封装的突破" class="headerlink" title="更小封装的突破"></a>更小封装的突破</h4><p>​        从低速率的GBIC、SFF到SFP光模块，从10Gbit/s速率的Xenpak、X2、XFP到SFP+，从100G速率的CFP（28W）、CFP2到现今宽度1/4的CFP4以及QSFP+和更小的QSFP28（3.5W），意味着光模块在交换机上具有更高的端口密度，同样的功率可以驱动更多的光模块。最初产品CFP到市场运用最广的成熟产品QSFP28，体积缩小85%，功耗下降87.5%。未来封装的突破同样也是依赖于硬件技术的发展。由于下游应用的需要，会通过通道数减少，信号控制功能优化等方式，进行缩小光模块体积，降低光模块功耗的升级，以100G时代来看，成熟产品要比最初的产品体积缩小85%，功耗减小87.5%。</p>
<h2 id="参考文献"><a href="#参考文献" class="headerlink" title="参考文献"></a>参考文献</h2><p>[1] 电子发烧友. 光模块基础知识大全、分类及选用电子发烧友-光模块基础知识大全、分类及选用[EB/OL]. (2018.3.9)[2018.3.9]. <a href="https://www.elecfans.com/baike/buxian/guangqianshebei/20180309645014_a.html">https://www.elecfans.com/baike/buxian/guangqianshebei/20180309645014_a.html</a></p>
<p>[2] 沙利文研究院.项目报告-光模块行业市场独立研究[R].深圳：沙利文研究院, 2021: 4-5。</p>
<p>[3] 沙利文研究院.项目报告-光模块行业市场独立研究[R].深圳：沙利文研究院, 2021: 5-6.</p>
<p>[4] 国联证券. 国联证券-中际旭创(300308)境外市场优势明显，行业龙头业绩增长可期-220428[R]. 北京: 国联证券, 2022：11-12.</p>
<p>[5] 国联证券. 国联证券-中际旭创(300308)境外市场优势明显，行业龙头业绩增长可期-220428[R]. 北京: 国联证券, 2022：12-13.</p>
<p>[6] smartavlink. What does the optical module look like? [EB/OL]. (2021.7.5)[2021.7.5]<a href="https://www.smartavlink.com/2021/06/05/what-does-the-optical-module-look-like">https://www.smartavlink.com/2021/06/05/what-does-the-optical-module-look-like</a></p>
<p>[7] etulink. GBIC和SFP的区别有哪些？[EB/OL].(2017.7.12)[2017.7.12] <a href="https://www.etulink.com/blog/gbic和sfp的区别有哪些？_b241">https://www.etulink.com/blog/gbic和sfp的区别有哪些？_b241</a></p>
<p>[8]知乎. 光模块光芯片发展现状与技术趋势 [EB/OL] (2021.10.12)[2021.10.12] <a href="https://zhuanlan.zhihu.com/p/420570165">https://zhuanlan.zhihu.com/p/420570165</a></p>
<p>[9]T. G. Giallorenzi, “Optical communications research and technology: Fiber optics,” in Proceedings of the IEEE, vol. 66, no. 7, pp. 744-780, July 1978, doi: 10.1109/PROC.1978.11014.</p>
]]></content>
      <categories>
        <category>通信技术</category>
      </categories>
      <tags>
        <tag>光通信</tag>
      </tags>
  </entry>
  <entry>
    <title>语义分割任务的数据增强方式</title>
    <url>/2022/10/14/Segmentation%20Augmentation/</url>
    <content><![CDATA[<p>记录了一些视觉任务中的图像处理方式。</p>
<span id="more"></span>
<h1 id="语义分割中数据增强方式（待补充）"><a href="#语义分割中数据增强方式（待补充）" class="headerlink" title="语义分割中数据增强方式（待补充）"></a>语义分割中数据增强方式（待补充）</h1><h2 id="EfficientNet-L2-NAS-FPN"><a href="#EfficientNet-L2-NAS-FPN" class="headerlink" title="EfficientNet-L2+NAS-FPN"></a>EfficientNet-L2+NAS-FPN</h2><p>VOC PASCAL 达到90.5%mIoU，次SOTA，2020年</p>
<ul>
<li><p>standard Flip ＆ Crop：包含了水平翻转和尺度抖动。水平翻转很常规，尺度抖动（Scale Jittering）即将不规则大小的img按照短边等比例缩放到某一个区间（一般为<code>crop_size</code>的$[0.8,1.2]$），并对等比例缩放后的结果进行固定尺寸大小的<code>crop_size</code>进行裁剪。</p>
</li>
<li><p>更大尺度的村都抖动：这篇文章里将尺度抖动放大到了$[0.5,2]$。</p>
</li>
<li><p>Auto Augment：<a href="https://arxiv.org/abs/1805.09501">[1805.09501] AutoAugment: Learning Augmentation Policies from Data (arxiv.org)</a>：是一种强化学习探索得到的针对数据集适合的数据增强方式，尽管达到当时的SOTA，但是参考价值不大。具体来说是构建一系列的基本图像数据增强方式：</p>
<p><img src="C:\Users\10706\AppData\Roaming\Typora\typora-user-images\image-20221014135442552.png" alt="image-20221014135442552"></p>
<p>随后通过PPO的迭代找到最优的策略操作，一共有两个operation，operation将从上面的增强方式中进行选取。</p>
</li>
<li><p>RandAugment：<a href="https://arxiv.org/abs/1909.13719">[1909.13719] RandAugment: Practical automated data augmentation with a reduced search space (arxiv.org)</a>：</p>
<p>首先讲讲自动数据增强方法中的”随机性“。以AutoAugment为例，通过搜索得出的最佳增强策略中，有多个（假设有K个）子策略，然后在训练时，对于某一批次的数据，从这K个中随机选择一个进行应用（这是随机性的第一层体现）。每个子策略由两种增强操作构成，每个操作有概率和幅度两个参数，也就是说，即使选中了这个子策略，这一批次的数据有没有被增强，或者经过这两个操作中哪个的增强，都由该子策略中的这两个概率参数控制（这是随机性的第二层体现）。即使应用了某一操作，比如旋转，虽然幅度参数指定了增强的幅度（比如说旋转45度），但具体是逆时针还是顺时针同样也是随机的（这是随机性的第三层体现）。</p>
<p>对此，作者舍弃掉这一系列的随机性（按我的理解是，这些反复的随机性，其实是削弱了AutoAugment中概率和幅度参数的作用。因此作者认为舍弃掉概率参数，或者说，将这些参数设为统一的值，从而免去搜索这些值的时间，换来效率的提高是值得的），直接将每种操作的应用概率设置为一样。因此，RandAugment方法为：</p>
<ol>
<li><p>设定一个操作集，例如作者的操作集由14种操作构成：Identity、AutoContrast、Equalize、Rotate、Solarize、Color、Posterize、Contrast、Brightness、Sharpness、ShearX、ShearY、TranslateX、TranslateY。</p>
</li>
<li><p>RandAugment只有两个参数：N和M。其中N为在每次增强时使用N次操作（使用的这N个操作，都是从操作集中等概率抽取的，例如操作集中有14种操作，则每种操作被选中的概率为1/14，每张图像的N次增强中，选到的操作可能是一样的），M为正整数，表示所有操作在应用时，幅度都为M。</p>
</li>
<li><p>使用网格搜索，或者更为高端的方法（如反向传播等）在完整数据集、完整网络上实验，找到最适合的N和M。这样一来，假如说N的搜索空间为1和2，M为1至10，则搜索空间仅为10^2，远小于之前的自动增强方法。</p>
</li>
</ol>
<p>通过更改N、M的值，便能控制训练时的正则化强度。N、M越大，正则化强度则越高。</p>
</li>
</ul>
]]></content>
      <categories>
        <category>计算机视觉</category>
      </categories>
      <tags>
        <tag>计算机视觉</tag>
        <tag>数据增强</tag>
        <tag>TODO</tag>
      </tags>
  </entry>
  <entry>
    <title>从一维卷积到二维卷积：浅析图像卷积</title>
    <url>/2022/08/03/%E5%9B%BE%E5%83%8F%E5%8D%B7%E7%A7%AF/</url>
    <content><![CDATA[<h2 id="什么是卷积"><a href="#什么是卷积" class="headerlink" title="什么是卷积"></a>什么是卷积</h2><p>首先先给出一维情况的卷积的定义。</p>
<script type="math/tex; mode=display">
f(x)*g(x)=\int_{-\infty}^{\infty}f(x)g(\tau-x)d\tau</script><p>这个式子很难从直观层面进行理解，因为它包含了乘积、翻转、积分三个部分的内容。如果你是信通学子，那么你肯定会知道两个函数的卷积结果可以看作是他们对应的傅里叶变换在频域的乘积的反变换，也就是说把一个函数作为输入信号，另一个函数作为描述系统的一个方程，当这个系统接收到输入信号后会做出响应，这个响应$y(t)$就是输入信号$x(t)$与系统函数$h(t)$卷积的结果：</p>
<script type="math/tex; mode=display">
y(t)=x(t)*h(t)=\mathcal F^{-1}[X(jw)H(jw)]</script><p>但很明显不是所有人都学过信号与系统，所以我想了个更<del>好</del>恶心的例子进行描述。<span id="more"></span></p>
<h3 id="一个恶心的例子"><a href="#一个恶心的例子" class="headerlink" title="一个恶心的例子"></a>一个<del>恶心</del>的例子</h3><p>试想这样一个场景：一个热门旅游景点的厕所。我们知道厕所需要连连不断地接待客人（？），因此厕所的囤粪速度可以用函数$F(x)$表示，如图1。</p>
<p><img src="https://s2.loli.net/2022/08/03/7FHNVEs1uM5RCIB.png" alt="image-20220724172639005" style="zoom:50%;" /></p>
<center><small>图1粪便囤积变化率曲线</small></center>

<p>但是厕所连通的化粪池它的处理能力有限，它对排泄物的处理效率如图2所示，我们用函数$H(x)$来表示。</p>
<p><img src="https://s2.loli.net/2022/08/03/BtJzpROGo3rTNYF.png" alt="image-20220724172618665" style="zoom:50%;" /></p>
<center><small>图2 化粪池分解效率</small></center>

<p>下面我们的问题就是需要讨论，<strong>化粪池在某个时候还有多少粪便啦！</strong></p>
<h3 id="怎么计算？"><a href="#怎么计算？" class="headerlink" title="怎么计算？"></a>怎么计算？</h3><p>每一个粪便都是独立的个体，它们都会随着化粪池分解而减少。如果不考虑粪便的分解的话，那么粪便总量可以这样表示：</p>
<script type="math/tex; mode=display">
n =\int_{-\infty}^{\infty}F(x)dx</script><p>但是我们的粪便不是无线增加的，因此，需要考虑分解的情况。现在假设在$t$时刻时进行统计，经过时间间隔$\tau$后统计存在的粪便总量为：</p>
<script type="math/tex; mode=display">
n' = F(t)·H(\tau)</script><p>也就是说在$t+\tau$时刻，不考虑其他情况下的粪便输入，此时一共有$n’$这么多的粪便。这里则是对应了卷积操作中的乘积部分。我们换一种写法，令$T=t+\tau$，则在$T$时刻不考虑其他粪便的增加的情况下，粪便量可以记为:</p>
<script type="math/tex; mode=display">
n'=F(t)·H(T-t)</script><p>$H(t)$函数的变量出现了x轴反转的情况，我们离卷积的定义也越来越近啦！下一步就是积分的问题了。积分其实也很好理解，因为上面这些式子都是只考虑了单个时刻不考虑其他时刻的输入信息，因此如果要考虑其他时刻的输入的话，则是把其他时刻的粪便量进行一个叠加（离散域就是使用$\sum$求和，连续域就是使用$\int$积分）。因此$t$时刻的粪便总量可以表示为：</p>
<script type="math/tex; mode=display">
Y(t)=\int_{-\infty}^{t}F(t)H(\tau-t)d\tau</script><p>是不是这样就很好理解了？</p>
<h3 id="图像的卷积是什么？"><a href="#图像的卷积是什么？" class="headerlink" title="图像的卷积是什么？"></a>图像的卷积是什么？</h3><p>卷积的本质在刚刚已经说了，就是反转、乘积、求和。到了二维也是这样子的：\</p>
<script type="math/tex; mode=display">
Y(x,y)=F(x,y)*H(x,y)=\sum_{n_1=-\infty}^{\infty}\sum_{n_2=-\infty}^{\infty}F(n_1,n_2)·H(x-n_1,y-n_2)</script><p>好！下面我们给出图像卷积的一个步骤：</p>
<p><img src="https://img-blog.csdnimg.cn/20200308112430934.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L25hcnVoaW5h,size_16,color_FFFFFF,t_70" alt=""></p>
<p>其中这个<code>Convolution Kernel</code>叫做卷积核，<code>Source Pixel</code>就是我们的图像。在这张图里红色通道对应的地方就是卷积处理的第一个像素，计算的公式在右上角，输入是1，输出是8。随着卷积核往下一个像素移动，优惠计算出新的像素值，直到按设定的规则遍历完图像。</p>
<p><img src="https://pic3.zhimg.com/v2-8a6695c2e086525ac5a61610348739b2_b.gif" alt=""></p>
<p>唯一需要指出的是，在这里体现了乘积和加和，那么反转是在哪里体现的呢？其实是图中卷积核已经是翻转了180°了，也就是说原本的卷积核它的“4”是在”-4“的位置的。所以这就是图像卷积的操作，是不是很好理解捏？</p>
<h2 id="为什么是卷积"><a href="#为什么是卷积" class="headerlink" title="为什么是卷积"></a>为什么是卷积</h2><p>上结论：卷积的本质是提取图像中的特征。许多常用的图像处理方法都可以用卷积的方式表示，因此选择卷积。卷积的输出是<code>out_channel</code>个<code>feature_map</code>。其中的<code>feature_map</code>就是上面文章计算每一个求和的结果组成的一张新的“图像”，这个图像的尺寸大小是这样计算的：</p>
<ul>
<li><code>input</code>:$(N,C_{in},H_{in},W_{in})$or$(C_{in},H_{in},W_{in})$</li>
<li><code>output</code>:$(N,C_{out},H_{out},W_{out})$or$(C_{out},H_{out},W_{out})$</li>
</ul>
<script type="math/tex; mode=display">
\begin{aligned}
&H_{out}=[\frac{H_{in}+2\times \mathrm {padding[0]-\mathrm{dialation}[0]\times (\mathrm{kernal\_size[0]-1})-1}}{\mathrm{stride[0]}}+1]\\
&W_{out}=[\frac{W_{in}+2\times \mathrm {padding[1]-\mathrm{dialation}[1]\times (\mathrm{kernal\_size[1]-1})-1}}{\mathrm{stride[1]}}+1]\\
\end{aligned}</script><p>其中的$N$是<code>pytorch</code>的批量大小。</p>
<h2 id="Pytorch的图像卷积"><a href="#Pytorch的图像卷积" class="headerlink" title="Pytorch的图像卷积"></a>Pytorch的图像卷积</h2><p><img src="https://img-blog.csdnimg.cn/20201121195053531.gif" alt=""></p>
<p>终于来到这里了。我们先看看pytorch卷积层继承的父类<code>_ConvNd</code>:</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">_ConvNd</span>(<span class="title class_ inherited__">Module</span>):</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self,</span></span><br><span class="line"><span class="params">                 in_channels: <span class="built_in">int</span>,</span></span><br><span class="line"><span class="params">                 out_channels: <span class="built_in">int</span>,</span></span><br><span class="line"><span class="params">                 kernel_size: <span class="type">Tuple</span>[<span class="built_in">int</span>, ...],</span></span><br><span class="line"><span class="params">                 stride: <span class="type">Tuple</span>[<span class="built_in">int</span>, ...],</span></span><br><span class="line"><span class="params">                 padding: <span class="type">Tuple</span>[<span class="built_in">int</span>, ...],</span></span><br><span class="line"><span class="params">                 dilation: <span class="type">Tuple</span>[<span class="built_in">int</span>, ...],</span></span><br><span class="line"><span class="params">                 transposed: <span class="built_in">bool</span>,</span></span><br><span class="line"><span class="params">                 output_padding: <span class="type">Tuple</span>[<span class="built_in">int</span>, ...],</span></span><br><span class="line"><span class="params">                 groups: <span class="built_in">int</span>,</span></span><br><span class="line"><span class="params">                 bias: <span class="built_in">bool</span>,</span></span><br><span class="line"><span class="params">                 padding_mode: <span class="built_in">str</span>,</span></span><br><span class="line"><span class="params">                 device=<span class="literal">None</span>,</span></span><br><span class="line"><span class="params">                 dtype=<span class="literal">None</span></span>) -&gt; <span class="literal">None</span>:</span><br></pre></td></tr></table></figure>
<p>主要关注<code>in_channels</code>,<code>out_channels</code>,<code>kernel_size</code>,<code>stride</code>,<code>padding</code>这几个参数。</p>
<ul>
<li>in_channels</li>
</ul>
<p><code>in_channels</code>的输入是按<code>(N,C,H,W)</code>排列的，<code>N</code>是mini-batch大小，<code>C</code>是通道数channel，<code>H</code>和<code>W</code>分别是输入的高和宽，<strong>这和<code>Tensorflow</code>的不太一样。</strong></p>
<ul>
<li>out_channels</li>
</ul>
<p>在定义好了<code>in_channels</code>后，<code>out_channels</code>只需要关注输出通道数<code>K</code>即可。</p>
<ul>
<li>kernel_size</li>
</ul>
<p>卷积核大小，如果设为一个整数的话那么卷积核就是一个正方形的，否则就按长宽的顺序输入一个<code>tuple</code>作为卷积核形状。</p>
<ul>
<li>stride</li>
</ul>
<p>步长。也就是卷积核移动的距离，可以是一个整数也可以是一个<code>tuple</code>，类似<code>kernel_size</code>。</p>
<ul>
<li>padding</li>
</ul>
<p>补丁，就是只要使用了大小大于1的卷积核去做卷积的话，输出图像的大小是比原本的图像大小要小的，因此为了保证维度的大小一致，会引入padding填充原图像的边缘位置，该值表示的是沿原图边缘进行该值大小的延拓。</p>
<h2 id="那反卷积是干啥的？"><a href="#那反卷积是干啥的？" class="headerlink" title="那反卷积是干啥的？"></a>那反卷积是干啥的？</h2><p>从上面的文章我们知道了卷积是从高维的数据中不断地输出尺寸变小的特征图，是一个从大到小的变换过程，而反卷积就是从小变大的一个相反过程。但是需要注意：<strong>反卷积只能恢复图像原有的大小，而不能完全恢复图像原本的信息。</strong>它在<code>Pytorch</code>中的操作如下：</p>
<ul>
<li>input:$(N,C_{in},H_{in},W_{in})$or$(C_{in},H_{in},W_{in})$</li>
<li><code>output</code>:$(N,C_{out},H_{out},W_{out})$or$(C_{out},H_{out},W_{out})$</li>
</ul>
<script type="math/tex; mode=display">
\begin{aligned}
&H_{out}=(H_{in}-1)\times \mathrm{stride}[0]-2\times \mathrm{padding}[0]+\mathrm{dilation}[0]\times(\mathrm{kernel\_size}[0]-1)+\mathrm{output\_padding}[0]+1\\
&W_{out}=(H_{in}-1)\times \mathrm{stride}[1]-2\times \mathrm{padding}[1]+\mathrm{dilation}[1]\times(\mathrm{kernel\_size}[1]-1)+\mathrm{output\_padding}[1]+1
\end{aligned}</script><p>在<code>Pytorch</code>中的使用示例如下：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># With square kernels and equal stride</span></span><br><span class="line">m = nn.ConvTranspose2d(<span class="number">16</span>, <span class="number">33</span>, <span class="number">3</span>, stride=<span class="number">2</span>)</span><br><span class="line"><span class="comment"># non-square kernels and unequal stride and with padding</span></span><br><span class="line">m = nn.ConvTranspose2d(<span class="number">16</span>, <span class="number">33</span>, (<span class="number">3</span>, <span class="number">5</span>), stride=(<span class="number">2</span>, <span class="number">1</span>), padding=(<span class="number">4</span>, <span class="number">2</span>))</span><br><span class="line"><span class="built_in">input</span> = torch.randn(<span class="number">20</span>, <span class="number">16</span>, <span class="number">50</span>, <span class="number">100</span>)</span><br><span class="line">output = m(<span class="built_in">input</span>)</span><br><span class="line"><span class="comment"># exact output size can be also specified as an argument</span></span><br><span class="line"><span class="built_in">input</span> = torch.randn(<span class="number">1</span>, <span class="number">16</span>, <span class="number">12</span>, <span class="number">12</span>)</span><br><span class="line">downsample = nn.Conv2d(<span class="number">16</span>, <span class="number">16</span>, <span class="number">3</span>, stride=<span class="number">2</span>, padding=<span class="number">1</span>)</span><br><span class="line">upsample = nn.ConvTranspose2d(<span class="number">16</span>, <span class="number">16</span>, <span class="number">3</span>, stride=<span class="number">2</span>, padding=<span class="number">1</span>)</span><br><span class="line">h = downsample(<span class="built_in">input</span>)</span><br><span class="line">h.size()</span><br><span class="line">output = upsample(h, output_size=<span class="built_in">input</span>.size())</span><br><span class="line">output.size()</span><br></pre></td></tr></table></figure>
<p>参数其实和卷积的一样，我就不解释了。</p>
]]></content>
      <categories>
        <category>学习记录</category>
      </categories>
      <tags>
        <tag>计算机视觉</tag>
      </tags>
  </entry>
  <entry>
    <title>基站选址研究</title>
    <url>/2022/10/16/%E5%9F%BA%E7%AB%99%E5%88%86%E9%85%8D/</url>
    <content><![CDATA[<p>This is your introduction…好久没写数模了，正好选修课要写一个大报告的论文，我找了个和通信相关的题目来做一下找找感觉。选了<a href="http://www.mathorcup.org/detail/2377">2022年第十二届MathorCup高校数学建模挑战赛</a>中的D题来做，边写边记录吧，我也不是啥专家啥的，就只能见招拆招。</p>
<span id="more"></span>
<h2 id="题目背景"><a href="#题目背景" class="headerlink" title="题目背景"></a>题目背景</h2><p>​        移动通信技术规模飞速发展，运营规模也越来越大，导致带来的通信 网络越来越复杂。随着 5G 的发展，通信的带宽越来越大，但基站的能覆盖 范围越来越小，使得覆盖同样的区域，需要的基站数量变的更多。另外， 基站和天线的种类也变多了。这就使得通信网络的规划特别是站址选择的 问题变得越来越复杂。<strong>站址选择问题是：根据现网天线的覆盖情况，给出现网的弱覆盖区域，选择一定数量的点，使得在这些点上新建基站后，可 以解决现网的弱覆盖区域的覆盖问题。</strong>例如，下图为某城市某区域的现网覆盖情况，其中红色的区域表示为弱覆盖区域。</p>
<p><img src="https://s2.loli.net/2022/10/16/t2AcRWDB7VE9kHs.png" alt="题目配图" style="zoom:50%;" /></p>
<p>​        在实际网络规划中，考虑基站的建设成本和一些其他因素，有时候可 能无法把所有弱覆盖区域都解决，这时候就需要考虑业务量的因素，尽量 优先解决业务量高的弱覆盖区域。</p>
<p>​        为了便于计算，将给定的区域用很小的栅格进行划分，只考虑每个栅格的中心点，即任给一个区域，都可以划分成有限个点。每个点有一些属性值，包括：坐标，是否为弱覆盖点，业务量等。站址也只能选择区域内的点。某个点是否被规划基站覆盖可以按如下方法判断： 设选择基站的覆盖范围为 d，基站所规划的点的坐标为：$P_0(x_0,y_0)$ ，则对于坐标为$P(x,y)$的点，若$||P-P_0||_2\leq d$，则认为该点被该基站覆盖，否则认 为该点没有被该基站覆盖。 同时，实际中还需要考虑一个约束条件，即新建站址之间以及新建站 址和现有站址之间的距离不能<strong>小于等于给定门限</strong>。</p>
<p>​        <strong>问题1</strong>：给定区域的大小是 2500×2500 个栅格即 2500×2500 个点， 其中横坐标范围是 0 到 2499，纵坐标范围是 0 到 2499。附件 1 中是筛选出 该区域中的弱覆盖点的信息，包括每个点的坐标和业务量。给定 2 种基站， 分别为：宏基站（覆盖范围30，成本10），微基站（覆盖范围10，成本1）。附件 2 中还给出了现网基站的坐标点，<strong>新建站址之间以及新建站址和现有站址之间的距离的门限是10</strong>。根据给定的信息和附件中的数据，进行站址规划，<strong>使得弱覆盖点总业务量的 90%被规划基站覆盖。</strong>给出选择的站址的坐标以及每个站址选择的基站种类。站址的坐标只能在给定区域内的 2500×2500 个点中选择。</p>
<p>​        <strong>问题 2</strong>：进一步考虑，实际中，每个站并不是完全的圆形覆盖，而是 每个站上有 3 个扇区，每个扇区指向一个方向。每个扇区在主方向上覆盖 范围最大（宏基站为 30，微基站为 10），在主方向左右 60 度的范围内可以 覆盖，覆盖范围按线性逐渐缩小，在 60 度的时候，覆盖范围为主方向覆盖范围的一半。超过 60 度，则无法被该扇区覆盖。 考虑每个站的任意 2 个扇区的主方向之间的夹角不能小于 45 度，同时仍然考虑上一问中的基站成本等其他条件，问在最优站址和扇区角度的条 件下，新建站能否覆盖弱覆盖点总业务量的 90%。若能，给出最优站址和扇区角度的结果；否则，给出最优站址和扇区角度的结果，并给出最多可以覆盖的弱覆盖点的总业务量的比例。</p>
<p>​        <strong>问题 3</strong>：实际工作中，为了更好的解决弱覆盖问题，需要对弱覆盖点进行区域聚类，把距离近的弱覆盖点聚成一类，可以得到弱覆盖区域，这样可以对不同的弱覆盖区域分开管理使得可以更好的解决弱覆盖问题。 若 2 个弱覆盖点的距离不大于 20，则这 2 个弱覆盖点应聚为一类，并 且考虑聚类性质具有传递性，即若点 A 和点 B 是一类的，点 B 和点 C 是一 类的，则点 A、B 和 C 都是一类的。试对所有弱覆盖点进行聚类，要求聚 类所用方法的总时间复杂度尽量低。</p>
<h2 id="第一题的解答"><a href="#第一题的解答" class="headerlink" title="第一题的解答"></a>第一题的解答</h2><p>第一题就让我们看两个附件了，之后的题要我干什么我都不敢想了😡</p>
<p><img src="https://s2.loli.net/2022/10/16/2g1SRCftv83ITkU.png" alt="image-20221016225907864"></p>
<p>首先先看看附件1的数据：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">data = pd.read_csv(<span class="string">&#x27;附件\附件1 弱覆盖栅格数据(筛选).csv&#x27;</span>)</span><br><span class="line"><span class="built_in">print</span>(data.head())</span><br><span class="line"></span><br><span class="line"><span class="comment">#      x     y     traffic</span></span><br><span class="line"><span class="comment"># 0   66  1486  140.581390</span></span><br><span class="line"><span class="comment"># 1   67  1486  140.518829</span></span><br><span class="line"><span class="comment"># 2  177  1486   48.919178</span></span><br><span class="line"><span class="comment"># 3  187  1486    4.322495</span></span><br><span class="line"><span class="comment"># 4  284  1486   71.528404</span></span><br></pre></td></tr></table></figure>
<p>一共有三列，<code>traffic</code>代表的是业务量吧，然后前面的xy是坐标。这时候我的第一反应是画一个热力图（非常自然的想法啊对不对），所以我先生成一个<code>2500*2500</code>的零矩阵。然后根据<code>(x,y)</code>对应到矩阵中的元素对其进行修改成对应的<code>traffic</code>值：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">grid_blank = np.zeros((<span class="number">2500</span>,<span class="number">2500</span>))</span><br><span class="line">x_index = data[<span class="string">&#x27;x&#x27;</span>].tolist()</span><br><span class="line">y_index = data[<span class="string">&#x27;y&#x27;</span>].tolist()</span><br><span class="line">value = data[<span class="string">&#x27;traffic&#x27;</span>].tolist()</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(x_index)):</span><br><span class="line">    grid_blank[x_index[i]][y_index[i]] = value[i]</span><br><span class="line"></span><br><span class="line">heatmap = sns.heatmap(grid_blank)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>
<p>运行！然后发现问题不对劲了：</p>
<p><img src="https://s2.loli.net/2022/10/16/OGsgkXahJ6WRUAu.png" alt="失败的热力图"></p>
<p>这能看到个啥？？？原本理应为方块的地方已经变成了像素了…所以我决定换一种作图方式！选择散点图：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">fig,ax = plt.subplots(figsize = (<span class="number">12</span>,<span class="number">10</span>))</span><br><span class="line"> <span class="comment">#注意 s 离散化的方法，因为需要通过点的大小来直观感受其所表示的数值大小</span></span><br><span class="line"> <span class="comment">#参数是 X 轴数据、Y 轴数据、各个点的大小、各个点的颜色</span></span><br><span class="line">scatter = ax.scatter(x_index, y_index , s = value, c = value, cmap = plt.cm.get_cmap(<span class="string">&#x27;RdYlBu&#x27;</span>), linewidth = <span class="number">0.5</span>, alpha = <span class="number">0.5</span>)</span><br><span class="line">ax.grid()</span><br><span class="line">fig.colorbar(scatter)</span><br><span class="line">plt.show()</span><br><span class="line"><span class="comment">#plt.savefig(&quot;Figure1.png&quot;)</span></span><br></pre></td></tr></table></figure>
<p>当然可以选择3维的柱状图，不过实际效果可能没那么好…</p>
<p><img src="https://s2.loli.net/2022/10/16/jlto3HRpqcNhTs8.jpg" style="zoom:50%;" /></p>
<center><small>数据初探：基站的业务痛点</small></center>

<p>在这里越蓝的点代表了其越重要的业务承担，也可以通过点的大小来表示（其实这个时候也不能说是点了…说是圆的大小还差不多）。既然我们可视化了，下一步就该思考下这个问题该怎么走下去了。首先我们先关注那些业务量大的点，保证他们能被优先覆盖。题目给的要求是要覆盖90%以上的业务，意思就是说，你选择的基站的业务量要占总的业务量的90%以上。我们先研究下这些薄弱基站的业务量的分布：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">value_cnt = data.value_counts(<span class="string">&#x27;traffic&#x27;</span>,sort=<span class="literal">False</span>)</span><br><span class="line">value_cnt_index = value_cnt.index.to_list()</span><br><span class="line">value_cnt_data = value_cnt.to_list()</span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> pyecharts.charts <span class="keyword">import</span> Bar</span><br><span class="line"><span class="keyword">from</span> pyecharts <span class="keyword">import</span> options <span class="keyword">as</span> opts</span><br><span class="line">bar = (</span><br><span class="line">    Bar()</span><br><span class="line">    .add_xaxis(value_cnt_index)</span><br><span class="line">    .add_yaxis(<span class="string">&#x27;业务量&#x27;</span>,value_cnt_data, label_opts=opts.LabelOpts(is_show=<span class="literal">False</span>))</span><br><span class="line">    .set_global_opts(</span><br><span class="line">        title_opts=opts.TitleOpts(</span><br><span class="line">            title=<span class="string">&quot;业务量统计📈&quot;</span>,</span><br><span class="line">            pos_left=<span class="string">&#x27;center&#x27;</span>),</span><br><span class="line">        datazoom_opts=[opts.DataZoomOpts(), opts.DataZoomOpts(type_=<span class="string">&quot;inside&quot;</span>)],</span><br><span class="line">        legend_opts=opts.LegendOpts(is_show=<span class="literal">False</span>)</span><br><span class="line">    )</span><br><span class="line">)</span><br><span class="line">bar.render(<span class="string">&#x27;Traffic.html&#x27;</span>)</span><br></pre></td></tr></table></figure>
<p><img src="https://s2.loli.net/2022/10/16/7uLQ93UVwIfjA1r.png" alt="image-20221016164231319" style="zoom: 80%;" /></p>
<p>我们可以看到薄弱基站的业务量的大头其实集中在低端区域<code>[0,2]</code>左右的区间。这说明如果我们只考虑覆盖业务总量的条件下，我们只需要优先考虑大业务量的基站即可。即：优先覆盖大区域，然后再已覆盖的大区域附近选取更多的小业务量基站以达到更优的覆盖率。</p>
<p>至于你说为什么我突然转成了<code>pyecharts</code>？我也不想的，但是<code>sns</code>不知道为啥卡了…而且效果图也不是很好。如果你要坚持要用也不是不行，很慢就是了：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">bar = sns.barplot(x=value_cnt_index, y=value_cnt_data)</span><br><span class="line">plt.savefig(<span class="string">&#x27;Figure2.png&#x27;</span>)</span><br></pre></td></tr></table></figure>
<p><img src="https://s2.loli.net/2022/10/16/LY8j4vVWpFOfMZt.png" style="zoom: 80%;" /></p>
<p>OK。下一步就是筛选出最优先考虑覆盖的薄弱基站，我们要获取这些基站的坐标信息。获取这些坐标信息的逻辑很简单：我们只需要先对这些薄弱基站按业务量进行排序，先计算业务量总和，然后对排序后的结果进行累加直至累加到某一个基站达到设定的业务阈值（也就是题目1中的0.9）后跳出迭代过程，并把所以参加过累加的基站索引给取出即可。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">sort_data = data.sort_values(by=<span class="string">&#x27;traffic&#x27;</span>,ascending=<span class="literal">False</span>)</span><br><span class="line">traffic_total = sort_data[<span class="string">&#x27;traffic&#x27;</span>].<span class="built_in">sum</span>()</span><br><span class="line">percentage = sort_data[<span class="string">&#x27;traffic&#x27;</span>].cumsum()/data[<span class="string">&#x27;traffic&#x27;</span>].<span class="built_in">sum</span>()</span><br><span class="line"><span class="built_in">print</span>(percentage)</span><br><span class="line"></span><br><span class="line">threshold = <span class="number">0.9</span></span><br><span class="line">better_choice = percentage[percentage &gt; threshold]</span><br><span class="line">at_least = better_choice.index[<span class="number">0</span>]</span><br><span class="line">better_choice_idx = sort_data.index.to_list().index(at_least)</span><br><span class="line"></span><br><span class="line">key_station = sort_data[:better_choice_idx]</span><br><span class="line">key_station.to_csv(<span class="string">&#x27;Key_station.csv&#x27;</span>)</span><br><span class="line"></span><br><span class="line">x_index = key_station[<span class="string">&#x27;x&#x27;</span>].to_list()</span><br><span class="line">y_index = key_station[<span class="string">&#x27;y&#x27;</span>].to_list()</span><br><span class="line">value = key_station[<span class="string">&#x27;traffic&#x27;</span>].to_list()</span><br><span class="line"></span><br><span class="line">fig,ax = plt.subplots(figsize = (<span class="number">12</span>,<span class="number">10</span>))</span><br><span class="line">bubble = ax.scatter(x_index, y_index , s = value, c = value, cmap = plt.cm.get_cmap(<span class="string">&#x27;RdYlBu&#x27;</span>), linewidth = <span class="number">0.5</span>, alpha = <span class="number">0.5</span>)</span><br><span class="line">ax.grid()</span><br><span class="line">fig.colorbar(bubble)</span><br><span class="line">plt.title(<span class="string">&quot;Base Station Distribution.[Selected]&quot;</span>)</span><br><span class="line">plt.savefig(<span class="string">&#x27;Figure_3.jpg&#x27;</span>)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>
<p><img src="https://s2.loli.net/2022/10/16/fEevjtYrQm5BlyO.jpg" style="zoom: 80%;" /></p>
<p>下一步则是根据已经获得的坐标进行规划了。</p>
<p>我们先看看已有的基站和弱覆盖区域的分布：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">data = pd.read_csv(<span class="string">&#x27;附件\附件1 弱覆盖栅格数据(筛选).csv&#x27;</span>)</span><br><span class="line">data2 = pd.read_csv(<span class="string">&#x27;附件\附件2 现网站址坐标(筛选).csv&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># print(data.head())</span></span><br><span class="line"><span class="comment"># grid_blank = np.zeros((2500,2500))</span></span><br><span class="line">x_index = data[<span class="string">&#x27;x&#x27;</span>].tolist()</span><br><span class="line">y_index = data[<span class="string">&#x27;y&#x27;</span>].tolist()</span><br><span class="line">value = data[<span class="string">&#x27;traffic&#x27;</span>].tolist()</span><br><span class="line"></span><br><span class="line">x_index_2 = data2[<span class="string">&#x27;x&#x27;</span>].tolist()</span><br><span class="line">y_index_2 = data2[<span class="string">&#x27;y&#x27;</span>].tolist()</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># for i in range(len(x_index)):</span></span><br><span class="line"><span class="comment">#     grid_blank[x_index[i]][y_index[i]] = value[i]</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># heatmap = sns.heatmap(grid_blank)</span></span><br><span class="line"><span class="comment"># plt.show()</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">fig,ax = plt.subplots(figsize = (<span class="number">12</span>,<span class="number">10</span>))</span><br><span class="line"> <span class="comment">#注意 s 离散化的方法，因为需要通过点的大小来直观感受其所表示的数值大小</span></span><br><span class="line"> <span class="comment">#参数是 X 轴数据、Y 轴数据、各个点的大小、各个点的颜色</span></span><br><span class="line">ax.scatter(x_index, y_index , s = <span class="number">4</span>, c = <span class="string">&#x27;red&#x27;</span>, linewidth = <span class="number">0.5</span>, alpha = <span class="number">0.5</span>)</span><br><span class="line">ax.scatter(x_index_2,y_index_2,s =<span class="number">20</span>, c=<span class="string">&quot;blue&quot;</span>, linewidth = <span class="number">0.5</span>, alpha = <span class="number">0.5</span>, marker=<span class="number">7</span>)</span><br><span class="line">ax.grid()</span><br><span class="line"><span class="comment">#fig.colorbar(bubble)</span></span><br><span class="line">plt.title(<span class="string">&#x27;Weak Area And Exsisted Base Station Distribution&#x27;</span>)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>
<p><img src="https://s2.loli.net/2022/10/18/BSX9ClrxwaGJmON.png" style="zoom: 50%;" /></p>
<p>其中的蓝色三角点代表的是已有基站，红色点代表的是弱覆盖区域。可以看到已有的基站其实挺多的，我们先假设这些基站都是微基站，也就是覆盖半径为10，我们先通过这个假设排除掉一些被覆盖的薄弱区域。考虑到后面还有宏基站，以及需要对基站分配结果进行检验，故设计了几个函数：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># Debug用的装饰器，计时用</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">count_time</span>(<span class="params">func</span>):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">wrapper</span>(<span class="params">*args, **kwargs</span>):</span><br><span class="line">        start = time.time()</span><br><span class="line">        a = func(*args, **kwargs)</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&quot;Cost time: &#123;&#125; secondes.&quot;</span>.<span class="built_in">format</span>(time.time()-start))</span><br><span class="line">        <span class="keyword">return</span> a</span><br><span class="line">    <span class="keyword">return</span> wrapper</span><br><span class="line"></span><br><span class="line"><span class="comment"># 根据偏移坐标点生成实际覆盖区域的坐标点集</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">generate_area</span>(<span class="params">x,y,offset_list</span>):</span><br><span class="line">    <span class="keyword">return</span> [[x+each[index],y+each[index]]<span class="keyword">for</span> each <span class="keyword">in</span> offset_list <span class="keyword">for</span> index,_ <span class="keyword">in</span> <span class="built_in">enumerate</span>(each)]</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment">#@count_time	#Debug完记得注释掉</span></span><br><span class="line"><span class="comment">#通过在(0,0)计算相对允许偏移点集合</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">generate_offset</span>(<span class="params">radius</span>):</span><br><span class="line">    <span class="keyword">return</span> [[i,j] <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(-radius,radius+<span class="number">1</span>) <span class="keyword">for</span> j <span class="keyword">in</span> <span class="built_in">range</span>(-radius,radius+<span class="number">1</span>) <span class="keyword">if</span> i ** <span class="number">2</span> + j ** <span class="number">2</span> &lt;= radius**<span class="number">2</span>]</span><br></pre></td></tr></table></figure>
<p>就是说如果对于每一个选择的基站，我们要计算其部署后的覆盖点集，但我们即便在最低的运算条件下，即只是用给定的现有的<code>1474</code>个基站计算，每个基站就要算<code>317</code>个点，总共的大小为<code>317*1474 = 465783</code>。如果你用一个列表来保存这些点那么你的内存可能会爆掉，所以最好的办法就是用一个哈希表来保存。假如某两个基站的覆盖点重合了，那么只记录已有的点，然后进行下一个点的生成，这样就能保证列表中的点是唯一的。Python怎么实现哈希表？字典就可以了，把<code>Key</code>设成字符串型的坐标，value只需要标记成True即可。依然选择我最爱用的Generator，快的一批：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">coverage_min = &#123;<span class="built_in">str</span>(each) :<span class="literal">True</span> <span class="keyword">for</span> index,_ <span class="keyword">in</span> data2.iterrows() <span class="keyword">for</span> each <span class="keyword">in</span> generate_area(data2[<span class="string">&#x27;x&#x27;</span>][index],data2[<span class="string">&#x27;y&#x27;</span>][index],offset_list_10)&#125;</span><br></pre></td></tr></table></figure>
<p><img src="https://s2.loli.net/2022/10/18/1zOtCEDvocih49b.png" alt="image-20221018170311840"></p>
<p>内存占用一下子变成了<code>29786</code>，对比原本的<code>465783</code>，内存占用一下子就少了93%好吧？很他吗强！下面我们可以把所有已覆盖区域给标记一下，为了防止翻车我做了个backup：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">data_copy = data.copy()</span><br><span class="line">data_copy[<span class="string">&#x27;is_covered&#x27;</span>] = <span class="literal">False</span></span><br><span class="line"><span class="keyword">for</span> index,_ <span class="keyword">in</span> data_copy.iterrows():</span><br><span class="line">    <span class="keyword">if</span> <span class="built_in">str</span>([data_copy[<span class="string">&#x27;x&#x27;</span>][index],data_copy[<span class="string">&#x27;y&#x27;</span>][index]]) <span class="keyword">in</span> coverage_min:</span><br><span class="line">         data_copy[<span class="string">&#x27;is_covered&#x27;</span>][index] =  <span class="literal">True</span></span><br></pre></td></tr></table></figure>
<p><img src="https://s2.loli.net/2022/10/18/A74QLXWGdfcueNS.png" alt="image-20221018175832659"></p>
<p>然后清洗一下，把还没覆盖的点给选出来画个图：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">unconvered = data_copy[data_copy[<span class="string">&#x27;is_covered&#x27;</span>] == <span class="literal">False</span>]</span><br><span class="line">convered = data_copy[data_copy[<span class="string">&#x27;is_covered&#x27;</span>] == <span class="literal">True</span>]</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(convered.head())</span><br><span class="line"><span class="comment">#          x     y    traffic  is_covered</span></span><br><span class="line"><span class="comment"># 316   1735   529   0.964652        True</span></span><br><span class="line"><span class="comment"># 717   1736   530   3.396427        True</span></span><br><span class="line"><span class="comment"># 897    332   849   2.226614        True</span></span><br><span class="line"><span class="comment"># 1113  2187   211  27.612494        True</span></span><br><span class="line"><span class="comment"># 1209  2313  1488   1.841420        True</span></span><br><span class="line"><span class="built_in">print</span>(unconvered.head())</span><br><span class="line"><span class="comment">#      x     y     traffic  is_covered</span></span><br><span class="line"><span class="comment"># 0   66  1486  140.581390       False</span></span><br><span class="line"><span class="comment"># 1   67  1486  140.518829       False</span></span><br><span class="line"><span class="comment"># 2  177  1486   48.919178       False</span></span><br><span class="line"><span class="comment"># 3  187  1486    4.322495       False</span></span><br><span class="line"><span class="comment"># 4  284  1486   71.528404       False</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> seaborn <span class="keyword">as</span> sns</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"></span><br><span class="line">x_index = unconvered[<span class="string">&#x27;x&#x27;</span>].to_list()</span><br><span class="line">y_index = unconvered[<span class="string">&#x27;y&#x27;</span>].to_list()</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">fig,ax = plt.subplots(figsize = (<span class="number">12</span>,<span class="number">10</span>))</span><br><span class="line"> <span class="comment">#注意 s 离散化的方法，因为需要通过点的大小来直观感受其所表示的数值大小</span></span><br><span class="line"> <span class="comment">#参数是 X 轴数据、Y 轴数据、各个点的大小、各个点的颜色</span></span><br><span class="line">bubble = ax.scatter(x_index, y_index , s = <span class="number">10</span>, c= <span class="string">&#x27;red&#x27;</span>)</span><br><span class="line">ax.grid()</span><br><span class="line">plt.title(<span class="string">&quot;Unconvered Area&quot;</span>)</span><br><span class="line">plt.savefig(<span class="string">&#x27;Unconvered Area.jpg&#x27;</span>)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>
<p><img src="https://s2.loli.net/2022/10/18/uvZoD1zFyeKdGjH.jpg" style="zoom:67%;" /></p>
<p>我陷入了思考…这好像也没多少变化啊？对比一下看看到底有多少区域是覆盖的：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">x_index2 = convered[<span class="string">&#x27;x&#x27;</span>].to_list()</span><br><span class="line">y_index2 = convered[<span class="string">&#x27;y&#x27;</span>].to_list()</span><br><span class="line"></span><br><span class="line">fig,ax = plt.subplots(figsize = (<span class="number">12</span>,<span class="number">10</span>))</span><br><span class="line"> <span class="comment">#注意 s 离散化的方法，因为需要通过点的大小来直观感受其所表示的数值大小</span></span><br><span class="line"> <span class="comment">#参数是 X 轴数据、Y 轴数据、各个点的大小、各个点的颜色</span></span><br><span class="line">bubble = ax.scatter(x_index, y_index , s = <span class="number">10</span>, c= <span class="string">&#x27;red&#x27;</span>)</span><br><span class="line"></span><br><span class="line">ax.grid()</span><br><span class="line"></span><br><span class="line">ax.grid()</span><br><span class="line"></span><br><span class="line">ax.scatter(x_index,y_index,c=<span class="string">&#x27;red&#x27;</span>,s=<span class="number">10</span>)</span><br><span class="line">ax.scatter(x_index2,y_index2,c=<span class="string">&#x27;blue&#x27;</span>,s=<span class="number">10</span>)</span><br><span class="line">plt.title(<span class="string">&quot;Unconvered Area and Convered Area&quot;</span>)</span><br><span class="line">plt.savefig(<span class="string">&#x27;Unconvered Area and Convered Area.jpg&#x27;</span>)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>
<p><img src="https://s2.loli.net/2022/10/18/9cflhKytuzVJN1Z.jpg" style="zoom: 67%;" /></p>
<p>沉默…覆盖的点太少了。覆盖点有728个，但未覆盖的点有182079个，这两个差的数量级不是一星半点…那该怎么办捏？</p>
<p><img src="https://s2.loli.net/2022/10/16/uflPdJQp1Wrh4ne.png" alt="image-20221016225955434" style="zoom:50%;" /></p>
<p>这个时候千万别灰心啊，因为你是在最垃圾的情况下覆盖了728个薄弱点，本来就没指望它能覆盖的啊。如果我们把原有基站的覆盖半径设置为30会怎样呢？</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">offset_list_30 = generate_offset(<span class="number">30</span>)</span><br><span class="line">coverage_max = &#123;<span class="built_in">str</span>(each) :<span class="literal">True</span> <span class="keyword">for</span> index,_ <span class="keyword">in</span> data2.iterrows() <span class="keyword">for</span> each <span class="keyword">in</span> generate_area(data2[<span class="string">&#x27;x&#x27;</span>][index],data2[<span class="string">&#x27;y&#x27;</span>][index],offset_list_30)&#125;</span><br><span class="line"><span class="keyword">with</span> <span class="built_in">open</span> (<span class="string">&#x27;coverage_max.txt&#x27;</span>,<span class="string">&#x27;w&#x27;</span>) <span class="keyword">as</span> f:</span><br><span class="line">    f.write(<span class="built_in">str</span>(coverage_max))</span><br><span class="line">    f.close()</span><br><span class="line"></span><br><span class="line">data_copy2 = data.copy()</span><br><span class="line">data_copy2[<span class="string">&#x27;is_covered&#x27;</span>] = <span class="literal">False</span></span><br><span class="line"><span class="keyword">for</span> index,_ <span class="keyword">in</span> data_copy2.iterrows():</span><br><span class="line">    <span class="keyword">if</span> <span class="built_in">str</span>([data_copy2[<span class="string">&#x27;x&#x27;</span>][index],data_copy2[<span class="string">&#x27;y&#x27;</span>][index]]) <span class="keyword">in</span> coverage_max:</span><br><span class="line">         data_copy2[<span class="string">&#x27;is_covered&#x27;</span>][index] =  <span class="literal">True</span></span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(data_copy2.head())</span><br><span class="line"></span><br><span class="line">unconvered2 = data_copy2[data_copy2[<span class="string">&#x27;is_covered&#x27;</span>] == <span class="literal">False</span>]</span><br><span class="line">convered2 = data_copy2[data_copy2[<span class="string">&#x27;is_covered&#x27;</span>] == <span class="literal">True</span>]</span><br><span class="line"></span><br><span class="line">x_index1 = unconvered2[<span class="string">&#x27;x&#x27;</span>].to_list()</span><br><span class="line">y_index1 = unconvered2[<span class="string">&#x27;y&#x27;</span>].to_list()</span><br><span class="line"></span><br><span class="line">x_index2_ = convered2[<span class="string">&#x27;x&#x27;</span>].to_list()</span><br><span class="line">y_index2_ = convered2[<span class="string">&#x27;y&#x27;</span>].to_list()</span><br><span class="line"></span><br><span class="line">fig,ax = plt.subplots(figsize = (<span class="number">12</span>,<span class="number">10</span>))</span><br><span class="line"> <span class="comment">#注意 s 离散化的方法，因为需要通过点的大小来直观感受其所表示的数值大小</span></span><br><span class="line"> <span class="comment">#参数是 X 轴数据、Y 轴数据、各个点的大小、各个点的颜色</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">ax.grid()</span><br><span class="line"></span><br><span class="line">ax.scatter(x_index1,y_index1,c=<span class="string">&#x27;red&#x27;</span>,s=<span class="number">10</span>)</span><br><span class="line">ax.scatter(x_index2_,y_index2_,c=<span class="string">&#x27;blue&#x27;</span>,s=<span class="number">10</span>)</span><br><span class="line">plt.title(<span class="string">&quot;Unconvered Area and Convered Area --30&quot;</span>)</span><br><span class="line">plt.savefig(<span class="string">&#x27;Unconvered Area and Convered Area --30.jpg&#x27;</span>)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>
<p><img src="https://s2.loli.net/2022/10/18/GDfWIudyUkbqi9g.jpg" style="zoom:67%;" /></p>
<p>额…我觉得不太对劲。只比原来多了两千个覆盖点，而且我发现覆盖的点分布有点奇怪啊？方向都是斜向上的，为此我写了个已有基站的覆盖点可视化，不写不知道，一写吓一跳：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">coverage_max_list = [each <span class="keyword">for</span> index,_ <span class="keyword">in</span> data2.iterrows() <span class="keyword">for</span> each <span class="keyword">in</span> generate_area(data2[<span class="string">&#x27;x&#x27;</span>][index],data2[<span class="string">&#x27;y&#x27;</span>][index],offset_list_30)]</span><br><span class="line"></span><br><span class="line">cover_max_data = pd.DataFrame(coverage_max_list,columns=[<span class="string">&#x27;x&#x27;</span>,<span class="string">&#x27;y&#x27;</span>])</span><br><span class="line"></span><br><span class="line">cover_index_x = cover_max_data[<span class="string">&#x27;x&#x27;</span>].to_list()</span><br><span class="line">cover_index_y = cover_max_data[<span class="string">&#x27;y&#x27;</span>].to_list()</span><br><span class="line"></span><br><span class="line">fig,ax = plt.subplots(figsize = (<span class="number">12</span>,<span class="number">10</span>))</span><br><span class="line"> <span class="comment">#注意 s 离散化的方法，因为需要通过点的大小来直观感受其所表示的数值大小</span></span><br><span class="line"> <span class="comment">#参数是 X 轴数据、Y 轴数据、各个点的大小、各个点的颜色</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">ax.grid()</span><br><span class="line"></span><br><span class="line"> </span><br><span class="line">ax.scatter(cover_index_x,cover_index_y,c=<span class="string">&#x27;red&#x27;</span>,s=<span class="number">5</span>,alpha=<span class="number">0.5</span>)</span><br><span class="line">ax.scatter(x_index1,y_index1,c=<span class="string">&#x27;blue&#x27;</span>,s=<span class="number">20</span>,alpha = <span class="number">0.5</span>,marker=<span class="string">&#x27;s&#x27;</span>,label = <span class="string">&#x27;Base Station&#x27;</span>)</span><br><span class="line"></span><br><span class="line">plt.title(<span class="string">&quot;Coverage Area 30&quot;</span>)</span><br><span class="line">plt.savefig(<span class="string">&#x27;Coverage Area 30.jpg&#x27;</span>)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>
<p><img src="https://s2.loli.net/2022/10/19/aSp9kCDtQ6PwjAc.jpg" style="zoom: 80%;" /></p>
<p>Holly shit…我也不知道为啥他只在第一三象限有覆盖，难道是我<code>generate_offset</code>函数出问题了，我们单点可视化一下：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">generate_offset_list</span>(<span class="params">radius</span>):</span><br><span class="line">    base = []</span><br><span class="line">    <span class="comment">#return [[i,j] for i in range(-radius,radius+1) for j in range(-radius,radius+1) if i ** 2 + j ** 2 &lt;= radius**2]</span></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(-<span class="number">1</span>*radius,radius+<span class="number">1</span>):</span><br><span class="line">        <span class="keyword">for</span> j <span class="keyword">in</span> <span class="built_in">range</span>(-radius,radius+<span class="number">1</span>):</span><br><span class="line">            <span class="keyword">if</span> (i**<span class="number">2</span>) + (j**<span class="number">2</span>) &lt;= radius ** <span class="number">2</span>:</span><br><span class="line">                base.append([i,j])</span><br><span class="line">    <span class="keyword">return</span> base</span><br><span class="line"><span class="keyword">def</span> <span class="title function_">generate_area</span>(<span class="params">x,y,offset_list</span>):</span><br><span class="line">    <span class="keyword">return</span> [[x+each[index],y+each[index]] <span class="keyword">for</span> each <span class="keyword">in</span> offset_list <span class="keyword">for</span> index,_ <span class="keyword">in</span> <span class="built_in">enumerate</span>(each)]</span><br><span class="line"></span><br><span class="line">offset_list = generate_offset_list(<span class="number">30</span>)</span><br><span class="line"></span><br><span class="line">basic = generate_area(<span class="number">0</span>,<span class="number">0</span>,offset_list)</span><br><span class="line"></span><br><span class="line">data = pd.DataFrame(offset_list,columns=[<span class="string">&#x27;x&#x27;</span>,<span class="string">&#x27;y&#x27;</span>])</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(data.head())</span><br><span class="line"></span><br><span class="line">x_index = data[<span class="string">&#x27;x&#x27;</span>].to_list()</span><br><span class="line">y_index = data[<span class="string">&#x27;y&#x27;</span>].to_list()</span><br><span class="line"></span><br><span class="line">fig,ax = plt.subplots(figsize = (<span class="number">12</span>,<span class="number">10</span>))</span><br><span class="line"> <span class="comment">#注意 s 离散化的方法，因为需要通过点的大小来直观感受其所表示的数值大小</span></span><br><span class="line"> <span class="comment">#参数是 X 轴数据、Y 轴数据、各个点的大小、各个点的颜色</span></span><br><span class="line">bubble = ax.scatter(x_index, y_index , s = <span class="number">10</span>, linewidth = <span class="number">0.5</span>, alpha = <span class="number">0.8</span>)</span><br><span class="line">ax.grid()</span><br><span class="line">plt.title(<span class="string">&quot;base point&quot;</span>)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>
<p><img src="https://s2.loli.net/2022/10/19/whRdZeXjWuLpV2g.png" style="zoom: 50%;" /></p>
<p>显然问题不在他，那么我们看看另一个函数：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">generate_offset_list</span>(<span class="params">radius</span>):</span><br><span class="line">    base = []</span><br><span class="line">    <span class="comment">#return [[i,j] for i in range(-radius,radius+1) for j in range(-radius,radius+1) if i ** 2 + j ** 2 &lt;= radius**2]</span></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(-<span class="number">1</span>*radius,radius+<span class="number">1</span>):</span><br><span class="line">        <span class="keyword">for</span> j <span class="keyword">in</span> <span class="built_in">range</span>(-radius,radius+<span class="number">1</span>):</span><br><span class="line">            <span class="keyword">if</span> (i**<span class="number">2</span>) + (j**<span class="number">2</span>) &lt;= radius ** <span class="number">2</span>:</span><br><span class="line">                base.append([i,j])</span><br><span class="line">    <span class="keyword">return</span> base</span><br><span class="line"><span class="keyword">def</span> <span class="title function_">generate_area</span>(<span class="params">x,y,offset_list</span>):</span><br><span class="line">    <span class="keyword">return</span> [[x+each[index],y+each[index]] <span class="keyword">for</span> each <span class="keyword">in</span> offset_list <span class="keyword">for</span> index,_ <span class="keyword">in</span> <span class="built_in">enumerate</span>(each)]</span><br><span class="line"></span><br><span class="line">offset_list = generate_offset_list(<span class="number">30</span>)</span><br><span class="line"></span><br><span class="line">basic = generate_area(<span class="number">0</span>,<span class="number">0</span>,offset_list)</span><br><span class="line"></span><br><span class="line">data = pd.DataFrame(basic,columns=[<span class="string">&#x27;x&#x27;</span>,<span class="string">&#x27;y&#x27;</span>])</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(data.head())</span><br><span class="line"></span><br><span class="line">x_index = data[<span class="string">&#x27;x&#x27;</span>].to_list()</span><br><span class="line">y_index = data[<span class="string">&#x27;y&#x27;</span>].to_list()</span><br><span class="line"></span><br><span class="line">fig,ax = plt.subplots(figsize = (<span class="number">12</span>,<span class="number">10</span>))</span><br><span class="line"> <span class="comment">#注意 s 离散化的方法，因为需要通过点的大小来直观感受其所表示的数值大小</span></span><br><span class="line"> <span class="comment">#参数是 X 轴数据、Y 轴数据、各个点的大小、各个点的颜色</span></span><br><span class="line">bubble = ax.scatter(x_index, y_index , s = <span class="number">10</span>, linewidth = <span class="number">0.5</span>, alpha = <span class="number">0.8</span>)</span><br><span class="line">ax.grid()</span><br><span class="line">plt.title(<span class="string">&quot;base point&quot;</span>)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>
<p><img src="https://s2.loli.net/2022/10/19/aTMvI4P1BhQjcNE.png" style="zoom: 50%;" /></p>
<p>好了，罪魁祸首找到了。我看到那个<code>enumerate(each)</code>的时候沉思了一下。我为啥要写这个啊？？？改下：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">generate_area</span>(<span class="params">x,y,offset_list</span>):</span><br><span class="line">    <span class="comment">#return [[x+each[index],y+each[index]] for each in offset_list for index,_ in enumerate(each)]</span></span><br><span class="line">    <span class="keyword">return</span> [[x+each[<span class="number">0</span>],y+each[<span class="number">1</span>]] <span class="keyword">for</span> each <span class="keyword">in</span> offset_list]</span><br></pre></td></tr></table></figure>
<p>然后重新从前面开始跑一下代码，先看看最低覆盖情况：</p>
<p><img src="https://s2.loli.net/2022/10/19/naPGY8xoDiHerfy.png" alt="image-20221019101251078"></p>
<p>这时候已经有四十多万个点覆盖了啊啊啊啊啊啊！！！！！！！看下其他的图：</p>
<p><img src="https://s2.loli.net/2022/10/19/fbU5TZiXJDILl4R.jpg" style="zoom:67%;" /></p>
<p><img src="https://s2.loli.net/2022/10/19/bv573DKYAtWou8G.jpg" style="zoom:67%;" /></p>
<p>虽然修复了BUG，但是全设成微基站依然覆盖率不足，此时覆盖率为<code>7.58%</code>，所以还是得上宏基站看看。代码就不重复了，我把所有图都放到了一起：</p>
<p><img src="https://s2.loli.net/2022/10/19/ebKsmrG4H9zPkNU.jpg" alt=""></p>
<p>哎，爽多了吧！这时候可以确定红色区域附近时没有蓝色基站点的，但是以防万一我们看看覆盖图：</p>
<p><img src="https://s2.loli.net/2022/10/19/RydS6o7W3ckPBFI.jpg" style="zoom: 67%;" /></p>
<p>终于不再是线粒体了！太感动了555…业务量如何呢？</p>
<p><img src="https://s2.loli.net/2022/10/19/jmq6GCJxrpIAyc5.png" alt="image-20221019104004178"></p>
<p>我们还是选择宏基站吧！先生成个DataFrame保存一下：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">uncovered2.to_csv(<span class="string">&#x27;Uncovered.csv&#x27;</span>,index=<span class="literal">False</span>)</span><br></pre></td></tr></table></figure>
<p>明天继续！</p>
]]></content>
      <categories>
        <category>学习记录</category>
      </categories>
      <tags>
        <tag>数学模型</tag>
        <tag>基站选址</tag>
        <tag>聚类</tag>
      </tags>
  </entry>
  <entry>
    <title>【学习记录】2022-9-26</title>
    <url>/2022/10/03/%E5%AD%A6%E4%B9%A0%E8%AE%B0%E5%BD%95%20%E7%AC%AC%E4%B8%89%E5%91%A8/</url>
    <content><![CDATA[<p>本周工作主要是看《SoftdEfined heteRogeneous VehICular nEtwork》以及弄清楚师兄让我搭的5G小系统。</p>
<span id="more"></span>
<h2 id="5G核心网架构"><a href="#5G核心网架构" class="headerlink" title="5G核心网架构"></a>5G核心网架构</h2><p>在前面已经提到，5G核心网采用的是服务化架构，如图所示：</p>
<p><img src="https://s2.loli.net/2022/09/27/ociUB37CxXeaYzF.png" alt="image-20220926141829546"></p>
<p>以前的网络是按层来划分的，是一种节点与节点、边与边的拓扑网络结构，关系错综复杂，集成度很高，共嗯大包大揽，入网简单，但是也有问题：首先扩展性差、升级困难，而且升级只能基于原本的硬件平台进行。</p>
<p>但是SBA架构没有这种问题，因为它拆分了网络功能（NF），这些网络功能通过接口介入到系统中，这样一来：</p>
<ul>
<li>相同的网络功能一起承担和提供网络功能服务（NFS），负荷可以均衡分担。</li>
<li>任意的网络功能出现障碍，可以通过智能化的网络管理功能让他暂时退出服务，将其负责的业务转移到其他的正常的网络功能上处理。</li>
<li>扩展新的网络功能非常方便，调用接口就可以了。</li>
<li>升级很容易，软件和硬件都可以直接接入</li>
<li>网络开放，在标准接口下其他的系统也可以入网。</li>
</ul>
<p>总的来说，SBA在核心网中就是对核心网进行改革，实现核心网软件化、灵活化、开放化和智慧化，<strong>做到即插即用的效果。</strong></p>
<p><img src="https://s2.loli.net/2022/09/27/LCl8MaBjpXFkcKY.png" alt="image-20220926143041127"></p>
<h2 id="服务化架构关键技术点"><a href="#服务化架构关键技术点" class="headerlink" title="服务化架构关键技术点"></a>服务化架构关键技术点</h2><p>服务化架构的主要技术要点又如下三点：</p>
<ul>
<li><p>服务的提供通过生产者与消费者之间的信息交互达成。交互模式分成两种：Request-Response以及Subscrive-Notify，因为这样足够简单，所以在各类的网络功能（NF）之间接口交互很方便。</p>
<ul>
<li><p>Request-Response：网络功能服务消费者<code>NF_A</code>向网络功能服务生产者<code>NF_B</code>请求特定的网络功能服务（服务内容可能是某种操作或者提供信息之类的），网络功能生产者根据请求的内容返回相应的服务结果。</p>
<center><img src="https://s2.loli.net/2022/09/27/wicEF3nIHYOUr1V.png" alt="image-20220926143901796" style="zoom: 25%;" />
    &nbsp&nbsp&nbsp&nbsp&nbsp&nbsp&nbsp&nbsp
    <img src="https://s2.loli.net/2022/09/27/g6iZfKh374VaG2S.png" alt="image-20220926143949780" style="zoom:25%;" /></center>
</li>
<li><p>Subscribe-Notify：<code>NF_A</code>向<code>NF_B</code>订阅网络功能服务。<code>NF_B</code>对所有订阅服务的NF发送通知并返回结果。订阅的服务可能是按周期更新的信息或者特定事件的触发通知（某个东西到达了峰值、某个地方发生了改变）。</p>
<p><img src="https://s2.loli.net/2022/09/27/qm8ApOoStYaC1rU.png" alt="image-20220926144803196" style="zoom:25%;" /></p>
</li>
</ul>
</li>
<li><p>实现了服务的自动化注册和发现。NF 通过服务化接口，将自身的能力作为一种服务暴露到网络中，并 被其他 NF 复用；NF 通过服务化接口的发现获取拥有所需 NF 服务的其它 NF 实例。这种注册和发现是通过 5G 核 心网引入的新型网络功能 NRF 来实现的： NRF 接收其它 NF 发来的服务注册信息，维护 NF 实例的相关信息和支 持的服务信息； NRF 接收其它 NF 发来的 NF 发现请求，返回对应的 NF 示例信息。</p>
</li>
<li><p>采用统一服务化接口协议。 R15 阶段在设计接口协议时，考虑了适应 IT 化、虚拟化、微服务化的需求， 目前定义的接口协议栈从下往上在传输层采用了 TCP，在应用层采用 HTTP/2.0 [3]，在序列化协议方面采用了 JSON， 接口描述语言采用 OpenAPI3.0， API 的设计方式采用 RESTFul。</p>
</li>
</ul>
<h2 id="架构调整"><a href="#架构调整" class="headerlink" title="架构调整"></a>架构调整</h2><p>5G中的核心网主要有三个关键的逻辑节点：AMF、SMF和UPF。</p>
<p><img src="https://s2.loli.net/2022/09/29/7gy6U18w2jLNfDp.png" alt="image-20220929092924527"></p>
<p>同时从另一个维度进行讨论的控制面（Control Pannel）和用户面（User Pannel）在5G也进行了重构：控制平面分成了AMF和SMF两个逻辑节点，AMF负责移动性相关的管理，SMF则负责会话管理；UPF替代了4G时代的服务网关SGW和PDN网关PGW，控制面功能集中了，与用户面进一步分离，这样大家都能灵活配置网络功能了。</p>
<h2 id="关于AMF"><a href="#关于AMF" class="headerlink" title="关于AMF"></a>关于AMF</h2><p><strong>AMF是核心网的重中之重</strong>，所有UE的接入靠的是他们与AMF之间的接口NG-RAN接口，再次声明下，不要把接口想象成一个四四方方的充电器插槽，在5G时代一切都要虚拟化（不能说百分百虚拟化，但至少是看不见的），都什么年代了，还在玩传统核心网？（bushi）</p>
<p>AMF的功能挺多的，这里加个<code>TODO</code>标签，以后提醒自己补一补。</p>
<h2 id="SoftdEfined-heteRogeneous-VehICular-nEtwork"><a href="#SoftdEfined-heteRogeneous-VehICular-nEtwork" class="headerlink" title="SoftdEfined heteRogeneous VehICular nEtwork"></a>SoftdEfined heteRogeneous VehICular nEtwork</h2><p>软件定义的车联异构网络。文章介绍了一个SOTA级别的框架，这个框架结合了异构网络的特点，同时也充分发挥了软件定义的框架的优势。整个网络架构分成三层：网络设施层（位于顶层）、控制层（位于中层）以及应用层（位于顶层）。</p>
<p><img src="https://s2.loli.net/2022/09/28/S7jZtGRDOCr8MQh.png" alt="image-20220928150707187" style="zoom: 80%;" /></p>
<h3 id="网络设施层"><a href="#网络设施层" class="headerlink" title="网络设施层"></a>网络设施层</h3><p><img src="https://s2.loli.net/2022/09/28/PfrtkgBe1bja2ST.png" alt="image-20220928150824672" style="zoom:80%;" /></p>
<p>设施层主要是基础功能的集合，在SERVICE框架中设施主要分为三类，分别是通信设施、存储设施以及计算设施。这些设施在原文是这么给出的（图中左边中间的蜂窝区部分）：</p>
<p><img src="https://s2.loli.net/2022/09/28/S8pzMnNeykGQxRj.png" alt="image-20220928152113627"></p>
<p>作者们对这个层的组件的称呼是“设施”，但是我们很容易先入为主的认为“设施”是某一类型的硬件设施，但在SERVICE这个软件定义网络的异构网络中，<strong>“设施”应该理解成一种资源</strong>，作者给出的样例中有计算资源、存储资源以及通信资源。其中计算资源以及存储资源又可以按照性能分成三种类型：微观云资源、本地云资源以及远程云资源。</p>
<p>这种资源的划分是合理的（通信资源为什么不在列，我的理解是通信在车辆行驶中的重要性是首要的，必须优先保障的，安全服务需要的资源是即时的，因此不能承受远程、云端的时效性风险），因为存储资源与计算资源的设立需要的设施（这次是真的硬件设施了，包括硬盘、算卡等资源）在路段很难部署，但是需求又不能不处理，而完全交给一个节点完成又会造成瘫痪，所以负载均衡是最好的选择。</p>
<h3 id="控制层"><a href="#控制层" class="headerlink" title="控制层"></a>控制层</h3><p><img src="https://s2.loli.net/2022/09/28/VfKHdp2MTi6SrP3.png" alt="image-20220928151313382" style="zoom: 28%;" /></p>
<p>控制层是一个层级结构，在一个服务区域（Service Area，一般认为设备的覆盖区域就是服务区域）中，由<strong>主控制器</strong>和<strong>次控制器</strong>构成的控制层对计算资源、通信资源以及存储资源进行分配。控制层由于其处于SERVICE结构的中层，因此它需要与上下层进行信息的流通与交互，交互的方式一共有三种：南向（控制层到网络设施层、应用层到控制层）交互、北向交互（控制层到应用层、网络设施层到控制层）。</p>
<p><img src="https://s2.loli.net/2022/09/28/9rN3HPmvzWiS8AR.png" alt="image-20220928151556984"></p>
<p>值得一提的是，这个所谓的<code>控制器</code>其实<strong>并不是真的是一个具体的器件</strong>，因为在一个软件定义的网络框架中一切都可以软件化，所以<strong>与其说“控制器”倒不如说“控制算法”或“控制软件”</strong>。还有一点注意的是，控制层的控制对象是“通信控制”、“计算控制”和“存储控制”，这与网络设施层相呼应。</p>
<h3 id="应用层"><a href="#应用层" class="headerlink" title="应用层"></a>应用层</h3><p>应用层高高在上，但是它主要是一般网络功能应用设计者用来存放、部署他们的成果的地方，前文提到，控制层位于网络架构的中层，所以应用层通过API与控制层交互，从而达到应用层控制一切的效果，但其实我们都知道真正在起作用的是控制层，应用层只是个指挥人干活的领导（抱歉，好像内涵了某些人）。作者给出的例子是接入管理和动态资源分配，本质上其实都是资源分配的过程问题。</p>
<h2 id="虚拟化"><a href="#虚拟化" class="headerlink" title="虚拟化"></a>虚拟化</h2><p>前文提到网络设施层是资源的集合地，作者在后面干脆不装了，直接搬出了软件化的概念：把一切都虚拟化吧！把基站虚拟化，把计算资源虚拟化，把存储资源虚拟化……这不是我乱说，它真的是直接不装了把资源直接上云了。我们知道以往的通信设备比较垄断，要搞一套完整的通信系统很麻烦，几百万买个基站、天线以及配套的乱七八糟的东西才能搭建起来一个通信系统，但是到了5G时代，一切都软件化了：网元被拆成了网络功能，开放的接口、易于扩展的特点让大家都感叹真牛逼，所以SERVICE框架也想向这方面靠拢，因此在传统网络框架底层的部分原本应该陈列大件硬件设施的地方换成了几乎（话不能说太死）不占空间的虚拟资源。</p>
<p><img src="https://s2.loli.net/2022/09/30/TgC1m76tD9E543O.png" alt="image-20220930111139061"></p>
<p>软件化一切是一种趋势，因为我们知道现在是个AI时代，你上大学没学过点人工智能或者机器学习都不好意思说你是工科生，我们知道人工智能最吃算力资源，算力资源的承载体——服务器有多大、多脆弱相信大家都知道了，所以资源虚拟化能很好迎合人工智能算法的部署（也方便我水论文^_^）。</p>
<h3 id="虚拟化资源"><a href="#虚拟化资源" class="headerlink" title="虚拟化资源"></a>虚拟化资源</h3><p>前面提到SERVICE中存在多种资源（计算、通信、存储），然而在一个异构网络框架中还是要将他们标准化到一种特定的形式，才能方便后续的资源调度。SERVICE框架中的资源称为MDR（Multi Domain Resouce），他们存在MDRP（Multi Domain Resouce Pool）中。</p>
]]></content>
      <categories>
        <category>通信技术</category>
      </categories>
      <tags>
        <tag>5G</tag>
        <tag>核心网</tag>
      </tags>
  </entry>
  <entry>
    <title>帝国时代2决定版数据分析</title>
    <url>/2022/08/23/Aoe/</url>
    <content><![CDATA[<p><img src="https://s2.loli.net/2022/08/23/XR4r9qmpelQZ3gW.png" alt=""></p>
<center><big>伟大的帝国正在召唤！</big></center>

<span id="more"></span>
<p>我们从这里下载数据集，解压之后可以发现一共有两个<code>.csv</code>文件。我们通过<code>pandas</code>分别对其读取，观察一下数据的大致摸样：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">match_data = pd.read_csv(<span class="string">&#x27;matches.csv&#x27;</span>)</span><br><span class="line">player_data = pd.read_csv(<span class="string">&#x27;match_players.csv&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(match_data.head())</span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">              token             match  rating   color      civ  team  winner</span></span><br><span class="line"><span class="string">0  rFWxLAdY6TF78xlo  axps4XstiBOmrDeG  1565.0     Red  Chinese     1   False</span></span><br><span class="line"><span class="string">1  zsyvxRyzLh85YIba  axps4XstiBOmrDeG  1600.0    Blue    Goths     2    True</span></span><br><span class="line"><span class="string">2  CHrJISNtjKDKM114  uQdosqwC7uiQ78ya  2145.0  Orange    Incas     1   False</span></span><br><span class="line"><span class="string">3  X147inwVdQuaegxT  uQdosqwC7uiQ78ya  2124.0   Green   Tatars     2    True</span></span><br><span class="line"><span class="string">4  kNckdaCe6pjKm6Au  uQdosqwC7uiQ78ya  2105.0     Red  Magyars     1   False</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="built_in">print</span>(player_data.head())</span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">              token             match  rating   color      civ  team  winner</span></span><br><span class="line"><span class="string">0  rFWxLAdY6TF78xlo  axps4XstiBOmrDeG  1565.0     Red  Chinese     1   False</span></span><br><span class="line"><span class="string">1  zsyvxRyzLh85YIba  axps4XstiBOmrDeG  1600.0    Blue    Goths     2    True</span></span><br><span class="line"><span class="string">2  CHrJISNtjKDKM114  uQdosqwC7uiQ78ya  2145.0  Orange    Incas     1   False</span></span><br><span class="line"><span class="string">3  X147inwVdQuaegxT  uQdosqwC7uiQ78ya  2124.0   Green   Tatars     2    True</span></span><br><span class="line"><span class="string">4  kNckdaCe6pjKm6Au  uQdosqwC7uiQ78ya  2105.0     Red  Magyars     1   False</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"></span><br></pre></td></tr></table></figure>
<p>从中可以看到这份数据其实是有些瑕疵的，比如说NAN的缺失值在开头就能看到了。所以第一步要先对数据进行清洗操作，除了需要关注缺失值处理，对于竞技类游戏我们还需要清洗掉挂机和开挂等异常大的游戏数据，这种异常游戏数据的判断方法可以通过游戏进行的时间长度进行筛选。这里我过滤掉那些游戏时间小于5分钟或游戏时间超出两个小时的（这好像有点误伤，因为我第一喜欢看的八方混战的黑铁局都要酣畅淋漓地打上个三小时，但是那些数据的参考意义不大所以还是忍痛筛掉了）。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">tidy_matches = match_data.copy()</span><br><span class="line">tidy_matches = tidy_matches.dropna(subset=[<span class="string">&quot;average_rating&quot;</span>])</span><br><span class="line">tidy_matches[<span class="string">&quot;patch&quot;</span>] = tidy_matches[<span class="string">&quot;patch&quot;</span>].replace(<span class="number">37650</span>, <span class="number">37906</span>)</span><br><span class="line">tidy_matches[<span class="string">&quot;duration&quot;</span>] = pd.to_timedelta(tidy_matches[<span class="string">&quot;duration&quot;</span>])</span><br><span class="line">tidy_matches[<span class="string">&quot;duration_s&quot;</span>] = tidy_matches[<span class="string">&quot;duration&quot;</span>].dt.total_seconds()</span><br><span class="line">tidy_matches = tidy_matches[(tidy_matches[<span class="string">&quot;duration_s&quot;</span>] &gt; <span class="number">60</span> * <span class="number">5</span>) &amp; (tidy_matches[<span class="string">&quot;duration_s&quot;</span>] &lt; <span class="number">60</span> * <span class="number">60</span> * <span class="number">2</span>)]</span><br></pre></td></tr></table></figure>
<p>随后就是对数据类型进行整理：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">tidy_matches[<span class="string">&quot;map&quot;</span>] = tidy_matches[<span class="string">&quot;map&quot;</span>].astype(<span class="string">&quot;category&quot;</span>)</span><br><span class="line">tidy_matches[<span class="string">&quot;map_size&quot;</span>] = tidy_matches[<span class="string">&quot;map_size&quot;</span>].astype(<span class="string">&quot;category&quot;</span>)</span><br><span class="line">tidy_matches[<span class="string">&quot;ladder&quot;</span>] = tidy_matches[<span class="string">&quot;ladder&quot;</span>].astype(<span class="string">&quot;category&quot;</span>)</span><br><span class="line">tidy_matches[<span class="string">&quot;patch&quot;</span>] = tidy_matches[<span class="string">&quot;patch&quot;</span>].astype(<span class="string">&quot;category&quot;</span>)</span><br><span class="line">tidy_matches[<span class="string">&quot;server&quot;</span>] = tidy_matches[<span class="string">&quot;server&quot;</span>].astype(<span class="string">&quot;category&quot;</span>)</span><br><span class="line">player_data[<span class="string">&quot;civ&quot;</span>] = player_data[<span class="string">&quot;civ&quot;</span>].astype(<span class="string">&quot;category&quot;</span>)</span><br></pre></td></tr></table></figure>
<p>然后整理一下，得到一个干净的整合体：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">joined_df = pd.merge(player_data, tidy_matches, left_on=<span class="string">&quot;match&quot;</span>, right_on=<span class="string">&quot;token&quot;</span>, suffixes=[<span class="string">&quot;_player&quot;</span>, <span class="string">&quot;_match&quot;</span>])</span><br><span class="line"><span class="comment">#joined_df.to_csv(&#x27;merge.csv&#x27;)</span></span><br></pre></td></tr></table></figure>
<p>根据这份数据，我们可以做出一些有意思的分析，我们开始吧！</p>
<h1 id="统计计数类"><a href="#统计计数类" class="headerlink" title="统计计数类"></a>统计计数类</h1><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">rate_count1 = joined_df.value_counts(<span class="string">&#x27;average_rating&#x27;</span>,sort=<span class="literal">False</span>)</span><br><span class="line">rate_count_index1 = rate_count1.index.to_list()</span><br><span class="line">rate_count_data1 = rate_count1.to_list()</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">bar = (</span><br><span class="line">    Bar()</span><br><span class="line">    .add_xaxis(rate_count_index1)</span><br><span class="line">    .add_yaxis(<span class="string">&#x27;1v1平均Rating&#x27;</span>,rate_count_data1, label_opts=opts.LabelOpts(is_show=<span class="literal">False</span>))</span><br><span class="line">    .set_global_opts(</span><br><span class="line">        title_opts=opts.TitleOpts(</span><br><span class="line">            title=<span class="string">&quot;平均Rating统计📈&quot;</span>,</span><br><span class="line">            pos_left=<span class="string">&#x27;center&#x27;</span>),</span><br><span class="line">        datazoom_opts=[opts.DataZoomOpts(), opts.DataZoomOpts(type_=<span class="string">&quot;inside&quot;</span>)],</span><br><span class="line">        legend_opts=opts.LegendOpts(is_show=<span class="literal">False</span>)</span><br><span class="line">    )</span><br><span class="line">)</span><br><span class="line">bar.render(<span class="string">&#x27;rate.html&#x27;</span>)</span><br></pre></td></tr></table></figure>
<script src="https://cdn.jsdelivr.net/npm/echarts@4.8.0/dist/echarts.min.js"></script>
<div id="echarts4303" style="width: 81%;height: 400px;margin: 0 auto"></div>

<script type="text/javascript">
        // 基于准备好的dom，初始化echarts实例
        var myChart = echarts.init(document.getElementById('echarts4303'));

        // 指定图表的配置项和数据
        var option = {
    animation: true,
    animationThreshold: 2000,
    animationDuration: 1000,
    animationEasing: "cubicOut",
    animationDelay: 0,
    animationDurationUpdate: 300,
    animationEasingUpdate: "cubicOut",
    animationDelayUpdate: 0,
    color: [
        "#c23531",
        "#2f4554",
        "#61a0a8",
        "#d48265",
        "#749f83",
        "#ca8622",
        "#bda29a",
        "#6e7074",
        "#546570",
        "#c4ccd3",
        "#f05b72",
        "#ef5b9c",
        "#f47920",
        "#905a3d",
        "#fab27b",
        "#2a5caa",
        "#444693",
        "#726930",
        "#b2d235",
        "#6d8346",
        "#ac6767",
        "#1d953f",
        "#6950a1",
        "#918597"
    ],
    series: [
        {
            "type": "bar",
            "name": "number",
            "data": [
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                2,
                1,
                1,
                2,
                1,
                1,
                2,
                2,
                1,
                2,
                2,
                2,
                1,
                1,
                3,
                1,
                2,
                1,
                1,
                2,
                3,
                1,
                1,
                2,
                2,
                1,
                3,
                3,
                2,
                6,
                2,
                1,
                2,
                3,
                2,
                6,
                5,
                7,
                1,
                2,
                1,
                2,
                4,
                2,
                5,
                1,
                6,
                3,
                3,
                7,
                3,
                4,
                4,
                7,
                1,
                2,
                5,
                1,
                3,
                1,
                6,
                5,
                2,
                4,
                4,
                4,
                5,
                4,
                6,
                2,
                6,
                4,
                6,
                7,
                5,
                3,
                9,
                6,
                5,
                5,
                7,
                5,
                9,
                7,
                5,
                3,
                5,
                5,
                6,
                6,
                13,
                4,
                10,
                10,
                3,
                2,
                7,
                3,
                6,
                10,
                7,
                13,
                13,
                6,
                3,
                3,
                4,
                7,
                12,
                9,
                7,
                2,
                11,
                11,
                13,
                7,
                11,
                10,
                8,
                4,
                11,
                3,
                8,
                9,
                14,
                10,
                10,
                9,
                13,
                12,
                14,
                4,
                15,
                12,
                11,
                9,
                14,
                11,
                16,
                12,
                16,
                17,
                12,
                8,
                16,
                12,
                11,
                12,
                12,
                14,
                17,
                14,
                11,
                11,
                13,
                8,
                12,
                15,
                16,
                19,
                22,
                19,
                10,
                12,
                11,
                11,
                16,
                18,
                10,
                23,
                12,
                18,
                10,
                20,
                17,
                32,
                17,
                16,
                13,
                13,
                23,
                10,
                20,
                16,
                23,
                23,
                17,
                28,
                12,
                26,
                29,
                17,
                20,
                15,
                25,
                25,
                28,
                18,
                9,
                23,
                24,
                23,
                18,
                23,
                13,
                28,
                30,
                25,
                30,
                23,
                22,
                36,
                29,
                38,
                30,
                19,
                24,
                28,
                28,
                33,
                26,
                24,
                30,
                23,
                29,
                25,
                24,
                26,
                29,
                29,
                29,
                32,
                35,
                31,
                38,
                33,
                39,
                36,
                31,
                27,
                26,
                33,
                43,
                41,
                36,
                31,
                44,
                44,
                33,
                30,
                37,
                34,
                46,
                44,
                44,
                38,
                52,
                43,
                53,
                47,
                47,
                47,
                33,
                36,
                46,
                42,
                36,
                52,
                41,
                43,
                59,
                53,
                47,
                53,
                52,
                46,
                49,
                48,
                49,
                54,
                48,
                50,
                41,
                54,
                59,
                46,
                65,
                61,
                56,
                54,
                77,
                53,
                57,
                63,
                58,
                75,
                62,
                66,
                51,
                59,
                64,
                63,
                70,
                68,
                61,
                81,
                66,
                84,
                78,
                69,
                70,
                77,
                66,
                71,
                66,
                64,
                79,
                75,
                94,
                73,
                81,
                74,
                100,
                92,
                96,
                97,
                81,
                76,
                109,
                81,
                93,
                99,
                91,
                106,
                91,
                89,
                102,
                85,
                106,
                120,
                103,
                95,
                107,
                117,
                120,
                103,
                110,
                100,
                110,
                114,
                121,
                103,
                124,
                111,
                130,
                108,
                117,
                123,
                133,
                121,
                141,
                117,
                127,
                124,
                114,
                153,
                139,
                116,
                151,
                134,
                142,
                119,
                131,
                153,
                175,
                152,
                139,
                145,
                148,
                174,
                148,
                172,
                167,
                163,
                174,
                185,
                174,
                177,
                207,
                201,
                191,
                171,
                189,
                174,
                171,
                190,
                207,
                187,
                199,
                197,
                207,
                213,
                211,
                213,
                229,
                215,
                201,
                266,
                217,
                198,
                237,
                233,
                216,
                218,
                237,
                242,
                210,
                248,
                251,
                287,
                250,
                259,
                248,
                254,
                281,
                283,
                281,
                279,
                302,
                276,
                280,
                302,
                293,
                333,
                279,
                322,
                330,
                328,
                320,
                324,
                333,
                364,
                335,
                353,
                329,
                347,
                374,
                356,
                391,
                397,
                390,
                396,
                380,
                489,
                393,
                407,
                418,
                423,
                424,
                453,
                457,
                487,
                470,
                437,
                495,
                497,
                479,
                493,
                470,
                460,
                512,
                510,
                553,
                546,
                586,
                546,
                567,
                569,
                568,
                574,
                615,
                617,
                620,
                612,
                653,
                629,
                640,
                651,
                707,
                676,
                719,
                696,
                727,
                752,
                755,
                744,
                777,
                758,
                837,
                825,
                746,
                797,
                836,
                843,
                874,
                871,
                928,
                936,
                935,
                954,
                932,
                960,
                946,
                966,
                919,
                950,
                1016,
                1070,
                1074,
                1122,
                1100,
                1105,
                1115,
                1150,
                1177,
                1148,
                1202,
                1165,
                1183,
                1245,
                1238,
                1218,
                1225,
                1249,
                1279,
                1342,
                1248,
                1388,
                1409,
                1351,
                1348,
                1406,
                1363,
                1379,
                1376,
                1390,
                1427,
                1446,
                1409,
                1466,
                1497,
                1498,
                1442,
                1480,
                1570,
                1561,
                1596,
                1496,
                1554,
                1584,
                1597,
                1682,
                1623,
                1673,
                1636,
                1708,
                1636,
                1726,
                1759,
                1714,
                1781,
                1773,
                1790,
                1801,
                1759,
                1819,
                1720,
                1757,
                1719,
                1821,
                1779,
                1796,
                1782,
                1876,
                1829,
                1844,
                1923,
                1917,
                1983,
                1931,
                1909,
                2010,
                1951,
                1867,
                1882,
                1985,
                2039,
                1953,
                1962,
                2061,
                2000,
                1959,
                2074,
                2002,
                1988,
                2072,
                2083,
                2075,
                2076,
                2103,
                2129,
                2060,
                2115,
                2122,
                2220,
                2135,
                2192,
                2106,
                2175,
                2141,
                2199,
                2173,
                2147,
                2219,
                2242,
                2231,
                2201,
                2233,
                2363,
                2258,
                2229,
                2338,
                2355,
                2376,
                2387,
                2339,
                2321,
                2295,
                2355,
                2331,
                2364,
                2315,
                2402,
                2390,
                2419,
                2462,
                2383,
                2440,
                2466,
                2405,
                2368,
                2532,
                2378,
                2467,
                2401,
                2421,
                2498,
                2532,
                2516,
                2568,
                2574,
                2544,
                2549,
                2538,
                2612,
                2592,
                2589,
                2645,
                2620,
                2649,
                2478,
                2800,
                2618,
                2597,
                2557,
                2650,
                2660,
                2673,
                2635,
                2657,
                2709,
                2670,
                2648,
                2735,
                2638,
                2636,
                2608,
                2779,
                2677,
                2731,
                2672,
                2778,
                2682,
                2730,
                2785,
                2807,
                2733,
                2635,
                2714,
                2847,
                2834,
                2785,
                2746,
                2840,
                2657,
                2782,
                2839,
                2812,
                2764,
                2781,
                2795,
                2886,
                2754,
                2822,
                2885,
                2825,
                2901,
                2855,
                2713,
                2882,
                2899,
                2875,
                2895,
                2916,
                2877,
                2895,
                2932,
                2844,
                2914,
                2981,
                2855,
                2891,
                2875,
                2854,
                2923,
                2940,
                2857,
                2930,
                2951,
                3026,
                2970,
                2927,
                2985,
                2957,
                2870,
                3001,
                2931,
                2941,
                2901,
                3034,
                2960,
                2950,
                2939,
                2932,
                2988,
                2914,
                2950,
                2997,
                2948,
                2804,
                3101,
                3009,
                2984,
                2961,
                2915,
                2952,
                3066,
                2982,
                2825,
                2989,
                2951,
                2860,
                2928,
                2942,
                3037,
                2907,
                3072,
                3004,
                2992,
                2873,
                2972,
                2993,
                2885,
                2873,
                2938,
                2902,
                2994,
                3062,
                2874,
                2989,
                2981,
                2923,
                2882,
                2843,
                2918,
                2957,
                3001,
                2956,
                2888,
                2983,
                3019,
                2993,
                2924,
                2993,
                2945,
                2964,
                2908,
                2939,
                2955,
                2936,
                2903,
                2852,
                2944,
                2952,
                2952,
                2858,
                3026,
                3004,
                2972,
                2937,
                2961,
                2967,
                2935,
                2931,
                2957,
                3035,
                2903,
                2896,
                2895,
                2968,
                2882,
                2900,
                2866,
                2901,
                2963,
                2945,
                2905,
                2945,
                2878,
                2841,
                2922,
                2809,
                2891,
                2910,
                2905,
                2933,
                2940,
                2838,
                2894,
                2827,
                2826,
                2861,
                2821,
                2874,
                2800,
                2857,
                2909,
                2876,
                2733,
                2750,
                2881,
                2775,
                2822,
                2856,
                2822,
                2803,
                2851,
                2787,
                2772,
                2861,
                2793,
                2785,
                2734,
                2773,
                2821,
                2831,
                2763,
                2735,
                2772,
                2768,
                2673,
                2746,
                2799,
                2731,
                2717,
                2799,
                2730,
                2724,
                2744,
                2697,
                2774,
                2655,
                2739,
                2663,
                2747,
                2686,
                2675,
                2763,
                2670,
                2602,
                2635,
                2664,
                2689,
                2802,
                2639,
                2618,
                2669,
                2624,
                2682,
                2636,
                2622,
                2589,
                2634,
                2553,
                2545,
                2656,
                2607,
                2551,
                2525,
                2603,
                2573,
                2528,
                2561,
                2557,
                2532,
                2671,
                2580,
                2465,
                2617,
                2534,
                2477,
                2584,
                2605,
                2539,
                2484,
                2512,
                2497,
                2546,
                2554,
                2535,
                2478,
                2511,
                2473,
                2452,
                2486,
                2533,
                2470,
                2417,
                2348,
                2398,
                2432,
                2420,
                2275,
                2457,
                2423,
                2415,
                2388,
                2406,
                2335,
                2413,
                2402,
                2382,
                2388,
                2356,
                2410,
                2321,
                2337,
                2360,
                2340,
                2368,
                2329,
                2382,
                2352,
                2325,
                2271,
                2322,
                2227,
                2329,
                2207,
                2354,
                2250,
                2456,
                2289,
                2208,
                2265,
                2331,
                2239,
                2238,
                2256,
                2262,
                2190,
                2272,
                2299,
                2202,
                2239,
                2282,
                2238,
                2235,
                2148,
                2185,
                2202,
                2228,
                2303,
                2240,
                2182,
                2180,
                2168,
                2197,
                2214,
                2124,
                2185,
                2133,
                2151,
                2177,
                2112,
                2246,
                2228,
                2114,
                2147,
                2104,
                2134,
                2086,
                2152,
                2126,
                2087,
                2096,
                1992,
                2103,
                2051,
                2102,
                2010,
                2035,
                2070,
                2085,
                2017,
                2114,
                2008,
                2006,
                1960,
                2079,
                2013,
                1925,
                2031,
                1988,
                2014,
                1919,
                2026,
                2010,
                1983,
                2036,
                1971,
                2082,
                2028,
                1999,
                1929,
                1991,
                1989,
                2016,
                1927,
                1902,
                1910,
                1878,
                1949,
                1850,
                1899,
                2032,
                1894,
                1910,
                1942,
                1901,
                1877,
                1777,
                1950,
                1878,
                1926,
                1849,
                1921,
                1917,
                1826,
                1831,
                1847,
                1860,
                1873,
                1856,
                1696,
                1816,
                1868,
                1808,
                1784,
                1802,
                1854,
                1769,
                1820,
                1832,
                1735,
                1709,
                1750,
                1819,
                1750,
                1777,
                1823,
                1705,
                1726,
                1672,
                1703,
                1744,
                1706,
                1652,
                1746,
                1722,
                1698,
                1695,
                1696,
                1634,
                1628,
                1738,
                1608,
                1670,
                1659,
                1629,
                1605,
                1618,
                1651,
                1662,
                1689,
                1637,
                1543,
                1650,
                1608,
                1622,
                1680,
                1589,
                1573,
                1596,
                1593,
                1515,
                1533,
                1602,
                1525,
                1470,
                1518,
                1506,
                1482,
                1576,
                1504,
                1484,
                1434,
                1493,
                1442,
                1505,
                1453,
                1477,
                1419,
                1484,
                1410,
                1432,
                1457,
                1505,
                1481,
                1497,
                1491,
                1398,
                1427,
                1506,
                1432,
                1470,
                1451,
                1439,
                1464,
                1405,
                1381,
                1406,
                1321,
                1381,
                1360,
                1395,
                1393,
                1394,
                1361,
                1350,
                1348,
                1341,
                1357,
                1311,
                1330,
                1373,
                1373,
                1354,
                1315,
                1295,
                1254,
                1320,
                1303,
                1321,
                1302,
                1309,
                1305,
                1239,
                1336,
                1238,
                1221,
                1341,
                1273,
                1304,
                1306,
                1276,
                1304,
                1280,
                1313,
                1217,
                1242,
                1265,
                1210,
                1229,
                1174,
                1193,
                1220,
                1211,
                1208,
                1199,
                1237,
                1186,
                1236,
                1191,
                1223,
                1219,
                1243,
                1196,
                1175,
                1202,
                1135,
                1124,
                1213,
                1107,
                1111,
                1233,
                1146,
                1189,
                1119,
                1162,
                1095,
                1175,
                1140,
                1053,
                1143,
                1120,
                1103,
                1076,
                1106,
                1074,
                1123,
                1141,
                1080,
                1080,
                1074,
                1087,
                1089,
                1047,
                1062,
                1101,
                1098,
                1028,
                1034,
                1003,
                1084,
                1054,
                1082,
                1026,
                1017,
                1016,
                1041,
                1056,
                966,
                1042,
                981,
                1027,
                997,
                1002,
                978,
                971,
                971,
                980,
                955,
                1009,
                964,
                958,
                1034,
                1032,
                926,
                959,
                956,
                940,
                946,
                946,
                992,
                926,
                944,
                971,
                936,
                913,
                971,
                946,
                864,
                872,
                945,
                890,
                915,
                902,
                920,
                880,
                895,
                906,
                921,
                837,
                835,
                859,
                891,
                846,
                905,
                908,
                849,
                831,
                845,
                868,
                851,
                843,
                858,
                819,
                899,
                758,
                889,
                806,
                861,
                798,
                781,
                795,
                833,
                834,
                824,
                789,
                793,
                794,
                815,
                833,
                819,
                837,
                824,
                770,
                792,
                757,
                808,
                788,
                780,
                748,
                854,
                746,
                766,
                748,
                715,
                756,
                715,
                787,
                728,
                751,
                701,
                704,
                691,
                715,
                704,
                712,
                713,
                651,
                713,
                753,
                740,
                690,
                668,
                747,
                699,
                642,
                707,
                697,
                733,
                680,
                667,
                668,
                725,
                639,
                671,
                693,
                647,
                703,
                665,
                668,
                669,
                653,
                694,
                683,
                664,
                631,
                656,
                699,
                670,
                631,
                643,
                642,
                636,
                676,
                641,
                577,
                616,
                619,
                670,
                629,
                595,
                609,
                644,
                614,
                574,
                661,
                598,
                607,
                571,
                550,
                621,
                556,
                573,
                561,
                627,
                582,
                557,
                566,
                561,
                540,
                534,
                574,
                572,
                533,
                570,
                551,
                577,
                570,
                532,
                529,
                527,
                542,
                548,
                575,
                562,
                524,
                499,
                561,
                513,
                547,
                575,
                507,
                475,
                517,
                586,
                543,
                511,
                507,
                523,
                503,
                507,
                538,
                494,
                482,
                499,
                505,
                509,
                548,
                523,
                499,
                495,
                502,
                486,
                490,
                469,
                490,
                459,
                463,
                470,
                463,
                490,
                482,
                474,
                452,
                457,
                465,
                432,
                432,
                436,
                453,
                386,
                456,
                462,
                459,
                415,
                434,
                422,
                434,
                458,
                410,
                435,
                458,
                444,
                416,
                425,
                394,
                390,
                397,
                438,
                424,
                409,
                426,
                419,
                414,
                419,
                407,
                394,
                410,
                434,
                419,
                407,
                398,
                410,
                361,
                422,
                413,
                402,
                422,
                386,
                383,
                365,
                382,
                393,
                359,
                382,
                387,
                371,
                385,
                340,
                408,
                384,
                376,
                369,
                399,
                366,
                361,
                354,
                393,
                394,
                369,
                368,
                362,
                377,
                393,
                350,
                373,
                342,
                371,
                392,
                342,
                362,
                367,
                309,
                372,
                368,
                336,
                351,
                319,
                348,
                369,
                367,
                364,
                327,
                336,
                342,
                329,
                369,
                327,
                334,
                331,
                361,
                333,
                361,
                371,
                331,
                309,
                316,
                332,
                320,
                337,
                326,
                345,
                318,
                314,
                376,
                323,
                331,
                333,
                332,
                316,
                300,
                314,
                317,
                340,
                314,
                340,
                305,
                301,
                358,
                336,
                316,
                294,
                312,
                283,
                274,
                333,
                315,
                343,
                301,
                306,
                319,
                343,
                286,
                306,
                309,
                289,
                275,
                316,
                275,
                279,
                294,
                282,
                287,
                307,
                295,
                268,
                273,
                269,
                293,
                305,
                274,
                281,
                302,
                299,
                298,
                268,
                288,
                268,
                276,
                310,
                259,
                294,
                273,
                285,
                250,
                283,
                260,
                296,
                272,
                282,
                277,
                292,
                249,
                267,
                282,
                286,
                262,
                290,
                271,
                248,
                273,
                248,
                265,
                250,
                271,
                264,
                271,
                242,
                243,
                269,
                281,
                265,
                241,
                225,
                271,
                205,
                257,
                248,
                267,
                266,
                227,
                273,
                242,
                252,
                258,
                262,
                258,
                266,
                265,
                247,
                233,
                233,
                246,
                222,
                227,
                236,
                252,
                241,
                255,
                198,
                235,
                208,
                241,
                218,
                240,
                216,
                222,
                219,
                219,
                233,
                220,
                245,
                253,
                236,
                234,
                215,
                207,
                224,
                225,
                219,
                260,
                228,
                210,
                203,
                223,
                245,
                203,
                219,
                217,
                207,
                215,
                200,
                233,
                217,
                200,
                203,
                231,
                198,
                200,
                207,
                191,
                224,
                184,
                191,
                221,
                201,
                198,
                219,
                205,
                216,
                192,
                217,
                209,
                185,
                205,
                202,
                210,
                187,
                210,
                209,
                204,
                224,
                180,
                213,
                228,
                179,
                218,
                210,
                200,
                212,
                210,
                185,
                206,
                219,
                206,
                186,
                201,
                179,
                182,
                198,
                194,
                196,
                191,
                176,
                204,
                186,
                190,
                195,
                196,
                209,
                206,
                201,
                195,
                213,
                216,
                179,
                178,
                185,
                217,
                209,
                213,
                216,
                185,
                211,
                171,
                193,
                208,
                193,
                191,
                197,
                162,
                169,
                183,
                199,
                208,
                194,
                195,
                198,
                174,
                213,
                192,
                189,
                205,
                186,
                198,
                204,
                187,
                198,
                199,
                179,
                177,
                174,
                199,
                164,
                208,
                207,
                186,
                212,
                209,
                190,
                178,
                180,
                179,
                168,
                199,
                190,
                189,
                182,
                186,
                178,
                182,
                213,
                183,
                178,
                193,
                205,
                202,
                183,
                187,
                189,
                217,
                175,
                199,
                183,
                164,
                181,
                197,
                181,
                192,
                178,
                183,
                145,
                170,
                182,
                202,
                180,
                188,
                167,
                143,
                181,
                182,
                200,
                165,
                187,
                172,
                190,
                172,
                187,
                172,
                185,
                196,
                137,
                172,
                152,
                156,
                138,
                173,
                181,
                169,
                142,
                176,
                177,
                168,
                179,
                169,
                140,
                165,
                155,
                152,
                165,
                166,
                157,
                146,
                170,
                172,
                175,
                152,
                169,
                152,
                139,
                164,
                137,
                178,
                138,
                150,
                165,
                143,
                136,
                137,
                143,
                148,
                142,
                152,
                119,
                126,
                108,
                110,
                122,
                111,
                145,
                146,
                117,
                130,
                128,
                132,
                131,
                125,
                141,
                135,
                102,
                125,
                141,
                141,
                137,
                122,
                157,
                124,
                137,
                132,
                137,
                130,
                119,
                104,
                128,
                105,
                144,
                112,
                121,
                129,
                115,
                111,
                117,
                109,
                118,
                105,
                119,
                120,
                128,
                109,
                104,
                101,
                110,
                141,
                122,
                108,
                124,
                93,
                121,
                121,
                122,
                106,
                107,
                117,
                117,
                85,
                111,
                89,
                104,
                110,
                129,
                96,
                94,
                104,
                109,
                105,
                103,
                100,
                125,
                91,
                95,
                108,
                116,
                99,
                118,
                114,
                118,
                95,
                115,
                120,
                114,
                81,
                100,
                89,
                106,
                106,
                96,
                90,
                91,
                104,
                82,
                114,
                98,
                95,
                86,
                95,
                83,
                68,
                102,
                78,
                103,
                84,
                78,
                96,
                86,
                100,
                87,
                91,
                80,
                82,
                99,
                98,
                79,
                91,
                87,
                103,
                89,
                102,
                97,
                88,
                95,
                82,
                69,
                86,
                98,
                85,
                102,
                77,
                94,
                78,
                99,
                79,
                76,
                64,
                79,
                84,
                91,
                79,
                61,
                105,
                64,
                85,
                83,
                73,
                76,
                72,
                78,
                64,
                89,
                84,
                78,
                103,
                87,
                71,
                79,
                78,
                79,
                95,
                96,
                73,
                74,
                85,
                67,
                72,
                67,
                61,
                72,
                81,
                80,
                78,
                73,
                80,
                76,
                70,
                72,
                73,
                64,
                84,
                68,
                79,
                85,
                74,
                66,
                74,
                70,
                70,
                72,
                82,
                82,
                59,
                70,
                71,
                68,
                71,
                74,
                64,
                65,
                63,
                71,
                70,
                53,
                79,
                72,
                77,
                68,
                67,
                68,
                63,
                55,
                70,
                60,
                64,
                62,
                60,
                66,
                53,
                80,
                54,
                63,
                76,
                56,
                53,
                66,
                73,
                57,
                54,
                57,
                55,
                65,
                52,
                69,
                71,
                49,
                55,
                61,
                57,
                59,
                58,
                54,
                57,
                38,
                64,
                54,
                52,
                49,
                61,
                64,
                62,
                47,
                37,
                53,
                45,
                46,
                55,
                63,
                50,
                41,
                53,
                59,
                46,
                45,
                56,
                55,
                40,
                44,
                53,
                40,
                49,
                31,
                45,
                37,
                55,
                44,
                37,
                50,
                46,
                46,
                56,
                47,
                40,
                56,
                47,
                36,
                40,
                41,
                44,
                42,
                36,
                47,
                40,
                39,
                29,
                33,
                40,
                41,
                36,
                38,
                42,
                37,
                41,
                44,
                44,
                27,
                43,
                41,
                52,
                31,
                36,
                41,
                35,
                29,
                40,
                33,
                31,
                40,
                38,
                39,
                53,
                41,
                43,
                32,
                40,
                33,
                25,
                31,
                25,
                37,
                37,
                36,
                34,
                29,
                36,
                29,
                33,
                30,
                29,
                23,
                35,
                32,
                32,
                40,
                35,
                31,
                28,
                29,
                41,
                31,
                20,
                30,
                31,
                26,
                21,
                27,
                23,
                32,
                25,
                31,
                26,
                21,
                28,
                29,
                25,
                20,
                19,
                26,
                23,
                22,
                25,
                33,
                23,
                24,
                31,
                24,
                22,
                23,
                19,
                24,
                26,
                22,
                21,
                30,
                20,
                24,
                21,
                21,
                22,
                25,
                18,
                25,
                20,
                24,
                19,
                26,
                29,
                18,
                27,
                24,
                27,
                10,
                14,
                26,
                17,
                25,
                25,
                14,
                20,
                13,
                21,
                18,
                20,
                14,
                11,
                16,
                14,
                14,
                17,
                21,
                16,
                14,
                20,
                16,
                17,
                16,
                16,
                19,
                15,
                9,
                9,
                13,
                15,
                17,
                19,
                15,
                18,
                22,
                19,
                14,
                14,
                12,
                18,
                13,
                17,
                20,
                14,
                16,
                15,
                20,
                14,
                14,
                10,
                10,
                15,
                17,
                21,
                16,
                7,
                10,
                22,
                12,
                19,
                16,
                11,
                9,
                19,
                11,
                11,
                9,
                6,
                11,
                7,
                14,
                12,
                9,
                11,
                17,
                17,
                12,
                12,
                6,
                16,
                8,
                10,
                9,
                11,
                8,
                10,
                9,
                15,
                3,
                9,
                10,
                17,
                15,
                10,
                9,
                14,
                7,
                4,
                13,
                9,
                8,
                4,
                13,
                8,
                10,
                7,
                8,
                5,
                8,
                2,
                6,
                16,
                9,
                4,
                5,
                6,
                4,
                7,
                8,
                8,
                3,
                5,
                5,
                4,
                3,
                8,
                4,
                6,
                7,
                8,
                9,
                4,
                5,
                5,
                6,
                3,
                9,
                4,
                3,
                7,
                5,
                8,
                7,
                7,
                10,
                5,
                4,
                11,
                2,
                2,
                2,
                9,
                11,
                11,
                12,
                2,
                4,
                6,
                6,
                2,
                4,
                1,
                7,
                2,
                5,
                4,
                2,
                3,
                5,
                3,
                3,
                5,
                4,
                4,
                2,
                2,
                4,
                1,
                5,
                2,
                3,
                3,
                3,
                1,
                3,
                2,
                4,
                1,
                5,
                2,
                1,
                3,
                6,
                2,
                5,
                6,
                1,
                5,
                4,
                3,
                4,
                3,
                1,
                3,
                2,
                2,
                1,
                1,
                1,
                4,
                1,
                2,
                2,
                4,
                1,
                3,
                3,
                1,
                2,
                2,
                2,
                2,
                1,
                2,
                5,
                2,
                1,
                1,
                1,
                1,
                2,
                2,
                1,
                2,
                1,
                1,
                1,
                1,
                1,
                3,
                1,
                1,
                1,
                1,
                1,
                1,
                3,
                1,
                1,
                1,
                1,
                1,
                1,
                2,
                1,
                1,
                1,
                1,
                1,
                1,
                1
            ],
            "barCategoryGap": "20%",
            "label": {
                "show": false,
                "position": "top",
                "margin": 8
            },
            "areaStyle": {
                "opacity": 0.5
            },
            "rippleEffect": {
                "show": true,
                "brushType": "stroke",
                "scale": 2.5,
                "period": 4
            }
        }
    ],
    legend: [
        {
            "data": [
                "number"
            ],
            "selected": {
                "number": true
            },
            "show": false,
            "padding": 5,
            "itemGap": 10,
            "itemWidth": 25,
            "itemHeight": 14,
            "bottom": "bottom"
        }
    ],
    tooltip: {
        "show": true,
        "trigger": "item",
        "triggerOn": "mousemove|click",
        "axisPointer": {
            "type": "line"
        },
        textStyle: {
            "fontSize": 14,
            "fontFamily": "Fusion Pixel",
        

        },
        borderWidth: 0
    },
    xAxis: [
        {
            "show": true,
            "scale": false,
            "nameLocation": "end",
            "nameGap": 15,
            "gridIndex": 0,
            "axisTick": {
                "show": true,
                "alignWithLabel": true,
                "inside": false
            },
            inverse: false,
            offset: 0,
            splitNumber: 5,
            boundaryGap: false,
            minInterval: 0,
            splitLine: {
                "show": false,
                "lineStyle": {
                    "show": true,
                    "width": 1,
                    "opacity": 1,
                    "curveness": 0,
                    "type": "solid"
                }
            },
            data: [
                144.0,
                147.0,
                171.0,
                181.0,
                193.0,
                195.0,
                198.0,
                204.0,
                220.0,
                222.0,
                234.0,
                235.0,
                237.0,
                246.0,
                247.0,
                248.0,
                253.0,
                254.0,
                255.0,
                257.0,
                259.0,
                260.0,
                265.0,
                267.0,
                270.0,
                271.0,
                273.0,
                277.0,
                278.0,
                280.0,
                281.0,
                282.0,
                283.0,
                285.0,
                286.0,
                287.0,
                289.0,
                290.0,
                291.0,
                293.0,
                294.0,
                295.0,
                298.0,
                299.0,
                300.0,
                301.0,
                302.0,
                303.0,
                304.0,
                305.0,
                306.0,
                308.0,
                309.0,
                310.0,
                311.0,
                312.0,
                313.0,
                314.0,
                315.0,
                317.0,
                318.0,
                319.0,
                320.0,
                321.0,
                322.0,
                323.0,
                324.0,
                326.0,
                327.0,
                328.0,
                329.0,
                330.0,
                331.0,
                332.0,
                333.0,
                334.0,
                335.0,
                336.0,
                337.0,
                339.0,
                340.0,
                341.0,
                342.0,
                343.0,
                344.0,
                345.0,
                346.0,
                347.0,
                348.0,
                349.0,
                350.0,
                351.0,
                352.0,
                353.0,
                354.0,
                355.0,
                356.0,
                357.0,
                358.0,
                359.0,
                360.0,
                361.0,
                362.0,
                363.0,
                364.0,
                365.0,
                366.0,
                367.0,
                368.0,
                369.0,
                370.0,
                371.0,
                372.0,
                373.0,
                374.0,
                375.0,
                376.0,
                377.0,
                378.0,
                379.0,
                380.0,
                381.0,
                382.0,
                383.0,
                384.0,
                385.0,
                386.0,
                387.0,
                388.0,
                389.0,
                390.0,
                391.0,
                392.0,
                393.0,
                394.0,
                395.0,
                396.0,
                397.0,
                398.0,
                399.0,
                400.0,
                401.0,
                402.0,
                403.0,
                404.0,
                405.0,
                406.0,
                407.0,
                408.0,
                409.0,
                410.0,
                411.0,
                412.0,
                413.0,
                414.0,
                415.0,
                416.0,
                417.0,
                418.0,
                419.0,
                420.0,
                421.0,
                422.0,
                423.0,
                424.0,
                425.0,
                426.0,
                427.0,
                428.0,
                429.0,
                430.0,
                431.0,
                432.0,
                433.0,
                434.0,
                435.0,
                436.0,
                437.0,
                438.0,
                439.0,
                440.0,
                441.0,
                442.0,
                443.0,
                444.0,
                445.0,
                446.0,
                447.0,
                448.0,
                449.0,
                450.0,
                451.0,
                452.0,
                453.0,
                454.0,
                455.0,
                456.0,
                457.0,
                458.0,
                459.0,
                460.0,
                461.0,
                462.0,
                463.0,
                464.0,
                465.0,
                466.0,
                467.0,
                468.0,
                469.0,
                470.0,
                471.0,
                472.0,
                473.0,
                474.0,
                475.0,
                476.0,
                477.0,
                478.0,
                479.0,
                480.0,
                481.0,
                482.0,
                483.0,
                484.0,
                485.0,
                486.0,
                487.0,
                488.0,
                489.0,
                490.0,
                491.0,
                492.0,
                493.0,
                494.0,
                495.0,
                496.0,
                497.0,
                498.0,
                499.0,
                500.0,
                501.0,
                502.0,
                503.0,
                504.0,
                505.0,
                506.0,
                507.0,
                508.0,
                509.0,
                510.0,
                511.0,
                512.0,
                513.0,
                514.0,
                515.0,
                516.0,
                517.0,
                518.0,
                519.0,
                520.0,
                521.0,
                522.0,
                523.0,
                524.0,
                525.0,
                526.0,
                527.0,
                528.0,
                529.0,
                530.0,
                531.0,
                532.0,
                533.0,
                534.0,
                535.0,
                536.0,
                537.0,
                538.0,
                539.0,
                540.0,
                541.0,
                542.0,
                543.0,
                544.0,
                545.0,
                546.0,
                547.0,
                548.0,
                549.0,
                550.0,
                551.0,
                552.0,
                553.0,
                554.0,
                555.0,
                556.0,
                557.0,
                558.0,
                559.0,
                560.0,
                561.0,
                562.0,
                563.0,
                564.0,
                565.0,
                566.0,
                567.0,
                568.0,
                569.0,
                570.0,
                571.0,
                572.0,
                573.0,
                574.0,
                575.0,
                576.0,
                577.0,
                578.0,
                579.0,
                580.0,
                581.0,
                582.0,
                583.0,
                584.0,
                585.0,
                586.0,
                587.0,
                588.0,
                589.0,
                590.0,
                591.0,
                592.0,
                593.0,
                594.0,
                595.0,
                596.0,
                597.0,
                598.0,
                599.0,
                600.0,
                601.0,
                602.0,
                603.0,
                604.0,
                605.0,
                606.0,
                607.0,
                608.0,
                609.0,
                610.0,
                611.0,
                612.0,
                613.0,
                614.0,
                615.0,
                616.0,
                617.0,
                618.0,
                619.0,
                620.0,
                621.0,
                622.0,
                623.0,
                624.0,
                625.0,
                626.0,
                627.0,
                628.0,
                629.0,
                630.0,
                631.0,
                632.0,
                633.0,
                634.0,
                635.0,
                636.0,
                637.0,
                638.0,
                639.0,
                640.0,
                641.0,
                642.0,
                643.0,
                644.0,
                645.0,
                646.0,
                647.0,
                648.0,
                649.0,
                650.0,
                651.0,
                652.0,
                653.0,
                654.0,
                655.0,
                656.0,
                657.0,
                658.0,
                659.0,
                660.0,
                661.0,
                662.0,
                663.0,
                664.0,
                665.0,
                666.0,
                667.0,
                668.0,
                669.0,
                670.0,
                671.0,
                672.0,
                673.0,
                674.0,
                675.0,
                676.0,
                677.0,
                678.0,
                679.0,
                680.0,
                681.0,
                682.0,
                683.0,
                684.0,
                685.0,
                686.0,
                687.0,
                688.0,
                689.0,
                690.0,
                691.0,
                692.0,
                693.0,
                694.0,
                695.0,
                696.0,
                697.0,
                698.0,
                699.0,
                700.0,
                701.0,
                702.0,
                703.0,
                704.0,
                705.0,
                706.0,
                707.0,
                708.0,
                709.0,
                710.0,
                711.0,
                712.0,
                713.0,
                714.0,
                715.0,
                716.0,
                717.0,
                718.0,
                719.0,
                720.0,
                721.0,
                722.0,
                723.0,
                724.0,
                725.0,
                726.0,
                727.0,
                728.0,
                729.0,
                730.0,
                731.0,
                732.0,
                733.0,
                734.0,
                735.0,
                736.0,
                737.0,
                738.0,
                739.0,
                740.0,
                741.0,
                742.0,
                743.0,
                744.0,
                745.0,
                746.0,
                747.0,
                748.0,
                749.0,
                750.0,
                751.0,
                752.0,
                753.0,
                754.0,
                755.0,
                756.0,
                757.0,
                758.0,
                759.0,
                760.0,
                761.0,
                762.0,
                763.0,
                764.0,
                765.0,
                766.0,
                767.0,
                768.0,
                769.0,
                770.0,
                771.0,
                772.0,
                773.0,
                774.0,
                775.0,
                776.0,
                777.0,
                778.0,
                779.0,
                780.0,
                781.0,
                782.0,
                783.0,
                784.0,
                785.0,
                786.0,
                787.0,
                788.0,
                789.0,
                790.0,
                791.0,
                792.0,
                793.0,
                794.0,
                795.0,
                796.0,
                797.0,
                798.0,
                799.0,
                800.0,
                801.0,
                802.0,
                803.0,
                804.0,
                805.0,
                806.0,
                807.0,
                808.0,
                809.0,
                810.0,
                811.0,
                812.0,
                813.0,
                814.0,
                815.0,
                816.0,
                817.0,
                818.0,
                819.0,
                820.0,
                821.0,
                822.0,
                823.0,
                824.0,
                825.0,
                826.0,
                827.0,
                828.0,
                829.0,
                830.0,
                831.0,
                832.0,
                833.0,
                834.0,
                835.0,
                836.0,
                837.0,
                838.0,
                839.0,
                840.0,
                841.0,
                842.0,
                843.0,
                844.0,
                845.0,
                846.0,
                847.0,
                848.0,
                849.0,
                850.0,
                851.0,
                852.0,
                853.0,
                854.0,
                855.0,
                856.0,
                857.0,
                858.0,
                859.0,
                860.0,
                861.0,
                862.0,
                863.0,
                864.0,
                865.0,
                866.0,
                867.0,
                868.0,
                869.0,
                870.0,
                871.0,
                872.0,
                873.0,
                874.0,
                875.0,
                876.0,
                877.0,
                878.0,
                879.0,
                880.0,
                881.0,
                882.0,
                883.0,
                884.0,
                885.0,
                886.0,
                887.0,
                888.0,
                889.0,
                890.0,
                891.0,
                892.0,
                893.0,
                894.0,
                895.0,
                896.0,
                897.0,
                898.0,
                899.0,
                900.0,
                901.0,
                902.0,
                903.0,
                904.0,
                905.0,
                906.0,
                907.0,
                908.0,
                909.0,
                910.0,
                911.0,
                912.0,
                913.0,
                914.0,
                915.0,
                916.0,
                917.0,
                918.0,
                919.0,
                920.0,
                921.0,
                922.0,
                923.0,
                924.0,
                925.0,
                926.0,
                927.0,
                928.0,
                929.0,
                930.0,
                931.0,
                932.0,
                933.0,
                934.0,
                935.0,
                936.0,
                937.0,
                938.0,
                939.0,
                940.0,
                941.0,
                942.0,
                943.0,
                944.0,
                945.0,
                946.0,
                947.0,
                948.0,
                949.0,
                950.0,
                951.0,
                952.0,
                953.0,
                954.0,
                955.0,
                956.0,
                957.0,
                958.0,
                959.0,
                960.0,
                961.0,
                962.0,
                963.0,
                964.0,
                965.0,
                966.0,
                967.0,
                968.0,
                969.0,
                970.0,
                971.0,
                972.0,
                973.0,
                974.0,
                975.0,
                976.0,
                977.0,
                978.0,
                979.0,
                980.0,
                981.0,
                982.0,
                983.0,
                984.0,
                985.0,
                986.0,
                987.0,
                988.0,
                989.0,
                990.0,
                991.0,
                992.0,
                993.0,
                994.0,
                995.0,
                996.0,
                997.0,
                998.0,
                999.0,
                1000.0,
                1001.0,
                1002.0,
                1003.0,
                1004.0,
                1005.0,
                1006.0,
                1007.0,
                1008.0,
                1009.0,
                1010.0,
                1011.0,
                1012.0,
                1013.0,
                1014.0,
                1015.0,
                1016.0,
                1017.0,
                1018.0,
                1019.0,
                1020.0,
                1021.0,
                1022.0,
                1023.0,
                1024.0,
                1025.0,
                1026.0,
                1027.0,
                1028.0,
                1029.0,
                1030.0,
                1031.0,
                1032.0,
                1033.0,
                1034.0,
                1035.0,
                1036.0,
                1037.0,
                1038.0,
                1039.0,
                1040.0,
                1041.0,
                1042.0,
                1043.0,
                1044.0,
                1045.0,
                1046.0,
                1047.0,
                1048.0,
                1049.0,
                1050.0,
                1051.0,
                1052.0,
                1053.0,
                1054.0,
                1055.0,
                1056.0,
                1057.0,
                1058.0,
                1059.0,
                1060.0,
                1061.0,
                1062.0,
                1063.0,
                1064.0,
                1065.0,
                1066.0,
                1067.0,
                1068.0,
                1069.0,
                1070.0,
                1071.0,
                1072.0,
                1073.0,
                1074.0,
                1075.0,
                1076.0,
                1077.0,
                1078.0,
                1079.0,
                1080.0,
                1081.0,
                1082.0,
                1083.0,
                1084.0,
                1085.0,
                1086.0,
                1087.0,
                1088.0,
                1089.0,
                1090.0,
                1091.0,
                1092.0,
                1093.0,
                1094.0,
                1095.0,
                1096.0,
                1097.0,
                1098.0,
                1099.0,
                1100.0,
                1101.0,
                1102.0,
                1103.0,
                1104.0,
                1105.0,
                1106.0,
                1107.0,
                1108.0,
                1109.0,
                1110.0,
                1111.0,
                1112.0,
                1113.0,
                1114.0,
                1115.0,
                1116.0,
                1117.0,
                1118.0,
                1119.0,
                1120.0,
                1121.0,
                1122.0,
                1123.0,
                1124.0,
                1125.0,
                1126.0,
                1127.0,
                1128.0,
                1129.0,
                1130.0,
                1131.0,
                1132.0,
                1133.0,
                1134.0,
                1135.0,
                1136.0,
                1137.0,
                1138.0,
                1139.0,
                1140.0,
                1141.0,
                1142.0,
                1143.0,
                1144.0,
                1145.0,
                1146.0,
                1147.0,
                1148.0,
                1149.0,
                1150.0,
                1151.0,
                1152.0,
                1153.0,
                1154.0,
                1155.0,
                1156.0,
                1157.0,
                1158.0,
                1159.0,
                1160.0,
                1161.0,
                1162.0,
                1163.0,
                1164.0,
                1165.0,
                1166.0,
                1167.0,
                1168.0,
                1169.0,
                1170.0,
                1171.0,
                1172.0,
                1173.0,
                1174.0,
                1175.0,
                1176.0,
                1177.0,
                1178.0,
                1179.0,
                1180.0,
                1181.0,
                1182.0,
                1183.0,
                1184.0,
                1185.0,
                1186.0,
                1187.0,
                1188.0,
                1189.0,
                1190.0,
                1191.0,
                1192.0,
                1193.0,
                1194.0,
                1195.0,
                1196.0,
                1197.0,
                1198.0,
                1199.0,
                1200.0,
                1201.0,
                1202.0,
                1203.0,
                1204.0,
                1205.0,
                1206.0,
                1207.0,
                1208.0,
                1209.0,
                1210.0,
                1211.0,
                1212.0,
                1213.0,
                1214.0,
                1215.0,
                1216.0,
                1217.0,
                1218.0,
                1219.0,
                1220.0,
                1221.0,
                1222.0,
                1223.0,
                1224.0,
                1225.0,
                1226.0,
                1227.0,
                1228.0,
                1229.0,
                1230.0,
                1231.0,
                1232.0,
                1233.0,
                1234.0,
                1235.0,
                1236.0,
                1237.0,
                1238.0,
                1239.0,
                1240.0,
                1241.0,
                1242.0,
                1243.0,
                1244.0,
                1245.0,
                1246.0,
                1247.0,
                1248.0,
                1249.0,
                1250.0,
                1251.0,
                1252.0,
                1253.0,
                1254.0,
                1255.0,
                1256.0,
                1257.0,
                1258.0,
                1259.0,
                1260.0,
                1261.0,
                1262.0,
                1263.0,
                1264.0,
                1265.0,
                1266.0,
                1267.0,
                1268.0,
                1269.0,
                1270.0,
                1271.0,
                1272.0,
                1273.0,
                1274.0,
                1275.0,
                1276.0,
                1277.0,
                1278.0,
                1279.0,
                1280.0,
                1281.0,
                1282.0,
                1283.0,
                1284.0,
                1285.0,
                1286.0,
                1287.0,
                1288.0,
                1289.0,
                1290.0,
                1291.0,
                1292.0,
                1293.0,
                1294.0,
                1295.0,
                1296.0,
                1297.0,
                1298.0,
                1299.0,
                1300.0,
                1301.0,
                1302.0,
                1303.0,
                1304.0,
                1305.0,
                1306.0,
                1307.0,
                1308.0,
                1309.0,
                1310.0,
                1311.0,
                1312.0,
                1313.0,
                1314.0,
                1315.0,
                1316.0,
                1317.0,
                1318.0,
                1319.0,
                1320.0,
                1321.0,
                1322.0,
                1323.0,
                1324.0,
                1325.0,
                1326.0,
                1327.0,
                1328.0,
                1329.0,
                1330.0,
                1331.0,
                1332.0,
                1333.0,
                1334.0,
                1335.0,
                1336.0,
                1337.0,
                1338.0,
                1339.0,
                1340.0,
                1341.0,
                1342.0,
                1343.0,
                1344.0,
                1345.0,
                1346.0,
                1347.0,
                1348.0,
                1349.0,
                1350.0,
                1351.0,
                1352.0,
                1353.0,
                1354.0,
                1355.0,
                1356.0,
                1357.0,
                1358.0,
                1359.0,
                1360.0,
                1361.0,
                1362.0,
                1363.0,
                1364.0,
                1365.0,
                1366.0,
                1367.0,
                1368.0,
                1369.0,
                1370.0,
                1371.0,
                1372.0,
                1373.0,
                1374.0,
                1375.0,
                1376.0,
                1377.0,
                1378.0,
                1379.0,
                1380.0,
                1381.0,
                1382.0,
                1383.0,
                1384.0,
                1385.0,
                1386.0,
                1387.0,
                1388.0,
                1389.0,
                1390.0,
                1391.0,
                1392.0,
                1393.0,
                1394.0,
                1395.0,
                1396.0,
                1397.0,
                1398.0,
                1399.0,
                1400.0,
                1401.0,
                1402.0,
                1403.0,
                1404.0,
                1405.0,
                1406.0,
                1407.0,
                1408.0,
                1409.0,
                1410.0,
                1411.0,
                1412.0,
                1413.0,
                1414.0,
                1415.0,
                1416.0,
                1417.0,
                1418.0,
                1419.0,
                1420.0,
                1421.0,
                1422.0,
                1423.0,
                1424.0,
                1425.0,
                1426.0,
                1427.0,
                1428.0,
                1429.0,
                1430.0,
                1431.0,
                1432.0,
                1433.0,
                1434.0,
                1435.0,
                1436.0,
                1437.0,
                1438.0,
                1439.0,
                1440.0,
                1441.0,
                1442.0,
                1443.0,
                1444.0,
                1445.0,
                1446.0,
                1447.0,
                1448.0,
                1449.0,
                1450.0,
                1451.0,
                1452.0,
                1453.0,
                1454.0,
                1455.0,
                1456.0,
                1457.0,
                1458.0,
                1459.0,
                1460.0,
                1461.0,
                1462.0,
                1463.0,
                1464.0,
                1465.0,
                1466.0,
                1467.0,
                1468.0,
                1469.0,
                1470.0,
                1471.0,
                1472.0,
                1473.0,
                1474.0,
                1475.0,
                1476.0,
                1477.0,
                1478.0,
                1479.0,
                1480.0,
                1481.0,
                1482.0,
                1483.0,
                1484.0,
                1485.0,
                1486.0,
                1487.0,
                1488.0,
                1489.0,
                1490.0,
                1491.0,
                1492.0,
                1493.0,
                1494.0,
                1495.0,
                1496.0,
                1497.0,
                1498.0,
                1499.0,
                1500.0,
                1501.0,
                1502.0,
                1503.0,
                1504.0,
                1505.0,
                1506.0,
                1507.0,
                1508.0,
                1509.0,
                1510.0,
                1511.0,
                1512.0,
                1513.0,
                1514.0,
                1515.0,
                1516.0,
                1517.0,
                1518.0,
                1519.0,
                1520.0,
                1521.0,
                1522.0,
                1523.0,
                1524.0,
                1525.0,
                1526.0,
                1527.0,
                1528.0,
                1529.0,
                1530.0,
                1531.0,
                1532.0,
                1533.0,
                1534.0,
                1535.0,
                1536.0,
                1537.0,
                1538.0,
                1539.0,
                1540.0,
                1541.0,
                1542.0,
                1543.0,
                1544.0,
                1545.0,
                1546.0,
                1547.0,
                1548.0,
                1549.0,
                1550.0,
                1551.0,
                1552.0,
                1553.0,
                1554.0,
                1555.0,
                1556.0,
                1557.0,
                1558.0,
                1559.0,
                1560.0,
                1561.0,
                1562.0,
                1563.0,
                1564.0,
                1565.0,
                1566.0,
                1567.0,
                1568.0,
                1569.0,
                1570.0,
                1571.0,
                1572.0,
                1573.0,
                1574.0,
                1575.0,
                1576.0,
                1577.0,
                1578.0,
                1579.0,
                1580.0,
                1581.0,
                1582.0,
                1583.0,
                1584.0,
                1585.0,
                1586.0,
                1587.0,
                1588.0,
                1589.0,
                1590.0,
                1591.0,
                1592.0,
                1593.0,
                1594.0,
                1595.0,
                1596.0,
                1597.0,
                1598.0,
                1599.0,
                1600.0,
                1601.0,
                1602.0,
                1603.0,
                1604.0,
                1605.0,
                1606.0,
                1607.0,
                1608.0,
                1609.0,
                1610.0,
                1611.0,
                1612.0,
                1613.0,
                1614.0,
                1615.0,
                1616.0,
                1617.0,
                1618.0,
                1619.0,
                1620.0,
                1621.0,
                1622.0,
                1623.0,
                1624.0,
                1625.0,
                1626.0,
                1627.0,
                1628.0,
                1629.0,
                1630.0,
                1631.0,
                1632.0,
                1633.0,
                1634.0,
                1635.0,
                1636.0,
                1637.0,
                1638.0,
                1639.0,
                1640.0,
                1641.0,
                1642.0,
                1643.0,
                1644.0,
                1645.0,
                1646.0,
                1647.0,
                1648.0,
                1649.0,
                1650.0,
                1651.0,
                1652.0,
                1653.0,
                1654.0,
                1655.0,
                1656.0,
                1657.0,
                1658.0,
                1659.0,
                1660.0,
                1661.0,
                1662.0,
                1663.0,
                1664.0,
                1665.0,
                1666.0,
                1667.0,
                1668.0,
                1669.0,
                1670.0,
                1671.0,
                1672.0,
                1673.0,
                1674.0,
                1675.0,
                1676.0,
                1677.0,
                1678.0,
                1679.0,
                1680.0,
                1681.0,
                1682.0,
                1683.0,
                1684.0,
                1685.0,
                1686.0,
                1687.0,
                1688.0,
                1689.0,
                1690.0,
                1691.0,
                1692.0,
                1693.0,
                1694.0,
                1695.0,
                1696.0,
                1697.0,
                1698.0,
                1699.0,
                1700.0,
                1701.0,
                1702.0,
                1703.0,
                1704.0,
                1705.0,
                1706.0,
                1707.0,
                1708.0,
                1709.0,
                1710.0,
                1711.0,
                1712.0,
                1713.0,
                1714.0,
                1715.0,
                1716.0,
                1717.0,
                1718.0,
                1719.0,
                1720.0,
                1721.0,
                1722.0,
                1723.0,
                1724.0,
                1725.0,
                1726.0,
                1727.0,
                1728.0,
                1729.0,
                1730.0,
                1731.0,
                1732.0,
                1733.0,
                1734.0,
                1735.0,
                1736.0,
                1737.0,
                1738.0,
                1739.0,
                1740.0,
                1741.0,
                1742.0,
                1743.0,
                1744.0,
                1745.0,
                1746.0,
                1747.0,
                1748.0,
                1749.0,
                1750.0,
                1751.0,
                1752.0,
                1753.0,
                1754.0,
                1755.0,
                1756.0,
                1757.0,
                1758.0,
                1759.0,
                1760.0,
                1761.0,
                1762.0,
                1763.0,
                1764.0,
                1765.0,
                1766.0,
                1767.0,
                1768.0,
                1769.0,
                1770.0,
                1771.0,
                1772.0,
                1773.0,
                1774.0,
                1775.0,
                1776.0,
                1777.0,
                1778.0,
                1779.0,
                1780.0,
                1781.0,
                1782.0,
                1783.0,
                1784.0,
                1785.0,
                1786.0,
                1787.0,
                1788.0,
                1789.0,
                1790.0,
                1791.0,
                1792.0,
                1793.0,
                1794.0,
                1795.0,
                1796.0,
                1797.0,
                1798.0,
                1799.0,
                1800.0,
                1801.0,
                1802.0,
                1803.0,
                1804.0,
                1805.0,
                1806.0,
                1807.0,
                1808.0,
                1809.0,
                1810.0,
                1811.0,
                1812.0,
                1813.0,
                1814.0,
                1815.0,
                1816.0,
                1817.0,
                1818.0,
                1819.0,
                1820.0,
                1821.0,
                1822.0,
                1823.0,
                1824.0,
                1825.0,
                1826.0,
                1827.0,
                1828.0,
                1829.0,
                1830.0,
                1831.0,
                1832.0,
                1833.0,
                1834.0,
                1835.0,
                1836.0,
                1837.0,
                1838.0,
                1839.0,
                1840.0,
                1841.0,
                1842.0,
                1843.0,
                1844.0,
                1845.0,
                1846.0,
                1847.0,
                1848.0,
                1849.0,
                1850.0,
                1851.0,
                1852.0,
                1853.0,
                1854.0,
                1855.0,
                1856.0,
                1857.0,
                1858.0,
                1859.0,
                1860.0,
                1861.0,
                1862.0,
                1863.0,
                1864.0,
                1865.0,
                1866.0,
                1867.0,
                1868.0,
                1869.0,
                1870.0,
                1871.0,
                1872.0,
                1873.0,
                1874.0,
                1875.0,
                1876.0,
                1877.0,
                1878.0,
                1879.0,
                1880.0,
                1881.0,
                1882.0,
                1883.0,
                1884.0,
                1885.0,
                1886.0,
                1887.0,
                1888.0,
                1889.0,
                1890.0,
                1891.0,
                1892.0,
                1893.0,
                1894.0,
                1895.0,
                1896.0,
                1897.0,
                1898.0,
                1899.0,
                1900.0,
                1901.0,
                1902.0,
                1903.0,
                1904.0,
                1905.0,
                1906.0,
                1907.0,
                1908.0,
                1909.0,
                1910.0,
                1911.0,
                1912.0,
                1913.0,
                1914.0,
                1915.0,
                1916.0,
                1917.0,
                1918.0,
                1919.0,
                1920.0,
                1921.0,
                1922.0,
                1923.0,
                1924.0,
                1925.0,
                1926.0,
                1927.0,
                1928.0,
                1929.0,
                1930.0,
                1931.0,
                1932.0,
                1933.0,
                1934.0,
                1935.0,
                1936.0,
                1937.0,
                1938.0,
                1939.0,
                1940.0,
                1941.0,
                1942.0,
                1943.0,
                1944.0,
                1945.0,
                1946.0,
                1947.0,
                1948.0,
                1949.0,
                1950.0,
                1951.0,
                1952.0,
                1953.0,
                1954.0,
                1955.0,
                1956.0,
                1957.0,
                1958.0,
                1959.0,
                1960.0,
                1961.0,
                1962.0,
                1963.0,
                1964.0,
                1965.0,
                1966.0,
                1967.0,
                1968.0,
                1969.0,
                1970.0,
                1971.0,
                1972.0,
                1973.0,
                1974.0,
                1975.0,
                1976.0,
                1977.0,
                1978.0,
                1979.0,
                1980.0,
                1981.0,
                1982.0,
                1983.0,
                1984.0,
                1985.0,
                1986.0,
                1987.0,
                1988.0,
                1989.0,
                1990.0,
                1991.0,
                1992.0,
                1993.0,
                1994.0,
                1995.0,
                1996.0,
                1997.0,
                1998.0,
                1999.0,
                2000.0,
                2001.0,
                2002.0,
                2003.0,
                2004.0,
                2005.0,
                2006.0,
                2007.0,
                2008.0,
                2009.0,
                2010.0,
                2011.0,
                2012.0,
                2013.0,
                2014.0,
                2015.0,
                2016.0,
                2017.0,
                2018.0,
                2019.0,
                2020.0,
                2021.0,
                2022.0,
                2023.0,
                2024.0,
                2025.0,
                2026.0,
                2027.0,
                2028.0,
                2029.0,
                2030.0,
                2031.0,
                2032.0,
                2033.0,
                2034.0,
                2035.0,
                2036.0,
                2037.0,
                2038.0,
                2039.0,
                2040.0,
                2041.0,
                2042.0,
                2043.0,
                2044.0,
                2045.0,
                2046.0,
                2047.0,
                2048.0,
                2049.0,
                2050.0,
                2051.0,
                2052.0,
                2053.0,
                2054.0,
                2055.0,
                2056.0,
                2057.0,
                2058.0,
                2059.0,
                2060.0,
                2061.0,
                2062.0,
                2063.0,
                2064.0,
                2065.0,
                2066.0,
                2067.0,
                2068.0,
                2069.0,
                2070.0,
                2071.0,
                2072.0,
                2073.0,
                2074.0,
                2075.0,
                2076.0,
                2077.0,
                2078.0,
                2079.0,
                2080.0,
                2081.0,
                2082.0,
                2083.0,
                2084.0,
                2085.0,
                2086.0,
                2087.0,
                2088.0,
                2089.0,
                2090.0,
                2091.0,
                2092.0,
                2093.0,
                2094.0,
                2095.0,
                2096.0,
                2097.0,
                2098.0,
                2099.0,
                2100.0,
                2101.0,
                2102.0,
                2103.0,
                2104.0,
                2105.0,
                2106.0,
                2107.0,
                2108.0,
                2109.0,
                2110.0,
                2111.0,
                2112.0,
                2113.0,
                2114.0,
                2115.0,
                2116.0,
                2117.0,
                2118.0,
                2119.0,
                2120.0,
                2121.0,
                2122.0,
                2123.0,
                2124.0,
                2125.0,
                2126.0,
                2127.0,
                2128.0,
                2129.0,
                2130.0,
                2131.0,
                2132.0,
                2133.0,
                2134.0,
                2135.0,
                2136.0,
                2137.0,
                2138.0,
                2139.0,
                2140.0,
                2141.0,
                2142.0,
                2143.0,
                2144.0,
                2145.0,
                2146.0,
                2147.0,
                2148.0,
                2149.0,
                2150.0,
                2151.0,
                2152.0,
                2153.0,
                2154.0,
                2155.0,
                2156.0,
                2157.0,
                2158.0,
                2159.0,
                2160.0,
                2161.0,
                2162.0,
                2163.0,
                2164.0,
                2165.0,
                2166.0,
                2167.0,
                2168.0,
                2169.0,
                2170.0,
                2171.0,
                2172.0,
                2173.0,
                2174.0,
                2175.0,
                2176.0,
                2177.0,
                2178.0,
                2179.0,
                2180.0,
                2181.0,
                2182.0,
                2183.0,
                2184.0,
                2185.0,
                2186.0,
                2187.0,
                2188.0,
                2189.0,
                2190.0,
                2191.0,
                2192.0,
                2193.0,
                2194.0,
                2195.0,
                2196.0,
                2197.0,
                2198.0,
                2199.0,
                2200.0,
                2201.0,
                2202.0,
                2203.0,
                2204.0,
                2205.0,
                2206.0,
                2207.0,
                2208.0,
                2209.0,
                2210.0,
                2211.0,
                2212.0,
                2213.0,
                2214.0,
                2215.0,
                2216.0,
                2217.0,
                2218.0,
                2219.0,
                2220.0,
                2221.0,
                2222.0,
                2223.0,
                2224.0,
                2225.0,
                2226.0,
                2227.0,
                2228.0,
                2229.0,
                2230.0,
                2231.0,
                2232.0,
                2233.0,
                2234.0,
                2235.0,
                2236.0,
                2237.0,
                2238.0,
                2239.0,
                2240.0,
                2241.0,
                2242.0,
                2243.0,
                2244.0,
                2245.0,
                2246.0,
                2247.0,
                2248.0,
                2249.0,
                2250.0,
                2251.0,
                2252.0,
                2253.0,
                2254.0,
                2255.0,
                2256.0,
                2257.0,
                2258.0,
                2259.0,
                2260.0,
                2261.0,
                2262.0,
                2263.0,
                2264.0,
                2265.0,
                2266.0,
                2267.0,
                2268.0,
                2269.0,
                2270.0,
                2271.0,
                2272.0,
                2273.0,
                2274.0,
                2275.0,
                2276.0,
                2277.0,
                2278.0,
                2279.0,
                2280.0,
                2281.0,
                2282.0,
                2283.0,
                2284.0,
                2285.0,
                2286.0,
                2287.0,
                2288.0,
                2289.0,
                2290.0,
                2291.0,
                2292.0,
                2293.0,
                2294.0,
                2295.0,
                2296.0,
                2297.0,
                2298.0,
                2299.0,
                2300.0,
                2301.0,
                2302.0,
                2303.0,
                2304.0,
                2305.0,
                2306.0,
                2307.0,
                2308.0,
                2309.0,
                2310.0,
                2311.0,
                2312.0,
                2313.0,
                2314.0,
                2315.0,
                2316.0,
                2317.0,
                2318.0,
                2319.0,
                2320.0,
                2321.0,
                2322.0,
                2323.0,
                2324.0,
                2325.0,
                2326.0,
                2327.0,
                2328.0,
                2329.0,
                2330.0,
                2331.0,
                2332.0,
                2333.0,
                2334.0,
                2335.0,
                2336.0,
                2337.0,
                2338.0,
                2339.0,
                2340.0,
                2341.0,
                2342.0,
                2343.0,
                2344.0,
                2345.0,
                2346.0,
                2347.0,
                2348.0,
                2349.0,
                2350.0,
                2351.0,
                2352.0,
                2353.0,
                2354.0,
                2355.0,
                2356.0,
                2357.0,
                2358.0,
                2359.0,
                2360.0,
                2361.0,
                2362.0,
                2363.0,
                2364.0,
                2365.0,
                2366.0,
                2367.0,
                2368.0,
                2369.0,
                2370.0,
                2371.0,
                2372.0,
                2373.0,
                2374.0,
                2375.0,
                2376.0,
                2377.0,
                2378.0,
                2379.0,
                2380.0,
                2381.0,
                2382.0,
                2383.0,
                2384.0,
                2385.0,
                2386.0,
                2387.0,
                2388.0,
                2389.0,
                2390.0,
                2391.0,
                2392.0,
                2393.0,
                2394.0,
                2395.0,
                2396.0,
                2397.0,
                2398.0,
                2399.0,
                2400.0,
                2401.0,
                2402.0,
                2403.0,
                2404.0,
                2405.0,
                2406.0,
                2407.0,
                2408.0,
                2409.0,
                2410.0,
                2411.0,
                2412.0,
                2413.0,
                2414.0,
                2415.0,
                2416.0,
                2417.0,
                2418.0,
                2419.0,
                2420.0,
                2421.0,
                2422.0,
                2423.0,
                2424.0,
                2425.0,
                2426.0,
                2427.0,
                2428.0,
                2429.0,
                2430.0,
                2431.0,
                2432.0,
                2433.0,
                2434.0,
                2435.0,
                2436.0,
                2437.0,
                2438.0,
                2439.0,
                2440.0,
                2441.0,
                2442.0,
                2443.0,
                2444.0,
                2445.0,
                2446.0,
                2447.0,
                2448.0,
                2449.0,
                2450.0,
                2451.0,
                2452.0,
                2453.0,
                2454.0,
                2455.0,
                2456.0,
                2457.0,
                2458.0,
                2459.0,
                2460.0,
                2461.0,
                2462.0,
                2463.0,
                2464.0,
                2465.0,
                2466.0,
                2467.0,
                2468.0,
                2469.0,
                2470.0,
                2471.0,
                2472.0,
                2473.0,
                2474.0,
                2475.0,
                2476.0,
                2477.0,
                2478.0,
                2479.0,
                2480.0,
                2481.0,
                2482.0,
                2483.0,
                2484.0,
                2485.0,
                2486.0,
                2487.0,
                2488.0,
                2489.0,
                2490.0,
                2491.0,
                2492.0,
                2493.0,
                2494.0,
                2495.0,
                2496.0,
                2497.0,
                2498.0,
                2499.0,
                2500.0,
                2501.0,
                2502.0,
                2503.0,
                2504.0,
                2505.0,
                2506.0,
                2507.0,
                2508.0,
                2509.0,
                2510.0,
                2511.0,
                2512.0,
                2513.0,
                2514.0,
                2515.0,
                2516.0,
                2517.0,
                2518.0,
                2519.0,
                2520.0,
                2521.0,
                2522.0,
                2523.0,
                2524.0,
                2525.0,
                2526.0,
                2527.0,
                2528.0,
                2529.0,
                2530.0,
                2531.0,
                2532.0,
                2533.0,
                2534.0,
                2535.0,
                2536.0,
                2537.0,
                2538.0,
                2539.0,
                2540.0,
                2541.0,
                2542.0,
                2543.0,
                2544.0,
                2545.0,
                2546.0,
                2547.0,
                2548.0,
                2549.0,
                2550.0,
                2551.0,
                2552.0,
                2553.0,
                2554.0,
                2555.0,
                2556.0,
                2557.0,
                2558.0,
                2559.0,
                2560.0,
                2561.0,
                2562.0,
                2563.0,
                2564.0,
                2565.0,
                2566.0,
                2567.0,
                2568.0,
                2569.0,
                2570.0,
                2571.0,
                2572.0,
                2573.0,
                2574.0,
                2575.0,
                2576.0,
                2577.0,
                2578.0,
                2579.0,
                2580.0,
                2581.0,
                2582.0,
                2583.0,
                2584.0,
                2585.0,
                2586.0,
                2587.0,
                2588.0,
                2589.0,
                2590.0,
                2591.0,
                2592.0,
                2593.0,
                2594.0,
                2595.0,
                2596.0,
                2597.0,
                2598.0,
                2599.0,
                2600.0,
                2601.0,
                2602.0,
                2603.0,
                2604.0,
                2605.0,
                2606.0,
                2607.0,
                2608.0,
                2609.0,
                2610.0,
                2611.0,
                2612.0,
                2613.0,
                2614.0,
                2615.0,
                2616.0,
                2617.0,
                2618.0,
                2619.0,
                2620.0,
                2621.0,
                2622.0,
                2623.0,
                2624.0,
                2625.0,
                2626.0,
                2627.0,
                2628.0,
                2629.0,
                2630.0,
                2631.0,
                2632.0,
                2633.0,
                2634.0,
                2635.0,
                2636.0,
                2637.0,
                2638.0,
                2639.0,
                2640.0,
                2641.0,
                2642.0,
                2643.0,
                2644.0,
                2645.0,
                2646.0,
                2647.0,
                2648.0,
                2649.0,
                2650.0,
                2651.0,
                2652.0,
                2653.0,
                2654.0,
                2655.0,
                2656.0,
                2657.0,
                2658.0,
                2659.0,
                2660.0,
                2661.0,
                2662.0,
                2663.0,
                2664.0,
                2665.0,
                2666.0,
                2667.0,
                2668.0,
                2669.0,
                2670.0,
                2671.0,
                2672.0,
                2673.0,
                2674.0,
                2675.0,
                2676.0,
                2677.0,
                2678.0,
                2679.0,
                2680.0,
                2681.0,
                2682.0,
                2683.0,
                2684.0,
                2685.0,
                2686.0,
                2687.0,
                2688.0,
                2689.0,
                2690.0,
                2691.0,
                2692.0,
                2693.0,
                2694.0,
                2695.0,
                2696.0,
                2697.0,
                2698.0,
                2699.0,
                2700.0,
                2701.0,
                2702.0,
                2703.0,
                2704.0,
                2705.0,
                2706.0,
                2707.0,
                2708.0,
                2709.0,
                2710.0,
                2711.0,
                2712.0,
                2713.0,
                2714.0,
                2715.0,
                2716.0,
                2717.0,
                2718.0,
                2719.0,
                2720.0,
                2721.0,
                2722.0,
                2723.0,
                2724.0,
                2725.0,
                2726.0,
                2727.0,
                2728.0,
                2729.0,
                2730.0,
                2731.0,
                2732.0,
                2733.0,
                2734.0,
                2735.0,
                2736.0,
                2737.0,
                2738.0,
                2739.0,
                2740.0,
                2741.0,
                2742.0,
                2743.0,
                2744.0,
                2745.0,
                2746.0,
                2747.0,
                2748.0,
                2749.0,
                2750.0,
                2751.0,
                2752.0,
                2753.0,
                2754.0,
                2755.0,
                2756.0,
                2757.0,
                2758.0,
                2759.0,
                2760.0,
                2761.0,
                2762.0,
                2763.0,
                2764.0,
                2765.0,
                2766.0,
                2767.0,
                2768.0,
                2769.0,
                2770.0,
                2771.0,
                2772.0,
                2773.0,
                2774.0,
                2775.0,
                2776.0,
                2777.0,
                2778.0,
                2779.0,
                2780.0,
                2781.0,
                2782.0,
                2783.0,
                2784.0,
                2785.0,
                2786.0,
                2787.0,
                2788.0,
                2789.0,
                2790.0,
                2791.0,
                2792.0,
                2793.0,
                2794.0,
                2795.0,
                2796.0,
                2797.0,
                2798.0,
                2799.0,
                2800.0,
                2801.0,
                2802.0,
                2803.0,
                2804.0,
                2805.0,
                2806.0,
                2807.0,
                2808.0,
                2809.0,
                2810.0,
                2811.0,
                2812.0,
                2813.0,
                2814.0,
                2815.0,
                2816.0,
                2817.0,
                2818.0,
                2819.0,
                2820.0,
                2821.0,
                2822.0,
                2823.0,
                2824.0,
                2825.0,
                2826.0,
                2827.0,
                2828.0,
                2829.0,
                2831.0,
                2832.0,
                2834.0,
                2835.0,
                2836.0,
                2837.0,
                2839.0,
                2841.0,
                2843.0,
                2844.0,
                2845.0,
                2846.0,
                2847.0,
                2848.0,
                2849.0,
                2850.0,
                2851.0,
                2852.0,
                2853.0,
                2854.0,
                2855.0,
                2856.0,
                2857.0,
                2858.0,
                2860.0,
                2862.0,
                2863.0,
                2864.0,
                2865.0,
                2867.0,
                2868.0,
                2869.0,
                2871.0,
                2872.0,
                2873.0,
                2874.0,
                2878.0,
                2879.0,
                2880.0,
                2882.0,
                2883.0,
                2884.0,
                2889.0,
                2893.0,
                2897.0,
                2899.0,
                2900.0,
                2901.0,
                2907.0,
                2909.0,
                2910.0,
                2913.0,
                2914.0,
                2915.0,
                2920.0,
                2922.0,
                2924.0,
                2925.0,
                2927.0,
                2931.0,
                2933.0,
                2935.0,
                2940.0,
                2943.0,
                2944.0
            ]
        }
    ],
    yAxis: [
        {
            "show": true,
            "scale": false,
            "nameLocation": "end",
            "nameGap": 15,
            "gridIndex": 0,
            "inverse": false,
            "offset": 0,
            "splitNumber": 5,
            "minInterval": 0,
            "splitLine": {
                "show": false,
                "lineStyle": {
                    "show": true,
                    "width": 1,
                    "opacity": 1,
                    "curveness": 0,
                    "type": "solid"
                }
            }
        }
    ],
    title: [
        {
            "text": "平均得分统计📈",
            "padding": 5,
            "itemGap": 10,
            "left": 'center',
            "textStyle": {
                "fontSize": 30,
                "fontFamily": "Fusion Pixel",
            },
        }
    ],
    dataZoom: {
        "show": true,
        "type": "slider",
        "realtime": true,
        "start": 20,
        "end": 80,
        "orient": "horizontal",
        "zoomLock": false
    }

};

        // 使用刚指定的配置项和数据显示图表。
        myChart.setOption(option);
</script>


<p>胜率热力图分析：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">latest_patch = <span class="number">37906</span></span><br><span class="line">joined_1v1 = joined_df[(joined_df.ladder == <span class="string">&#x27;RM_1v1&#x27;</span>) &amp; (joined_df.patch == latest_patch)]</span><br><span class="line">renames = &#123;</span><br><span class="line">    <span class="string">&#x27;token_player&#x27;</span>: <span class="string">&#x27;opponent&#x27;</span>,</span><br><span class="line">    <span class="string">&#x27;civ&#x27;</span> : <span class="string">&#x27;opponent_civ&#x27;</span></span><br><span class="line">&#125;</span><br><span class="line">op_data = joined_1v1[[<span class="string">&#x27;match&#x27;</span>,<span class="string">&#x27;token_player&#x27;</span>,<span class="string">&#x27;civ&#x27;</span>]].rename(columns = renames)</span><br><span class="line">vs_data = pd.merge(joined_1v1,op_data,left_on=<span class="string">&#x27;match&#x27;</span>, right_on=<span class="string">&#x27;match&#x27;</span>)</span><br><span class="line">vs_data = vs_data[vs_data[<span class="string">&#x27;token_player&#x27;</span>]!=vs_data[<span class="string">&#x27;opponent&#x27;</span>]]</span><br><span class="line">vs_data.to_csv(<span class="string">&#x27;heat_data.csv&#x27;</span>)</span><br><span class="line">heat_data = vs_data.pivot_table(values=<span class="string">&#x27;winner&#x27;</span>, index=<span class="string">&#x27;civ&#x27;</span>, columns=<span class="string">&#x27;opponent_civ&#x27;</span>)</span><br><span class="line"><span class="built_in">print</span>(heat_data.head())</span><br><span class="line"></span><br><span class="line">xdata = heat_data.index.to_list()</span><br><span class="line">ydata = xdata</span><br><span class="line"></span><br><span class="line">heat = (</span><br><span class="line">    HeatMap()</span><br><span class="line">    .add_xaxis(xdata)</span><br><span class="line">    .add_yaxis(<span class="string">&#x27;胜率&#x27;</span>,ydata,[[i,j, <span class="number">100</span>*heat_data[xdata[i]][ydata[j]]] <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(xdata)) <span class="keyword">for</span> j <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(ydata))])</span><br><span class="line">    .set_global_opts(</span><br><span class="line">        title_opts=opts.TitleOpts(title=<span class="string">&quot;文明间胜率&quot;</span>,pos_left = <span class="string">&#x27;center&#x27;</span>),</span><br><span class="line">        visualmap_opts=opts.VisualMapOpts(</span><br><span class="line">            pos_left=<span class="string">&#x27;right&#x27;</span>,</span><br><span class="line">            pos_top = <span class="string">&#x27;center&#x27;</span>,</span><br><span class="line">            range_color=[<span class="string">&#x27;#FFA500&#x27;</span>,<span class="string">&#x27;#DC143C&#x27;</span>],</span><br><span class="line">            max_ = <span class="number">70</span>,</span><br><span class="line">            min_= <span class="number">30</span>,</span><br><span class="line">            ),</span><br><span class="line">        legend_opts=opts.LegendOpts(</span><br><span class="line">            is_show=<span class="literal">False</span></span><br><span class="line">        ),</span><br><span class="line">        xaxis_opts=opts.AxisOpts(</span><br><span class="line">            axislabel_opts=&#123;<span class="string">&quot;rotate&quot;</span>:-<span class="number">45</span>,<span class="string">&#x27;interval&#x27;</span>: <span class="number">0</span> &#125;,</span><br><span class="line">        )</span><br><span class="line">    )</span><br><span class="line">)</span><br><span class="line"></span><br><span class="line">heat.render(<span class="string">&#x27;heat_civ.html&#x27;</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">opponent_civ    Aztecs   Berbers   Britons  Bulgarians   Burmese  Byzantines     Celts   Chinese    Cumans  Ethiopians    Franks     Goths      Huns  ...   Malians    Mayans   Mongols  Persians  Portuguese  Saracens     Slavs   Spanish    Tatars   Teutons     Turks  Vietnamese   Vikings</span></span><br><span class="line"><span class="string">civ                                                                                                                                                   ...</span></span><br><span class="line"><span class="string">Aztecs        0.500000  0.519409  0.522204    0.444700  0.535714    0.572115  0.482425  0.553350  0.505618    0.515586  0.457627  0.455416  0.487547  ...  0.425428  0.491753  0.529975  0.521455    0.621993  0.557960  0.453731  0.508088  0.508224  0.443996  0.502899    0.550420  0.431284</span></span><br><span class="line"><span class="string">Berbers       0.480591  0.500000  0.513193    0.567050  0.541935    0.475336  0.449351  0.613027  0.542208    0.506527  0.458333  0.446680  0.473934  ...  0.446927  0.514644  0.545839  0.524510    0.552083  0.533654  0.477612  0.538690  0.574661  0.448387  0.511628    0.552511  0.498778</span></span><br><span class="line"><span class="string">Britons       0.477796  0.486807  0.500000    0.532271  0.573003    0.502203  0.486817  0.525826  0.508761    0.533719  0.469757  0.453132  0.446475  ...  0.492635  0.498131  0.535856  0.497549    0.617647  0.577160  0.503876  0.533037  0.541262  0.527235  0.563725    0.500497  0.501971</span></span><br><span class="line"><span class="string">Bulgarians    0.555300  0.432950  0.467729    0.500000  0.450000    0.571429  0.539232  0.516355  0.534636    0.457413  0.469477  0.502787  0.445667  ...  0.440329  0.480702  0.479428  0.526756    0.518293  0.495385  0.489097  0.485401  0.498452  0.503968  0.542751    0.503817  0.431271</span></span><br><span class="line"><span class="string">Burmese       0.464286  0.458065  0.426997    0.550000  0.500000    0.587571  0.513441  0.420601  0.567708    0.460317  0.536517  0.571134  0.463104  ...  0.570513  0.455405  0.501515  0.495702    0.493976  0.420849  0.569231  0.533708  0.505376  0.543860  0.613445    0.446281  0.494413</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">[5 rows x 35 columns]</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"></span><br></pre></td></tr></table></figure><br><script src="https://cdn.jsdelivr.net/npm/echarts@4.8.0/dist/echarts.min.js"></script>
<div id="echarts5661" style="width: 81%;height: 400px;margin: 0 auto"></div>

<script type="text/javascript">
        // 基于准备好的dom，初始化echarts实例
        var myChart = echarts.init(document.getElementById('echarts5661'));

        // 指定图表的配置项和数据
        var option = {
    "animation": true,
    "animationThreshold": 2000,
    "animationDuration": 1000,
    "animationEasing": "cubicOut",
    "animationDelay": 0,
    "animationDurationUpdate": 300,
    "animationEasingUpdate": "cubicOut",
    "animationDelayUpdate": 0,
    "color": [
        "#c23531",
        "#2f4554",
        "#61a0a8",
        "#d48265",
        "#749f83",
        "#ca8622",
        "#bda29a",
        "#6e7074",
        "#546570",
        "#c4ccd3",
        "#f05b72",
        "#ef5b9c",
        "#f47920",
        "#905a3d",
        "#fab27b",
        "#2a5caa",
        "#444693",
        "#726930",
        "#b2d235",
        "#6d8346",
        "#ac6767",
        "#1d953f",
        "#6950a1",
        "#918597"
    ],
    "series": [
        {
            "type": "heatmap",
            "name": "\u80dc\u7387",
            "data": [
                [
                    0,
                    0,
                    50.0
                ],
                [
                    0,
                    1,
                    48.059149722735675
                ],
                [
                    0,
                    2,
                    47.77960526315789
                ],
                [
                    0,
                    3,
                    55.52995391705069
                ],
                [
                    0,
                    4,
                    46.42857142857143
                ],
                [
                    0,
                    5,
                    42.78846153846153
                ],
                [
                    0,
                    6,
                    51.757469244288224
                ],
                [
                    0,
                    7,
                    44.66501240694789
                ],
                [
                    0,
                    8,
                    49.43820224719101
                ],
                [
                    0,
                    9,
                    48.44144903117102
                ],
                [
                    0,
                    10,
                    54.23728813559322
                ],
                [
                    0,
                    11,
                    54.45840813883902
                ],
                [
                    0,
                    12,
                    51.24528301886792
                ],
                [
                    0,
                    13,
                    54.53277545327755
                ],
                [
                    0,
                    14,
                    41.509433962264154
                ],
                [
                    0,
                    15,
                    46.45161290322581
                ],
                [
                    0,
                    16,
                    50.99750623441397
                ],
                [
                    0,
                    17,
                    46.59340659340659
                ],
                [
                    0,
                    18,
                    44.76439790575916
                ],
                [
                    0,
                    19,
                    48.16082121471343
                ],
                [
                    0,
                    20,
                    48.90829694323144
                ],
                [
                    0,
                    21,
                    48.8
                ],
                [
                    0,
                    22,
                    57.457212713936435
                ],
                [
                    0,
                    23,
                    50.82465277777778
                ],
                [
                    0,
                    24,
                    47.00251889168766
                ],
                [
                    0,
                    25,
                    47.8544776119403
                ],
                [
                    0,
                    26,
                    37.80068728522337
                ],
                [
                    0,
                    27,
                    44.20401854714065
                ],
                [
                    0,
                    28,
                    54.62686567164179
                ],
                [
                    0,
                    29,
                    49.19124643196955
                ],
                [
                    0,
                    30,
                    49.17763157894737
                ],
                [
                    0,
                    31,
                    55.60040363269425
                ],
                [
                    0,
                    32,
                    49.710144927536234
                ],
                [
                    0,
                    33,
                    44.957983193277315
                ],
                [
                    0,
                    34,
                    56.87160940325497
                ],
                [
                    1,
                    0,
                    51.940850277264325
                ],
                [
                    1,
                    1,
                    50.0
                ],
                [
                    1,
                    2,
                    48.68073878627968
                ],
                [
                    1,
                    3,
                    43.29501915708812
                ],
                [
                    1,
                    4,
                    45.806451612903224
                ],
                [
                    1,
                    5,
                    52.46636771300448
                ],
                [
                    1,
                    6,
                    55.064935064935064
                ],
                [
                    1,
                    7,
                    38.69731800766284
                ],
                [
                    1,
                    8,
                    45.77922077922078
                ],
                [
                    1,
                    9,
                    49.34725848563969
                ],
                [
                    1,
                    10,
                    54.166666666666664
                ],
                [
                    1,
                    11,
                    55.33199195171026
                ],
                [
                    1,
                    12,
                    52.60663507109005
                ],
                [
                    1,
                    13,
                    54.066985645933016
                ],
                [
                    1,
                    14,
                    49.696969696969695
                ],
                [
                    1,
                    15,
                    46.835443037974684
                ],
                [
                    1,
                    16,
                    47.043010752688176
                ],
                [
                    1,
                    17,
                    49.32249322493225
                ],
                [
                    1,
                    18,
                    46.715328467153284
                ],
                [
                    1,
                    19,
                    49.863760217983646
                ],
                [
                    1,
                    20,
                    43.333333333333336
                ],
                [
                    1,
                    21,
                    45.28301886792453
                ],
                [
                    1,
                    22,
                    55.3072625698324
                ],
                [
                    1,
                    23,
                    48.53556485355649
                ],
                [
                    1,
                    24,
                    45.41607898448519
                ],
                [
                    1,
                    25,
                    47.549019607843135
                ],
                [
                    1,
                    26,
                    44.79166666666667
                ],
                [
                    1,
                    27,
                    46.63461538461539
                ],
                [
                    1,
                    28,
                    52.23880597014925
                ],
                [
                    1,
                    29,
                    46.13095238095239
                ],
                [
                    1,
                    30,
                    42.53393665158371
                ],
                [
                    1,
                    31,
                    55.16129032258065
                ],
                [
                    1,
                    32,
                    48.837209302325576
                ],
                [
                    1,
                    33,
                    44.74885844748858
                ],
                [
                    1,
                    34,
                    50.12224938875306
                ],
                [
                    2,
                    0,
                    52.2203947368421
                ],
                [
                    2,
                    1,
                    51.31926121372031
                ],
                [
                    2,
                    2,
                    50.0
                ],
                [
                    2,
                    3,
                    46.77290836653387
                ],
                [
                    2,
                    4,
                    42.69972451790633
                ],
                [
                    2,
                    5,
                    49.77973568281938
                ],
                [
                    2,
                    6,
                    51.31832797427652
                ],
                [
                    2,
                    7,
                    47.41744284504657
                ],
                [
                    2,
                    8,
                    49.123904881101375
                ],
                [
                    2,
                    9,
                    46.628131021194605
                ],
                [
                    2,
                    10,
                    53.02430751837196
                ],
                [
                    2,
                    11,
                    54.68682505399568
                ],
                [
                    2,
                    12,
                    55.35248041775457
                ],
                [
                    2,
                    13,
                    54.957805907173
                ],
                [
                    2,
                    14,
                    49.25373134328358
                ],
                [
                    2,
                    15,
                    47.14912280701755
                ],
                [
                    2,
                    16,
                    44.901315789473685
                ],
                [
                    2,
                    17,
                    55.65371024734982
                ],
                [
                    2,
                    18,
                    48.0865224625624
                ],
                [
                    2,
                    19,
                    51.183621241202815
                ],
                [
                    2,
                    20,
                    54.12474849094567
                ],
                [
                    2,
                    21,
                    49.84709480122324
                ],
                [
                    2,
                    22,
                    50.736497545008184
                ],
                [
                    2,
                    23,
                    50.18691588785047
                ],
                [
                    2,
                    24,
                    46.41441441441441
                ],
                [
                    2,
                    25,
                    50.245098039215684
                ],
                [
                    2,
                    26,
                    38.23529411764706
                ],
                [
                    2,
                    27,
                    42.28395061728395
                ],
                [
                    2,
                    28,
                    49.6124031007752
                ],
                [
                    2,
                    29,
                    46.69631512071156
                ],
                [
                    2,
                    30,
                    45.87378640776699
                ],
                [
                    2,
                    31,
                    47.27653631284916
                ],
                [
                    2,
                    32,
                    43.627450980392155
                ],
                [
                    2,
                    33,
                    49.95034756703078
                ],
                [
                    2,
                    34,
                    49.80289093298292
                ],
                [
                    3,
                    0,
                    44.47004608294931
                ],
                [
                    3,
                    1,
                    56.70498084291188
                ],
                [
                    3,
                    2,
                    53.22709163346614
                ],
                [
                    3,
                    3,
                    50.0
                ],
                [
                    3,
                    4,
                    55.00000000000001
                ],
                [
                    3,
                    5,
                    42.857142857142854
                ],
                [
                    3,
                    6,
                    46.07679465776294
                ],
                [
                    3,
                    7,
                    48.36448598130841
                ],
                [
                    3,
                    8,
                    46.53641207815276
                ],
                [
                    3,
                    9,
                    54.25867507886435
                ],
                [
                    3,
                    10,
                    53.05232558139535
                ],
                [
                    3,
                    11,
                    49.72129319955407
                ],
                [
                    3,
                    12,
                    55.43328748280605
                ],
                [
                    3,
                    13,
                    47.179487179487175
                ],
                [
                    3,
                    14,
                    51.291512915129154
                ],
                [
                    3,
                    15,
                    49.43181818181818
                ],
                [
                    3,
                    16,
                    53.49301397205589
                ],
                [
                    3,
                    17,
                    51.31578947368421
                ],
                [
                    3,
                    18,
                    48.458149779735685
                ],
                [
                    3,
                    19,
                    53.98671096345515
                ],
                [
                    3,
                    20,
                    50.99009900990099
                ],
                [
                    3,
                    21,
                    48.74551971326165
                ],
                [
                    3,
                    22,
                    55.96707818930041
                ],
                [
                    3,
                    23,
                    51.92982456140351
                ],
                [
                    3,
                    24,
                    52.05724508050089
                ],
                [
                    3,
                    25,
                    47.324414715719065
                ],
                [
                    3,
                    26,
                    48.170731707317074
                ],
                [
                    3,
                    27,
                    50.46153846153846
                ],
                [
                    3,
                    28,
                    51.09034267912772
                ],
                [
                    3,
                    29,
                    51.45985401459854
                ],
                [
                    3,
                    30,
                    50.15479876160991
                ],
                [
                    3,
                    31,
                    49.60317460317461
                ],
                [
                    3,
                    32,
                    45.72490706319702
                ],
                [
                    3,
                    33,
                    49.61832061068702
                ],
                [
                    3,
                    34,
                    56.87285223367697
                ],
                [
                    4,
                    0,
                    53.57142857142857
                ],
                [
                    4,
                    1,
                    54.19354838709678
                ],
                [
                    4,
                    2,
                    57.30027548209367
                ],
                [
                    4,
                    3,
                    45.0
                ],
                [
                    4,
                    4,
                    50.0
                ],
                [
                    4,
                    5,
                    41.24293785310734
                ],
                [
                    4,
                    6,
                    48.655913978494624
                ],
                [
                    4,
                    7,
                    57.93991416309014
                ],
                [
                    4,
                    8,
                    43.22916666666667
                ],
                [
                    4,
                    9,
                    53.96825396825397
                ],
                [
                    4,
                    10,
                    46.348314606741575
                ],
                [
                    4,
                    11,
                    42.88659793814433
                ],
                [
                    4,
                    12,
                    53.68956743002544
                ],
                [
                    4,
                    13,
                    49.25373134328358
                ],
                [
                    4,
                    14,
                    38.513513513513516
                ],
                [
                    4,
                    15,
                    58.47457627118644
                ],
                [
                    4,
                    16,
                    55.1094890510949
                ],
                [
                    4,
                    17,
                    46.008403361344534
                ],
                [
                    4,
                    18,
                    48.529411764705884
                ],
                [
                    4,
                    19,
                    45.90643274853801
                ],
                [
                    4,
                    20,
                    45.57823129251701
                ],
                [
                    4,
                    21,
                    47.12643678160919
                ],
                [
                    4,
                    22,
                    42.94871794871795
                ],
                [
                    4,
                    23,
                    54.45945945945946
                ],
                [
                    4,
                    24,
                    49.848484848484844
                ],
                [
                    4,
                    25,
                    50.429799426934096
                ],
                [
                    4,
                    26,
                    50.602409638554214
                ],
                [
                    4,
                    27,
                    57.91505791505791
                ],
                [
                    4,
                    28,
                    43.07692307692308
                ],
                [
                    4,
                    29,
                    46.62921348314607
                ],
                [
                    4,
                    30,
                    49.46236559139785
                ],
                [
                    4,
                    31,
                    45.614035087719294
                ],
                [
                    4,
                    32,
                    38.655462184873954
                ],
                [
                    4,
                    33,
                    55.371900826446286
                ],
                [
                    4,
                    34,
                    50.5586592178771
                ],
                [
                    5,
                    0,
                    57.21153846153846
                ],
                [
                    5,
                    1,
                    47.53363228699551
                ],
                [
                    5,
                    2,
                    50.22026431718062
                ],
                [
                    5,
                    3,
                    57.14285714285714
                ],
                [
                    5,
                    4,
                    58.75706214689266
                ],
                [
                    5,
                    5,
                    50.0
                ],
                [
                    5,
                    6,
                    53.96825396825397
                ],
                [
                    5,
                    7,
                    47.744360902255636
                ],
                [
                    5,
                    8,
                    48.831775700934585
                ],
                [
                    5,
                    9,
                    50.0
                ],
                [
                    5,
                    10,
                    55.25525525525525
                ],
                [
                    5,
                    11,
                    56.03715170278638
                ],
                [
                    5,
                    12,
                    55.10204081632652
                ],
                [
                    5,
                    13,
                    53.54330708661418
                ],
                [
                    5,
                    14,
                    48.743718592964825
                ],
                [
                    5,
                    15,
                    51.63934426229508
                ],
                [
                    5,
                    16,
                    60.328638497652584
                ],
                [
                    5,
                    17,
                    50.31982942430704
                ],
                [
                    5,
                    18,
                    46.8421052631579
                ],
                [
                    5,
                    19,
                    56.59955257270693
                ],
                [
                    5,
                    20,
                    53.46534653465347
                ],
                [
                    5,
                    21,
                    49.787234042553195
                ],
                [
                    5,
                    22,
                    54.78723404255319
                ],
                [
                    5,
                    23,
                    53.69458128078818
                ],
                [
                    5,
                    24,
                    50.56890012642224
                ],
                [
                    5,
                    25,
                    52.683896620278325
                ],
                [
                    5,
                    26,
                    49.193548387096776
                ],
                [
                    5,
                    27,
                    41.76706827309237
                ],
                [
                    5,
                    28,
                    55.172413793103445
                ],
                [
                    5,
                    29,
                    50.99009900990099
                ],
                [
                    5,
                    30,
                    48.01762114537445
                ],
                [
                    5,
                    31,
                    54.54545454545454
                ],
                [
                    5,
                    32,
                    55.47703180212014
                ],
                [
                    5,
                    33,
                    49.416342412451364
                ],
                [
                    5,
                    34,
                    56.209150326797385
                ],
                [
                    6,
                    0,
                    48.242530755711776
                ],
                [
                    6,
                    1,
                    44.935064935064936
                ],
                [
                    6,
                    2,
                    48.68167202572347
                ],
                [
                    6,
                    3,
                    53.923205342237054
                ],
                [
                    6,
                    4,
                    51.344086021505376
                ],
                [
                    6,
                    5,
                    46.03174603174603
                ],
                [
                    6,
                    6,
                    50.0
                ],
                [
                    6,
                    7,
                    46.85314685314685
                ],
                [
                    6,
                    8,
                    42.89772727272727
                ],
                [
                    6,
                    9,
                    48.16901408450705
                ],
                [
                    6,
                    10,
                    51.9434628975265
                ],
                [
                    6,
                    11,
                    49.46808510638298
                ],
                [
                    6,
                    12,
                    50.10683760683761
                ],
                [
                    6,
                    13,
                    45.26315789473684
                ],
                [
                    6,
                    14,
                    42.71844660194174
                ],
                [
                    6,
                    15,
                    48.63813229571984
                ],
                [
                    6,
                    16,
                    48.812664907651715
                ],
                [
                    6,
                    17,
                    46.800947867298575
                ],
                [
                    6,
                    18,
                    39.784946236559136
                ],
                [
                    6,
                    19,
                    45.363408521303256
                ],
                [
                    6,
                    20,
                    45.40880503144654
                ],
                [
                    6,
                    21,
                    47.95180722891566
                ],
                [
                    6,
                    22,
                    50.877192982456144
                ],
                [
                    6,
                    23,
                    47.12254570074475
                ],
                [
                    6,
                    24,
                    52.19899062725306
                ],
                [
                    6,
                    25,
                    46.40522875816993
                ],
                [
                    6,
                    26,
                    48.98989898989899
                ],
                [
                    6,
                    27,
                    43.40909090909091
                ],
                [
                    6,
                    28,
                    49.75845410628019
                ],
                [
                    6,
                    29,
                    49.056603773584904
                ],
                [
                    6,
                    30,
                    46.80365296803653
                ],
                [
                    6,
                    31,
                    51.97080291970803
                ],
                [
                    6,
                    32,
                    55.18018018018018
                ],
                [
                    6,
                    33,
                    42.70152505446623
                ],
                [
                    6,
                    34,
                    49.51690821256038
                ],
                [
                    7,
                    0,
                    55.33498759305211
                ],
                [
                    7,
                    1,
                    61.30268199233716
                ],
                [
                    7,
                    2,
                    52.58255715495343
                ],
                [
                    7,
                    3,
                    51.63551401869159
                ],
                [
                    7,
                    4,
                    42.06008583690987
                ],
                [
                    7,
                    5,
                    52.255639097744364
                ],
                [
                    7,
                    6,
                    53.14685314685315
                ],
                [
                    7,
                    7,
                    50.0
                ],
                [
                    7,
                    8,
                    48.82226980728051
                ],
                [
                    7,
                    9,
                    46.470588235294116
                ],
                [
                    7,
                    10,
                    56.559513466550825
                ],
                [
                    7,
                    11,
                    56.22435020519836
                ],
                [
                    7,
                    12,
                    53.57142857142857
                ],
                [
                    7,
                    13,
                    47.04225352112676
                ],
                [
                    7,
                    14,
                    52.44444444444445
                ],
                [
                    7,
                    15,
                    48.19277108433735
                ],
                [
                    7,
                    16,
                    54.502369668246445
                ],
                [
                    7,
                    17,
                    55.39823008849557
                ],
                [
                    7,
                    18,
                    54.4973544973545
                ],
                [
                    7,
                    19,
                    51.903807615230455
                ],
                [
                    7,
                    20,
                    56.57894736842105
                ],
                [
                    7,
                    21,
                    47.24770642201835
                ],
                [
                    7,
                    22,
                    48.41628959276018
                ],
                [
                    7,
                    23,
                    53.059273422562136
                ],
                [
                    7,
                    24,
                    50.34013605442177
                ],
                [
                    7,
                    25,
                    53.94736842105263
                ],
                [
                    7,
                    26,
                    38.46153846153847
                ],
                [
                    7,
                    27,
                    56.09756097560976
                ],
                [
                    7,
                    28,
                    51.15511551155115
                ],
                [
                    7,
                    29,
                    53.74449339207048
                ],
                [
                    7,
                    30,
                    45.80152671755725
                ],
                [
                    7,
                    31,
                    51.13924050632911
                ],
                [
                    7,
                    32,
                    51.37254901960784
                ],
                [
                    7,
                    33,
                    50.71633237822349
                ],
                [
                    7,
                    34,
                    52.307692307692314
                ],
                [
                    8,
                    0,
                    50.56179775280899
                ],
                [
                    8,
                    1,
                    54.22077922077923
                ],
                [
                    8,
                    2,
                    50.876095118898625
                ],
                [
                    8,
                    3,
                    53.46358792184724
                ],
                [
                    8,
                    4,
                    56.770833333333336
                ],
                [
                    8,
                    5,
                    51.16822429906542
                ],
                [
                    8,
                    6,
                    57.10227272727273
                ],
                [
                    8,
                    7,
                    51.17773019271949
                ],
                [
                    8,
                    8,
                    50.0
                ],
                [
                    8,
                    9,
                    51.21951219512195
                ],
                [
                    8,
                    10,
                    55.700934579439256
                ],
                [
                    8,
                    11,
                    55.56561085972851
                ],
                [
                    8,
                    12,
                    53.789731051344745
                ],
                [
                    8,
                    13,
                    58.25471698113207
                ],
                [
                    8,
                    14,
                    56.04026845637584
                ],
                [
                    8,
                    15,
                    52.0
                ],
                [
                    8,
                    16,
                    53.38208409506399
                ],
                [
                    8,
                    17,
                    51.78197064989518
                ],
                [
                    8,
                    18,
                    50.68027210884354
                ],
                [
                    8,
                    19,
                    56.101190476190474
                ],
                [
                    8,
                    20,
                    50.07153075822603
                ],
                [
                    8,
                    21,
                    52.72206303724928
                ],
                [
                    8,
                    22,
                    49.64028776978417
                ],
                [
                    8,
                    23,
                    51.80279617365711
                ],
                [
                    8,
                    24,
                    48.379254457050244
                ],
                [
                    8,
                    25,
                    51.051051051051054
                ],
                [
                    8,
                    26,
                    40.963855421686745
                ],
                [
                    8,
                    27,
                    50.89686098654709
                ],
                [
                    8,
                    28,
                    53.80952380952381
                ],
                [
                    8,
                    29,
                    52.16819973718791
                ],
                [
                    8,
                    30,
                    46.264367816091955
                ],
                [
                    8,
                    31,
                    53.27635327635327
                ],
                [
                    8,
                    32,
                    48.927038626609445
                ],
                [
                    8,
                    33,
                    50.10570824524313
                ],
                [
                    8,
                    34,
                    52.85505124450952
                ],
                [
                    9,
                    0,
                    51.558550968828975
                ],
                [
                    9,
                    1,
                    50.65274151436031
                ],
                [
                    9,
                    2,
                    53.371868978805395
                ],
                [
                    9,
                    3,
                    45.74132492113564
                ],
                [
                    9,
                    4,
                    46.03174603174603
                ],
                [
                    9,
                    5,
                    50.0
                ],
                [
                    9,
                    6,
                    51.83098591549295
                ],
                [
                    9,
                    7,
                    53.529411764705884
                ],
                [
                    9,
                    8,
                    48.78048780487805
                ],
                [
                    9,
                    9,
                    50.0
                ],
                [
                    9,
                    10,
                    52.429378531073446
                ],
                [
                    9,
                    11,
                    49.904761904761905
                ],
                [
                    9,
                    12,
                    52.21621621621622
                ],
                [
                    9,
                    13,
                    48.51063829787234
                ],
                [
                    9,
                    14,
                    50.81967213114754
                ],
                [
                    9,
                    15,
                    46.92982456140351
                ],
                [
                    9,
                    16,
                    51.87074829931972
                ],
                [
                    9,
                    17,
                    53.1628532974428
                ],
                [
                    9,
                    18,
                    47.63779527559055
                ],
                [
                    9,
                    19,
                    52.710027100271006
                ],
                [
                    9,
                    20,
                    51.26658624849216
                ],
                [
                    9,
                    21,
                    51.82724252491694
                ],
                [
                    9,
                    22,
                    50.73529411764706
                ],
                [
                    9,
                    23,
                    53.06649451258877
                ],
                [
                    9,
                    24,
                    50.835148874364556
                ],
                [
                    9,
                    25,
                    52.14646464646465
                ],
                [
                    9,
                    26,
                    48.148148148148145
                ],
                [
                    9,
                    27,
                    46.92982456140351
                ],
                [
                    9,
                    28,
                    55.75620767494357
                ],
                [
                    9,
                    29,
                    51.674641148325364
                ],
                [
                    9,
                    30,
                    49.40047961630695
                ],
                [
                    9,
                    31,
                    54.372019077901435
                ],
                [
                    9,
                    32,
                    47.214854111405835
                ],
                [
                    9,
                    33,
                    52.370689655172406
                ],
                [
                    9,
                    34,
                    52.431011826544015
                ],
                [
                    10,
                    0,
                    45.76271186440678
                ],
                [
                    10,
                    1,
                    45.83333333333333
                ],
                [
                    10,
                    2,
                    46.97569248162804
                ],
                [
                    10,
                    3,
                    46.94767441860465
                ],
                [
                    10,
                    4,
                    53.65168539325843
                ],
                [
                    10,
                    5,
                    44.74474474474475
                ],
                [
                    10,
                    6,
                    48.0565371024735
                ],
                [
                    10,
                    7,
                    43.440486533449175
                ],
                [
                    10,
                    8,
                    44.299065420560744
                ],
                [
                    10,
                    9,
                    47.570621468926554
                ],
                [
                    10,
                    10,
                    50.0
                ],
                [
                    10,
                    11,
                    49.76887519260401
                ],
                [
                    10,
                    12,
                    51.34649910233393
                ],
                [
                    10,
                    13,
                    50.697674418604656
                ],
                [
                    10,
                    14,
                    50.34770514603616
                ],
                [
                    10,
                    15,
                    44.8405253283302
                ],
                [
                    10,
                    16,
                    47.2463768115942
                ],
                [
                    10,
                    17,
                    44.237695078031216
                ],
                [
                    10,
                    18,
                    38.18181818181819
                ],
                [
                    10,
                    19,
                    48.66279069767442
                ],
                [
                    10,
                    20,
                    46.04473540643753
                ],
                [
                    10,
                    21,
                    46.60894660894661
                ],
                [
                    10,
                    22,
                    45.875542691751086
                ],
                [
                    10,
                    23,
                    44.8729446935725
                ],
                [
                    10,
                    24,
                    43.49370358411366
                ],
                [
                    10,
                    25,
                    46.54605263157895
                ],
                [
                    10,
                    26,
                    42.06730769230769
                ],
                [
                    10,
                    27,
                    45.8546571136131
                ],
                [
                    10,
                    28,
                    45.56962025316456
                ],
                [
                    10,
                    29,
                    47.02341137123746
                ],
                [
                    10,
                    30,
                    42.73772204806687
                ],
                [
                    10,
                    31,
                    50.82617316589557
                ],
                [
                    10,
                    32,
                    43.27272727272727
                ],
                [
                    10,
                    33,
                    42.709313264346186
                ],
                [
                    10,
                    34,
                    49.51807228915663
                ],
                [
                    11,
                    0,
                    45.54159186116098
                ],
                [
                    11,
                    1,
                    44.668008048289735
                ],
                [
                    11,
                    2,
                    45.31317494600432
                ],
                [
                    11,
                    3,
                    50.278706800445924
                ],
                [
                    11,
                    4,
                    57.113402061855666
                ],
                [
                    11,
                    5,
                    43.962848297213625
                ],
                [
                    11,
                    6,
                    50.53191489361703
                ],
                [
                    11,
                    7,
                    43.77564979480164
                ],
                [
                    11,
                    8,
                    44.43438914027149
                ],
                [
                    11,
                    9,
                    50.095238095238095
                ],
                [
                    11,
                    10,
                    50.231124807396
                ],
                [
                    11,
                    11,
                    50.0
                ],
                [
                    11,
                    12,
                    47.1608832807571
                ],
                [
                    11,
                    13,
                    49.30662557781202
                ],
                [
                    11,
                    14,
                    37.77292576419214
                ],
                [
                    11,
                    15,
                    39.726027397260275
                ],
                [
                    11,
                    16,
                    55.18394648829431
                ],
                [
                    11,
                    17,
                    42.99363057324841
                ],
                [
                    11,
                    18,
                    39.37947494033413
                ],
                [
                    11,
                    19,
                    43.54275741710297
                ],
                [
                    11,
                    20,
                    43.00970873786408
                ],
                [
                    11,
                    21,
                    45.744680851063826
                ],
                [
                    11,
                    22,
                    50.61425061425061
                ],
                [
                    11,
                    23,
                    42.857142857142854
                ],
                [
                    11,
                    24,
                    42.21052631578948
                ],
                [
                    11,
                    25,
                    41.27957931638913
                ],
                [
                    11,
                    26,
                    43.72623574144487
                ],
                [
                    11,
                    27,
                    47.51655629139073
                ],
                [
                    11,
                    28,
                    47.25274725274725
                ],
                [
                    11,
                    29,
                    50.046772684752106
                ],
                [
                    11,
                    30,
                    42.281879194630875
                ],
                [
                    11,
                    31,
                    54.39503619441572
                ],
                [
                    11,
                    32,
                    53.8860103626943
                ],
                [
                    11,
                    33,
                    43.57864357864358
                ],
                [
                    11,
                    34,
                    56.238185255198495
                ],
                [
                    12,
                    0,
                    48.75471698113208
                ],
                [
                    12,
                    1,
                    47.39336492890995
                ],
                [
                    12,
                    2,
                    44.64751958224543
                ],
                [
                    12,
                    3,
                    44.56671251719395
                ],
                [
                    12,
                    4,
                    46.31043256997455
                ],
                [
                    12,
                    5,
                    44.89795918367347
                ],
                [
                    12,
                    6,
                    49.89316239316239
                ],
                [
                    12,
                    7,
                    46.42857142857143
                ],
                [
                    12,
                    8,
                    46.21026894865526
                ],
                [
                    12,
                    9,
                    47.78378378378378
                ],
                [
                    12,
                    10,
                    48.65350089766607
                ],
                [
                    12,
                    11,
                    52.83911671924291
                ],
                [
                    12,
                    12,
                    50.0
                ],
                [
                    12,
                    13,
                    49.91482112436116
                ],
                [
                    12,
                    14,
                    49.49238578680203
                ],
                [
                    12,
                    15,
                    41.23376623376623
                ],
                [
                    12,
                    16,
                    44.827586206896555
                ],
                [
                    12,
                    17,
                    45.13089005235602
                ],
                [
                    12,
                    18,
                    47.86585365853659
                ],
                [
                    12,
                    19,
                    47.60448521916412
                ],
                [
                    12,
                    20,
                    48.24561403508772
                ],
                [
                    12,
                    21,
                    43.69369369369369
                ],
                [
                    12,
                    22,
                    45.378151260504204
                ],
                [
                    12,
                    23,
                    46.78298800436205
                ],
                [
                    12,
                    24,
                    45.24259609325772
                ],
                [
                    12,
                    25,
                    48.93822393822394
                ],
                [
                    12,
                    26,
                    39.726027397260275
                ],
                [
                    12,
                    27,
                    41.338582677165356
                ],
                [
                    12,
                    28,
                    47.60914760914761
                ],
                [
                    12,
                    29,
                    45.5820476858345
                ],
                [
                    12,
                    30,
                    43.7037037037037
                ],
                [
                    12,
                    31,
                    48.06924101198402
                ],
                [
                    12,
                    32,
                    44.18604651162791
                ],
                [
                    12,
                    33,
                    43.47826086956522
                ],
                [
                    12,
                    34,
                    46.99286442405708
                ],
                [
                    13,
                    0,
                    45.467224546722456
                ],
                [
                    13,
                    1,
                    45.933014354066984
                ],
                [
                    13,
                    2,
                    45.042194092827
                ],
                [
                    13,
                    3,
                    52.820512820512825
                ],
                [
                    13,
                    4,
                    50.74626865671642
                ],
                [
                    13,
                    5,
                    46.45669291338583
                ],
                [
                    13,
                    6,
                    54.736842105263165
                ],
                [
                    13,
                    7,
                    52.95774647887323
                ],
                [
                    13,
                    8,
                    41.74528301886792
                ],
                [
                    13,
                    9,
                    51.48936170212765
                ],
                [
                    13,
                    10,
                    49.30232558139535
                ],
                [
                    13,
                    11,
                    50.693374422187986
                ],
                [
                    13,
                    12,
                    50.08517887563884
                ],
                [
                    13,
                    13,
                    50.0
                ],
                [
                    13,
                    14,
                    46.231155778894475
                ],
                [
                    13,
                    15,
                    44.44444444444444
                ],
                [
                    13,
                    16,
                    50.46296296296296
                ],
                [
                    13,
                    17,
                    46.71052631578947
                ],
                [
                    13,
                    18,
                    43.85026737967914
                ],
                [
                    13,
                    19,
                    46.924829157175395
                ],
                [
                    13,
                    20,
                    49.794238683127574
                ],
                [
                    13,
                    21,
                    48.756218905472636
                ],
                [
                    13,
                    22,
                    50.526315789473685
                ],
                [
                    13,
                    23,
                    46.53465346534654
                ],
                [
                    13,
                    24,
                    45.46511627906977
                ],
                [
                    13,
                    25,
                    46.10778443113773
                ],
                [
                    13,
                    26,
                    44.66019417475729
                ],
                [
                    13,
                    27,
                    48.797250859106526
                ],
                [
                    13,
                    28,
                    49.645390070921984
                ],
                [
                    13,
                    29,
                    49.28571428571429
                ],
                [
                    13,
                    30,
                    39.71291866028708
                ],
                [
                    13,
                    31,
                    49.26108374384236
                ],
                [
                    13,
                    32,
                    50.43859649122807
                ],
                [
                    13,
                    33,
                    44.73684210526316
                ],
                [
                    13,
                    34,
                    51.20967741935484
                ],
                [
                    14,
                    0,
                    58.490566037735846
                ],
                [
                    14,
                    1,
                    50.303030303030305
                ],
                [
                    14,
                    2,
                    50.74626865671642
                ],
                [
                    14,
                    3,
                    48.708487084870846
                ],
                [
                    14,
                    4,
                    61.48648648648649
                ],
                [
                    14,
                    5,
                    51.256281407035175
                ],
                [
                    14,
                    6,
                    57.28155339805825
                ],
                [
                    14,
                    7,
                    47.55555555555556
                ],
                [
                    14,
                    8,
                    43.95973154362416
                ],
                [
                    14,
                    9,
                    49.18032786885246
                ],
                [
                    14,
                    10,
                    49.65229485396384
                ],
                [
                    14,
                    11,
                    62.227074235807855
                ],
                [
                    14,
                    12,
                    50.50761421319797
                ],
                [
                    14,
                    13,
                    53.768844221105525
                ],
                [
                    14,
                    14,
                    50.0
                ],
                [
                    14,
                    15,
                    59.79381443298969
                ],
                [
                    14,
                    16,
                    55.72519083969466
                ],
                [
                    14,
                    17,
                    50.473186119873816
                ],
                [
                    14,
                    18,
                    50.0
                ],
                [
                    14,
                    19,
                    50.306748466257666
                ],
                [
                    14,
                    20,
                    47.96511627906977
                ],
                [
                    14,
                    21,
                    45.16129032258064
                ],
                [
                    14,
                    22,
                    51.127819548872175
                ],
                [
                    14,
                    23,
                    58.45648604269294
                ],
                [
                    14,
                    24,
                    44.09722222222222
                ],
                [
                    14,
                    25,
                    41.69184290030212
                ],
                [
                    14,
                    26,
                    36.36363636363637
                ],
                [
                    14,
                    27,
                    47.73869346733669
                ],
                [
                    14,
                    28,
                    52.84090909090909
                ],
                [
                    14,
                    29,
                    43.79310344827586
                ],
                [
                    14,
                    30,
                    46.285714285714285
                ],
                [
                    14,
                    31,
                    50.0
                ],
                [
                    14,
                    32,
                    50.943396226415096
                ],
                [
                    14,
                    33,
                    44.66019417475729
                ],
                [
                    14,
                    34,
                    51.76470588235295
                ],
                [
                    15,
                    0,
                    53.5483870967742
                ],
                [
                    15,
                    1,
                    53.16455696202531
                ],
                [
                    15,
                    2,
                    52.85087719298246
                ],
                [
                    15,
                    3,
                    50.56818181818182
                ],
                [
                    15,
                    4,
                    41.52542372881356
                ],
                [
                    15,
                    5,
                    48.36065573770492
                ],
                [
                    15,
                    6,
                    51.36186770428015
                ],
                [
                    15,
                    7,
                    51.80722891566265
                ],
                [
                    15,
                    8,
                    48.0
                ],
                [
                    15,
                    9,
                    53.07017543859649
                ],
                [
                    15,
                    10,
                    55.1594746716698
                ],
                [
                    15,
                    11,
                    60.273972602739725
                ],
                [
                    15,
                    12,
                    58.76623376623377
                ],
                [
                    15,
                    13,
                    55.55555555555556
                ],
                [
                    15,
                    14,
                    40.20618556701031
                ],
                [
                    15,
                    15,
                    50.0
                ],
                [
                    15,
                    16,
                    46.68008048289739
                ],
                [
                    15,
                    17,
                    50.79365079365079
                ],
                [
                    15,
                    18,
                    52.352941176470594
                ],
                [
                    15,
                    19,
                    55.70776255707762
                ],
                [
                    15,
                    20,
                    60.526315789473685
                ],
                [
                    15,
                    21,
                    49.80988593155893
                ],
                [
                    15,
                    22,
                    52.44755244755245
                ],
                [
                    15,
                    23,
                    51.07913669064749
                ],
                [
                    15,
                    24,
                    53.086419753086425
                ],
                [
                    15,
                    25,
                    53.470437017994854
                ],
                [
                    15,
                    26,
                    40.119760479041915
                ],
                [
                    15,
                    27,
                    50.77720207253886
                ],
                [
                    15,
                    28,
                    53.84615384615385
                ],
                [
                    15,
                    29,
                    50.403225806451616
                ],
                [
                    15,
                    30,
                    50.38167938931297
                ],
                [
                    15,
                    31,
                    50.282485875706215
                ],
                [
                    15,
                    32,
                    51.06382978723404
                ],
                [
                    15,
                    33,
                    47.55244755244755
                ],
                [
                    15,
                    34,
                    48.7468671679198
                ],
                [
                    16,
                    0,
                    49.00249376558604
                ],
                [
                    16,
                    1,
                    52.956989247311824
                ],
                [
                    16,
                    2,
                    55.098684210526315
                ],
                [
                    16,
                    3,
                    46.506986027944116
                ],
                [
                    16,
                    4,
                    44.89051094890511
                ],
                [
                    16,
                    5,
                    39.671361502347416
                ],
                [
                    16,
                    6,
                    51.187335092348285
                ],
                [
                    16,
                    7,
                    45.497630331753555
                ],
                [
                    16,
                    8,
                    46.61791590493601
                ],
                [
                    16,
                    9,
                    48.12925170068027
                ],
                [
                    16,
                    10,
                    52.7536231884058
                ],
                [
                    16,
                    11,
                    44.81605351170568
                ],
                [
                    16,
                    12,
                    55.172413793103445
                ],
                [
                    16,
                    13,
                    49.53703703703704
                ],
                [
                    16,
                    14,
                    44.274809160305345
                ],
                [
                    16,
                    15,
                    53.31991951710262
                ],
                [
                    16,
                    16,
                    50.0
                ],
                [
                    16,
                    17,
                    47.94069192751236
                ],
                [
                    16,
                    18,
                    45.97315436241611
                ],
                [
                    16,
                    19,
                    48.57142857142857
                ],
                [
                    16,
                    20,
                    49.8502994011976
                ],
                [
                    16,
                    21,
                    47.31543624161073
                ],
                [
                    16,
                    22,
                    48.10126582278481
                ],
                [
                    16,
                    23,
                    52.05992509363296
                ],
                [
                    16,
                    24,
                    49.47735191637631
                ],
                [
                    16,
                    25,
                    54.131054131054135
                ],
                [
                    16,
                    26,
                    45.63106796116505
                ],
                [
                    16,
                    27,
                    46.7866323907455
                ],
                [
                    16,
                    28,
                    50.92592592592593
                ],
                [
                    16,
                    29,
                    50.08576329331046
                ],
                [
                    16,
                    30,
                    50.841750841750844
                ],
                [
                    16,
                    31,
                    45.667870036101085
                ],
                [
                    16,
                    32,
                    50.16949152542372
                ],
                [
                    16,
                    33,
                    49.85507246376812
                ],
                [
                    16,
                    34,
                    50.177935943060504
                ],
                [
                    17,
                    0,
                    53.40659340659341
                ],
                [
                    17,
                    1,
                    50.67750677506775
                ],
                [
                    17,
                    2,
                    44.34628975265017
                ],
                [
                    17,
                    3,
                    48.68421052631579
                ],
                [
                    17,
                    4,
                    53.99159663865546
                ],
                [
                    17,
                    5,
                    49.68017057569296
                ],
                [
                    17,
                    6,
                    53.19905213270142
                ],
                [
                    17,
                    7,
                    44.60176991150443
                ],
                [
                    17,
                    8,
                    48.21802935010482
                ],
                [
                    17,
                    9,
                    46.837146702557206
                ],
                [
                    17,
                    10,
                    55.762304921968784
                ],
                [
                    17,
                    11,
                    57.00636942675159
                ],
                [
                    17,
                    12,
                    54.86910994764398
                ],
                [
                    17,
                    13,
                    53.289473684210535
                ],
                [
                    17,
                    14,
                    49.52681388012618
                ],
                [
                    17,
                    15,
                    49.2063492063492
                ],
                [
                    17,
                    16,
                    52.05930807248764
                ],
                [
                    17,
                    17,
                    50.0
                ],
                [
                    17,
                    18,
                    47.5
                ],
                [
                    17,
                    19,
                    52.51798561151079
                ],
                [
                    17,
                    20,
                    49.53020134228188
                ],
                [
                    17,
                    21,
                    44.87804878048781
                ],
                [
                    17,
                    22,
                    44.84848484848485
                ],
                [
                    17,
                    23,
                    48.16625916870416
                ],
                [
                    17,
                    24,
                    47.60341431385424
                ],
                [
                    17,
                    25,
                    47.93814432989691
                ],
                [
                    17,
                    26,
                    41.365461847389554
                ],
                [
                    17,
                    27,
                    43.96887159533074
                ],
                [
                    17,
                    28,
                    53.680430879712745
                ],
                [
                    17,
                    29,
                    52.50917992656059
                ],
                [
                    17,
                    30,
                    47.3922902494331
                ],
                [
                    17,
                    31,
                    53.70813397129187
                ],
                [
                    17,
                    32,
                    49.84177215189873
                ],
                [
                    17,
                    33,
                    43.258426966292134
                ],
                [
                    17,
                    34,
                    47.984886649874056
                ],
                [
                    18,
                    0,
                    55.235602094240846
                ],
                [
                    18,
                    1,
                    53.284671532846716
                ],
                [
                    18,
                    2,
                    51.9134775374376
                ],
                [
                    18,
                    3,
                    51.541850220264315
                ],
                [
                    18,
                    4,
                    51.470588235294116
                ],
                [
                    18,
                    5,
                    53.1578947368421
                ],
                [
                    18,
                    6,
                    60.215053763440864
                ],
                [
                    18,
                    7,
                    45.5026455026455
                ],
                [
                    18,
                    8,
                    49.31972789115646
                ],
                [
                    18,
                    9,
                    52.362204724409445
                ],
                [
                    18,
                    10,
                    61.81818181818181
                ],
                [
                    18,
                    11,
                    60.62052505966587
                ],
                [
                    18,
                    12,
                    52.13414634146341
                ],
                [
                    18,
                    13,
                    56.14973262032086
                ],
                [
                    18,
                    14,
                    50.0
                ],
                [
                    18,
                    15,
                    47.647058823529406
                ],
                [
                    18,
                    16,
                    54.0268456375839
                ],
                [
                    18,
                    17,
                    52.5
                ],
                [
                    18,
                    18,
                    50.0
                ],
                [
                    18,
                    19,
                    58.984375
                ],
                [
                    18,
                    20,
                    53.84615384615385
                ],
                [
                    18,
                    21,
                    59.89010989010989
                ],
                [
                    18,
                    22,
                    52.67857142857143
                ],
                [
                    18,
                    23,
                    59.54631379962193
                ],
                [
                    18,
                    24,
                    55.919854280510016
                ],
                [
                    18,
                    25,
                    54.492753623188406
                ],
                [
                    18,
                    26,
                    44.66019417475729
                ],
                [
                    18,
                    27,
                    51.578947368421055
                ],
                [
                    18,
                    28,
                    64.77987421383648
                ],
                [
                    18,
                    29,
                    53.597122302158276
                ],
                [
                    18,
                    30,
                    49.333333333333336
                ],
                [
                    18,
                    31,
                    59.25925925925925
                ],
                [
                    18,
                    32,
                    52.89855072463768
                ],
                [
                    18,
                    33,
                    46.42857142857143
                ],
                [
                    18,
                    34,
                    58.139534883720934
                ],
                [
                    19,
                    0,
                    51.83917878528656
                ],
                [
                    19,
                    1,
                    50.13623978201635
                ],
                [
                    19,
                    2,
                    48.816378758797185
                ],
                [
                    19,
                    3,
                    46.013289036544855
                ],
                [
                    19,
                    4,
                    54.09356725146199
                ],
                [
                    19,
                    5,
                    43.40044742729307
                ],
                [
                    19,
                    6,
                    54.63659147869674
                ],
                [
                    19,
                    7,
                    48.09619238476954
                ],
                [
                    19,
                    8,
                    43.898809523809526
                ],
                [
                    19,
                    9,
                    47.289972899729
                ],
                [
                    19,
                    10,
                    51.33720930232558
                ],
                [
                    19,
                    11,
                    56.45724258289704
                ],
                [
                    19,
                    12,
                    52.39551478083588
                ],
                [
                    19,
                    13,
                    53.075170842824605
                ],
                [
                    19,
                    14,
                    49.693251533742334
                ],
                [
                    19,
                    15,
                    44.29223744292237
                ],
                [
                    19,
                    16,
                    51.42857142857142
                ],
                [
                    19,
                    17,
                    47.482014388489205
                ],
                [
                    19,
                    18,
                    41.015625
                ],
                [
                    19,
                    19,
                    50.0
                ],
                [
                    19,
                    20,
                    47.14475431606906
                ],
                [
                    19,
                    21,
                    47.486033519553075
                ],
                [
                    19,
                    22,
                    50.0
                ],
                [
                    19,
                    23,
                    51.664447403462056
                ],
                [
                    19,
                    24,
                    45.616535994297934
                ],
                [
                    19,
                    25,
                    48.82903981264637
                ],
                [
                    19,
                    26,
                    39.59390862944163
                ],
                [
                    19,
                    27,
                    44.44444444444444
                ],
                [
                    19,
                    28,
                    51.78571428571429
                ],
                [
                    19,
                    29,
                    45.63253012048193
                ],
                [
                    19,
                    30,
                    42.364532019704434
                ],
                [
                    19,
                    31,
                    52.40963855421686
                ],
                [
                    19,
                    32,
                    47.46192893401015
                ],
                [
                    19,
                    33,
                    43.46938775510204
                ],
                [
                    19,
                    34,
                    52.156862745098046
                ],
                [
                    20,
                    0,
                    51.09170305676856
                ],
                [
                    20,
                    1,
                    56.666666666666664
                ],
                [
                    20,
                    2,
                    45.87525150905433
                ],
                [
                    20,
                    3,
                    49.00990099009901
                ],
                [
                    20,
                    4,
                    54.421768707483
                ],
                [
                    20,
                    5,
                    46.53465346534654
                ],
                [
                    20,
                    6,
                    54.59119496855346
                ],
                [
                    20,
                    7,
                    43.42105263157895
                ],
                [
                    20,
                    8,
                    49.92846924177397
                ],
                [
                    20,
                    9,
                    48.73341375150784
                ],
                [
                    20,
                    10,
                    53.95526459356247
                ],
                [
                    20,
                    11,
                    56.99029126213592
                ],
                [
                    20,
                    12,
                    51.75438596491229
                ],
                [
                    20,
                    13,
                    50.20576131687243
                ],
                [
                    20,
                    14,
                    52.03488372093024
                ],
                [
                    20,
                    15,
                    39.473684210526315
                ],
                [
                    20,
                    16,
                    50.1497005988024
                ],
                [
                    20,
                    17,
                    50.46979865771812
                ],
                [
                    20,
                    18,
                    46.15384615384615
                ],
                [
                    20,
                    19,
                    52.85524568393094
                ],
                [
                    20,
                    20,
                    50.0
                ],
                [
                    20,
                    21,
                    44.61077844311377
                ],
                [
                    20,
                    22,
                    53.205128205128204
                ],
                [
                    20,
                    23,
                    47.983870967741936
                ],
                [
                    20,
                    24,
                    45.63520227111427
                ],
                [
                    20,
                    25,
                    49.601063829787236
                ],
                [
                    20,
                    26,
                    41.43646408839779
                ],
                [
                    20,
                    27,
                    45.94594594594595
                ],
                [
                    20,
                    28,
                    51.87793427230047
                ],
                [
                    20,
                    29,
                    48.23529411764706
                ],
                [
                    20,
                    30,
                    46.81724845995893
                ],
                [
                    20,
                    31,
                    52.04855842185129
                ],
                [
                    20,
                    32,
                    51.245551601423486
                ],
                [
                    20,
                    33,
                    47.347740667976424
                ],
                [
                    20,
                    34,
                    50.847457627118644
                ],
                [
                    21,
                    0,
                    51.2
                ],
                [
                    21,
                    1,
                    54.71698113207547
                ],
                [
                    21,
                    2,
                    50.15290519877675
                ],
                [
                    21,
                    3,
                    51.25448028673835
                ],
                [
                    21,
                    4,
                    52.87356321839081
                ],
                [
                    21,
                    5,
                    50.212765957446805
                ],
                [
                    21,
                    6,
                    52.04819277108433
                ],
                [
                    21,
                    7,
                    52.752293577981646
                ],
                [
                    21,
                    8,
                    47.277936962750715
                ],
                [
                    21,
                    9,
                    48.17275747508305
                ],
                [
                    21,
                    10,
                    53.39105339105339
                ],
                [
                    21,
                    11,
                    54.25531914893617
                ],
                [
                    21,
                    12,
                    56.30630630630631
                ],
                [
                    21,
                    13,
                    51.243781094527364
                ],
                [
                    21,
                    14,
                    54.83870967741935
                ],
                [
                    21,
                    15,
                    50.19011406844106
                ],
                [
                    21,
                    16,
                    52.68456375838926
                ],
                [
                    21,
                    17,
                    55.1219512195122
                ],
                [
                    21,
                    18,
                    40.10989010989011
                ],
                [
                    21,
                    19,
                    52.513966480446925
                ],
                [
                    21,
                    20,
                    55.38922155688623
                ],
                [
                    21,
                    21,
                    50.0
                ],
                [
                    21,
                    22,
                    56.75675675675676
                ],
                [
                    21,
                    23,
                    50.0
                ],
                [
                    21,
                    24,
                    51.26582278481012
                ],
                [
                    21,
                    25,
                    56.16438356164384
                ],
                [
                    21,
                    26,
                    49.34210526315789
                ],
                [
                    21,
                    27,
                    51.674641148325364
                ],
                [
                    21,
                    28,
                    54.891304347826086
                ],
                [
                    21,
                    29,
                    53.776435045317214
                ],
                [
                    21,
                    30,
                    51.955307262569825
                ],
                [
                    21,
                    31,
                    47.58842443729904
                ],
                [
                    21,
                    32,
                    40.77669902912621
                ],
                [
                    21,
                    33,
                    48.803827751196174
                ],
                [
                    21,
                    34,
                    52.32198142414861
                ],
                [
                    22,
                    0,
                    42.54278728606357
                ],
                [
                    22,
                    1,
                    44.6927374301676
                ],
                [
                    22,
                    2,
                    49.263502454991816
                ],
                [
                    22,
                    3,
                    44.03292181069959
                ],
                [
                    22,
                    4,
                    57.05128205128205
                ],
                [
                    22,
                    5,
                    45.21276595744681
                ],
                [
                    22,
                    6,
                    49.122807017543856
                ],
                [
                    22,
                    7,
                    51.58371040723983
                ],
                [
                    22,
                    8,
                    50.35971223021583
                ],
                [
                    22,
                    9,
                    49.26470588235294
                ],
                [
                    22,
                    10,
                    54.12445730824892
                ],
                [
                    22,
                    11,
                    49.385749385749385
                ],
                [
                    22,
                    12,
                    54.621848739495796
                ],
                [
                    22,
                    13,
                    49.473684210526315
                ],
                [
                    22,
                    14,
                    48.87218045112782
                ],
                [
                    22,
                    15,
                    47.55244755244755
                ],
                [
                    22,
                    16,
                    51.89873417721519
                ],
                [
                    22,
                    17,
                    55.15151515151515
                ],
                [
                    22,
                    18,
                    47.32142857142857
                ],
                [
                    22,
                    19,
                    50.0
                ],
                [
                    22,
                    20,
                    46.794871794871796
                ],
                [
                    22,
                    21,
                    43.24324324324324
                ],
                [
                    22,
                    22,
                    50.0
                ],
                [
                    22,
                    23,
                    49.08424908424908
                ],
                [
                    22,
                    24,
                    51.26903553299492
                ],
                [
                    22,
                    25,
                    46.98795180722892
                ],
                [
                    22,
                    26,
                    50.0
                ],
                [
                    22,
                    27,
                    49.275362318840585
                ],
                [
                    22,
                    28,
                    56.41025641025641
                ],
                [
                    22,
                    29,
                    54.263565891472865
                ],
                [
                    22,
                    30,
                    45.78947368421053
                ],
                [
                    22,
                    31,
                    54.1044776119403
                ],
                [
                    22,
                    32,
                    48.61111111111111
                ],
                [
                    22,
                    33,
                    46.96969696969697
                ],
                [
                    22,
                    34,
                    51.3595166163142
                ],
                [
                    23,
                    0,
                    49.17534722222222
                ],
                [
                    23,
                    1,
                    51.46443514644351
                ],
                [
                    23,
                    2,
                    49.81308411214953
                ],
                [
                    23,
                    3,
                    48.07017543859649
                ],
                [
                    23,
                    4,
                    45.54054054054054
                ],
                [
                    23,
                    5,
                    46.30541871921182
                ],
                [
                    23,
                    6,
                    52.87745429925524
                ],
                [
                    23,
                    7,
                    46.94072657743786
                ],
                [
                    23,
                    8,
                    48.1972038263429
                ],
                [
                    23,
                    9,
                    46.93350548741123
                ],
                [
                    23,
                    10,
                    55.12705530642751
                ],
                [
                    23,
                    11,
                    57.14285714285714
                ],
                [
                    23,
                    12,
                    53.217011995637954
                ],
                [
                    23,
                    13,
                    53.46534653465347
                ],
                [
                    23,
                    14,
                    41.54351395730706
                ],
                [
                    23,
                    15,
                    48.92086330935252
                ],
                [
                    23,
                    16,
                    47.940074906367045
                ],
                [
                    23,
                    17,
                    51.83374083129584
                ],
                [
                    23,
                    18,
                    40.45368620037807
                ],
                [
                    23,
                    19,
                    48.33555259653795
                ],
                [
                    23,
                    20,
                    52.016129032258064
                ],
                [
                    23,
                    21,
                    50.0
                ],
                [
                    23,
                    22,
                    50.91575091575091
                ],
                [
                    23,
                    23,
                    50.0
                ],
                [
                    23,
                    24,
                    45.55388093443858
                ],
                [
                    23,
                    25,
                    49.75230007077141
                ],
                [
                    23,
                    26,
                    45.56962025316456
                ],
                [
                    23,
                    27,
                    42.29471316085489
                ],
                [
                    23,
                    28,
                    47.896039603960396
                ],
                [
                    23,
                    29,
                    50.4973221117062
                ],
                [
                    23,
                    30,
                    41.48681055155875
                ],
                [
                    23,
                    31,
                    50.41876046901172
                ],
                [
                    23,
                    32,
                    40.54834054834055
                ],
                [
                    23,
                    33,
                    45.90347923681257
                ],
                [
                    23,
                    34,
                    50.10281014393421
                ],
                [
                    24,
                    0,
                    52.997481108312336
                ],
                [
                    24,
                    1,
                    54.58392101551481
                ],
                [
                    24,
                    2,
                    53.585585585585584
                ],
                [
                    24,
                    3,
                    47.9427549194991
                ],
                [
                    24,
                    4,
                    50.15151515151515
                ],
                [
                    24,
                    5,
                    49.43109987357775
                ],
                [
                    24,
                    6,
                    47.80100937274693
                ],
                [
                    24,
                    7,
                    49.65986394557823
                ],
                [
                    24,
                    8,
                    51.620745542949756
                ],
                [
                    24,
                    9,
                    49.16485112563544
                ],
                [
                    24,
                    10,
                    56.50629641588634
                ],
                [
                    24,
                    11,
                    57.78947368421052
                ],
                [
                    24,
                    12,
                    54.75740390674228
                ],
                [
                    24,
                    13,
                    54.534883720930225
                ],
                [
                    24,
                    14,
                    55.90277777777778
                ],
                [
                    24,
                    15,
                    46.913580246913575
                ],
                [
                    24,
                    16,
                    50.522648083623686
                ],
                [
                    24,
                    17,
                    52.39658568614577
                ],
                [
                    24,
                    18,
                    44.080145719489984
                ],
                [
                    24,
                    19,
                    54.383464005702066
                ],
                [
                    24,
                    20,
                    54.36479772888574
                ],
                [
                    24,
                    21,
                    48.734177215189874
                ],
                [
                    24,
                    22,
                    48.73096446700508
                ],
                [
                    24,
                    23,
                    54.44611906556142
                ],
                [
                    24,
                    24,
                    50.0
                ],
                [
                    24,
                    25,
                    52.31923601637107
                ],
                [
                    24,
                    26,
                    42.119565217391305
                ],
                [
                    24,
                    27,
                    51.48401826484018
                ],
                [
                    24,
                    28,
                    50.0
                ],
                [
                    24,
                    29,
                    48.78048780487805
                ],
                [
                    24,
                    30,
                    48.419721871049305
                ],
                [
                    24,
                    31,
                    48.90939597315436
                ],
                [
                    24,
                    32,
                    46.53333333333333
                ],
                [
                    24,
                    33,
                    49.362688296639625
                ],
                [
                    24,
                    34,
                    53.68991198375085
                ],
                [
                    25,
                    0,
                    52.1455223880597
                ],
                [
                    25,
                    1,
                    52.450980392156865
                ],
                [
                    25,
                    2,
                    49.754901960784316
                ],
                [
                    25,
                    3,
                    52.675585284280935
                ],
                [
                    25,
                    4,
                    49.570200573065904
                ],
                [
                    25,
                    5,
                    47.31610337972167
                ],
                [
                    25,
                    6,
                    53.59477124183007
                ],
                [
                    25,
                    7,
                    46.05263157894737
                ],
                [
                    25,
                    8,
                    48.94894894894895
                ],
                [
                    25,
                    9,
                    47.85353535353536
                ],
                [
                    25,
                    10,
                    53.45394736842105
                ],
                [
                    25,
                    11,
                    58.72042068361086
                ],
                [
                    25,
                    12,
                    51.061776061776065
                ],
                [
                    25,
                    13,
                    53.89221556886228
                ],
                [
                    25,
                    14,
                    58.30815709969789
                ],
                [
                    25,
                    15,
                    46.52956298200514
                ],
                [
                    25,
                    16,
                    45.86894586894587
                ],
                [
                    25,
                    17,
                    52.0618556701031
                ],
                [
                    25,
                    18,
                    45.507246376811594
                ],
                [
                    25,
                    19,
                    51.17096018735363
                ],
                [
                    25,
                    20,
                    50.39893617021277
                ],
                [
                    25,
                    21,
                    43.83561643835616
                ],
                [
                    25,
                    22,
                    53.01204819277109
                ],
                [
                    25,
                    23,
                    50.247699929228595
                ],
                [
                    25,
                    24,
                    47.68076398362892
                ],
                [
                    25,
                    25,
                    50.0
                ],
                [
                    25,
                    26,
                    43.04347826086957
                ],
                [
                    25,
                    27,
                    47.4468085106383
                ],
                [
                    25,
                    28,
                    51.29533678756477
                ],
                [
                    25,
                    29,
                    48.8822652757079
                ],
                [
                    25,
                    30,
                    47.97136038186158
                ],
                [
                    25,
                    31,
                    54.98575498575499
                ],
                [
                    25,
                    32,
                    48.97959183673469
                ],
                [
                    25,
                    33,
                    52.653927813163484
                ],
                [
                    25,
                    34,
                    52.35546038543897
                ],
                [
                    26,
                    0,
                    62.19931271477663
                ],
                [
                    26,
                    1,
                    55.208333333333336
                ],
                [
                    26,
                    2,
                    61.76470588235294
                ],
                [
                    26,
                    3,
                    51.829268292682926
                ],
                [
                    26,
                    4,
                    49.39759036144578
                ],
                [
                    26,
                    5,
                    50.806451612903224
                ],
                [
                    26,
                    6,
                    51.010101010101
                ],
                [
                    26,
                    7,
                    61.53846153846154
                ],
                [
                    26,
                    8,
                    59.036144578313255
                ],
                [
                    26,
                    9,
                    51.85185185185185
                ],
                [
                    26,
                    10,
                    57.932692307692314
                ],
                [
                    26,
                    11,
                    56.27376425855514
                ],
                [
                    26,
                    12,
                    60.273972602739725
                ],
                [
                    26,
                    13,
                    55.33980582524271
                ],
                [
                    26,
                    14,
                    63.63636363636363
                ],
                [
                    26,
                    15,
                    59.88023952095808
                ],
                [
                    26,
                    16,
                    54.36893203883495
                ],
                [
                    26,
                    17,
                    58.63453815261044
                ],
                [
                    26,
                    18,
                    55.33980582524271
                ],
                [
                    26,
                    19,
                    60.40609137055838
                ],
                [
                    26,
                    20,
                    58.5635359116022
                ],
                [
                    26,
                    21,
                    50.6578947368421
                ],
                [
                    26,
                    22,
                    50.0
                ],
                [
                    26,
                    23,
                    54.43037974683544
                ],
                [
                    26,
                    24,
                    57.88043478260869
                ],
                [
                    26,
                    25,
                    56.95652173913044
                ],
                [
                    26,
                    26,
                    50.0
                ],
                [
                    26,
                    27,
                    60.447761194029844
                ],
                [
                    26,
                    28,
                    59.64912280701754
                ],
                [
                    26,
                    29,
                    60.0
                ],
                [
                    26,
                    30,
                    65.0
                ],
                [
                    26,
                    31,
                    50.66666666666667
                ],
                [
                    26,
                    32,
                    66.12903225806451
                ],
                [
                    26,
                    33,
                    52.459016393442624
                ],
                [
                    26,
                    34,
                    50.42492917847026
                ],
                [
                    27,
                    0,
                    55.79598145285936
                ],
                [
                    27,
                    1,
                    53.36538461538461
                ],
                [
                    27,
                    2,
                    57.71604938271605
                ],
                [
                    27,
                    3,
                    49.53846153846154
                ],
                [
                    27,
                    4,
                    42.084942084942085
                ],
                [
                    27,
                    5,
                    58.23293172690763
                ],
                [
                    27,
                    6,
                    56.59090909090909
                ],
                [
                    27,
                    7,
                    43.90243902439025
                ],
                [
                    27,
                    8,
                    49.10313901345291
                ],
                [
                    27,
                    9,
                    53.07017543859649
                ],
                [
                    27,
                    10,
                    54.14534288638689
                ],
                [
                    27,
                    11,
                    52.483443708609265
                ],
                [
                    27,
                    12,
                    58.661417322834644
                ],
                [
                    27,
                    13,
                    51.20274914089347
                ],
                [
                    27,
                    14,
                    52.26130653266332
                ],
                [
                    27,
                    15,
                    49.22279792746114
                ],
                [
                    27,
                    16,
                    53.213367609254504
                ],
                [
                    27,
                    17,
                    56.03112840466926
                ],
                [
                    27,
                    18,
                    48.421052631578945
                ],
                [
                    27,
                    19,
                    55.55555555555556
                ],
                [
                    27,
                    20,
                    54.054054054054056
                ],
                [
                    27,
                    21,
                    48.32535885167464
                ],
                [
                    27,
                    22,
                    50.72463768115942
                ],
                [
                    27,
                    23,
                    57.70528683914511
                ],
                [
                    27,
                    24,
                    48.51598173515982
                ],
                [
                    27,
                    25,
                    52.55319148936171
                ],
                [
                    27,
                    26,
                    39.55223880597015
                ],
                [
                    27,
                    27,
                    50.0
                ],
                [
                    27,
                    28,
                    47.05882352941176
                ],
                [
                    27,
                    29,
                    51.91873589164786
                ],
                [
                    27,
                    30,
                    49.61832061068702
                ],
                [
                    27,
                    31,
                    50.282485875706215
                ],
                [
                    27,
                    32,
                    50.73891625615764
                ],
                [
                    27,
                    33,
                    52.313167259786475
                ],
                [
                    27,
                    34,
                    52.52707581227437
                ],
                [
                    28,
                    0,
                    45.37313432835821
                ],
                [
                    28,
                    1,
                    47.76119402985074
                ],
                [
                    28,
                    2,
                    50.3875968992248
                ],
                [
                    28,
                    3,
                    48.90965732087228
                ],
                [
                    28,
                    4,
                    56.92307692307692
                ],
                [
                    28,
                    5,
                    44.827586206896555
                ],
                [
                    28,
                    6,
                    50.24154589371981
                ],
                [
                    28,
                    7,
                    48.84488448844885
                ],
                [
                    28,
                    8,
                    46.19047619047619
                ],
                [
                    28,
                    9,
                    44.24379232505643
                ],
                [
                    28,
                    10,
                    54.43037974683544
                ],
                [
                    28,
                    11,
                    52.74725274725275
                ],
                [
                    28,
                    12,
                    52.390852390852395
                ],
                [
                    28,
                    13,
                    50.35460992907801
                ],
                [
                    28,
                    14,
                    47.159090909090914
                ],
                [
                    28,
                    15,
                    46.15384615384615
                ],
                [
                    28,
                    16,
                    49.074074074074076
                ],
                [
                    28,
                    17,
                    46.319569120287255
                ],
                [
                    28,
                    18,
                    35.22012578616352
                ],
                [
                    28,
                    19,
                    48.214285714285715
                ],
                [
                    28,
                    20,
                    48.12206572769953
                ],
                [
                    28,
                    21,
                    45.108695652173914
                ],
                [
                    28,
                    22,
                    43.58974358974359
                ],
                [
                    28,
                    23,
                    52.103960396039604
                ],
                [
                    28,
                    24,
                    50.0
                ],
                [
                    28,
                    25,
                    48.704663212435236
                ],
                [
                    28,
                    26,
                    40.35087719298245
                ],
                [
                    28,
                    27,
                    52.94117647058824
                ],
                [
                    28,
                    28,
                    50.0
                ],
                [
                    28,
                    29,
                    52.41730279898219
                ],
                [
                    28,
                    30,
                    52.03619909502263
                ],
                [
                    28,
                    31,
                    52.38095238095239
                ],
                [
                    28,
                    32,
                    50.79365079365079
                ],
                [
                    28,
                    33,
                    45.32374100719424
                ],
                [
                    28,
                    34,
                    53.271028037383175
                ],
                [
                    29,
                    0,
                    50.808753568030454
                ],
                [
                    29,
                    1,
                    53.86904761904761
                ],
                [
                    29,
                    2,
                    53.30368487928844
                ],
                [
                    29,
                    3,
                    48.54014598540146
                ],
                [
                    29,
                    4,
                    53.37078651685393
                ],
                [
                    29,
                    5,
                    49.00990099009901
                ],
                [
                    29,
                    6,
                    50.943396226415096
                ],
                [
                    29,
                    7,
                    46.25550660792951
                ],
                [
                    29,
                    8,
                    47.83180026281209
                ],
                [
                    29,
                    9,
                    48.32535885167464
                ],
                [
                    29,
                    10,
                    52.97658862876254
                ],
                [
                    29,
                    11,
                    49.953227315247894
                ],
                [
                    29,
                    12,
                    54.4179523141655
                ],
                [
                    29,
                    13,
                    50.71428571428571
                ],
                [
                    29,
                    14,
                    56.20689655172414
                ],
                [
                    29,
                    15,
                    49.596774193548384
                ],
                [
                    29,
                    16,
                    49.914236706689536
                ],
                [
                    29,
                    17,
                    47.49082007343941
                ],
                [
                    29,
                    18,
                    46.402877697841724
                ],
                [
                    29,
                    19,
                    54.36746987951807
                ],
                [
                    29,
                    20,
                    51.76470588235295
                ],
                [
                    29,
                    21,
                    46.22356495468278
                ],
                [
                    29,
                    22,
                    45.73643410852713
                ],
                [
                    29,
                    23,
                    49.5026778882938
                ],
                [
                    29,
                    24,
                    51.21951219512195
                ],
                [
                    29,
                    25,
                    51.1177347242921
                ],
                [
                    29,
                    26,
                    40.0
                ],
                [
                    29,
                    27,
                    48.081264108352144
                ],
                [
                    29,
                    28,
                    47.58269720101781
                ],
                [
                    29,
                    29,
                    50.0
                ],
                [
                    29,
                    30,
                    48.4593837535014
                ],
                [
                    29,
                    31,
                    49.920255183413076
                ],
                [
                    29,
                    32,
                    48.82629107981221
                ],
                [
                    29,
                    33,
                    50.35128805620609
                ],
                [
                    29,
                    34,
                    53.26704545454546
                ],
                [
                    30,
                    0,
                    50.82236842105263
                ],
                [
                    30,
                    1,
                    57.466063348416284
                ],
                [
                    30,
                    2,
                    54.12621359223301
                ],
                [
                    30,
                    3,
                    49.84520123839009
                ],
                [
                    30,
                    4,
                    50.53763440860215
                ],
                [
                    30,
                    5,
                    51.98237885462555
                ],
                [
                    30,
                    6,
                    53.19634703196348
                ],
                [
                    30,
                    7,
                    54.19847328244275
                ],
                [
                    30,
                    8,
                    53.735632183908045
                ],
                [
                    30,
                    9,
                    50.59952038369304
                ],
                [
                    30,
                    10,
                    57.26227795193313
                ],
                [
                    30,
                    11,
                    57.71812080536913
                ],
                [
                    30,
                    12,
                    56.2962962962963
                ],
                [
                    30,
                    13,
                    60.28708133971292
                ],
                [
                    30,
                    14,
                    53.714285714285715
                ],
                [
                    30,
                    15,
                    49.61832061068702
                ],
                [
                    30,
                    16,
                    49.158249158249156
                ],
                [
                    30,
                    17,
                    52.60770975056689
                ],
                [
                    30,
                    18,
                    50.66666666666667
                ],
                [
                    30,
                    19,
                    57.635467980295566
                ],
                [
                    30,
                    20,
                    53.182751540041075
                ],
                [
                    30,
                    21,
                    48.04469273743017
                ],
                [
                    30,
                    22,
                    54.21052631578947
                ],
                [
                    30,
                    23,
                    58.51318944844125
                ],
                [
                    30,
                    24,
                    51.580278128950695
                ],
                [
                    30,
                    25,
                    52.02863961813843
                ],
                [
                    30,
                    26,
                    35.0
                ],
                [
                    30,
                    27,
                    50.38167938931297
                ],
                [
                    30,
                    28,
                    47.963800904977376
                ],
                [
                    30,
                    29,
                    51.540616246498594
                ],
                [
                    30,
                    30,
                    50.0
                ],
                [
                    30,
                    31,
                    53.98230088495575
                ],
                [
                    30,
                    32,
                    44.88636363636363
                ],
                [
                    30,
                    33,
                    45.6
                ],
                [
                    30,
                    34,
                    56.45933014354066
                ],
                [
                    31,
                    0,
                    44.39959636730575
                ],
                [
                    31,
                    1,
                    44.83870967741935
                ],
                [
                    31,
                    2,
                    52.72346368715084
                ],
                [
                    31,
                    3,
                    50.39682539682539
                ],
                [
                    31,
                    4,
                    54.385964912280706
                ],
                [
                    31,
                    5,
                    45.45454545454545
                ],
                [
                    31,
                    6,
                    48.02919708029197
                ],
                [
                    31,
                    7,
                    48.860759493670884
                ],
                [
                    31,
                    8,
                    46.72364672364672
                ],
                [
                    31,
                    9,
                    45.62798092209857
                ],
                [
                    31,
                    10,
                    49.17382683410443
                ],
                [
                    31,
                    11,
                    45.60496380558428
                ],
                [
                    31,
                    12,
                    51.93075898801598
                ],
                [
                    31,
                    13,
                    50.73891625615764
                ],
                [
                    31,
                    14,
                    50.0
                ],
                [
                    31,
                    15,
                    49.717514124293785
                ],
                [
                    31,
                    16,
                    54.332129963898915
                ],
                [
                    31,
                    17,
                    46.291866028708135
                ],
                [
                    31,
                    18,
                    40.74074074074074
                ],
                [
                    31,
                    19,
                    47.59036144578313
                ],
                [
                    31,
                    20,
                    47.95144157814871
                ],
                [
                    31,
                    21,
                    52.41157556270096
                ],
                [
                    31,
                    22,
                    45.8955223880597
                ],
                [
                    31,
                    23,
                    49.58123953098828
                ],
                [
                    31,
                    24,
                    51.09060402684564
                ],
                [
                    31,
                    25,
                    45.01424501424501
                ],
                [
                    31,
                    26,
                    49.333333333333336
                ],
                [
                    31,
                    27,
                    49.717514124293785
                ],
                [
                    31,
                    28,
                    47.61904761904761
                ],
                [
                    31,
                    29,
                    50.079744816586924
                ],
                [
                    31,
                    30,
                    46.017699115044245
                ],
                [
                    31,
                    31,
                    50.0
                ],
                [
                    31,
                    32,
                    50.22026431718062
                ],
                [
                    31,
                    33,
                    45.91346153846153
                ],
                [
                    31,
                    34,
                    51.2630014858841
                ],
                [
                    32,
                    0,
                    50.289855072463766
                ],
                [
                    32,
                    1,
                    51.162790697674424
                ],
                [
                    32,
                    2,
                    56.372549019607845
                ],
                [
                    32,
                    3,
                    54.27509293680297
                ],
                [
                    32,
                    4,
                    61.34453781512605
                ],
                [
                    32,
                    5,
                    44.522968197879855
                ],
                [
                    32,
                    6,
                    44.81981981981982
                ],
                [
                    32,
                    7,
                    48.627450980392155
                ],
                [
                    32,
                    8,
                    51.072961373390555
                ],
                [
                    32,
                    9,
                    52.785145888594165
                ],
                [
                    32,
                    10,
                    56.72727272727273
                ],
                [
                    32,
                    11,
                    46.1139896373057
                ],
                [
                    32,
                    12,
                    55.81395348837209
                ],
                [
                    32,
                    13,
                    49.56140350877193
                ],
                [
                    32,
                    14,
                    49.056603773584904
                ],
                [
                    32,
                    15,
                    48.93617021276596
                ],
                [
                    32,
                    16,
                    49.83050847457628
                ],
                [
                    32,
                    17,
                    50.15822784810127
                ],
                [
                    32,
                    18,
                    47.10144927536232
                ],
                [
                    32,
                    19,
                    52.53807106598985
                ],
                [
                    32,
                    20,
                    48.754448398576514
                ],
                [
                    32,
                    21,
                    59.22330097087378
                ],
                [
                    32,
                    22,
                    51.388888888888886
                ],
                [
                    32,
                    23,
                    59.45165945165945
                ],
                [
                    32,
                    24,
                    53.46666666666666
                ],
                [
                    32,
                    25,
                    51.02040816326531
                ],
                [
                    32,
                    26,
                    33.87096774193548
                ],
                [
                    32,
                    27,
                    49.26108374384236
                ],
                [
                    32,
                    28,
                    49.2063492063492
                ],
                [
                    32,
                    29,
                    51.173708920187785
                ],
                [
                    32,
                    30,
                    55.11363636363637
                ],
                [
                    32,
                    31,
                    49.77973568281938
                ],
                [
                    32,
                    32,
                    50.0
                ],
                [
                    32,
                    33,
                    46.99248120300752
                ],
                [
                    32,
                    34,
                    50.142450142450144
                ],
                [
                    33,
                    0,
                    55.04201680672269
                ],
                [
                    33,
                    1,
                    55.25114155251142
                ],
                [
                    33,
                    2,
                    50.04965243296922
                ],
                [
                    33,
                    3,
                    50.38167938931297
                ],
                [
                    33,
                    4,
                    44.62809917355372
                ],
                [
                    33,
                    5,
                    50.583657587548636
                ],
                [
                    33,
                    6,
                    57.29847494553377
                ],
                [
                    33,
                    7,
                    49.28366762177651
                ],
                [
                    33,
                    8,
                    49.89429175475687
                ],
                [
                    33,
                    9,
                    47.62931034482759
                ],
                [
                    33,
                    10,
                    57.29068673565381
                ],
                [
                    33,
                    11,
                    56.421356421356414
                ],
                [
                    33,
                    12,
                    56.52173913043478
                ],
                [
                    33,
                    13,
                    55.26315789473685
                ],
                [
                    33,
                    14,
                    55.33980582524271
                ],
                [
                    33,
                    15,
                    52.44755244755245
                ],
                [
                    33,
                    16,
                    50.14492753623189
                ],
                [
                    33,
                    17,
                    56.74157303370787
                ],
                [
                    33,
                    18,
                    53.57142857142857
                ],
                [
                    33,
                    19,
                    56.53061224489796
                ],
                [
                    33,
                    20,
                    52.652259332023576
                ],
                [
                    33,
                    21,
                    51.196172248803826
                ],
                [
                    33,
                    22,
                    53.03030303030303
                ],
                [
                    33,
                    23,
                    54.09652076318743
                ],
                [
                    33,
                    24,
                    50.63731170336037
                ],
                [
                    33,
                    25,
                    47.346072186836516
                ],
                [
                    33,
                    26,
                    47.540983606557376
                ],
                [
                    33,
                    27,
                    47.686832740213525
                ],
                [
                    33,
                    28,
                    54.67625899280576
                ],
                [
                    33,
                    29,
                    49.64871194379391
                ],
                [
                    33,
                    30,
                    54.400000000000006
                ],
                [
                    33,
                    31,
                    54.08653846153846
                ],
                [
                    33,
                    32,
                    53.00751879699248
                ],
                [
                    33,
                    33,
                    50.0
                ],
                [
                    33,
                    34,
                    52.67326732673268
                ],
                [
                    34,
                    0,
                    43.12839059674503
                ],
                [
                    34,
                    1,
                    49.877750611246945
                ],
                [
                    34,
                    2,
                    50.19710906701709
                ],
                [
                    34,
                    3,
                    43.12714776632303
                ],
                [
                    34,
                    4,
                    49.44134078212291
                ],
                [
                    34,
                    5,
                    43.790849673202615
                ],
                [
                    34,
                    6,
                    50.48309178743962
                ],
                [
                    34,
                    7,
                    47.69230769230769
                ],
                [
                    34,
                    8,
                    47.14494875549048
                ],
                [
                    34,
                    9,
                    47.56898817345598
                ],
                [
                    34,
                    10,
                    50.48192771084338
                ],
                [
                    34,
                    11,
                    43.76181474480151
                ],
                [
                    34,
                    12,
                    53.00713557594292
                ],
                [
                    34,
                    13,
                    48.79032258064516
                ],
                [
                    34,
                    14,
                    48.23529411764706
                ],
                [
                    34,
                    15,
                    51.253132832080205
                ],
                [
                    34,
                    16,
                    49.8220640569395
                ],
                [
                    34,
                    17,
                    52.015113350125944
                ],
                [
                    34,
                    18,
                    41.86046511627907
                ],
                [
                    34,
                    19,
                    47.84313725490196
                ],
                [
                    34,
                    20,
                    49.152542372881356
                ],
                [
                    34,
                    21,
                    47.6780185758514
                ],
                [
                    34,
                    22,
                    48.6404833836858
                ],
                [
                    34,
                    23,
                    49.8971898560658
                ],
                [
                    34,
                    24,
                    46.31008801624915
                ],
                [
                    34,
                    25,
                    47.644539614561026
                ],
                [
                    34,
                    26,
                    49.57507082152974
                ],
                [
                    34,
                    27,
                    47.47292418772563
                ],
                [
                    34,
                    28,
                    46.728971962616825
                ],
                [
                    34,
                    29,
                    46.73295454545455
                ],
                [
                    34,
                    30,
                    43.54066985645933
                ],
                [
                    34,
                    31,
                    48.736998514115896
                ],
                [
                    34,
                    32,
                    49.85754985754986
                ],
                [
                    34,
                    33,
                    47.32673267326732
                ],
                [
                    34,
                    34,
                    50.0
                ]
            ],
            "label": {
                "show": true,
                "position": "top",
                "margin": 8
            }
        }
    ],
    "legend": [
        {
            "data": [
                "\u80dc\u7387"
            ],
            "selected": {
                "\u80dc\u7387": true
            },
            "show": false,
            "padding": 5,
            "itemGap": 10,
            "itemWidth": 25,
            "itemHeight": 14
        }
    ],
    "tooltip": {
        "show": true,
        "trigger": "item",
        "triggerOn": "mousemove|click",
        "axisPointer": {
            "type": "line"
        },
        "showContent": true,
        "alwaysShowContent": false,
        "showDelay": 0,
        "hideDelay": 100,
        "textStyle": {
            "fontSize": 14
        },
        "borderWidth": 0,
        "padding": 5
    },
    "xAxis": [
        {
            "show": true,
            "scale": false,
            "nameLocation": "end",
            "nameGap": 15,
            "gridIndex": 0,
            "axisLabel": {
                "rotate": -45,
                "interval": 0
            },
            "inverse": false,
            "offset": 0,
            "splitNumber": 5,
            "minInterval": 0,
            "splitLine": {
                "show": false,
                "lineStyle": {
                    "show": true,
                    "width": 1,
                    "opacity": 1,
                    "curveness": 0,
                    "type": "solid"
                }
            },
            "data": [
                "Aztecs",
                "Berbers",
                "Britons",
                "Bulgarians",
                "Burmese",
                "Byzantines",
                "Celts",
                "Chinese",
                "Cumans",
                "Ethiopians",
                "Franks",
                "Goths",
                "Huns",
                "Incas",
                "Indians",
                "Italians",
                "Japanese",
                "Khmer",
                "Koreans",
                "Lithuanians",
                "Magyars",
                "Malay",
                "Malians",
                "Mayans",
                "Mongols",
                "Persians",
                "Portuguese",
                "Saracens",
                "Slavs",
                "Spanish",
                "Tatars",
                "Teutons",
                "Turks",
                "Vietnamese",
                "Vikings"
            ]
        }
    ],
    "yAxis": [
        {
            "show": true,
            "scale": false,
            "nameLocation": "end",
            "nameGap": 15,
            "gridIndex": 0,
            "inverse": false,
            "offset": 0,
            "splitNumber": 5,
            "minInterval": 0,
            "splitLine": {
                "show": false,
                "lineStyle": {
                    "show": true,
                    "width": 1,
                    "opacity": 1,
                    "curveness": 0,
                    "type": "solid"
                }
            },
            "data": [
                "Aztecs",
                "Berbers",
                "Britons",
                "Bulgarians",
                "Burmese",
                "Byzantines",
                "Celts",
                "Chinese",
                "Cumans",
                "Ethiopians",
                "Franks",
                "Goths",
                "Huns",
                "Incas",
                "Indians",
                "Italians",
                "Japanese",
                "Khmer",
                "Koreans",
                "Lithuanians",
                "Magyars",
                "Malay",
                "Malians",
                "Mayans",
                "Mongols",
                "Persians",
                "Portuguese",
                "Saracens",
                "Slavs",
                "Spanish",
                "Tatars",
                "Teutons",
                "Turks",
                "Vietnamese",
                "Vikings"
            ]
        }
    ],
    "title": [
        {
            "text": "文明互殴胜率⚒️",
            "left": "center",
            "padding": 5,
            "itemGap": 10,
            "textStyle": {
                "color": "black",
                "fontSize": 30,
                "fontFamily": "Fusion Pixel"
            }
        }
    ],
    "visualMap": {
        "show": true,
        "type": "continuous",
        "min": 30,
        "max": 70,
        "inRange": {
            "color": [
                "#FFA500",
                "#FF0000"
            ]
        },
        "calculable": true,
        "inverse": false,
        "splitNumber": 5,
        "orient": "vertical",
        "left": "right",
        "top": "center",
        "showLabel": true,
        "itemWidth": 20,
        "itemHeight": 140,
        "borderWidth": 0
    }
};


        // 使用刚指定的配置项和数据显示图表。
        myChart.setOption(option);
</script>

</p>
<script src="https://cdn.jsdelivr.net/npm/echarts@4.8.0/dist/echarts.min.js"></script>
<div id="echarts700" style="width: 81%;height: 400px;margin: 0 auto"></div>

<script type="text/javascript">
        // 基于准备好的dom，初始化echarts实例
        var myChart = echarts.init(document.getElementById('echarts700'));

        // 指定图表的配置项和数据
        var option = {
    backgroundColor: "white",
    animation: true,
    animationThreshold: 2000,
    animationDuration: 1000,
    animationEasing: "cubicOut",
    animationDelay: 0,
    animationDurationUpdate: 300,
    animationEasingUpdate: "cubicOut",
    animationDelayUpdate: 0,
    color: [
        "#c23531",
        "#2f4554",
        "#61a0a8",
        "#d48265",
        "#749f83",
        "#ca8622",
        "#bda29a",
        "#6e7074",
        "#546570",
        "#c4ccd3",
        "#f05b72",
        "#ef5b9c",
        "#f47920",
        "#905a3d",
        "#fab27b",
        "#2a5caa",
        "#444693",
        "#726930",
        "#b2d235",
        "#6d8346",
        "#ac6767",
        "#1d953f",
        "#6950a1",
        "#918597"
    ],
    series: [
        {
            "type": "pie",
            "name": "Server",
            "clockwise": true,
            "data": [
                {
                    "name": "australiasoutheast",
                    "value": 65894
                },
                {
                    "name": "brazilsouth",
                    "value": 402240
                },
                {
                    "name": "eastus",
                    "value": 432171
                },
                {
                    "name": "koreacentral",
                    "value": 25220
                },
                {
                    "name": "southeastasia",
                    "value": 114114
                },
                {
                    "name": "ukwest",
                    "value": 1085889
                },
                {
                    "name": "westeurope",
                    "value": 51915
                },
                {
                    "name": "westindia",
                    "value": 114281
                },
                {
                    "name": "westus2",
                    "value": 82254
                }
            ],
            "radius": [
                "40%",
                "55%"
            ],
            "center": [
                "50%",
                "50%"
            ],
            "roseType": "radius",
            "label": {
                "show": true,
                "position": "Outside",
                "margin": 8,
                "formatter": "{a|{a}}{abg|}\n{hr|}\n {b|{b}: }{c}  {per|{d}%}  ",
                "backgroundColor": "#eee",
                "borderColor": "#aaa",
                "borderWidth": 1,
                "borderRadius": 4,
                "rich": {
                    "a": {
                        "color": "#999",
                        "lineHeight": 22,
                        "align": "center"
                    },
                    "abg": {
                        "backgroundColor": "#e3e3e3",
                        "width": "100%",
                        "align": "right",
                        "height": 22,
                        "borderRadius": [
                            4,
                            4,
                            0,
                            0
                        ]
                    },
                    "hr": {
                        "borderColor": "#aaa",
                        "width": "100%",
                        "borderWidth": 0.5,
                        "height": 0
                    },
                    "b": {
                        "fontSize": 16,
                        "lineHeight": 33
                    },
                    "per": {
                        "color": "#eee",
                        "backgroundColor": "#334455",
                        "padding": [
                            2,
                            4
                        ],
                        "borderRadius": 2
                    }
                }
            }
        }
    ],
    legend: [
        {
            "data": [
                "australiasoutheast",
                "brazilsouth",
                "eastus",
                "koreacentral",
                "southeastasia",
                "ukwest",
                "westeurope",
                "westindia",
                "westus2"
            ],
            "selected": {},
            "show": true,
            "bottom": "bottom",
            "padding": 5,
            "itemGap": 10,
            "itemWidth": 25,
            "itemHeight": 14,
            "textStyle": {
                "color": "black",
                "fontSize": 20,
                "fontFamily": "Fusion Pixel",
            }
        }
    ],
    tooltip: {
        "show": true,
        "trigger": "item",
        "triggerOn": "mousemove|click",
        "axisPointer": {
            "type": "line"
        },
        "textStyle": {
            "fontSize": 14,
            "fontFamily": "Fusion Pixel",
        },
        "borderWidth": 0
    },
    title: [
        {
            "text": "服务器热度🧲",
            "left": "center",
            "padding": 5,
            "itemGap": 10,
            "textStyle": {
                "color": "black",
                "fontSize": 30,
                "fontFamily": "Fusion Pixel",
            }
        }
    ]
}

        // 使用刚指定的配置项和数据显示图表。
        myChart.setOption(option);
</script>


<script src="https://cdn.jsdelivr.net/npm/echarts@4.8.0/dist/echarts.min.js"></script>
<div id="echarts1838" style="width: 81%;height: 400px;margin: 0 auto"></div>

<script type="text/javascript">
        // 基于准备好的dom，初始化echarts实例
        var myChart = echarts.init(document.getElementById('echarts1838'));

        // 指定图表的配置项和数据
        var option = {
    "animation": true,
    "animationThreshold": 2000,
    "animationDuration": 1000,
    "animationEasing": "cubicOut",
    "animationDelay": 0,
    "animationDurationUpdate": 300,
    "animationEasingUpdate": "cubicOut",
    "animationDelayUpdate": 0,
    "color": [
        "#c23531",
        "#2f4554",
        "#61a0a8",
        "#d48265",
        "#749f83",
        "#ca8622",
        "#bda29a",
        "#6e7074",
        "#546570",
        "#c4ccd3",
        "#f05b72",
        "#ef5b9c",
        "#f47920",
        "#905a3d",
        "#fab27b",
        "#2a5caa",
        "#444693",
        "#726930",
        "#b2d235",
        "#6d8346",
        "#ac6767",
        "#1d953f",
        "#6950a1",
        "#918597"
    ],
    "series": [
        {
            "type": "bar",
            "name": "RM_TEAM",
            "data": [
                265458,
                225940,
                196599,
                192815,
                186104,
                159150,
                150228,
                116617,
                107173,
                102177,
                99226,
                96342,
                96054,
                93913,
                93497,
                87729,
                84323,
                77615,
                74428,
                70549,
                66742,
                64482,
                58644,
                55065,
                51395,
                50743,
                47740,
                45941,
                43281,
                41814,
                39886,
                39326,
                35228,
                32868,
                32784
            ],
            "stack": "stack1",
            "barCategoryGap": "20%",
            "label": {
                "show": false,
                "position": "top",
                "margin": 8
            }
        },
        {
            "type": "bar",
            "name": "RM_1v1",
            "data": [
                193375,
                166356,
                164468,
                163484,
                126912,
                125738,
                120366,
                109739,
                100385,
                95724,
                86457,
                85859,
                84650,
                84298,
                83741,
                77420,
                75760,
                71471,
                63386,
                62078,
                55867,
                55730,
                53742,
                49075,
                46694,
                44299,
                43869,
                43438,
                41098,
                38553,
                38470,
                38003,
                33701,
                32494,
                26098
            ],
            "stack": "stack1",
            "barCategoryGap": "20%",
            "label": {
                "show": false,
                "position": "top",
                "margin": 8
            }
        }
    ],
    "legend": [
        {
            "data": [
                "RM_TEAM",
                "RM_1v1"
            ],
            "selected": {
                "RM_TEAM": true,
                "RM_1v1": true
            },
            "show": true,
            

            "left": "center",
            "top":100,
            "bottom": "bottom",
            "orient": "vertical",
            "padding": 5,
            "itemGap": 10,
            "itemWidth": 25,
            "itemHeight": 14,
            "textStyle": {
                "color": "black",
                "fontSize": 10
            }
            
        }
    ],
    "tooltip": {
        "show": true,
        "trigger": "item",
        "triggerOn": "mousemove|click",
        "axisPointer": {
            "type": "line"
        },
        "textStyle": {
            "fontSize": 14,
            "fontFamily": "Fusion Pixel",
        },
        "borderWidth": 0
    },
    "xAxis": [
        {
            "show": true,
            "scale": false,
            "nameLocation": "end",
            "nameGap": 15,
            "gridIndex": 0,
            "axisLabel": {
                "show": true,
                "position": "top",
                "rotate": -45,
                "margin": 8
            },
            "inverse": false,
            "offset": 0,
            "splitNumber": 5,
            "minInterval": 0,
            "splitLine": {
                "show": false,
                "lineStyle": {
                    "show": true,
                    "width": 1,
                    "opacity": 1,
                    "curveness": 0,
                    "type": "solid"
                }
            },
            "data": [
                "Franks",
                "Britons",
                "Mayans",
                "Mongols",
                "Persians",
                "Aztecs",
                "Goths",
                "Huns",
                "Khmer",
                "Vikings",
                "Japanese",
                "Lithuanians",
                "Celts",
                "Ethiopians",
                "Magyars",
                "Cumans",
                "Spanish",
                "Teutons",
                "Chinese",
                "Bulgarians",
                "Incas",
                "Byzantines",
                "Vietnamese",
                "Saracens",
                "Slavs",
                "Tatars",
                "Berbers",
                "Turks",
                "Malay",
                "Burmese",
                "Italians",
                "Malians",
                "Indians",
                "Koreans",
                "Portuguese"
            ]
        }
    ],
    "yAxis": [
        {
            "show": true,
            "scale": false,
            "nameLocation": "end",
            "nameGap": 15,
            "gridIndex": 0,
            "inverse": false,
            "offset": 0,
            "splitNumber": 5,
            "minInterval": 0,
            "splitLine": {
                "show": false,
                "lineStyle": {
                    "show": true,
                    "width": 1,
                    "opacity": 1,
                    "curveness": 0,
                    "type": "solid"
                }
            }
        }
    ],
    "title": [
        {
            "text": "文明游玩情况⛳",
            "left": "center",
            "padding": 5,
            "itemGap": 10,
            "textStyle": {
                "color": "black",
                "fontSize": 30,
                "fontFamily": "Fusion Pixel",
            }
        }
    ]

};

        // 使用刚指定的配置项和数据显示图表。
        myChart.setOption(option);
</script>


<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">color_count = joined_df[~joined_df[<span class="string">&#x27;color&#x27;</span>].isna()].value_counts(<span class="string">&#x27;color&#x27;</span>,sort=<span class="literal">False</span>)</span><br><span class="line">color_count_index = color_count.index.to_list()</span><br><span class="line">color_count_data = color_count.to_list()</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">pie = (</span><br><span class="line">    Pie()</span><br><span class="line">    .add(</span><br><span class="line">        <span class="string">&quot;&quot;</span>,</span><br><span class="line">        [<span class="built_in">list</span>(z) <span class="keyword">for</span> z <span class="keyword">in</span> <span class="built_in">zip</span> (color_count_index,color_count_data)],</span><br><span class="line">        radius=[<span class="string">&quot;30%&quot;</span>, <span class="string">&quot;75%&quot;</span>],</span><br><span class="line">        center=[<span class="string">&quot;50%&quot;</span>, <span class="string">&quot;50%&quot;</span>],</span><br><span class="line">        rosetype=<span class="string">&quot;radius&quot;</span>,</span><br><span class="line">        label_opts=opts.LabelOpts(is_show=<span class="literal">False</span>),</span><br><span class="line">        </span><br><span class="line">    )</span><br><span class="line">    .set_colors(color_count_index)</span><br><span class="line">    .set_global_opts(</span><br><span class="line">        title_opts=opts.TitleOpts(title=<span class="string">&quot;颜色使用情况🎨&quot;</span>,pos_left=<span class="string">&#x27;center&#x27;</span>),</span><br><span class="line">        legend_opts=opts.LegendOpts(pos_bottom=<span class="string">&#x27;bottom&#x27;</span>)</span><br><span class="line"></span><br><span class="line">    )</span><br><span class="line">).render(<span class="string">&#x27;colors.html&#x27;</span>)</span><br></pre></td></tr></table></figure>
<script src="https://cdn.jsdelivr.net/npm/echarts@4.8.0/dist/echarts.min.js"></script>
<div id="echarts5639" style="width: 81%;height: 400px;margin: 0 auto"></div>

<script type="text/javascript">
        // 基于准备好的dom，初始化echarts实例
        var myChart = echarts.init(document.getElementById('echarts5639'));

        // 指定图表的配置项和数据
        var option = {
    "animation": true,
    "animationThreshold": 2000,
    "animationDuration": 1000,
    "animationEasing": "cubicOut",
    "animationDelay": 0,
    "animationDurationUpdate": 300,
    "animationEasingUpdate": "cubicOut",
    "animationDelayUpdate": 0,
    "color": [
        "Blue",
        "Cyan",
        "Green",
        "Grey",
        "Orange",
        "Purple",
        "Red",
        "Yellow"
    ],
    "series": [
        {
            "type": "pie",
            "clockwise": true,
            "data": [
                {
                    "name": "Blue",
                    "value": 2483131
                },
                {
                    "name": "Cyan",
                    "value": 609446
                },
                {
                    "name": "Green",
                    "value": 988391
                },
                {
                    "name": "Grey",
                    "value": 329814
                },
                {
                    "name": "Orange",
                    "value": 387382
                },
                {
                    "name": "Purple",
                    "value": 611774
                },
                {
                    "name": "Red",
                    "value": 2483060
                },
                {
                    "name": "Yellow",
                    "value": 929323
                }
            ],
            "radius": [
                "30%",
                "75%"
            ],
            "center": [
                "50%",
                "50%"
            ],
            "roseType": "radius",
            "label": {
                "show": false,
                "position": "top",
                "margin": 8
            }
        }
    ],
    "legend": [
        {
            "data": [
                "Blue",
                "Cyan",
                "Green",
                "Grey",
                "Orange",
                "Purple",
                "Red",
                "Yellow"
            ],
            "selected": {},
            "show": true,
            "bottom": "bottom",
            "padding": 5,
            "itemGap": 10,
            "itemWidth": 25,
            "itemHeight": 14
        }
    ],
    "tooltip": {
        "show": true,
        "trigger": "item",
        "triggerOn": "mousemove|click",
        "axisPointer": {
            "type": "line"
        },
        "showContent": true,
        "alwaysShowContent": false,
        "showDelay": 0,
        "hideDelay": 100,
        "textStyle": {
            "fontSize": 14
        },
        "borderWidth": 0,
        "padding": 5
    },
    "title": [
        {
            "text": "颜色使用情况🎨",
            "left": "center",
            "padding": 5,
            "itemGap": 10,
            "textStyle": {
                "fontFamily": "Fusion Pixel",
                "color": "rgba(0,0,0)",
                "fontSize": 30,
            }
        }
    ]
};

        // 使用刚指定的配置项和数据显示图表。
        myChart.setOption(option);
</script>


<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">win_team_count = joined_df[(joined_df.winner==<span class="literal">True</span>) &amp; (joined_df.ladder==<span class="string">&quot;RM_TEAM&quot;</span>)].value_counts(<span class="string">&#x27;civ&#x27;</span>,sort=<span class="literal">False</span>)</span><br><span class="line">win_team_count_data = win_team_count.to_list()</span><br><span class="line">win_team_count_index = win_team_count.index.to_list()</span><br><span class="line"></span><br><span class="line">bar = (</span><br><span class="line">    Bar()</span><br><span class="line">    .add_xaxis(win_team_count_index)</span><br><span class="line">    .add_yaxis(<span class="string">&quot;team&quot;</span>,win_team_count_data,category_gap=<span class="number">12</span>)</span><br><span class="line">    .set_global_opts(</span><br><span class="line">        title_opts=opts.TitleOpts(</span><br><span class="line">            title=<span class="string">&quot;团战文明胜利场次统计🎊&quot;</span>,</span><br><span class="line">            pos_left=<span class="string">&#x27;center&#x27;</span>),</span><br><span class="line">        legend_opts=opts.LegendOpts(</span><br><span class="line">            pos_bottom=<span class="string">&#x27;bottom&#x27;</span>,</span><br><span class="line">            is_show=<span class="literal">False</span>),</span><br><span class="line">        xaxis_opts=opts.AxisOpts(</span><br><span class="line">            axislabel_opts=&#123;<span class="string">&quot;rotate&quot;</span>:-<span class="number">45</span>,<span class="string">&#x27;interval&#x27;</span>: <span class="number">0</span> &#125;,</span><br><span class="line">            name_textstyle_opts=opts.TextStyleOpts(</span><br><span class="line">                font_size=<span class="number">2</span></span><br><span class="line">            )),)</span><br><span class="line">    .set_series_opts(label_opts=opts.LabelOpts(is_show=<span class="literal">False</span>))</span><br><span class="line">)</span><br><span class="line"></span><br><span class="line">bar.render(<span class="string">&#x27;win_team_count.html&#x27;</span>)</span><br></pre></td></tr></table></figure>
<script src="https://cdn.jsdelivr.net/npm/echarts@4.8.0/dist/echarts.min.js"></script>
<div id="echarts1252" style="width: 81%;height: 400px;margin: 0 auto"></div>

<script type="text/javascript">
        // 基于准备好的dom，初始化echarts实例
        var myChart = echarts.init(document.getElementById('echarts1252'));

        // 指定图表的配置项和数据
        var option = {
    "animation": true,
    "animationThreshold": 2000,
    "animationDuration": 1000,
    "animationEasing": "cubicOut",
    "animationDelay": 0,
    "animationDurationUpdate": 300,
    "animationEasingUpdate": "cubicOut",
    "animationDelayUpdate": 0,
    "color": [
        "#c23531",
        "#2f4554",
        "#61a0a8",
        "#d48265",
        "#749f83",
        "#ca8622",
        "#bda29a",
        "#6e7074",
        "#546570",
        "#c4ccd3",
        "#f05b72",
        "#ef5b9c",
        "#f47920",
        "#905a3d",
        "#fab27b",
        "#2a5caa",
        "#444693",
        "#726930",
        "#b2d235",
        "#6d8346",
        "#ac6767",
        "#1d953f",
        "#6950a1",
        "#918597"
    ],
    "series": [
        {
            "type": "bar",
            "name": "1v1",
            "legendHoverLink": true,
            "data": [
                91022,
                33941,
                111515,
                46748,
                29658,
                37237,
                65383,
                43138,
                51391,
                63503,
                159227,
                89151,
                76998,
                43401,
                24603,
                25789,
                57209,
                72422,
                21081,
                74500,
                61684,
                27138,
                30889,
                115448,
                108927,
                80711,
                18398,
                34346,
                35160,
                48385,
                32423,
                54620,
                32286,
                36930,
                69902
            ],
            "showBackground": false,
            "barMinHeight": 0,
            "barCategoryGap": 12,
            "barGap": "30%",
            "large": false,
            "largeThreshold": 400,
            "seriesLayoutBy": "column",
            "datasetIndex": 0,
            "clip": true,
            "zlevel": 0,
            "z": 2,
            "label": {
                "show": false,
                "position": "top",
                "margin": 8
            },
            "rippleEffect": {
                "show": true,
                "brushType": "stroke",
                "scale": 2.5,
                "period": 4
            }
        }
    ],
    "legend": [
        {
            "data": [
                "1v1"
            ],
            "selected": {
                "1v1": true
            },
            "show": false,
            "bottom": "bottom",
            "padding": 5,
            "itemGap": 10,
            "itemWidth": 25,
            "itemHeight": 14
        }
    ],
    "tooltip": {
        "show": true,
        "trigger": "item",
        "triggerOn": "mousemove|click",
        "axisPointer": {
            "type": "line"
        },
        "showContent": true,
        "alwaysShowContent": false,
        "showDelay": 0,
        "hideDelay": 100,
        "textStyle": {
            "fontSize": 14
        },
        "borderWidth": 0,
        "padding": 5
    },
    "xAxis": [
        {
            "show": true,
            "scale": false,
            "nameLocation": "end",
            "nameGap": 15,
            "nameTextStyle": {
                "fontSize": 2
            },
            "gridIndex": 0,
            "axisLabel": {
                "rotate": -45,
                "interval": 0
            },
            "inverse": false,
            "offset": 0,
            "splitNumber": 5,
            "minInterval": 0,
            "splitLine": {
                "show": false,
                "lineStyle": {
                    "show": true,
                    "width": 1,
                    "opacity": 1,
                    "curveness": 0,
                    "type": "solid"
                }
            },
            "data": [
                "Aztecs",
                "Berbers",
                "Britons",
                "Bulgarians",
                "Burmese",
                "Byzantines",
                "Celts",
                "Chinese",
                "Cumans",
                "Ethiopians",
                "Franks",
                "Goths",
                "Huns",
                "Incas",
                "Indians",
                "Italians",
                "Japanese",
                "Khmer",
                "Koreans",
                "Lithuanians",
                "Magyars",
                "Malay",
                "Malians",
                "Mayans",
                "Mongols",
                "Persians",
                "Portuguese",
                "Saracens",
                "Slavs",
                "Spanish",
                "Tatars",
                "Teutons",
                "Turks",
                "Vietnamese",
                "Vikings"
            ]
        }
    ],
    "yAxis": [
        {
            "show": true,
            "scale": false,
            "nameLocation": "end",
            "nameGap": 15,
            "gridIndex": 0,
            "inverse": false,
            "offset": 0,
            "splitNumber": 5,
            "minInterval": 0,
            "splitLine": {
                "show": false,
                "lineStyle": {
                    "show": true,
                    "width": 1,
                    "opacity": 1,
                    "curveness": 0,
                    "type": "solid"
                }
            }
        }
    ],
    "title": [
        {
            "text": "1v1文明胜利场次统计🎊",
            "left": "center",
            "padding": 5,
            "itemGap": 10,
            "textStyle": {
                "fontFamily": "Fusion Pixel",
                "color": "rgba(0,0,0)",
                "fontSize": 30,
            }
        }
    ]
};

        // 使用刚指定的配置项和数据显示图表。
        myChart.setOption(option);
</script>


<script src="https://cdn.jsdelivr.net/npm/echarts@4.8.0/dist/echarts.min.js"></script>
<div id="echarts7650" style="width: 81%;height: 400px;margin: 0 auto"></div>

<script type="text/javascript">
        // 基于准备好的dom，初始化echarts实例
        var myChart = echarts.init(document.getElementById('echarts7650'));

        // 指定图表的配置项和数据
        var option = {
    "animation": true,
    "animationThreshold": 2000,
    "animationDuration": 1000,
    "animationEasing": "cubicOut",
    "animationDelay": 0,
    "animationDurationUpdate": 300,
    "animationEasingUpdate": "cubicOut",
    "animationDelayUpdate": 0,
    "color": [
        "#c23531",
        "#2f4554",
        "#61a0a8",
        "#d48265",
        "#749f83",
        "#ca8622",
        "#bda29a",
        "#6e7074",
        "#546570",
        "#c4ccd3",
        "#f05b72",
        "#ef5b9c",
        "#f47920",
        "#905a3d",
        "#fab27b",
        "#2a5caa",
        "#444693",
        "#726930",
        "#b2d235",
        "#6d8346",
        "#ac6767",
        "#1d953f",
        "#6950a1",
        "#918597"
    ],
    "series": [
        {
            "type": "bar",
            "name": "team",
            "legendHoverLink": true,
            "data": [
                65469,
                35800,
                160502,
                42498,
                37732,
                42589,
                61284,
                47902,
                68633,
                81460,
                207523,
                138029,
                79585,
                35575,
                63769,
                28364,
                45380,
                115044,
                23620,
                80297,
                65188,
                27862,
                25801,
                145722,
                136307,
                100364,
                27956,
                45416,
                37761,
                70665,
                30384,
                69509,
                37228,
                53787,
                70863
            ],
            "showBackground": false,
            "barMinHeight": 0,
            "barCategoryGap": 12,
            "barGap": "30%",
            "large": false,
            "largeThreshold": 400,
            "seriesLayoutBy": "column",
            "datasetIndex": 0,
            "clip": true,
            "zlevel": 0,
            "z": 2,
            "label": {
                "show": false,
                "position": "top",
                "margin": 8
            },
            "rippleEffect": {
                "show": true,
                "brushType": "stroke",
                "scale": 2.5,
                "period": 4
            }
        }
    ],
    "legend": [
        {
            "data": [
                "team"
            ],
            "selected": {
                "team": true
            },
            "show": false,
            "bottom": "bottom",
            "padding": 5,
            "itemGap": 10,
            "itemWidth": 25,
            "itemHeight": 14
        }
    ],
    "tooltip": {
        "show": true,
        "trigger": "item",
        "triggerOn": "mousemove|click",
        "axisPointer": {
            "type": "line"
        },
        "showContent": true,
        "alwaysShowContent": false,
        "showDelay": 0,
        "hideDelay": 100,
        "textStyle": {
            "fontSize": 14
        },
        "borderWidth": 0,
        "padding": 5
    },
    "xAxis": [
        {
            "show": true,
            "scale": false,
            "nameLocation": "end",
            "nameGap": 15,
            "nameTextStyle": {
                "fontSize": 2
            },
            "gridIndex": 0,
            "axisLabel": {
                "rotate": -45,
                "interval": 0
            },
            "inverse": false,
            "offset": 0,
            "splitNumber": 5,
            "minInterval": 0,
            "splitLine": {
                "show": false,
                "lineStyle": {
                    "show": true,
                    "width": 1,
                    "opacity": 1,
                    "curveness": 0,
                    "type": "solid"
                }
            },
            "data": [
                "Aztecs",
                "Berbers",
                "Britons",
                "Bulgarians",
                "Burmese",
                "Byzantines",
                "Celts",
                "Chinese",
                "Cumans",
                "Ethiopians",
                "Franks",
                "Goths",
                "Huns",
                "Incas",
                "Indians",
                "Italians",
                "Japanese",
                "Khmer",
                "Koreans",
                "Lithuanians",
                "Magyars",
                "Malay",
                "Malians",
                "Mayans",
                "Mongols",
                "Persians",
                "Portuguese",
                "Saracens",
                "Slavs",
                "Spanish",
                "Tatars",
                "Teutons",
                "Turks",
                "Vietnamese",
                "Vikings"
            ]
        }
    ],
    "yAxis": [
        {
            "show": true,
            "scale": false,
            "nameLocation": "end",
            "nameGap": 15,
            "gridIndex": 0,
            "inverse": false,
            "offset": 0,
            "splitNumber": 5,
            "minInterval": 0,
            "splitLine": {
                "show": false,
                "lineStyle": {
                    "show": true,
                    "width": 1,
                    "opacity": 1,
                    "curveness": 0,
                    "type": "solid"
                }
            }
        }
    ],
    "title": [
        {
            "text": "团战文明胜利场次统计🎊",
            "left": "center",
            "padding": 5,
            "itemGap": 10,
            "textStyle": {
                "fontFamily": "Fusion Pixel",
                "color": "rgba(0,0,0)",
                "fontSize": 30,
            }
        }
    ]
};

        // 使用刚指定的配置项和数据显示图表。
        myChart.setOption(option);
</script>

]]></content>
      <categories>
        <category>学习记录</category>
      </categories>
      <tags>
        <tag>帝国时代2</tag>
        <tag>数据分析</tag>
      </tags>
  </entry>
  <entry>
    <title>【学习记录】2022-7-22-2022-8-5</title>
    <url>/2022/08/03/%E5%AD%A6%E4%B9%A0%E8%AE%B0%E5%BD%952022-7-22/</url>
    <content><![CDATA[<p>要写一个yolov5+faceNet的人脸识别，没给定数据集和模型要求，所以我按<del>最高性价比</del>最摸鱼的原则进行构建。这个任务的由三部分组成的，首先是使用<code>Yolov5</code>完成人脸的识别并裁剪，随后用<code>FaceNet</code>进行特征的提取，最后使用提取的特征通过一个<code>classifier</code>完成人脸所属对象的识别。</p>
<p>测试用的demo使用了B站Up主<a href="https://space.bilibili.com/298054634">马哥巨离谱</a>的作品：<a href="https://www.bilibili.com/video/BV1z34y167KD?spm_id_from=333.999.0.0&amp;vd_source=ab34db443b112b108b42c31ac575fd1f">穿山甲之【广东分甲】</a>，人物共有五个，人脸信息分布也很足；FaceNet作为局部的信息提取，我是使用MobileNet作为主干网络，并使用了一些预训练的权重进行训练。至于最后的分类器，我觉就只用了一个FC就完成了，效果还算不错。</p>
<span id="more"></span>
<h1 id="Yolov5"><a href="#Yolov5" class="headerlink" title="Yolov5"></a>Yolov5</h1><p><img src="https://s2.loli.net/2022/07/25/AtufwTK238Z1sPR.png" alt="yolov5s_1"></p>
<center><small>Yolov5s结构，图源知乎@江大白</small></center>

<p>Yolov5其实就是一个大锅炉，整个网络就分为Backbone、Neck、head和prediction四个部分。可以看到Yolov5用到的模块还挺多的，下面简单的分析一下每个模块。</p>
<h2 id="Backbone部分"><a href="#Backbone部分" class="headerlink" title="Backbone部分"></a>Backbone部分</h2><p>Backbone就是用来提取主要的特征的。Backbone网络一般都很大，且有人训练好了一些权重，不用我们自己从头再训练，直接到官网下载模型权重就可以了。在训练时只需Finetune一下就可以了。</p>
<h3 id="CBL模块"><a href="#CBL模块" class="headerlink" title="CBL模块"></a>CBL模块</h3><p><code>CBL</code>其实就是卷积层BN层再加一个激活函数LeakyReLU。卷积层和BN层没啥好说的了，现在成功的网络结构的基本模块都是这样搭配，值得一提的是这个LeakyReLU，区别于传统ReLU的，它增强了非线性能力。</p>
<h3 id="Res模块"><a href="#Res模块" class="headerlink" title="Res模块"></a>Res模块</h3><p>就是改进过后的残差块。Kaiming的<code>ResNet</code>出来之后<code>ResBlock</code>的使用就广泛起来了，当今的网络发展趋势就是不断的加深、加参数，ResBlock的出现就是为了解决深度加大后的梯度弥散问题，跳跃连接可以将梯度信息不那么快的消失掉。</p>
<h3 id="Focus模块"><a href="#Focus模块" class="headerlink" title="Focus模块"></a>Focus模块</h3><p>这个其实我觉得挺关键的，作者也在<a href="https://github.com/ultralytics/yolov5/discussions/3181">Issue</a>有给出设计的目的。结论就是：减少参数和计算量。</p>
<p><img src="https://s2.loli.net/2022/07/25/kBKaHcQCPdO3RmV.png" alt="image-20220725125709651"></p>
<p>首先<code>Focus</code>模块是放在图像输入后的第一个位置，它使用了4个slice对图像进行分割，具体的操作是这样子的：</p>
<p><img src="https://s2.loli.net/2022/07/25/9scCXZ3rOhavUBQ.png" alt="slice操作"></p>
<center><small>Focus模块的Slice操作</small></center>

<p>具体就是在一张图片中每隔一个像素拿到一个值，按照图中这样的Slice方法可以得到4张图片（原始图像是<code>4*4*3</code>，新图像是<code>2*2*12</code>）。这样做的目的我的理解是将图像的宽、高信息转换到了通道channel中，然后这时图像大小类似下采样虽然缩小了一倍，但它蕴含的信息量并未减少，只是信息转换到了通道中，为后续的处理预留了方便吧。为什么这样说呢，首先要明确网络的参数和计算量的概念。</p>
<p><strong>网络的参数量（parmas）决定了网络的大小</strong>，由于一般使用<code>float32</code>进行保存，因此模型大小是参数量的4倍；<strong>计算量（FLOPs）即浮点运算数</strong>，可以用来衡量算法/模型的复杂度，这关系到算法速度，大模型的单位通常为G，小模型单位通常为M；通常只考虑乘加操作的数量，而且只考虑Conv和FC等参数层的计算量，忽略BN和PReLU等，一般情况下，Conv和FC层也会忽略仅纯加操作的计算量，如bias偏置加和shoutcut残差加等，目前技术有BN和CNN可以不加bias。</p>
<p>经过<code>Focus</code>模块后的图像类似经过了下采样的操作，但是和卷积实现的下采样不同，Slice不但减少了计算量也减少了参数。作者做了一个和Yolov3对比的实验：</p>
<p><img src="https://s2.loli.net/2022/07/25/mhyW6EGT37RCYuA.png" alt="image-20220725130745790"></p>
<h3 id="CSP模块"><a href="#CSP模块" class="headerlink" title="CSP模块"></a>CSP模块</h3><p>和Yolov4不同，CSP的结构在Yolov5中有两种，分别运用在Backbone和Neck部分，而在Yolov4中只有Backbone使用了CSP结构。CSP结构就是<strong>跨阶段局部网络（Cross Stage Paritial Network）</strong>，用于缓解以往工作需要从网络架构角度进行大量推理计算的问题，CSPNet作者认为这个问题的<strong>出现原因是网络优化中的重复梯度信息。</strong></p>
<p>简单总结一下CSP结构的有点：</p>
<ul>
<li>增强CNN的学习能力，在轻量化和准确性这两方面两手抓。</li>
<li>降低计算瓶颈。</li>
<li>降低内存成本。</li>
</ul>
<h2 id="Neck部分"><a href="#Neck部分" class="headerlink" title="Neck部分"></a>Neck部分</h2><p>Neck的作用就是更好的利用Backbone提取的特征进行更精细的划分。Yolov5最新的模型是使用了特征金字塔网络(FPN,Feature Pyramid Network)+路径聚合网络(PAN，Path Aggregation Network)结构。</p>
<h2 id="使用方法"><a href="#使用方法" class="headerlink" title="使用方法"></a>使用方法</h2><h3 id="制作数据集和配置文件"><a href="#制作数据集和配置文件" class="headerlink" title="制作数据集和配置文件"></a>制作数据集和配置文件</h3><p>首先使用<code>git clone</code>把Yolov5的代码给下载下来：</p>
<p><img src="https://s2.loli.net/2022/08/03/B9C1MgU4N7XrHdW.png" alt="image-20220727114737933"></p>
<p>然后再这个目录下新建一个文件夹，命名随意，但不用用已有的<code>data</code>。我这里用的是<code>Facedata</code>，然后在<code>Facedata</code>下面再新建两个文件夹<code>Annotations</code>和<code>images</code>，分别用于存储用<code>labelimg</code>标注的数据(<code>.xml</code>)和图片(<code>.jpg</code>)。</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">- yolov5</span><br><span class="line">	- Facedata</span><br><span class="line">		- Annotations</span><br><span class="line">			- 1.xml</span><br><span class="line">			- 2.xml</span><br><span class="line">			- ...</span><br><span class="line">		- images</span><br><span class="line">			- 1.jpg</span><br><span class="line">			- 2.jpg</span><br><span class="line">			- ...</span><br></pre></td></tr></table></figure>
<p>然后在自己数据集的文件夹下新建一个用于分离训练集和测试集的脚本<code>split_train_test.py</code>:</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># coding:utf-8</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> os</span><br><span class="line"><span class="keyword">import</span> random</span><br><span class="line"><span class="keyword">import</span> argparse</span><br><span class="line"></span><br><span class="line">parser = argparse.ArgumentParser()</span><br><span class="line"><span class="comment">#xml文件的地址，根据自己的数据进行修改 xml一般存放在Annotations下</span></span><br><span class="line">parser.add_argument(<span class="string">&#x27;--xml_path&#x27;</span>, default=<span class="string">&#x27;Annotations&#x27;</span>, <span class="built_in">type</span>=<span class="built_in">str</span>, <span class="built_in">help</span>=<span class="string">&#x27;input xml label path&#x27;</span>)</span><br><span class="line"><span class="comment">#数据集的划分，地址选择自己数据下的ImageSets/Main</span></span><br><span class="line">parser.add_argument(<span class="string">&#x27;--txt_path&#x27;</span>, default=<span class="string">&#x27;ImageSets/Main&#x27;</span>, <span class="built_in">type</span>=<span class="built_in">str</span>, <span class="built_in">help</span>=<span class="string">&#x27;output txt label path&#x27;</span>)</span><br><span class="line">opt = parser.parse_args()</span><br><span class="line"></span><br><span class="line">trainval_percent = <span class="number">1.0</span>  <span class="comment"># 训练集和验证集所占比例。 这里没有划分测试集</span></span><br><span class="line">train_percent = <span class="number">0.9</span>     <span class="comment"># 训练集所占比例，可自己进行调整</span></span><br><span class="line">xmlfilepath = opt.xml_path</span><br><span class="line">txtsavepath = opt.txt_path</span><br><span class="line">total_xml = os.listdir(xmlfilepath)</span><br><span class="line"><span class="keyword">if</span> <span class="keyword">not</span> os.path.exists(txtsavepath):</span><br><span class="line">    os.makedirs(txtsavepath)</span><br><span class="line"></span><br><span class="line">num = <span class="built_in">len</span>(total_xml)</span><br><span class="line">list_index = <span class="built_in">range</span>(num)</span><br><span class="line">tv = <span class="built_in">int</span>(num * trainval_percent)</span><br><span class="line">tr = <span class="built_in">int</span>(tv * train_percent)</span><br><span class="line">trainval = random.sample(list_index, tv)</span><br><span class="line">train = random.sample(trainval, tr)</span><br><span class="line"></span><br><span class="line">file_trainval = <span class="built_in">open</span>(txtsavepath + <span class="string">&#x27;/trainval.txt&#x27;</span>, <span class="string">&#x27;w&#x27;</span>)</span><br><span class="line">file_test = <span class="built_in">open</span>(txtsavepath + <span class="string">&#x27;/test.txt&#x27;</span>, <span class="string">&#x27;w&#x27;</span>)</span><br><span class="line">file_train = <span class="built_in">open</span>(txtsavepath + <span class="string">&#x27;/train.txt&#x27;</span>, <span class="string">&#x27;w&#x27;</span>)</span><br><span class="line">file_val = <span class="built_in">open</span>(txtsavepath + <span class="string">&#x27;/val.txt&#x27;</span>, <span class="string">&#x27;w&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> list_index:</span><br><span class="line">    name = total_xml[i][:-<span class="number">4</span>] + <span class="string">&#x27;\n&#x27;</span></span><br><span class="line">    <span class="keyword">if</span> i <span class="keyword">in</span> trainval:</span><br><span class="line">        file_trainval.write(name)</span><br><span class="line">        <span class="keyword">if</span> i <span class="keyword">in</span> train:</span><br><span class="line">            file_train.write(name)</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            file_val.write(name)</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        file_test.write(name)</span><br><span class="line"></span><br><span class="line">file_trainval.close()</span><br><span class="line">file_train.close()</span><br><span class="line">file_val.close()</span><br><span class="line">file_test.close()</span><br></pre></td></tr></table></figure>
<p>然后同样是在这个目录下新建<code>xml_to_yolo.py</code>文件，这个主要是用来转换yolov5训练的格式(<code>.txt</code>)，代码如下：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> xml.etree.ElementTree <span class="keyword">as</span> ET</span><br><span class="line"><span class="keyword">import</span> os</span><br><span class="line"><span class="keyword">from</span> os <span class="keyword">import</span> getcwd</span><br><span class="line"></span><br><span class="line">sets = [<span class="string">&#x27;train&#x27;</span>, <span class="string">&#x27;val&#x27;</span>, <span class="string">&#x27;test&#x27;</span>]</span><br><span class="line">classes = [<span class="string">&quot;face&quot;</span>]   <span class="comment"># 改成自己的类别</span></span><br><span class="line">abs_path = os.getcwd()</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">convert</span>(<span class="params">size, box</span>):</span><br><span class="line">    dw = <span class="number">1.</span> / (size[<span class="number">0</span>])</span><br><span class="line">    dh = <span class="number">1.</span> / (size[<span class="number">1</span>])</span><br><span class="line">    x = (box[<span class="number">0</span>] + box[<span class="number">1</span>]) / <span class="number">2.0</span> - <span class="number">1</span></span><br><span class="line">    y = (box[<span class="number">2</span>] + box[<span class="number">3</span>]) / <span class="number">2.0</span> - <span class="number">1</span></span><br><span class="line">    w = box[<span class="number">1</span>] - box[<span class="number">0</span>]</span><br><span class="line">    h = box[<span class="number">3</span>] - box[<span class="number">2</span>]</span><br><span class="line">    x = x * dw</span><br><span class="line">    w = w * dw</span><br><span class="line">    y = y * dh</span><br><span class="line">    h = h * dh</span><br><span class="line">    <span class="keyword">return</span> x, y, w, h</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">convert_annotation</span>(<span class="params">image_id</span>):</span><br><span class="line">    in_file = <span class="built_in">open</span>(<span class="string">&#x27;yolov5\\Facedata\\Annotations\\%s.xml&#x27;</span> % (image_id), encoding=<span class="string">&#x27;UTF-8&#x27;</span>)</span><br><span class="line">    out_file = <span class="built_in">open</span>(<span class="string">&#x27;yolov5\\Facedata\\labels\\%s.txt&#x27;</span> % (image_id), <span class="string">&#x27;w&#x27;</span>)</span><br><span class="line">    tree = ET.parse(in_file)</span><br><span class="line">    root = tree.getroot()</span><br><span class="line">    size = root.find(<span class="string">&#x27;size&#x27;</span>)</span><br><span class="line">    w = <span class="built_in">int</span>(size.find(<span class="string">&#x27;width&#x27;</span>).text)</span><br><span class="line">    h = <span class="built_in">int</span>(size.find(<span class="string">&#x27;height&#x27;</span>).text)</span><br><span class="line">    <span class="keyword">for</span> obj <span class="keyword">in</span> root.<span class="built_in">iter</span>(<span class="string">&#x27;object&#x27;</span>):</span><br><span class="line">        difficult = obj.find(<span class="string">&#x27;difficult&#x27;</span>).text</span><br><span class="line">        </span><br><span class="line">        <span class="comment">#difficult = obj.find(&#x27;Difficult&#x27;).text</span></span><br><span class="line">        cls = obj.find(<span class="string">&#x27;name&#x27;</span>).text</span><br><span class="line">        <span class="keyword">if</span> cls <span class="keyword">not</span> <span class="keyword">in</span> classes <span class="keyword">or</span> <span class="built_in">int</span>(difficult) == <span class="number">1</span>:</span><br><span class="line">            <span class="keyword">continue</span></span><br><span class="line">        cls_id = classes.index(cls)</span><br><span class="line">        xmlbox = obj.find(<span class="string">&#x27;bndbox&#x27;</span>)</span><br><span class="line">        b = (<span class="built_in">float</span>(xmlbox.find(<span class="string">&#x27;xmin&#x27;</span>).text), <span class="built_in">float</span>(xmlbox.find(<span class="string">&#x27;xmax&#x27;</span>).text), <span class="built_in">float</span>(xmlbox.find(<span class="string">&#x27;ymin&#x27;</span>).text),</span><br><span class="line">             <span class="built_in">float</span>(xmlbox.find(<span class="string">&#x27;ymax&#x27;</span>).text))</span><br><span class="line">        b1, b2, b3, b4 = b</span><br><span class="line">        <span class="comment"># 标注越界修正</span></span><br><span class="line">        <span class="keyword">if</span> b2 &gt; w:</span><br><span class="line">            b2 = w</span><br><span class="line">        <span class="keyword">if</span> b4 &gt; h:</span><br><span class="line">            b4 = h</span><br><span class="line">        b = (b1, b2, b3, b4)</span><br><span class="line">        bb = convert((w, h), b)</span><br><span class="line">        </span><br><span class="line">        out_file.write(<span class="built_in">str</span>(cls_id) + <span class="string">&quot; &quot;</span> + <span class="string">&quot; &quot;</span>.join([<span class="built_in">str</span>(a) <span class="keyword">for</span> a <span class="keyword">in</span> bb]) + <span class="string">&#x27;\n&#x27;</span>)</span><br><span class="line">        </span><br><span class="line">        </span><br><span class="line"></span><br><span class="line">wd = getcwd()</span><br><span class="line"><span class="keyword">for</span> image_set <span class="keyword">in</span> sets:</span><br><span class="line">    <span class="keyword">if</span> <span class="keyword">not</span> os.path.exists(<span class="string">&#x27;yolov5\\Facedata\\labels&#x27;</span>):</span><br><span class="line">        os.makedirs(<span class="string">&#x27;yolov5\\Facedata\\labels&#x27;</span>)</span><br><span class="line">    image_ids = <span class="built_in">open</span>(<span class="string">&#x27;yolov5\\Facedata\\ImageSets\\Main\\%s.txt&#x27;</span> % (image_set)).read().strip().split()</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">if</span> <span class="keyword">not</span> os.path.exists(<span class="string">&#x27;yolov5\\Facedata\\dataSet_path&#x27;</span>):</span><br><span class="line">        os.makedirs(<span class="string">&#x27;yolov5\\Facedata\\dataSet_path&#x27;</span>)</span><br><span class="line">     </span><br><span class="line">    list_file = <span class="built_in">open</span>(<span class="string">&#x27;yolov5\\Facedata\\dataSet_path\\%s.txt&#x27;</span> % (image_set), <span class="string">&#x27;w&#x27;</span>)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> image_id <span class="keyword">in</span> image_ids:</span><br><span class="line">        list_file.write(<span class="string">&#x27;yolov5\\Facedata\\images\\%s.jpg\n&#x27;</span> % (image_id))</span><br><span class="line">        convert_annotation(image_id)</span><br><span class="line">    list_file.close()</span><br></pre></td></tr></table></figure>
<p>然后到Yolov5文件夹下的data文件夹新建自己的数据库索引文件<code>Facedata.yaml</code>:</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="attr">train:</span> <span class="string">F:/Programme/Demo/FaceDetection/yolov5/Facedata/dataSet_path/train.txt</span></span><br><span class="line"><span class="attr">val:</span> <span class="string">F:/Programme/Demo/FaceDetection/yolov5/Facedata/dataSet_path/val.txt</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># number of classes</span></span><br><span class="line"><span class="attr">nc:</span> <span class="number">1</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># class names</span></span><br><span class="line"><span class="attr">names:</span> [<span class="string">&quot;face&quot;</span>]</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<p>最后在<code>model</code>文件夹中选择使用的模型，我选的是<code>Yolov5s.yaml</code>，然后修改一下nc对应的数量就可以了。</p>
<h3 id="正式训练"><a href="#正式训练" class="headerlink" title="正式训练"></a>正式训练</h3><p>正式训练是在这个<code>train.py</code>的文件里。打开看一下可以看到很多的参数：</p>
<p><img src="https://s2.loli.net/2022/07/27/jIfv8VZgLep4OHt.png" alt="image-20220727170725337"></p>
<p>主要是修改以下几个东西：</p>
<ul>
<li><code>--weights</code>：初始权重，要和模型对应，脚本会从官网下载预训练好的权重。</li>
<li><code>--data</code>：训练数据配置文件<code>xxx.yaml</code>，存放在Yolov5文件夹下的<code>data</code>文件夹中</li>
<li><code>--epochs</code>：训练轮数，一般来说小数据（不到一千张）100轮左右就有结果了。</li>
<li><code>--batch-size</code>：取决于设备内存大小，我设置为16。</li>
<li><code>device</code>：用于训练的设备，一般个人单显卡且有CUDA环境支持的话就设成0就好。</li>
<li><code>workers</code>：似乎是CPU核心控制的线程数量，电脑配置低一点的就设成0或者1就好。</li>
</ul>
<h3 id="使用训练后的模型"><a href="#使用训练后的模型" class="headerlink" title="使用训练后的模型"></a>使用训练后的模型</h3><p>测试模型的话，在yolov5的文件夹下方有一个<code>detect.py</code>的文件，按照代码的说明修改程序就可以测试了。测试的结果是放在<code>runs/detect/expx/</code>的文件夹中。</p>
<h3 id="如何部署自定义模型"><a href="#如何部署自定义模型" class="headerlink" title="如何部署自定义模型"></a>如何部署自定义模型</h3><p>如果图省事的话，可以用<code>pytorchhub</code>直接加载集成好的环境，具体的操作可以见<a href="https://github.com/ultralytics/yolov5/issues/36">作者写的Documentation</a>：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"></span><br><span class="line"><span class="comment"># Model</span></span><br><span class="line">model = torch.hub.load(<span class="string">&#x27;yolov5&#x27;</span>, <span class="string">&#x27;custom&#x27;</span>, path=<span class="string">&#x27;best&#x27;</span>, source=<span class="string">&#x27;local&#x27;</span>) </span><br><span class="line"><span class="comment"># Image</span></span><br><span class="line">img = <span class="string">r&#x27;dataset\video\VideoCapture\9.jpg&#x27;</span></span><br><span class="line"><span class="comment"># Inference</span></span><br><span class="line">results = model(img)</span><br><span class="line"><span class="built_in">print</span>(results.pandas().xyxy[<span class="number">0</span>])</span><br><span class="line"><span class="comment">#         xmin        ymin        xmax        ymax  confidence  class  name</span></span><br><span class="line"><span class="comment">#0  714.960083  141.053375  932.943726  412.439209    0.924156      0  face</span></span><br></pre></td></tr></table></figure>
<p>甚至可以使用<code>ndarrays</code>作为输入：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> cv2</span><br><span class="line"><span class="comment"># Model</span></span><br><span class="line">model = torch.hub.load(<span class="string">&#x27;yolov5&#x27;</span>, <span class="string">&#x27;custom&#x27;</span>, path=<span class="string">&#x27;best&#x27;</span>, source=<span class="string">&#x27;local&#x27;</span>) </span><br><span class="line"><span class="comment"># Image</span></span><br><span class="line">img = <span class="string">r&#x27;F:\Programme\Demo\FaceDetection\dataset\video\VideoCapture\9.jpg&#x27;</span></span><br><span class="line">img = cv2.imread(img)</span><br><span class="line"><span class="built_in">print</span>(<span class="built_in">type</span>(img))</span><br><span class="line"><span class="comment"># &lt;class &#x27;numpy.ndarray&#x27;&gt;</span></span><br><span class="line"><span class="comment"># Inference</span></span><br><span class="line">results = model(img)</span><br><span class="line"><span class="built_in">print</span>(results.pandas().xyxy[<span class="number">0</span>])</span><br><span class="line"><span class="comment">#         xmin        ymin        xmax        ymax  confidence  class  name</span></span><br><span class="line"><span class="comment">#0  714.960083  141.053375  932.943726  412.439209    0.924156      0  face</span></span><br></pre></td></tr></table></figure>
<p>但如果想进一步拓展Yolov5的输入端性能的话，<code>Yolov5</code>的作者把跟<code>Pytorchhub</code>加载的模型相关的内容放在了<code>models/common.py</code>里面，它的核心功能靠两个类<code>AutoShape</code>和<code>Detections</code>完成，其中<code>AutoShape</code>完成了模型的核心，<code>Detections</code>完成结果的展示以及渲染。用好这两个类足够完成大部分的输入任务了。</p>
<h2 id="用Yolov5的预测结果获取人脸数据的训练集"><a href="#用Yolov5的预测结果获取人脸数据的训练集" class="headerlink" title="用Yolov5的预测结果获取人脸数据的训练集"></a>用Yolov5的预测结果获取人脸数据的训练集</h2><p>观察到模型输出的信息：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment">#         xmin        ymin        xmax        ymax  confidence  class  name</span></span><br><span class="line"><span class="comment">#0  714.960083  141.053375  932.943726  412.439209    0.924156      0  face</span></span><br></pre></td></tr></table></figure>
<p>是使用<code>pandas.DataFrame</code>类表示的，且内取值为浮点数。因此需要对数据进行抽取排序以及取整处理：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">crop_images</span>(<span class="params">file_path, file_name, save_dir</span>):</span><br><span class="line">    <span class="comment"># file_path: 文件路径</span></span><br><span class="line">    <span class="comment"># file_name: 文件名称</span></span><br><span class="line">    <span class="comment"># save_dir:  保存路径</span></span><br><span class="line">    img = cv2.imread(file_path)</span><br><span class="line">    results = model(img)</span><br><span class="line">    df = results.pandas().xyxy[<span class="number">0</span>]</span><br><span class="line">    <span class="keyword">for</span> index, row <span class="keyword">in</span> df.iterrows():</span><br><span class="line">        xmin, ymin, xmax, ymax = <span class="built_in">int</span>(row[<span class="string">&#x27;xmin&#x27;</span>]), <span class="built_in">int</span>(row[<span class="string">&#x27;ymin&#x27;</span>]), <span class="built_in">int</span>(row[<span class="string">&#x27;xmax&#x27;</span>]), <span class="built_in">int</span>(row[<span class="string">&#x27;ymax&#x27;</span>])</span><br><span class="line">        crop = img[ymin : ymax, xmin : xmax]</span><br><span class="line">        cv2.imwrite(<span class="string">r&#x27;&#123;&#125;\&#123;&#125;-&#123;&#125;.jpg&#x27;</span>.<span class="built_in">format</span>(save_dir, file_name[:-<span class="number">4</span>], index), crop)   <span class="comment"># index是图像识别中的第x个对象</span></span><br></pre></td></tr></table></figure>
<p>随后使用模型裁剪人脸数据：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># Easy way to use customed yolov5 model to predict</span></span><br><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> cv2</span><br><span class="line"><span class="keyword">import</span> os</span><br><span class="line"></span><br><span class="line"><span class="comment"># Model</span></span><br><span class="line">model = torch.hub.load(<span class="string">&#x27;yolov5&#x27;</span>, <span class="string">&#x27;custom&#x27;</span>, path=<span class="string">&#x27;best&#x27;</span>, source=<span class="string">&#x27;local&#x27;</span>) </span><br><span class="line"><span class="comment"># Inference</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">crop_images</span>(<span class="params">file_path, file_name, save_dir</span>):</span><br><span class="line">    <span class="comment"># file_path: 文件路径</span></span><br><span class="line">    <span class="comment"># file_name: 文件名称</span></span><br><span class="line">    <span class="comment"># save_dir:  保存路径</span></span><br><span class="line">    img = cv2.imread(file_path)</span><br><span class="line">    results = model(img)</span><br><span class="line">    df = results.pandas().xyxy[<span class="number">0</span>]</span><br><span class="line">    <span class="keyword">for</span> index, row <span class="keyword">in</span> df.iterrows():</span><br><span class="line">        xmin, ymin, xmax, ymax = <span class="built_in">int</span>(row[<span class="string">&#x27;xmin&#x27;</span>]), <span class="built_in">int</span>(row[<span class="string">&#x27;ymin&#x27;</span>]), <span class="built_in">int</span>(row[<span class="string">&#x27;xmax&#x27;</span>]), <span class="built_in">int</span>(row[<span class="string">&#x27;ymax&#x27;</span>])</span><br><span class="line">        crop = img[ymin : ymax, xmin : xmax]</span><br><span class="line">        cv2.imwrite(<span class="string">r&#x27;&#123;&#125;\&#123;&#125;-&#123;&#125;.jpg&#x27;</span>.<span class="built_in">format</span>(save_dir, file_name[:-<span class="number">4</span>], index), crop)   <span class="comment"># index是图像识别中的第x个对象</span></span><br><span class="line">        </span><br><span class="line"></span><br><span class="line">path = <span class="string">r&#x27;dataset\raw&#x27;</span></span><br><span class="line">files= os.listdir(path) <span class="comment">#得到文件夹下的所有文件名称</span></span><br><span class="line"><span class="keyword">for</span> each <span class="keyword">in</span> files:</span><br><span class="line">    crop_images(<span class="string">r&#x27;dataset\raw\&#123;&#125;&#x27;</span>.<span class="built_in">format</span>(each), each, save_dir=<span class="string">r&#x27;dataset\train&#x27;</span>)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&#x27;file &#123;&#125; has been crop.&#x27;</span>.<span class="built_in">format</span>(each))</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<p>得到后人工对人脸进行分类放入不同类别的文件夹中。</p>
<h1 id="FaceNet"><a href="#FaceNet" class="headerlink" title="FaceNet+"></a>FaceNet+</h1><p>论文链接：<a href="https://arxiv.org/abs/1503.03832">[1503.03832] FaceNet: A Unified Embedding for Face Recognition and Clustering (arxiv.org)</a>。FaceNet是谷歌提出的，特点是CNN的端到端训练、Triplet loss 以及 特征欧几里得距离，模型大小仅有128Bytes，达到了当时的SOTA水平。论文使用的模型如下：</p>
<p><img src="https://s2.loli.net/2022/08/02/bWgmUj4fKGweoMr.png" alt="image-20220802190434704" style="zoom: 80%;" /></p>
<h2 id="网络部分"><a href="#网络部分" class="headerlink" title="网络部分"></a>网络部分</h2><p>论文当时的Backbone使用的是<code>Inception-net</code>的结构，然后后续为了更加轻便的部署我又更换成了<code>MobileNet-v1</code>的结构。下面的内容主要针对的是<code>MobileNet-V1</code>。</p>
<h3 id="深度可分离卷积"><a href="#深度可分离卷积" class="headerlink" title="深度可分离卷积"></a>深度可分离卷积</h3><p>首先<code>MobileNet</code>也是谷歌提出来的，它的核心组件是一种叫做<code>“深度可分离卷积块”</code>的结构组成的，其结构如下：</p>
<p><img src="https://s2.loli.net/2022/08/02/WAr5wIh4ZbStVuF.jpg" alt="img"></p>
<p>其具体的解析在<a href="https://towardsdatascience.com/a-basic-introduction-to-separable-convolutions-b99ec3102728">这篇文章</a>有。深度可分离卷积块由两部分组成，分别为<code>Depthwise Convolutional Filters</code>和<code>Pointwise Convolutional Filters</code>。深度可分离卷积块的目的是使用更少的参数来代替普通的卷积。下面给出普通卷积和可分离卷积的对比：</p>
<p><img src="https://s2.loli.net/2022/08/02/ChxozZ3PRFp2nyO.png" alt="img" style="zoom: 33%;" /></p>
<center><small>普通卷积，对于12*12*3->8*8*256的映射需要256个[5,5,3]的卷积核，<br>参数量为256 x 5 x 5 x 3 = 19200</small></center>

<p><img src="https://s2.loli.net/2022/08/02/LKJy9svTaERXUZS.png" alt="img" style="zoom: 33%;" /></p>
<p><img src="https://s2.loli.net/2022/08/02/quI9WnQZ4kzRDKo.png" alt="img" style="zoom: 33%;" /></p>
<center><small>可分离卷积，对于12*12*3->8*8*256的映射需要3个[5,5,1]的卷积核(Depthwise)和256个[1,1,3]的卷积核(Pointwise)<br>参数量为3 x 5 x 5 x 1 + 256 x 1 x 1 x 3 = 843</small></center>

<p>可以看出来深度可分离卷积结构块可以减少模型的参数。</p>
<h3 id="网络结构"><a href="#网络结构" class="headerlink" title="网络结构"></a>网络结构</h3><p>网络结构由Backbone+Classifier两个部分组成。Backbone前文也提及到使用的是<code>MobileNet</code>，而<code>Classifier</code>则是一个多层感知机。师兄给了一篇参考的博客给我看，他的<code>Classifier</code>用的是<code>SVM</code>，我能理解这样做的目的，舍弃了端到端的直观过程，让神经网络的黑盒少了最后那部分的可解释性差的问题。但是这样就很麻烦，部署起来很费时间，所以我最终还是选择了用MLP作为分类器，还有一个原因我会放在后面的训练技巧部分那里说。</p>
<p>Backbone部分的代码：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> torch.nn <span class="keyword">as</span> nn</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">conv_bn</span>(<span class="params">inp, oup, stride = <span class="number">1</span></span>):</span><br><span class="line">    <span class="keyword">return</span> nn.Sequential(</span><br><span class="line">        nn.Conv2d(inp, oup, <span class="number">3</span>, stride, <span class="number">1</span>, bias=<span class="literal">False</span>),</span><br><span class="line">        nn.BatchNorm2d(oup),</span><br><span class="line">        nn.ReLU6()</span><br><span class="line">    )</span><br><span class="line">    </span><br><span class="line"><span class="keyword">def</span> <span class="title function_">conv_dw</span>(<span class="params">inp, oup, stride = <span class="number">1</span></span>):</span><br><span class="line">    <span class="keyword">return</span> nn.Sequential(</span><br><span class="line">        nn.Conv2d(inp, inp, <span class="number">3</span>, stride, <span class="number">1</span>, groups=inp, bias=<span class="literal">False</span>),</span><br><span class="line">        nn.BatchNorm2d(inp),</span><br><span class="line">        nn.ReLU6(),</span><br><span class="line"></span><br><span class="line">        nn.Conv2d(inp, oup, <span class="number">1</span>, <span class="number">1</span>, <span class="number">0</span>, bias=<span class="literal">False</span>),</span><br><span class="line">        nn.BatchNorm2d(oup),</span><br><span class="line">        nn.ReLU6(),</span><br><span class="line">    )</span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">MobileNetV1</span>(nn.Module):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="built_in">super</span>(MobileNetV1, self).__init__()</span><br><span class="line">        self.stage1 = nn.Sequential(</span><br><span class="line">            <span class="comment"># 160,160,3 -&gt; 80,80,32</span></span><br><span class="line">            conv_bn(<span class="number">3</span>, <span class="number">32</span>, <span class="number">2</span>), </span><br><span class="line">            <span class="comment"># 80,80,32 -&gt; 80,80,64</span></span><br><span class="line">            conv_dw(<span class="number">32</span>, <span class="number">64</span>, <span class="number">1</span>), </span><br><span class="line"></span><br><span class="line">            <span class="comment"># 80,80,64 -&gt; 40,40,128</span></span><br><span class="line">            conv_dw(<span class="number">64</span>, <span class="number">128</span>, <span class="number">2</span>),</span><br><span class="line">            conv_dw(<span class="number">128</span>, <span class="number">128</span>, <span class="number">1</span>),</span><br><span class="line"></span><br><span class="line">            <span class="comment"># 40,40,128 -&gt; 20,20,256</span></span><br><span class="line">            conv_dw(<span class="number">128</span>, <span class="number">256</span>, <span class="number">2</span>),</span><br><span class="line">            conv_dw(<span class="number">256</span>, <span class="number">256</span>, <span class="number">1</span>),</span><br><span class="line">        )</span><br><span class="line">        self.stage2 = nn.Sequential(</span><br><span class="line">            <span class="comment"># 20,20,256 -&gt; 10,10,512</span></span><br><span class="line">            conv_dw(<span class="number">256</span>, <span class="number">512</span>, <span class="number">2</span>),</span><br><span class="line">            conv_dw(<span class="number">512</span>, <span class="number">512</span>, <span class="number">1</span>),</span><br><span class="line">            conv_dw(<span class="number">512</span>, <span class="number">512</span>, <span class="number">1</span>),</span><br><span class="line">            conv_dw(<span class="number">512</span>, <span class="number">512</span>, <span class="number">1</span>),</span><br><span class="line">            conv_dw(<span class="number">512</span>, <span class="number">512</span>, <span class="number">1</span>),</span><br><span class="line">            conv_dw(<span class="number">512</span>, <span class="number">512</span>, <span class="number">1</span>),</span><br><span class="line">        )</span><br><span class="line">        self.stage3 = nn.Sequential(</span><br><span class="line">            <span class="comment"># 10,10,512 -&gt; 5,5,1024</span></span><br><span class="line">            conv_dw(<span class="number">512</span>, <span class="number">1024</span>, <span class="number">2</span>),</span><br><span class="line">            conv_dw(<span class="number">1024</span>, <span class="number">1024</span>, <span class="number">1</span>),</span><br><span class="line">        )</span><br><span class="line"></span><br><span class="line">        self.avg = nn.AdaptiveAvgPool2d((<span class="number">1</span>,<span class="number">1</span>))</span><br><span class="line">        self.fc = nn.Linear(<span class="number">1024</span>, <span class="number">1000</span>)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, x</span>):</span><br><span class="line">        x = self.stage1(x)</span><br><span class="line">        x = self.stage2(x)</span><br><span class="line">        x = self.stage3(x)</span><br><span class="line">        x = self.avg(x)</span><br><span class="line">        <span class="comment"># x = self.model(x)</span></span><br><span class="line">        x = x.view(-<span class="number">1</span>, <span class="number">1024</span>)</span><br><span class="line">        x = self.fc(x)</span><br><span class="line">        <span class="keyword">return</span> x</span><br></pre></td></tr></table></figure>
<p>FaceNet的代码：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">Facenet</span>(nn.Module):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, backbone=<span class="string">&quot;mobilenet&quot;</span>, dropout_keep_prob=<span class="number">0.5</span>, embedding_size=<span class="number">128</span>, num_classes=<span class="literal">None</span>, mode=<span class="string">&quot;train&quot;</span></span>):</span><br><span class="line">        <span class="built_in">super</span>(Facenet, self).__init__()</span><br><span class="line">        <span class="keyword">if</span> backbone == <span class="string">&quot;mobilenet&quot;</span>:</span><br><span class="line">            self.backbone = mobilenet()</span><br><span class="line">            flat_shape = <span class="number">1024</span></span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            <span class="keyword">raise</span> ValueError(<span class="string">&#x27;Unsupported backbone - `&#123;&#125;`, Use mobilenet.&#x27;</span>.<span class="built_in">format</span>(backbone))</span><br><span class="line">        self.avg = nn.AdaptiveAvgPool2d((<span class="number">1</span>,<span class="number">1</span>))</span><br><span class="line">        self.Dropout = nn.Dropout(<span class="number">1</span> - dropout_keep_prob)</span><br><span class="line">        self.Bottleneck = nn.Linear(flat_shape, embedding_size,bias=<span class="literal">False</span>)</span><br><span class="line">        self.last_bn = nn.BatchNorm1d(embedding_size, eps=<span class="number">0.001</span>, momentum=<span class="number">0.1</span>, affine=<span class="literal">True</span>)</span><br><span class="line">        <span class="keyword">if</span> mode == <span class="string">&quot;train&quot;</span>:</span><br><span class="line">            self.classifier = nn.Linear(embedding_size, num_classes)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, x</span>):</span><br><span class="line">        x = self.backbone(x)</span><br><span class="line">        x = self.avg(x)</span><br><span class="line">        x = x.view(x.size(<span class="number">0</span>), -<span class="number">1</span>)</span><br><span class="line">        x = self.Dropout(x)</span><br><span class="line">        x = self.Bottleneck(x)</span><br><span class="line">        x = self.last_bn(x)</span><br><span class="line">        x = F.normalize(x, p=<span class="number">2</span>, dim=<span class="number">1</span>)</span><br><span class="line">        <span class="keyword">return</span> x</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward_feature</span>(<span class="params">self, x</span>):</span><br><span class="line">        x = self.backbone(x)</span><br><span class="line">        x = self.avg(x)</span><br><span class="line">        x = x.view(x.size(<span class="number">0</span>), -<span class="number">1</span>)</span><br><span class="line">        x = self.Dropout(x)</span><br><span class="line">        x = self.Bottleneck(x)</span><br><span class="line">        before_normalize = self.last_bn(x)</span><br><span class="line">        x = F.normalize(before_normalize, p=<span class="number">2</span>, dim=<span class="number">1</span>)</span><br><span class="line">        <span class="keyword">return</span> before_normalize, x</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward_classifier</span>(<span class="params">self, x</span>):</span><br><span class="line">        x = self.classifier(x)</span><br><span class="line">        <span class="keyword">return</span> x</span><br></pre></td></tr></table></figure>
<h2 id="Loss部分"><a href="#Loss部分" class="headerlink" title="Loss部分"></a>Loss部分</h2><p>FaceNet使用了<code>Triplet Loss</code>。这个Loss的目的是：对于一张人脸图片<code>Anchor</code>输入$x_i^a$，通过神经网络$f(x)$的映射到$d$维特征空间$\Bbb R^d$的结果$f(x_i^a)$和所有的正样本<code>Positive</code>的结果(和Anchor输入的类别相同的所有照片的$d$维特征空间结果$f(x_i^p)$)的欧式距离最短，而与所有的负样本<code>Negative</code>（和Anchor输入的类别不同的所有照片的$d$维特征空间结果$f(x_i^n)$）的欧氏距离最长，如图所示：</p>
<p><img src="https://s2.loli.net/2022/08/02/OYi8dzawNkR26Vf.png" alt="image-20220802195743710" style="zoom:80%;" /></p>
<p>用公式表示一下这个<strong>约束条件</strong>就是：</p>
<script type="math/tex; mode=display">
||f(x_i^a)-f(x_i^p)||_2^2+\alpha<||f(x_i^a)-f(x_i^n)||_2^2,\\
\forall (f(x_i^a),f(x_i^p),f(x_i^n))\in\tau</script><p>其中，$\alpha$是规定的正负样本的边界距离，$\tau$代表的是三元组的每一组基组成的$N$维空间。对于这种情况，网络的优化目标就是最小化这个式子：</p>
<script type="math/tex; mode=display">
\sum_i^N{[||f(x_i^a)-f(x_i^p)||_2^2+\alpha-||f(x_i^a)-f(x_i^n)||_2^2]}_+</script><h2 id="训练技巧"><a href="#训练技巧" class="headerlink" title="训练技巧"></a>训练技巧</h2><h3 id="三元组Triplet的选择"><a href="#三元组Triplet的选择" class="headerlink" title="三元组Triplet的选择"></a>三元组Triplet的选择</h3><p>上文提到，把所有可能的三元组构建出来是非常耗时的，而且大部分的式子都能满足<strong>约束条件</strong>，而神经网络是一个基于差别进行反馈修正的系统，因此较小的Loss其实对训练的结果修改并没有很大的意义。举个例子，备战高考，在做往年题的时候发现自己的立体几何做得很强，但是导数题做得一塌糊涂漏洞百出。这个时候就需要专攻薄弱环节导数题进行训练，因为薄弱环节的提分可以最大程度地拉升和满分之间的差距（减小Loss，提高Accuracy）。基于这种想法，我们直接选择那些违背了约束条件的三元组进行训练即可。（但在实际的训练中，我将直接选择更改为了随机选择，因为考虑到模型的泛化性能我对违背约束条件的三元组的选择是以0.2的概率进行抽样送往网络训练）</p>
<h3 id="分类器的辅助训练"><a href="#分类器的辅助训练" class="headerlink" title="分类器的辅助训练"></a>分类器的辅助训练</h3><p>FaceNet输出的其实是要给长度为128的特征向量，下一步的分类器根据特征向量分类才输出最终的分类结果。仅仅使用Triplet Loss会难以让网络收敛，因此在训练过程中可以再加上一个MLP作为训练器，使用Cross-Entropy作为辅助Triplet-Loss收敛。这样做的话其实就已经自带了一个<code>Classifier</code>了，不再需要额外的训练。这就是为什么之前提到不使用SVM等等一类的分类算法进行最后的分类器。</p>
<h3 id="数据增强"><a href="#数据增强" class="headerlink" title="数据增强"></a>数据增强</h3><ul>
<li><p><strong>随机水平翻转。</strong>给定正态分布$X\sim \delta(0,1)$，对于随机变量$x$，当其取值小于0.5时，将输入的图像进行左右的翻转。在<code>opencv</code>中仅需要<code>cv2.flip(image,1)</code>即可完成操作。</p>
</li>
<li><p><strong>灰度边框+等比缩放。</strong>首先获取输入图片的原始尺寸，计算其长宽比$r_1$；然后根据长宽中的最大值和MobileNet的输入尺寸<code>160*160</code>进行比较，得到缩放倍率$d_{wh}=\frac{160}{\max(w,h)}$，随后根据长宽比和缩放倍率对原始图像进行缩放，使得长宽中的一边达到160；随后，针对不足160的部分使用灰色<code>RGB:(128,128,128)</code>矩形从两端均匀padding。代码如下：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">letterbox</span>(<span class="params">im, new_shape=(<span class="params"><span class="number">160</span>, <span class="number">160</span></span>), color=(<span class="params"><span class="number">128</span>, <span class="number">128</span>, <span class="number">128</span></span>), auto=<span class="literal">False</span>, scaleFill=<span class="literal">False</span>, scaleup=<span class="literal">True</span>, stride=<span class="number">32</span></span>):</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># Resize and pad image while meeting stride-multiple constraints</span></span><br><span class="line">    shape = im.shape[:<span class="number">2</span>]  <span class="comment"># current shape [height, width]</span></span><br><span class="line">    <span class="keyword">if</span> <span class="built_in">isinstance</span>(new_shape, <span class="built_in">int</span>):</span><br><span class="line">        new_shape = (new_shape, new_shape)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Scale ratio (new / old)</span></span><br><span class="line">    r = <span class="built_in">min</span>(new_shape[<span class="number">0</span>] / shape[<span class="number">0</span>], new_shape[<span class="number">1</span>] / shape[<span class="number">1</span>])</span><br><span class="line">    <span class="keyword">if</span> <span class="keyword">not</span> scaleup:  <span class="comment"># only scale down, do not scale up (for better val mAP)</span></span><br><span class="line">        r = <span class="built_in">min</span>(r, <span class="number">1.0</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Compute padding</span></span><br><span class="line">    ratio = r, r  <span class="comment"># width, height ratios</span></span><br><span class="line">    new_unpad = <span class="built_in">int</span>(<span class="built_in">round</span>(shape[<span class="number">1</span>] * r)), <span class="built_in">int</span>(<span class="built_in">round</span>(shape[<span class="number">0</span>] * r))</span><br><span class="line">    dw, dh = new_shape[<span class="number">1</span>] - new_unpad[<span class="number">0</span>], new_shape[<span class="number">0</span>] - new_unpad[<span class="number">1</span>]  <span class="comment"># wh padding</span></span><br><span class="line">    <span class="keyword">if</span> auto:  <span class="comment"># minimum rectangle</span></span><br><span class="line">        dw, dh = np.mod(dw, stride), np.mod(dh, stride)  <span class="comment"># wh padding</span></span><br><span class="line">    <span class="keyword">elif</span> scaleFill:  <span class="comment"># stretch</span></span><br><span class="line">        dw, dh = <span class="number">0.0</span>, <span class="number">0.0</span></span><br><span class="line">        new_unpad = (new_shape[<span class="number">1</span>], new_shape[<span class="number">0</span>])</span><br><span class="line">        ratio = new_shape[<span class="number">1</span>] / shape[<span class="number">1</span>], new_shape[<span class="number">0</span>] / shape[<span class="number">0</span>]  <span class="comment"># width, height ratios</span></span><br><span class="line"></span><br><span class="line">    dw /= <span class="number">2</span>  <span class="comment"># divide padding into 2 sides</span></span><br><span class="line">    dh /= <span class="number">2</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> shape[::-<span class="number">1</span>] != new_unpad:  <span class="comment"># resize</span></span><br><span class="line">        im = cv2.resize(im, new_unpad, interpolation=cv2.INTER_LINEAR)</span><br><span class="line">    top, bottom = <span class="built_in">int</span>(<span class="built_in">round</span>(dh - <span class="number">0.1</span>)), <span class="built_in">int</span>(<span class="built_in">round</span>(dh + <span class="number">0.1</span>))</span><br><span class="line">    left, right = <span class="built_in">int</span>(<span class="built_in">round</span>(dw - <span class="number">0.1</span>)), <span class="built_in">int</span>(<span class="built_in">round</span>(dw + <span class="number">0.1</span>))</span><br><span class="line">    im = cv2.copyMakeBorder(im, top, bottom, left, right, cv2.BORDER_CONSTANT, value=color)  <span class="comment"># add border</span></span><br><span class="line">    <span class="keyword">return</span> im<span class="comment"># , ratio, (dw, dh)</span></span><br></pre></td></tr></table></figure>
</li>
</ul>
<h1 id="整合收尾"><a href="#整合收尾" class="headerlink" title="整合收尾"></a>整合收尾</h1><p>终于到这里了！到了我第一喜欢的UI设计环节！！！</p>
<p><img src="https://s2.loli.net/2022/08/05/ldiUFYzgjBrqyQN.png" alt="image-20220805181658926"  /></p>
<center><small>其实也没啥设计，就是选了几个颜色而已</small></center>

<h2 id="性能测试"><a href="#性能测试" class="headerlink" title="性能测试"></a>性能测试</h2><p>Yolo推理速度直接搬运官网的0.01s左右，<code>FaceNet</code>推理时间为0.003秒左右。这里其实有个坑，就是一开始测试的时候发现时间差异太大了，然后查了一下发现好像是在部署到设备上进行推理的时候，需要使用一些数据进行<code>Warmup</code>的操作：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">device = torch.device(<span class="string">&#x27;cuda&#x27;</span>)</span><br><span class="line">dummy_input = torch.rand(<span class="number">1</span>,<span class="number">3</span>,<span class="number">160</span>,<span class="number">160</span>).to(device)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;Warming Up&#x27;</span>)</span><br><span class="line">    <span class="keyword">for</span> _ <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">20</span>):</span><br><span class="line">        _ = model(dummy_input)</span><br></pre></td></tr></table></figure>
<p>然后进行性能的测试。首先是推理时间：</p>
<p><img src="https://s2.loli.net/2022/08/07/JsfkZiAtdFRXL3P.png" alt="image-20220807092856305"></p>
<p>基本上可以做到100FPS的水平，也就是说，基本上实时检测是没问题的了。那么准确度如何呢？我使用了两个验证集进行测试，其中一个验证集是训练集数据来源的视频的下半部分（这部分没有任何数据用于训练、测试），另一个则是完全独立的新视频。先说几个存在的问题吧，首先无论是在哪个验证集上面进行效果测试，脸部画面占据画面20-50%的情况下，推理准确度为100%。然而在人脸屏占比为10~15%左右的时候，会出现分类抖动的情况，就是说分类结果会很不稳定，出现的原因可能是<code>FaceNet</code>要求的输入图像大小为<code>160*160</code>导致的，加上Resize函数和LetterBox的操作会导致一些特征的变换有所丢失。解决方法则是对对所有的小尺寸图片划分为子类，并固定Backbone参数重新训练FaceNet以及分类器，最后导出结果的时候再把子类合并到大类里面。</p>
<h2 id="探索实验"><a href="#探索实验" class="headerlink" title="探索实验"></a>探索实验</h2><p>然后这里我还额外做了个实验，研究模型的卷积层的关注点，对重点区域生成热力图，观察到底是什么特征区分了人脸：</p>
<p><img src="https://s2.loli.net/2022/08/05/qnpZ3vXkxS9uG78.png" alt="image-20220805183241174" style="zoom: 50%;" /></p>
<center><small>Grad-CAM钩在Backbone最后的卷积层上生成的热力图</small></center>

<p>可以看出网络主要是重点关注鼻子部分的信息进行分类决策的。就这个简单的分类任务而言基本上准确率处于一个可以接受的范围，但是就更广泛一点的人脸识别任务来说，这个网络的设计其实还是有缺陷的，因为我们希望的是网络<strong>更加关注五官的信息而不是针对数据集的差异关注某一局部的信息。</strong>所以如果要构建更通用的人脸识别系统的话，可以参考目标识别设定中的预设描框对人脸的五官局部进行裁剪或者滑动窗口+注意力机制综合运用，对局部信息进行特征向量的提取与embedding，甚至还可以降低特征向量的维度（FaceNet的输出特征向量维度是128），在我调参的过程中我也研究过<code>Embedding Size</code>的大小设置，针对这次使用的数据集而言，128的长度其实对5个类别来说其实有些冗余了，可以进行一定的缩减；其次，五官信息的特征可以以组合的形式输出一个新的特征向量，最后只需要对这个新的特征向量做分类工作即可。我更改了网络的主干部分，使用并修改了Swim Transformer的结构，但碍于设备性能未能进行实验探索，日后有机会的话可能会从这方面进行进一步的探索工作。</p>
]]></content>
      <categories>
        <category>学习记录</category>
      </categories>
      <tags>
        <tag>计算机视觉</tag>
        <tag>Yolov5</tag>
        <tag>FaceNet</tag>
      </tags>
  </entry>
  <entry>
    <title>【学习记录】2022-8-20-？</title>
    <url>/2022/08/20/%E5%AD%A6%E4%B9%A0%E8%AE%B0%E5%BD%952022-8-20/</url>
    <content><![CDATA[<p>师兄让我别去CV卷了，让我搞搞通信。然后就是让我看看5G核心网相关的内容，笑死😂，我本科的时候移动通信的老师也和我们一起摆烂，考试开卷基本没啥东西记住的。不过想想也是，CV就业压力挺大的，当成业余兴趣爱好去研究下也不错，做成工作可能也很难受，也卷不过985的顶级实验室出来的。娄山雀说他前几天有个北大ACM区域金牌的计算机硕去面他们的后端都没有机会，然后四个清华大学的硕去面OPPO连简历复筛都没过……很可怕很可怕。然后最近看了严曦老师的《造神年代》，我再次燃起了对通信事业的热情。链接每个节点、信息的传输，和生命的波纹好像，当这些所有波纹和对事件的响应结合到一起构建成了一个系统，就完成了一个宏观定义的世界交互（我好像在说一些乱七八糟的屁话😂）这种感觉和造物其实也挺像的。所以开始吧：</p>
<span id="more"></span>
<h2 id="说在开始前"><a href="#说在开始前" class="headerlink" title="说在开始前"></a>说在开始前</h2><p>我对通信比较喜欢不上来的点在于更新速度太快，然后各种缩写在查阅资料的时候又非常麻烦，所以这次真的是破釜沉舟，把每一个缩写都给吃透了。阅读的时候如果有需要查阅的缩写可以直接在网站的搜索功能进行搜索，应该会有解释的。这次学习的内容主要是5G的核心网，由于我的基础比较薄弱，所以我得花花时间了解下发展的历程和了解些工程的问题。</p>
<p><img src="https://s2.loli.net/2022/08/21/8tsFlNCMLvTDSeX.png" alt="img" style="zoom: 25%;" /></p>
<h2 id="核心网"><a href="#核心网" class="headerlink" title="核心网"></a>核心网</h2><h3 id="核心网是什么"><a href="#核心网是什么" class="headerlink" title="核心网是什么"></a>核心网是什么</h3><p>在了解5G核心网之前我们需要先了解核心网到底是什么。核心网，有个洋气的英文名，叫Core Network（核心网络），简称CN。说实话，核心网的概念很难定义！广义上的解释难以界定，而狭义角度的解释又没有对应实体。我们只能通过类比以下来描述一下核心网：试想一个快递分拣中心，上面的传送带装满了双十一的各种包裹，传送带是负责传送包裹的，但是哪一个包裹需要传送到哪个地方，是需要一个智体进行调配的。在这个分拣中心，包裹相当于需要传输的数据，传送带相当于一个承载网络，作为信息的承载介质，而我们的核心网就是负责调配数据应该如何传输的指挥官。在这个基础上，我们可以进一步看看核心网到底是怎么发展的。</p>
<h3 id="核心网的发展"><a href="#核心网的发展" class="headerlink" title="核心网的发展"></a>核心网的发展</h3><p>首先先说说2G，为什么不从1G开始说呢，<del>因为1G的时候根本上不了网啊😂</del>因为1G和2G的核心网架构是非常近似的，这里可以直接等价了。</p>
<p><img src="https://s2.loli.net/2022/08/21/xMaLeEgD5KvWkcp.jpg" alt="640?wx_fmt=png" style="zoom:50%;" /></p>
<center><small>2G核心网架构</small></center>



<p>2G其实前期也是没法上网的，直到2.5G出现才解决了这一问题。从图中可以看出来，2G的核心网组网非常简单，MSC就是核心网的最主要设备。HLR、EIR和用户身份有关，用于鉴权。值得注意的是，之所以图上面写的是“MSC/VLR”，是因为VLR是一个功能实体，但是物理上，VLR和MSC是同一个硬件设备。相当于一个设备实现了两个角色，所以画在一起。HLR/AUC也是如此，HLR和AUC物理合一。下面是2.5G的核心网：</p>
<p><img src = 'https://s2.loli.net/2022/08/21/2qwdskLl6fxXOhQ.jpg' style="zoom:50%;" ></p>
<center><small>2.5G核心网架构，为了图简单没有把2G核心网里面的HLR等模块画上去</small></center>



<p>相比于2G其实就是多了SGSN和GGSN两个模块。这两个模块都是为了实现GPRS数据业务而存在的，GPRS则是2.5G上网的核心服务：</p>
<p><img src="https://s2.loli.net/2022/08/21/vcplj7bGWZX9ymr.png" alt="640?wx_fmt=png" style="zoom:67%;" /></p>
<p>再之后就是3G时代了：</p>
<p><img src="https://s2.loli.net/2022/08/21/9JoVwjSYZR1Gvtb.jpg" alt="640?wx_fmt=png" style="zoom: 50%;" /></p>
<center><small>3G核心网架构，为了图简单没把HLR等模块画上去</small></center>



<p>可以看出3G其实变化较大的部分是基站部分，引入了一个<code>NodeB</code>和一个<code>RNC</code>的东西。这个<code>NodeB</code>其实就是专属于3G时代的基站，只是为了区分和2G时代的基站而另起一个名字而已😂这样的作法会在后面的4G、5G都有体现。尽管在图中3G核心网的变化与2G的相比没啥不同，但其实硬件设备已经经过了一轮新的迭代。我们知道，硬件才是工程里面最能指导性能突破的核心力量，因此3G的成功之处很大一部分要感谢硬件的蓬勃发展。不要小看了硬件平台，实际上，就像最开始<strong>华为的C&amp;C08</strong>、<strong>中兴的ZXJ10</strong>一样，设备商自家的很多不同业务的设备，都是基于同一个硬件平台进行开发的。不可能每个设备都单独开发硬件平台，既浪费时间和精力，又不利于生产和维护。稳定可靠且处理能力强大的硬件平台，是产品的基石。从2G到3G，除了IP化以及硬件平台的升级之外，最大的不同就在于分离。在通信系统里面，说白了，就两个（平）面，用户面和控制面：</p>
<p><img src="https://s2.loli.net/2022/08/21/ZrOvf4BPnq1sxW5.jpg" alt="640?wx_fmt=png" style="zoom:50%;" /></p>
<p><img src="https://s2.loli.net/2022/08/21/mjOSBUkM4HC8YiF.png" alt="640?wx_fmt=png" style="zoom:50%;" /></p>
<p>用户面，就是用户的实际业务数据，就是你的语音数据啊，视频流数据啊之类的。而控制面，是为了管理数据走向的信令、命令。这两个面，在通信设备内部，就相当于两个不同的系统，2G时代，用户面和控制面没有明显分开。3G时代，把两个面进行了分离。接着，SGSN变成MME，GGSN变成SGW/PGW，也就演进成了4G核心网：</p>
<p><img src="https://s2.loli.net/2022/08/21/jIu8dYUeKiX5HDp.jpg" alt="640?wx_fmt=png" style="zoom:50%;" /></p>
<p>值得注意的是基站里面的RNC没有了，为了实现扁平化，功能一部分给了核心网，一部分给了<code>eNodeB</code>（还记得我说的NodeB是什么嘛）。发展到这里的时候，硬件平台也升级了，以中兴为例，开始启用ATCA/ETCA平台（后来MME就用了它），还有xGW T8000平台（后面PGW和SGW用了它，PGW和SGW物理上是一体的）。</p>
<p><img src="https://s2.loli.net/2022/08/21/YTSwIyQ87Z5RUgC.jpg" alt="?wx_fmt=jpeg"></p>
<center><small>中兴ATCA机框</small></center>



<p>在3G到4G的过程中，IMS出现了，取代传统CS（也就是MSC那些），提供更强大的多媒体服务（语音、图片短信、视频电话等）。IMS，使用的也主要是ATCA平台。实际上这些硬件很像一个电脑，有处理器（MP单板），有网卡（以太网接口卡，光纤接口卡）。而ATCA平台，更像一台电脑了，前面你也看到了，名字就叫“先进电信计算平台”，也就是“电信服务器”嘛。确切说，ATCA里面的业务处理单板，本身就是一台单板造型的“小型化电脑”，有处理器、内存、硬盘，俗称“刀片”。</p>
<p><img src="https://s2.loli.net/2022/08/21/VNQCTUz3WoZdKhe.jpg" alt="640?wx_fmt=png"></p>
<center><small>ATCA业务处理板——“刀片”</small></center>



<p>既然都走到这一步，原来的专用硬件，越做越像IT机房里面的x86通用服务器，那么，不如干脆直接用x86服务器吧!于是虚拟化时代就到来了。虚拟化，就是网元功能虚拟化（Network Function Virtualization，<strong>NFV</strong>）。说白了就是在硬件上，直接采用HP、IBM等IT厂家的x86平台通用服务器（目前以刀片服务器为主，节约空间，也够用）。</p>
<p><img src="https://s2.loli.net/2022/08/21/9whUsXVCz2xHRl7.jpg" alt="640?wx_fmt=jpeg"></p>
<p>软件上，设备商基于openstack这样的开源平台，开发自己的虚拟化平台，把以前的核心网网元，“种植”在这个平台之上：</p>
<p><img src="https://s2.loli.net/2022/08/21/NnYyhD6bJQv3em9.jpg" alt="?wx_fmt=jpeg"></p>
<p>虚拟化平台不等于5G核心网。也就是说，并不是只有5G才能用虚拟化平台。也不是用了虚拟化平台，就是5G。按照惯例，设备商先在虚拟化平台部署4G核心网，也就是，在为后面5G做准备，提前实验。硬件平台，永远都会提前准备。上面说了5G核心网的硬件平台，接下来，我们仔细说说5G核心网的架构。到了5G，网络逻辑结构彻底改变了。</p>
<h3 id="5G核心网引入"><a href="#5G核心网引入" class="headerlink" title="5G核心网引入"></a>5G核心网引入</h3><p>5G核心网，采用的是SBA架构（Service Based Architecture，即基于服务的架构）。SBA架构，基于云原生构架设计，借鉴了IT领域的“微服务”理念，把原来具有多个功能的整体，分拆为多个具有独自功能的个体。每个个体，实现自己的微服务。这样的变化，会有一个明显的外部表现，就是网元大量增加了。</p>
<p><img src="https://s2.loli.net/2022/08/21/QTJyAWGHx68INun.jpg" alt="640?wx_fmt=png" style="zoom:50%;" /></p>
<center><small>红色虚线内为5G核心网,除了UPF之外，都是控制面</small></center>



<p>这些网元看上去很多，实际上，硬件都是在虚拟化平台里面虚拟出来的。简而言之，<strong>5G核心网就是模块化、软件化</strong>。5G核心网之所以要模块化，还有一个主要原因，就是为了<strong>“切片”</strong>。5G是一个天下一统的网络，通吃所有用户。设计之初，就需要它应对各种需求。这些需求，被整理为三大应用场景:</p>
<ul>
<li><p><strong>eMBB（增强型移动宽带）</strong></p>
<p>一般日常情况下的上网方式。</p>
</li>
<li><p><strong>mMTC（海量物联网通信）</strong></p>
<p>那堆搞物联网的应该就要搞这个。</p>
</li>
<li><p><strong>uRLLC（低时延、高可靠通信）</strong></p>
<p>用于智能无人驾驶、工业自动化等需要低时延高可靠连接的业务。</p>
</li>
</ul>
<p>既然网络用途不同，当然要见招拆招。以一个死板的固定网络结构去应对，肯定是不行的。只有拆分成模块，灵活组队，才能搞定。所以模块化的设计，有利于网络切片，根据业务需求进行模块的删改增补。</p>
]]></content>
      <categories>
        <category>学习记录</category>
      </categories>
      <tags>
        <tag>5G</tag>
        <tag>通信技术</tag>
        <tag>核心网</tag>
      </tags>
  </entry>
  <entry>
    <title>【学习记录】2022-09-19</title>
    <url>/2022/09/26/%E5%AD%A6%E4%B9%A0%E8%AE%B0%E5%BD%95%20%E7%AC%AC%E4%BA%8C%E5%91%A8/</url>
    <content><![CDATA[<p>本周主要工作是看了老师的论文《Delay-Optimal Virtualized Radio Resource Scheduling in Software-Defined Vehicular Networks via Stochastic Learning》，这篇将会称为我移动通信课程的presentation的内容。这篇文章的翻译可以参见<a href="https://cybercolyce.cn/2022/09/24/【文献翻译】Delay-Optimal Virtualized Radio Resource Scheduling in Software-Defined Vehicular Networks via Stochastic Learning/">这里</a>，是我翻译的，但是翻译到后期就开始摸鱼了。。。</p>
<span id="more"></span>
<p><strong>先说结论：这篇文章的架构很好，文章的内容也很详实。</strong>文章的工作是基于一篇文章《SoftdEfined heteRogeneous VehICular nEtwork》所提出的SERVICE框架而开展的，在这个框架中分析了车联网中的资源分配问题并使用了在线随机学习和部分可观测马尔可夫决策过程的方法来解决问题。</p>
<h2 id="文章结构"><a href="#文章结构" class="headerlink" title="文章结构"></a>文章结构</h2><p>文章结构分成引言、相关定义的引入与简要介绍、问题建模以及问题求解、仿真实验与结果分析这几个部分。</p>
<h2 id="关键问题"><a href="#关键问题" class="headerlink" title="关键问题"></a>关键问题</h2><p>计算复杂度、延迟的最优化。</p>
<h2 id="解决方法"><a href="#解决方法" class="headerlink" title="解决方法"></a>解决方法</h2><p>基于部分可观测的马尔可夫决策过程建模、Stochastic Learning、问题拆分成宏观与微观两个层面考察。</p>
<h2 id="结论分析"><a href="#结论分析" class="headerlink" title="结论分析"></a>结论分析</h2>]]></content>
      <categories>
        <category>通信技术</category>
        <category>学习记录</category>
      </categories>
      <tags>
        <tag>车联网</tag>
        <tag>资源分配</tag>
      </tags>
  </entry>
  <entry>
    <title>【学习记录】2022-10-4</title>
    <url>/2022/10/14/%E5%AD%A6%E4%B9%A0%E8%AE%B0%E5%BD%95%E7%AC%AC%E5%9B%9B%E5%91%A8/</url>
    <content><![CDATA[<p>这周终于把OAI给倒腾好了…一共有三个部分，分别是核心网、gNB以及UE终端。</p>
<span id="more"></span>
<h2 id="OpenAirInterface的5G小系统部署"><a href="#OpenAirInterface的5G小系统部署" class="headerlink" title="OpenAirInterface的5G小系统部署"></a>OpenAirInterface的5G小系统部署</h2><p>我尝试了两种部署的方式，分别是使用我的台式机和笔记本组成核心网与gNB，以及台式机充当gNB与部署在云端的Kubernetes的核心网组网。这个过程可谓折磨，因为OAI官方的文档是<strong>错误的</strong>！我跟着错误的tutorial和documentation做了很久都不成功…</p>
<h3 id="docker-compose部署"><a href="#docker-compose部署" class="headerlink" title="docker-compose部署"></a>docker-compose部署</h3><h4 id="部署前的问题"><a href="#部署前的问题" class="headerlink" title="部署前的问题"></a>部署前的问题</h4><p>部署前，先说说设备是怎么分配的。我原本是打算使用网线连着校园网的台式机作为核心网运行docker-compose，笔记本通过wifi连接校园网作为gNB。但是不知道笔记本是什么回事，gNB的部署需要USRP，但是笔记本在安装了UHD之后都一直无法识别USRP B210，甚至在我重装最新版本的UHD驱动也无济于事…所以最后的硬件分配是笔记本使用docker-compose运行核心网，台式机运行gNB。解决硬件问题之后，就是IP问题。Ubuntu下，查看ip的方法是<code>ifconfig</code>，我在台式机使用网线连接校园网、笔记本使用WiFi连接校园网时，他们的IP分别是这样的：</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="variable">$docker</span>-compose: 10.24.80.186</span><br><span class="line"><span class="variable">$gNB</span>:10.25.18.205</span><br></pre></td></tr></table></figure>
<p>他们俩明显不在同一个网段….所以我把台式机改成用wifi连接到校园网，它的IP也变了：</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="variable">$docker</span>-compose: 10.24.80.186</span><br><span class="line"><span class="variable">$gNB</span>:10.24.82.195</span><br></pre></td></tr></table></figure>
<p>似乎他们在同一个网段了吧？但其实还是不行…在后续的添加路由转发步骤依然会失败。出现该问题的原因可能是WIFI给他们划分到不同的地方去了，也就是说即使都是连接着校园网，但是并不是我们家庭中的“局域网”。其实解决方法也很简单：两台设备同时使用网线连接校园网或者两台设备同时连接手机热点即可。方法一得到的IP为：</p>
<p>方法而得到的IP为：</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="variable">$docker</span>-compose: 10.24.80.186</span><br><span class="line"><span class="variable">$gNB</span>:10.24.82.195</span><br></pre></td></tr></table></figure>
<p>而检验硬件配置是否成功的标准，我将会在下文提到。</p>
<h4 id="启动核心网"><a href="#启动核心网" class="headerlink" title="启动核心网"></a>启动核心网</h4><p>Docker Compose部署核心网其实是将核心网的网元（也可以称为网络功能，NF）部署在一个个的Docker中，我使用的是mini-deployment，这意味着只有<code>AMF</code>、<code>SMF</code>、<code>UPF</code>、<code>SPGWU</code>以及<code>NRF</code>这几个网元会运行起来。但是在进行部署之前，需要在<code>核心网主机</code>上面进行路由转发的接受操作：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">sudo sysctl net.ipv4.conf.<span class="built_in">all</span>.forwarding=<span class="number">1</span></span><br><span class="line">sudo iptables -P FORWARD ACCEPT</span><br></pre></td></tr></table></figure>
<p>在安装了docker-compose环境后，需要下载OAI的核心网的源码：</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">git <span class="built_in">clone</span> --branch v1.3.0 https://gitlab.eurecom.fr/oai/cn5g/oai-cn5g-fed.git</span><br><span class="line"><span class="built_in">cd</span> oai-cn5g-fed</span><br><span class="line">git checkout -f v1.4.0</span><br><span class="line">./scripts/syncComponents.sh </span><br></pre></td></tr></table></figure>
<p>需要注意的是，在截至2022/10/5时，<code>oai-cn5g-fed</code>最新的版本是<code>1.4.0</code>，后续不保证其他版本的源码也可以编译成功使用。</p>
<p>下载完源码以及执行完同步操作后，可以使用如下命令查看核心网启动的选项：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">python3 core-network.py --<span class="built_in">help</span></span><br></pre></td></tr></table></figure>
<p>由于我用mini部署，所以我的命令是：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">python3 ./core-network.py --<span class="built_in">type</span> start-mini</span><br></pre></td></tr></table></figure>
<p>当需要停止运行核心网（相当于是将docker-compose中的每个docker给删除掉，所以运行的信息也会清空）时，最好先对运行的日志进行保存：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">docker logs oai-amf &gt; amf.log</span><br><span class="line">docker logs oai-smf &gt; smf.log</span><br><span class="line">docker logs oai-nrf &gt; nrf.log</span><br><span class="line">docker logs oai-spgwu &gt; spgwu.log</span><br><span class="line"><span class="comment"># 停止核心网 注意type后的参数要和start的对应</span></span><br><span class="line">python3 ./core-network.py --<span class="built_in">type</span> stop-mini</span><br></pre></td></tr></table></figure>
<h4 id="启动gNB"><a href="#启动gNB" class="headerlink" title="启动gNB"></a>启动gNB</h4><p>gNB同样是需要配置的，最重要的一步就是添加路由转发：</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">sudo ip route add 192.168.70.128/26 via 192.168.28.153 dev enp4s0;</span><br></pre></td></tr></table></figure>
<p><strong>其中，<code>192.168.70.128/26</code>不要动！<code>enp4s0</code>是gNB的网口！``是Docker-compose部署的IP地址！不要被OAI官方的教程中的命令给骗了！！！</strong></p>
<p><img src="https://s2.loli.net/2022/10/07/mNgKAnOZLfrQk1x.jpg" alt="SA Demo" style="zoom: 67%;" /></p>
<center>这才是正确的图，已经更正了</center>

<p>命令则是去掉横线的这部分：</p>
<p><img src="C:\Users\cybercolyce\AppData\Roaming\Typora\typora-user-images\image-20221007093402599.png" alt="image-20221007093402599"></p>
<p>好了絮絮叨叨完了，下面就要验证IP配置是否成功了。第一步就是要验证两台设备之间的IP是否能ping通。在这个的基础上，gNB主机需要再ping通<code>192.168.70.129</code>这个IP；随后则要ping通docker-compose 中的各个容器的IP地址：</p>
<p><img src="https://s2.loli.net/2022/10/07/gDdqRhmy3fQeMzP.png" alt="image-20221007093725075" style="zoom:80%;" /></p>
<p>如果都ping通了，那么就可以启动gNB了。先确保核心网已经在运行了，然后切到存放gNB源码的文件夹中，同时插上USRP：</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="built_in">cd</span> cmake_targets/ran_build/build</span><br><span class="line">sudo ./nr-softmodem -E --sa -O ../../../targets/PROJECTS/GENERIC-NR-5GC/CONF/gnb.sa.band78.fr1.106PRB.usrpb210.conf </span><br></pre></td></tr></table></figure>
<p>然后就运行起来了。运行的过程以及记录可以再docker-compose中的amf日志进行查询。</p>
<h3 id="kubernetes的部署"><a href="#kubernetes的部署" class="headerlink" title="kubernetes的部署"></a>kubernetes的部署</h3><p>这个方式比较方便，师兄把核心网的网元都部署在了云端，然后我只需要运行gNB就可以了，很符合我对5G的想象，不觉得很酷吗？（对不起</p>
<p>这样的作法其实只需要更改gNB文件的配置就好，就是之前那个启动gNB命令中的<code>gnb.sa.band78.fr1.106PRB.usrpb210.conf</code>文件，需要更改的地方有如下几个：</p>
<ul>
<li><p>AMF的IP地址，师兄把它绑定在<code>x.x.x.x</code>，因此配置时：</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment">#gNB 参考配置中的AMF地址</span></span><br><span class="line">amf_ip_address      = ( &#123; ipv4       = <span class="string">&quot;x.x.x.x&quot;</span>;</span><br><span class="line">                          ipv6       = <span class="string">&quot;192:168:30::17&quot;</span>;</span><br><span class="line">                          active     = <span class="string">&quot;yes&quot;</span>;</span><br><span class="line">                          preference = <span class="string">&quot;ipv4&quot;</span>;</span><br><span class="line">                        &#125;</span><br><span class="line">                      );</span><br><span class="line">  </span><br><span class="line">  </span><br><span class="line">NETWORK_INTERFACES :</span><br><span class="line">&#123;</span><br><span class="line">    GNB_INTERFACE_NAME_FOR_NG_AMF            = <span class="string">&quot;网卡名称&quot;</span>;</span><br><span class="line">    GNB_IPV4_ADDRESS_FOR_NG_AMF              = <span class="string">&quot;IP地址（校园网）/24&quot;</span>;</span><br><span class="line">    GNB_INTERFACE_NAME_FOR_NGU               = 网卡名称<span class="string">&quot;;</span></span><br><span class="line"><span class="string">    GNB_IPV4_ADDRESS_FOR_NGU                 = &quot;</span>IP地址（校园网）/24<span class="string">&quot;;</span></span><br><span class="line"><span class="string">    GNB_PORT_FOR_S1U                         = 2152; # Spec 2152</span></span><br><span class="line"><span class="string">&#125;;</span></span><br><span class="line"><span class="string">  </span></span><br></pre></td></tr></table></figure>
</li>
</ul>
<ul>
<li><p>MCC/MNC配置：</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">plmn_support:</span><br><span class="line">  -</span><br><span class="line">    plmn_id:</span><br><span class="line">      mcc: 466</span><br><span class="line">      mnc: 92</span><br><span class="line">    s_nssai:</span><br><span class="line">    - sd: ffffff</span><br><span class="line">      sst: 1</span><br><span class="line">  -</span><br><span class="line">    plmn_id:</span><br><span class="line">      mcc: 466</span><br><span class="line">      mnc: 92</span><br><span class="line">    s_nssai:</span><br><span class="line">    - sd: 101010</span><br><span class="line">      sst: 1</span><br></pre></td></tr></table></figure>
</li>
</ul>
<p>然后启动就好了。</p>
<h2 id="手机连接gNB"><a href="#手机连接gNB" class="headerlink" title="手机连接gNB"></a>手机连接gNB</h2><p>开飞行模式，然后关掉飞行模式就好，可以连接，然后登陆验证（校园网的原因），可以测速了。</p>
]]></content>
      <categories>
        <category>通信技术</category>
      </categories>
      <tags>
        <tag>5G</tag>
        <tag>核心网</tag>
      </tags>
  </entry>
  <entry>
    <title>异构网络与同构网络</title>
    <url>/2022/09/27/%E5%BC%82%E6%9E%84%E7%BD%91%E7%BB%9C/</url>
    <content><![CDATA[<p><img src="https://s2.loli.net/2022/09/27/EveAk8j4pChcowF.png" alt="img"></p>
<span id="more"></span>
<p>Homogeneous networks are networks where all the nodes have the same function in the network. One user is interchangeable with the next in the basic function they perform. In a landline telephone network, for example, each node (telephone) performs basically the same function as any other, and people tend to get telephones for the same reasons. Telecommunications networks, in general, are often homogeneous.</p>
<p>同构网络中的所有节点都具备相同的功能。一个用户可以与下一个用户通过基本功能交互。在固定电话网络中，每个节点（电话）基本上执行与其他任何节点相同的功能，并且人们出于相同的原因而使用电话。电信网络通常是同构网络。</p>
<p>Heterogeneous networks are networks where there are two or more classes of nodes categorized by both function and utility. On the Honeybook market network, event planners behave differently than photographers, who behave differently from florists. Buyer nodes on eBay are on the network for fundamentally different reason from seller nodes.</p>
<p>异构网络是指按功能和效用将节点分为两类或更多类的网络。对于一台机房，一些设备是Linux系统，一些设备是Windows系统，还有一些Unix系统的其他设备，如果把这些设备互联起来组成一个网络，那么就属于是异构网络。 在日常生活中，连接多个电脑通常会用到路由器或者交换机，他们两个之间有区别，比如交换机只能连接电脑，但是路由器可以连接电脑，也可以提供wifi给手机连接。那么由交换机组成的网络就属于同构网络，由路由器组成的网络就属于异构网络。区分异构网络和同构网络的本质，是看是否兼容不同的协议，上述手机和电脑之间的功能相似，但是他们分别使用不同的协议，因此属于是异构网络，Linux和Windows同理。</p>
]]></content>
      <categories>
        <category>学习记录</category>
      </categories>
      <tags>
        <tag>计算机网络</tag>
      </tags>
  </entry>
  <entry>
    <title>字符串结构的高效实现——Rope</title>
    <url>/2022/11/12/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84-Rope/</url>
    <content><![CDATA[<p>Rope作为一种高效处理字符串的数据结构广泛应用于长文本的字符串操作中。下文给出Rope数据结构的基本结构以及Python的实现。</p>
<span id="more"></span>
<h2 id="Rope简介"><a href="#Rope简介" class="headerlink" title="Rope简介"></a>Rope简介</h2><p>字符串连接是一种十分常见的操作。当字符串以传统的方式(比如字符数组)存储的时候，连接操作需要花费$O(n)$的时间；而<code>Rope</code>可以高效处理字符串的拼接、查询、删除、及随机访问。Rope的一个典型应用场景是：<strong>在一个文本编辑程序里，用来保存较长的文本字符串</strong>。图1给出了Rope结构存储的字符串“Hello_my_name_is_Simon”。</p>
<p><img src="https://media.geeksforgeeks.org/wp-content/uploads/ropeDataStructure-1.jpg" alt="Rope Structure"></p>
<center><small></small>ropeDataStructure</small></center>

<p>从图中可看出，Rope是一个二叉树，叶节点包含的是字符串的子串，非叶节点是权重，其值等于左子树叶节点的所有字符之和。一个字符串被分割为两部分，左子树包含了字符串左部分，右子树包含了字符串的右部分，这些部分都是由用户自己确定的。</p>
<h2 id="Rope的Python实现"><a href="#Rope的Python实现" class="headerlink" title="Rope的Python实现"></a>Rope的Python实现</h2><p>一个Rope的数据结构有如下几种操作：</p>
<ul>
<li>索引<code>index()</code>。它返回位置为<code>i</code>的字符。我使用<code>__getitem__()</code>方法实现使它更符合<code>Python</code>语法。</li>
<li>拼接<code>concat()</code>。它连接两个<code>Rope</code>结构的字符串一个<code>Rope</code>中。我使用<code>__add__()</code>方法重载使得操作更加方便。</li>
<li>分割<code>split()</code>。它分离字符串<code>s</code>在位置<code>i</code>处的两个字符串，返回<code>s1</code>和<code>s2</code>。</li>
</ul>
<p>下面给出我的实现思路。把这个二叉树的所有节点都看成是一个<code>Rope</code>对象，任意的Rope对象之间都可以拼接，这种结构很递归，因此我们可以使用一个递归的结构进行实现，具体来说就是可以通过一个<code>List</code>存储所有的Rope的字符串<code>data</code>，叶节点的数据采用<code>str</code>，其左右子树指向<code>None</code>，节点大小定义为字符串大小。递归的终点就是Rope（对应如中的节点）的内容是<code>Str</code>，而不是若干被切分的<code>List</code>。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"></span><br><span class="line"><span class="comment"># 叶节点用Str表示，其左右子树指向None代表已经到底了</span></span><br><span class="line"><span class="comment"># 也可以用[Str]进行Rope构建</span></span><br><span class="line"><span class="comment"># 递归实现，任意组合都可以是一个Rope</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">Rope</span>(<span class="title class_ inherited__">object</span>):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, data=<span class="string">&#x27;&#x27;</span></span>) -&gt; <span class="literal">None</span>:</span><br><span class="line">        <span class="keyword">if</span> <span class="built_in">isinstance</span>(data,<span class="built_in">list</span>):</span><br><span class="line">            <span class="keyword">if</span> <span class="built_in">len</span>(data) == <span class="number">0</span>:</span><br><span class="line">                self.__init__()</span><br><span class="line">            <span class="keyword">elif</span> <span class="built_in">len</span>(data) == <span class="number">1</span>:</span><br><span class="line">                self.__init__(data[<span class="number">0</span>])</span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                idiv = <span class="built_in">len</span>(data)//<span class="number">2</span> + (<span class="built_in">len</span>(data)%<span class="number">2</span>&gt;<span class="number">0</span>)</span><br><span class="line"></span><br><span class="line">                self.left = Rope(data[:idiv])</span><br><span class="line">                self.right = Rope(data[idiv:])</span><br><span class="line">                self.data = <span class="string">&#x27;&#x27;</span></span><br><span class="line">                self.length = self.left.length + self.right.length</span><br><span class="line">        </span><br><span class="line">        <span class="keyword">elif</span> <span class="built_in">isinstance</span>(data,<span class="built_in">str</span>):</span><br><span class="line">            self.left = <span class="literal">None</span></span><br><span class="line">            self.right = <span class="literal">None</span></span><br><span class="line">            self.data = data</span><br><span class="line">            self.length = <span class="built_in">len</span>(data)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            <span class="keyword">raise</span> TypeError(<span class="string">&#x27;只能使用`Str`或`List:[Str]`作为Rope的传入数据&#x27;</span>)</span><br><span class="line">        </span><br><span class="line">        self.current = self</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__add__</span>(<span class="params">self, inputdata</span>):</span><br><span class="line">        <span class="keyword">if</span> <span class="built_in">isinstance</span>(inputdata, <span class="built_in">str</span>):</span><br><span class="line">            inputdata = Rope(inputdata)</span><br><span class="line">        </span><br><span class="line">        tmp = Rope()</span><br><span class="line">        tmp.left = self</span><br><span class="line">        tmp.right = inputdata</span><br><span class="line">        tmp.length = tmp.left.length + tmp.right.length</span><br><span class="line">        tmp.current = self</span><br><span class="line">        <span class="keyword">return</span> tmp</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__len__</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="comment"># 非叶节点长度</span></span><br><span class="line">        <span class="keyword">if</span> self.left <span class="keyword">and</span> self.right:</span><br><span class="line">            <span class="keyword">return</span> <span class="built_in">len</span>(self.left) + <span class="built_in">len</span>(self.right)</span><br><span class="line">        <span class="comment"># 叶节点长度</span></span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            <span class="keyword">return</span>(<span class="built_in">len</span>(self.data))</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__getitem__</span>(<span class="params">self, index</span>):</span><br><span class="line">        <span class="keyword">if</span> <span class="built_in">isinstance</span>(index, <span class="built_in">int</span>):</span><br><span class="line">            <span class="keyword">if</span> self.left <span class="keyword">and</span> self.right:</span><br><span class="line">                <span class="keyword">if</span> index &lt; -self.right.length:</span><br><span class="line">                    subindex = index + self.right.length</span><br><span class="line">                <span class="keyword">elif</span> index &gt;= self.left.length:</span><br><span class="line">                    subindex = index - self.left.length</span><br><span class="line">                <span class="keyword">else</span>:</span><br><span class="line">                    subindex = index</span><br><span class="line"></span><br><span class="line">                <span class="keyword">if</span> index &lt; -self.right.length <span class="keyword">or</span> <span class="number">0</span> &lt;= index &lt; self.left.length:</span><br><span class="line">                    <span class="keyword">return</span> self.left[subindex]</span><br><span class="line">                <span class="keyword">else</span>:</span><br><span class="line">                    <span class="keyword">return</span> self.right[subindex]</span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                <span class="keyword">return</span> Rope(self.data[index])</span><br><span class="line"></span><br><span class="line">        <span class="keyword">elif</span> <span class="built_in">isinstance</span>(index, <span class="built_in">slice</span>):</span><br><span class="line">            <span class="keyword">if</span> self.left <span class="keyword">and</span> self.right:</span><br><span class="line">                start = index.start</span><br><span class="line">                <span class="keyword">if</span> index.start <span class="keyword">is</span> <span class="literal">None</span>:</span><br><span class="line">                    <span class="keyword">if</span> index.step <span class="keyword">is</span> <span class="literal">None</span> <span class="keyword">or</span> index.step &gt; <span class="number">0</span>:</span><br><span class="line">                        head = self.left</span><br><span class="line">                    <span class="keyword">else</span>:</span><br><span class="line">                        head = self.right</span><br><span class="line">                <span class="keyword">elif</span> (index.start &lt; -self.right.length <span class="keyword">or</span></span><br><span class="line">                        <span class="number">0</span> &lt;= index.start &lt; self.left.length):</span><br><span class="line">                    head = self.left</span><br><span class="line">                    <span class="keyword">if</span> index.start <span class="keyword">and</span> index.start &lt; -self.right.length:</span><br><span class="line">                        start += self.right.length</span><br><span class="line">                <span class="keyword">else</span>:</span><br><span class="line">                    head = self.right</span><br><span class="line">                    <span class="keyword">if</span> index.start <span class="keyword">and</span> index.start &gt;= self.left.length:</span><br><span class="line">                        start -= self.left.length</span><br><span class="line"></span><br><span class="line">                <span class="comment"># <span class="doctag">TODO:</span> stop = -right.length could be on either subrope.</span></span><br><span class="line">                <span class="comment"># There are two options:</span></span><br><span class="line">                <span class="comment">#   1. tail = left and stop = None (or left.length)</span></span><br><span class="line">                <span class="comment">#   2. tail = right as a &#x27;&#x27; string, which is removed</span></span><br><span class="line">                <span class="comment"># Currently doing method 2, but I&#x27;m on the fence here.</span></span><br><span class="line">                stop = index.stop</span><br><span class="line">                <span class="keyword">if</span> index.step <span class="keyword">is</span> <span class="literal">None</span> <span class="keyword">or</span> index.step &gt; <span class="number">0</span>:</span><br><span class="line">                    <span class="keyword">if</span> (index.stop <span class="keyword">is</span> <span class="literal">None</span> <span class="keyword">or</span></span><br><span class="line">                            -self.right.length &lt;= index.stop &lt; <span class="number">0</span> <span class="keyword">or</span></span><br><span class="line">                            index.stop &gt; self.left.length):</span><br><span class="line">                        tail = self.right</span><br><span class="line">                        <span class="keyword">if</span> index.stop <span class="keyword">and</span> index.stop &gt; self.left.length:</span><br><span class="line">                            stop -= self.left.length</span><br><span class="line">                    <span class="keyword">else</span>:</span><br><span class="line">                        <span class="keyword">if</span> head == self.right:</span><br><span class="line">                            tail = self.right</span><br><span class="line">                            stop = <span class="number">0</span></span><br><span class="line">                        <span class="keyword">else</span>:</span><br><span class="line">                            tail = self.left</span><br><span class="line">                            <span class="keyword">if</span> index.stop &lt; -self.right.length:</span><br><span class="line">                                stop += self.right.length</span><br><span class="line">                <span class="keyword">else</span>:</span><br><span class="line">                    <span class="keyword">if</span> (index.stop <span class="keyword">is</span> <span class="literal">None</span> <span class="keyword">or</span></span><br><span class="line">                            index.stop &lt; (-self.right.length - <span class="number">1</span>) <span class="keyword">or</span></span><br><span class="line">                            <span class="number">0</span> &lt;= index.stop &lt; self.left.length):</span><br><span class="line">                        tail = self.left</span><br><span class="line">                        <span class="keyword">if</span> index.stop <span class="keyword">and</span> index.stop &lt; (-self.right.length - <span class="number">1</span>):</span><br><span class="line">                            stop += self.right.length</span><br><span class="line">                    <span class="keyword">else</span>:</span><br><span class="line">                        <span class="keyword">if</span> head == self.left:</span><br><span class="line">                            tail = self.left</span><br><span class="line">                            stop = -<span class="number">1</span>   <span class="comment"># Or self.left.length - 1 ?</span></span><br><span class="line">                        <span class="keyword">else</span>:</span><br><span class="line">                            tail = self.right</span><br><span class="line">                            <span class="keyword">if</span> index.stop &gt;= self.left.length:</span><br><span class="line">                                stop -= self.left.length</span><br><span class="line"></span><br><span class="line">                <span class="comment"># Construct the rope</span></span><br><span class="line">                <span class="keyword">if</span> head == tail:</span><br><span class="line">                    <span class="keyword">return</span> head[start:stop:index.step]</span><br><span class="line">                <span class="keyword">else</span>:</span><br><span class="line">                    <span class="keyword">if</span> <span class="keyword">not</span> index.step:</span><br><span class="line">                        offset = <span class="literal">None</span></span><br><span class="line">                    <span class="keyword">elif</span> index.step &gt; <span class="number">0</span>:</span><br><span class="line">                        <span class="keyword">if</span> start <span class="keyword">is</span> <span class="literal">None</span>:</span><br><span class="line">                            delta = -head.length</span><br><span class="line">                        <span class="keyword">elif</span> start &gt;= <span class="number">0</span>:</span><br><span class="line">                            delta = start - head.length</span><br><span class="line">                        <span class="keyword">else</span>:</span><br><span class="line">                            delta = <span class="built_in">max</span>(index.start, -self.length) + tail.length</span><br><span class="line"></span><br><span class="line">                        offset = delta % index.step</span><br><span class="line">                        <span class="keyword">if</span> offset == <span class="number">0</span>:</span><br><span class="line">                            offset = <span class="literal">None</span></span><br><span class="line">                    <span class="keyword">else</span>:</span><br><span class="line">                        <span class="keyword">if</span> start <span class="keyword">is</span> <span class="literal">None</span>:</span><br><span class="line">                            offset = index.step + (head.length - <span class="number">1</span>) % (-index.step)</span><br><span class="line">                        <span class="keyword">elif</span> start &gt;= <span class="number">0</span>:</span><br><span class="line">                            offset = index.step + <span class="built_in">min</span>(start, head.length - <span class="number">1</span>) % (-index.step)</span><br><span class="line">                        <span class="keyword">else</span>:</span><br><span class="line">                            offset = index.step + (start + head.length) % (-index.step)</span><br><span class="line"></span><br><span class="line">                    <span class="keyword">if</span> <span class="keyword">not</span> tail[offset:stop:index.step]:</span><br><span class="line">                        <span class="keyword">return</span> head[start::index.step]</span><br><span class="line">                    <span class="keyword">else</span>:</span><br><span class="line">                        <span class="keyword">return</span> head[start::index.step] + tail[offset:stop:index.step]</span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                <span class="keyword">return</span> Rope(self.data[index])</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__repr__</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="keyword">if</span> self.left <span class="keyword">and</span> self.right:</span><br><span class="line">            <span class="keyword">return</span> <span class="string">&#x27;&#123;&#125;&#123;&#125; + &#123;&#125;&#123;&#125;&#x27;</span>.<span class="built_in">format</span>(<span class="string">&#x27;(&#x27;</span> <span class="keyword">if</span> self.left <span class="keyword">else</span> <span class="string">&#x27;&#x27;</span>,</span><br><span class="line">                                        self.left.__repr__(),</span><br><span class="line">                                        self.right.__repr__(),</span><br><span class="line">                                        <span class="string">&#x27;)&#x27;</span> <span class="keyword">if</span> self.right <span class="keyword">else</span> <span class="string">&#x27;&#x27;</span>)</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            <span class="keyword">return</span> <span class="string">&quot;\033[1;37;42mRope [&#x27;&#123;&#125;&#x27;]\033[0m&quot;</span>.<span class="built_in">format</span>(self.data)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">split</span>(<span class="params">self, index</span>):</span><br><span class="line">        <span class="keyword">if</span> <span class="built_in">isinstance</span>(index, <span class="built_in">int</span>):</span><br><span class="line">            <span class="keyword">if</span> self.left <span class="keyword">and</span> self.right:</span><br><span class="line">                    <span class="keyword">if</span> index &lt; -self.right.length:</span><br><span class="line">                        subindex = index + self.right.length</span><br><span class="line">                    <span class="keyword">elif</span> index &gt;= self.left.length:</span><br><span class="line">                        subindex = index - self.left.length</span><br><span class="line">                    <span class="keyword">else</span>:</span><br><span class="line">                        subindex = index</span><br><span class="line"></span><br><span class="line">                    <span class="keyword">if</span> index &lt; -self.right.length <span class="keyword">or</span> <span class="number">0</span> &lt;= index &lt; self.left.length:</span><br><span class="line">                        <span class="keyword">return</span> self.left[:subindex], self.left[subindex:]</span><br><span class="line">                    <span class="keyword">else</span>:</span><br><span class="line">                        <span class="keyword">return</span> self.right[:subindex], self.right[subindex:]</span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                <span class="keyword">return</span> Rope(self.data[:index]), Rope(self.data[index:])</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            <span class="keyword">raise</span> TypeError(<span class="string">&quot;`index`必须为`Int`类型&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&quot;__main__&quot;</span>:</span><br><span class="line">    a = Rope(<span class="string">&#x27;hello&#x27;</span>)</span><br><span class="line">    b = Rope(<span class="string">&#x27;world&#x27;</span>)</span><br><span class="line">    c = Rope([<span class="string">&#x27;I &#x27;</span>, <span class="string">&quot;don&#x27;t&quot;</span>, <span class="string">&quot;know&quot;</span>])</span><br><span class="line"></span><br><span class="line">    r = a + b</span><br><span class="line">    <span class="built_in">print</span>(c)</span><br><span class="line">    <span class="built_in">print</span>(r)</span><br><span class="line">    <span class="built_in">print</span>(r[<span class="number">6</span>])</span><br><span class="line">    <span class="built_in">print</span>(r.split(<span class="number">3</span>))</span><br><span class="line">    </span><br><span class="line"><span class="comment"># ((Rope [&#x27;I &#x27;] + Rope [&#x27;don&#x27;t&#x27;]) + Rope [&#x27;know&#x27;])</span></span><br><span class="line"><span class="comment"># (Rope [&#x27;hello&#x27;] + Rope [&#x27;world&#x27;])</span></span><br><span class="line"><span class="comment"># Rope [&#x27;o&#x27;]</span></span><br><span class="line"><span class="comment"># (Rope [&#x27;hel&#x27;], Rope [&#x27;lo&#x27;])</span></span><br><span class="line"></span><br></pre></td></tr></table></figure>
<h2 id="性能比较"><a href="#性能比较" class="headerlink" title="性能比较"></a>性能比较</h2><div class="table-container">
<table>
<thead>
<tr>
<th></th>
<th>String</th>
<th>块状链表</th>
<th>Rope</th>
</tr>
</thead>
<tbody>
<tr>
<td>索引</td>
<td>$O(1)$</td>
<td>$O(\sqrt{N})$</td>
<td>$O(\log N)$</td>
</tr>
<tr>
<td>插入</td>
<td>$O(N)$</td>
<td>$O(\sqrt N)$</td>
<td>$O(1)$</td>
</tr>
<tr>
<td>删除</td>
<td>$O(N)$</td>
<td>$O(\sqrt N)$</td>
<td>$O(\log N)$</td>
</tr>
</tbody>
</table>
</div>
]]></content>
      <categories>
        <category>学习记录</category>
      </categories>
      <tags>
        <tag>数据结构</tag>
      </tags>
  </entry>
  <entry>
    <title>3D甜甜圈的计算优化</title>
    <url>/2022/11/27/%E7%94%9C%E7%94%9C%E5%9C%88%E7%9A%84%E4%BC%98%E5%8C%96/</url>
    <content><![CDATA[<p>对上一篇文章中的甜甜圈的优化方法</p>
<span id="more"></span>intro

## 不用cos()/sin()怎么计算正弦与余弦值

在这段代码中，不必计算每一处的正余弦值，因为我们计算这个值的原因是因为我们要实现“旋转”的效果，这个旋转是以我们规定的角度步进长度进行的。内层的循环只是画一个圆形，外层的本质也差不多，只不过是画一个更大的环面。在每一个循环中，角度的正余弦值变化量非常小。所以我们不必全程跟踪所有的角度，我们只需要以角度$\theta=0$开局，此时余弦值为1，正弦值为0，此时旋转圆形可以生成所有的正余弦值：
$$
\begin{bmatrix}
c'\\s'
\end{bmatrix}
=
\begin{bmatrix}
\cos \theta &-\sin\theta\\
\sin \theta &\cos \theta
\end{bmatrix}
\cdot
\begin{bmatrix}
c\\s
\end{bmatrix}
$$
举个例子，如果内层的半径的步进长度为0.02，那么迭代过程大概长这样子：

<figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="type">float</span> c=<span class="number">1</span>, s=<span class="number">0</span>;  <span class="comment">// c for cos, s for sin</span></span><br><span class="line"><span class="keyword">for</span> (<span class="type">int</span> i = <span class="number">0</span>; i &lt; <span class="number">314</span>; i++) &#123;  <span class="comment">// 314 * .02 ~= 2π</span></span><br><span class="line">  <span class="comment">// (use c, s in code)</span></span><br><span class="line">  <span class="type">float</span> newc = <span class="number">0.9998</span>*c - <span class="number">0.019998666</span>*s;</span><br><span class="line">  s = <span class="number">0.019998666</span>*c + <span class="number">0.9998</span>*s;</span><br><span class="line">  c = newc;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>(注：0.9998^2 + 0.019998666^2 ≈ 1)</p>
<h2 id="归一化"><a href="#归一化" class="headerlink" title="归一化"></a>归一化</h2><p>虽然上面的迭代式看着很爽，但是不管取值多精细，在大量的迭代后计算得到的正余弦值得平方和永远不可能是1，因为会有误差出现，并且这种误差是指数增长的。对于我们要一直使用这个循环的场景来说，这个误差必须被修正。</p>
<p><img src="https://www.a1k0n.net/img/sincos-mag.png" alt="err"></p>
<center>*an exaggerated illustration of what happens when repeatedly doing low-precision rotations*</center>

<p>最简单的方法就是乘以归一化系数$1/\sqrt{c^2+s^2}$，但这样我们又重新用到复杂的根号运算了。事实上，我们应该充分利用我们开始的幅度非常接近于1这个特点，我们可以在每轮迭代的旋转后执行一个<a href="https://zhuanlan.zhihu.com/p/97545001">牛顿步程</a>，这样就可以让幅度保持“足够接近”1了。</p>
<p>我们的目标是要找到一个基于$a = c^2+s^2$的平方根式的倒数，也就是我们的$(c,s)$向量的幅度。我们定义了这么一个函数$f=\frac{1}{x^2}-a$，这个函数在$x=\frac{1}{\sqrt{a}}$的时候值为0。我们先从$x=1$开始猜，然后执行牛顿迭代得到$x’$，这个迭代得到的值应该会“更接近”$\frac{1}{\sqrt{a}}$,这样，我们的$c^2+s^2$会更加接近1。</p>
<p>牛顿迭代过程是这样的：</p>
<script type="math/tex; mode=display">
x' = x -\frac{f(x)}{f'(x)}</script><p>使用<code>SymPy</code>进行微分和简化后，得到一个式子：</p>
<script type="math/tex; mode=display">
x'=\frac{x(3-ax^2)}{2}</script><p>由于只做一次，我们把$x=1$的初值带入进去，得到我们最后的迭代式：</p>
<script type="math/tex; mode=display">
x'=(3-c^2-s^2)/2</script><h2 id="旋转的优化"><a href="#旋转的优化" class="headerlink" title="旋转的优化"></a>旋转的优化</h2><p>然而我们还暂时不用太担心幅度的问题，我们可以用另一个捷径（作者看了一篇旧的CORDIC算法的研究得到了灵感）方式完成上述的工作。如果我们把所有的余弦值提取出原始的旋转矩阵，我们可以得到：</p>
<script type="math/tex; mode=display">
\begin{bmatrix}
c'\\s'
\end{bmatrix}
=\frac{1}{\cos \theta}
\begin{bmatrix}
1 & -\tan \theta\\
\tan \theta&1
\end{bmatrix}</script><p>由于我们只在很小的角度进行处理，因此前面的系数$\frac{1}{\cos \theta}$非常接近1，我们就把他忽略掉进行牛顿步程吧。</p>
<p>现在我们已经明白代码中旋转部分是如何实现的了，定义一个函数：</p>
<figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">define</span> R(t,x,y) \ </span></span><br><span class="line">  f = x; \</span><br><span class="line">  x -= t*y; \</span><br><span class="line">  y += t*f; \</span><br><span class="line">  f = (<span class="number">3</span>-x*x-y*y)/<span class="number">2</span>; \</span><br><span class="line">  x *= f; \</span><br><span class="line">  y *= f;</span><br></pre></td></tr></table></figure>
<p>这个函数是对向量<code>x,y</code>的旋转，其中的<code>t</code>参数是$\tan \theta $。<code>f</code>是临时变量，前三行做的矩阵乘法，<code>f</code>被重复利用与幅度调整，然后最终的$x,y$通过<code>f</code>的修正回单位圆。考虑到这个函数的特点以及实际场景，作者将这个<code>R()</code>函数替换了所有的<code>cos/sin</code>的计算，最后的结果也非常理想。</p>
<h2 id="干脆把浮点数也扔掉吧"><a href="#干脆把浮点数也扔掉吧" class="headerlink" title="干脆把浮点数也扔掉吧"></a>干脆把浮点数也扔掉吧</h2><p>作者优化好了，没问题（位操作我是没想到，作者好牛）</p>
<figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;stdint.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;stdio.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;string.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;unistd.h&gt;</span></span></span><br><span class="line"></span><br><span class="line"><span class="meta">#<span class="keyword">define</span> R(mul,shift,x,y) \</span></span><br><span class="line"><span class="meta">  _=x; \</span></span><br><span class="line"><span class="meta">  x -= mul*y&gt;&gt;shift; \</span></span><br><span class="line"><span class="meta">  y += mul*_&gt;&gt;shift; \</span></span><br><span class="line"><span class="meta">  _ = 3145728-x*x-y*y&gt;&gt;11; \</span></span><br><span class="line"><span class="meta">  x = x*_&gt;&gt;10; \</span></span><br><span class="line"><span class="meta">  y = y*_&gt;&gt;10;</span></span><br><span class="line"></span><br><span class="line"><span class="type">int8_t</span> b[<span class="number">1760</span>], z[<span class="number">1760</span>];</span><br><span class="line"></span><br><span class="line"><span class="type">void</span> <span class="title function_">main</span><span class="params">()</span> &#123;</span><br><span class="line">  <span class="type">int</span> sA=<span class="number">1024</span>,cA=<span class="number">0</span>,sB=<span class="number">1024</span>,cB=<span class="number">0</span>,_;</span><br><span class="line">  <span class="keyword">for</span> (;;) &#123;</span><br><span class="line">    <span class="built_in">memset</span>(b, <span class="number">32</span>, <span class="number">1760</span>);  <span class="comment">// text buffer</span></span><br><span class="line">    <span class="built_in">memset</span>(z, <span class="number">127</span>, <span class="number">1760</span>);   <span class="comment">// z buffer</span></span><br><span class="line">    <span class="type">int</span> sj=<span class="number">0</span>, cj=<span class="number">1024</span>; <span class="comment">//j是\theta，1024是对应的余弦值1</span></span><br><span class="line">    <span class="keyword">for</span> (<span class="type">int</span> j = <span class="number">0</span>; j &lt; <span class="number">90</span>; j++) &#123;</span><br><span class="line">      <span class="type">int</span> si = <span class="number">0</span>, ci = <span class="number">1024</span>;  <span class="comment">// sine and cosine of angle i// i是phi</span></span><br><span class="line">      <span class="keyword">for</span> (<span class="type">int</span> i = <span class="number">0</span>; i &lt; <span class="number">324</span>; i++) &#123;</span><br><span class="line">        <span class="type">int</span> R1 = <span class="number">1</span>, R2 = <span class="number">2048</span>, K2 = <span class="number">5120</span>*<span class="number">1024</span>;<span class="comment">//对应原本的1，2，5</span></span><br><span class="line"></span><br><span class="line">        <span class="type">int</span> x0 = R1*cj + R2, <span class="comment">//circlex = R2 + R1 * costheta</span></span><br><span class="line">            x1 = ci*x0 &gt;&gt; <span class="number">10</span>,</span><br><span class="line">            x2 = cA*sj &gt;&gt; <span class="number">10</span>,</span><br><span class="line">            x3 = si*x0 &gt;&gt; <span class="number">10</span>,</span><br><span class="line">            x4 = R1*x2 - (sA*x3 &gt;&gt; <span class="number">10</span>),</span><br><span class="line">            x5 = sA*sj &gt;&gt; <span class="number">10</span>,</span><br><span class="line">            x6 = K2 + R1*<span class="number">1024</span>*x5 + cA*x3,</span><br><span class="line">            x7 = cj*si &gt;&gt; <span class="number">10</span>,</span><br><span class="line">            x = <span class="number">40</span> + <span class="number">30</span>*(cB*x1 - sB*x4)/x6,</span><br><span class="line">            y = <span class="number">12</span> + <span class="number">15</span>*(cB*x4 + sB*x1)/x6,</span><br><span class="line">            N = (-cA*x7 - cB*((-sA*x7&gt;&gt;<span class="number">10</span>) + x2) - ci*(cj*sB &gt;&gt; <span class="number">10</span>) &gt;&gt; <span class="number">10</span>) - x5 &gt;&gt; <span class="number">7</span>;</span><br><span class="line"></span><br><span class="line">        <span class="type">int</span> o = x + <span class="number">80</span> * y;</span><br><span class="line">        <span class="type">int8_t</span> zz = (x6-K2)&gt;&gt;<span class="number">15</span>;</span><br><span class="line">        <span class="keyword">if</span> (<span class="number">22</span> &gt; y &amp;&amp; y &gt; <span class="number">0</span> &amp;&amp; x &gt; <span class="number">0</span> &amp;&amp; <span class="number">80</span> &gt; x &amp;&amp; zz &lt; z[o]) &#123;</span><br><span class="line">          z[o] = zz;</span><br><span class="line">          b[o] = <span class="string">&quot;.,-~:;=!*#$@&quot;</span>[N &gt; <span class="number">0</span> ? N : <span class="number">0</span>];</span><br><span class="line">        &#125;</span><br><span class="line">        R(<span class="number">5</span>, <span class="number">8</span>, ci, si)  <span class="comment">// rotate i</span></span><br><span class="line">      &#125;</span><br><span class="line">      R(<span class="number">9</span>, <span class="number">7</span>, cj, sj)  <span class="comment">// rotate j</span></span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">for</span> (<span class="type">int</span> k = <span class="number">0</span>; <span class="number">1761</span> &gt; k; k++)</span><br><span class="line">      <span class="built_in">putchar</span>(k % <span class="number">80</span> ? b[k] : <span class="number">10</span>);</span><br><span class="line">    R(<span class="number">5</span>, <span class="number">7</span>, cA, sA);</span><br><span class="line">    R(<span class="number">5</span>, <span class="number">8</span>, cB, sB);</span><br><span class="line">    usleep(<span class="number">15000</span>);</span><br><span class="line">    <span class="built_in">printf</span>(<span class="string">&quot;\x1b[23A&quot;</span>);</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
]]></content>
      <categories>
        <category>摸鱼记录</category>
      </categories>
      <tags>
        <tag>三角函数</tag>
        <tag>优化</tag>
      </tags>
  </entry>
  <entry>
    <title>关于SMMS更换国内域名导致Picgo不能上传图片的解决方法</title>
    <url>/2022/08/21/%E8%A7%A3%E5%86%B3Picgo%E4%B8%8A%E4%BC%A0%E5%9B%BE%E7%89%87/</url>
    <content><![CDATA[<p>最近（2022-8-20）在写文档，突然发现用<code>PicGo</code>上传图片一直报错，主要是<code>Error: connect ETIMEDOUT</code>和<code>Error: read ECONNRESET</code>这俩，但是我挂了梯子后用SMMS是可以直接上传图片的，所以问题出在<code>PicGo</code>上面了。查了下，估计是和SMMS更换了国内域名为<code>.app</code>的原因，这里给出我的解决方法:……</p>
<span id="more"></span>
<p>解决方法也很简单，打开<code>PicGo</code>然后点<code>PicGo设置</code>，设置下代理和镜像源就好：</p>
<p><img src="https://s2.loli.net/2022/08/21/YOnJ9T2FG3A8sEb.png" alt="image-20220821001419713" style="zoom:80%;" /></p>
<center><small>我的PicGo设置</small></center>

<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="string">上传代理:</span> <span class="string">http://127.0.0.1:7890</span></span><br><span class="line"><span class="string">插件安装代理:</span> <span class="string">http://127.0.0.1:7890</span></span><br><span class="line"><span class="string">插件镜像地址:</span> <span class="string">https://registry.npm.taobao.org/</span></span><br></pre></td></tr></table></figure>
<p>然后就点确定重启一下<code>PicGo</code>就好了~</p>
]]></content>
      <categories>
        <category>学习记录</category>
      </categories>
      <tags>
        <tag>PicGo</tag>
      </tags>
  </entry>
  <entry>
    <title>通信名词解释</title>
    <url>/2020/01/01/%E9%80%9A%E4%BF%A1%20%E5%90%8D%E8%AF%8D%E8%A7%A3%E9%87%8A/</url>
    <content><![CDATA[<p>本文主要用于记录常见的通信专业的专业术语，并尝试记录其简易的意义与功能，配合博客的本地搜索功能以达到查阅的目的。<span id="more"></span></p>
<h2 id="LTE"><a href="#LTE" class="headerlink" title="LTE"></a>LTE</h2><p>LTE即(Long Term Evolution)长期演化，它其实是一种网络制式（如CDMA、GSM这些）它是3G的演进，但<strong>并非人们普遍误解的4G技术</strong>，而是3G与4G技术之间的一个<strong>过渡</strong>，是3.9G的全球标准,它改进并增强了3G的空中接入技术，采用OFDM和MIMO作为其无线网络演进的唯一标准。在20MHz频谱带宽下能够提供下行326Mbit/s与上行86Mbit/s的峰值速率。改善了小区边缘用户的性能，提高小区容量和降低系统延迟。严格意义上，其实LTE一开始的定位仅仅是3G的加强版，但是随着后期的发展，大大超出当初设计者的预期。本来只能称做3.9G，但是由于不断的在继续改善升级，所以后续版本已经成为了真正的4G。</p>
<h2 id="OFDM"><a href="#OFDM" class="headerlink" title="OFDM"></a>OFDM</h2><p>OFDM即Orthogonal Frequency Division Multiplexing，正交频分复用，属于多载波调制的一种。OFDM技术是多载波传输方案的实现方式之一，通过<a href="https://baike.baidu.com/item/频分复用/7626706">频分复用</a>实现高速串行数据的<a href="https://baike.baidu.com/item/并行传输/5431953">并行传输</a>, 它具有较好的抗多径衰落的能力，能够支持多用户接入，它的调制和解调是分别基于IFFT和FFT来实现的，是实现复杂度最低、应用最广的一种多载波传输方案。</p>
<h2 id="MIMO"><a href="#MIMO" class="headerlink" title="MIMO"></a>MIMO</h2><p>Multiple-In Multiple-Out多进多出，使用多根天线在发送端和接受端构建多个像互不干扰的物理无线信道，同时在收发双方的物理层之间，构建多个并行的<strong>逻辑</strong>无线信道。MIMO系统的一个明显特点就是具有极高的频谱利用效率，在对现有频谱资源充分利用的基础上通过利用空间资源来获取可靠性与有效性两方面增益，<strong>其代价是增加了发送端与接收端的处理复杂度。</strong>详细介绍可见<a href="https://blog.csdn.net/HiWangWenBing/article/details/110871535">这篇文章</a>。</p>
<h2 id="NR"><a href="#NR" class="headerlink" title="NR"></a>NR</h2><p>手机和基站之间的接口，因为是基站和手机之间通过电磁波在空气中传播的，因此就叫做“空口”。由此可见，空口这套东西专用于基站子系统内部，跟核心网的没有直接联系。</p>
<p><img src="https://s2.loli.net/2022/07/11/IYReFBAspcuwLdU.jpg" alt=""></p>
<p>5G使用了新空口，即基站跟核心网这两个子系统的独立性增强了。因此，5G是非常灵活的，可以独立组网，也可以跟4G一起非独立组网。在独立组网时，5G基站连接的是5G核心网；非独立组网时，5G基站和4G基站可以连接4G核心网，也可以连接5G核心网。下图是一张非独立组网选项3和选项7的架构图。其中，4G基站和5G基站都连接到了同一套核心网，共同组成了5G非独立组网体系。</p>
<p><img src="https://s2.loli.net/2022/07/11/nxOfzviYrGQlWD6.jpg" alt=""></p>
<p>这样一来，不论连接的核心网是4G的EPC还是5G的5GC，同一部手机拥有两路空口连接，跟4G基站之间的链路就是“旧空口”，跟5G基站之间的连接就是所谓的“新空口”了。5G新空口是基于4G空口技术设计的，也使用了OFDM的调制方式，在帧结构上修正了4G的一些不合理之处，增加了对大连接和低时延的支持，因此更加灵活，频谱效率也更高了。</p>
<h2 id="NG"><a href="#NG" class="headerlink" title="NG"></a>NG</h2><p><strong>简单的解释就是无线接入网和5G核心网之间的接口。</strong>NG接口是一个逻辑接口，规范了NG接口，NG-RAN节点与不同制造商提供的AMF的互连；同时，分离NG接口无线网络功能和传输网络功能，以便于引入未来的技术。从任何一个NG-RAN节点向5GC可能存在多个NG-C逻辑接口。然后，通过NAS节点选择功能确定NG-C接口的选择。从任何一个NG-RAN节点向5GC可能存在多个NG-U逻辑接口。NG-U接口的选择在5GC内完成，并由AMF发信号通知NG-RAN节点。NG接口分为NG-C接口（NG-RAN和5GC之间的控制面接口）和NG-U接口（NG-RAN和5GC之间的用户面接口）。</p>
<h2 id="BTS"><a href="#BTS" class="headerlink" title="BTS"></a>BTS</h2><p>Base Transceiver Station，可以简单粗暴理解为专属于2G技术的基站。</p>
<h2 id="BSC"><a href="#BSC" class="headerlink" title="BSC"></a>BSC</h2><p>Base Station Controller：基站控制器，是基站收发台和移动交换中心之间的连接点，也为基站收发台（BTS）和移动交换中心（MSC）之间交换信息提供接口。</p>
<h2 id="MSC"><a href="#MSC" class="headerlink" title="MSC"></a>MSC</h2><p>Mobile Switch Center，移动交换中心，是在电话和数据系统之间提供呼叫转换服务和呼叫控制的设备。</p>
<h2 id="VLR"><a href="#VLR" class="headerlink" title="VLR"></a>VLR</h2><p>Visitor Location Register，访问地址寄存器。是一个动态的数据库，在网络中VLR都是与MSCS合设，协助MSCS记录当前覆盖区域内的所有移动用户的相关信息。</p>
<h2 id="HLR"><a href="#HLR" class="headerlink" title="HLR"></a>HLR</h2><p>Home Location Register，归属地址寄存器。是一个静态数据库，是移动网络中存储永久用户信息的主数据库，包括地址、帐户状态和偏好，是GSM系统的一个集成构件，由用户的网络运营商维护。</p>
<h2 id="AUC"><a href="#AUC" class="headerlink" title="AUC"></a>AUC</h2><p>Authentication Center，鉴权中心，是用于产生为确定移动用户身份和对呼叫身份保密所需鉴权、加密的三参数（随机号码 RAND 、符合响应 SRES 和密钥 Kc ）的功能实体。</p>
<h2 id="EIR"><a href="#EIR" class="headerlink" title="EIR"></a>EIR</h2><p>Equipment Identity Register，设备标识寄存器。简单理解为存储终端设备的标识符。</p>
<h2 id="ISDN"><a href="#ISDN" class="headerlink" title="ISDN"></a>ISDN</h2><p>Integrated Services Digital Network，综合业务数字网。是一个数字电话网络国际标准，是一种典型的电路交换网络系统。在ITU的建议中，ISDN是一种在数字电话网IDN的基础上发展起来的通信网络，ISDN能够支持多种业务，包括电话业务和非电话业务。</p>
<h2 id="PSTN"><a href="#PSTN" class="headerlink" title="PSTN"></a>PSTN</h2><p> Public Switched Telephone Network，公共交换电话网络，一种常用旧式电话系统。即我们日常生活中常用的电话网。</p>
<h2 id="PLMN"><a href="#PLMN" class="headerlink" title="PLMN"></a>PLMN</h2><p>Public Land Mobile Network，公共陆地移动网。由政府或它所批准的经营者，为公众提供陆地移动通信业务目的而建立和经营的网络。该网路通常与公众交换电话网（PSTN）互连，形成整个地区或国家规模的通信网。</p>
<h2 id="MME"><a href="#MME" class="headerlink" title="MME"></a>MME</h2><p>Mobility Management Entity，移动管理实体。它负责空闲模式的UE (User Equipment)的定位，传呼过程，包括中继，简单的说MME是负责信令处理部分。</p>
<h2 id="SGW"><a href="#SGW" class="headerlink" title="SGW"></a>SGW</h2><p>Serving Gateway，服务网关。SGW（Serving GateWay，服务网关）是<a href="https://baike.baidu.com/item/移动通信网络/22287927">移动通信网络</a>EPC中的重要网元。EPC网络实际上是原3G核心网PS域的演进版本，而SGW的功能和作用与原3G核心网SGSN网元的用户面相当，即在新的EPC网络中，控制面功能和媒体面功能分离更加彻底。</p>
<h2 id="PGW"><a href="#PGW" class="headerlink" title="PGW"></a>PGW</h2><p>PDN Gateway，PDN网关。类似于GGSN网元的功能，为EPC网络的边界网关，提供用户的会话管理和承载控制、数据转发、IP地址分配以及非3GPP用户接入等功能。它是3GPP接入和非3GPP接入公用数据网络PDN的锚点。所谓3GPP接入，是指3GPP标准家族出来的无线接入技术，比如我国中国移动和中国联通的手机，就是3GPP接入技术；所谓非3GPP接入，就是3GPP标准家族以外的无线接入技术，典型的比如中国电信的CDMA接入技术以及流行的WiFi接入技术等。就是说，在EPC网络中，移动终端如果是非3GPP接入，它可以不经过MME网元和SGW网元，但一定会经过PGW网元，才能接入到PDN。</p>
<h2 id="SGSN"><a href="#SGSN" class="headerlink" title="SGSN"></a>SGSN</h2><p>Serving GPRS Support Node，服务GPRS支持节点。SGSN与GGSN 配合，共同完成移动通信网络分组业务（PS，Packet Service）功能。其地位和作用类似于移动通信网络电路域（CS，Circuit Switch）中的MSC/VLR。当用户处于GPRS Attach（GPRS附着）状态时，SGSN 中存储了同分组相关的用户信息和位置信息。</p>
<h2 id="GGSN"><a href="#GGSN" class="headerlink" title="GGSN"></a>GGSN</h2><p>Gateway GPRS Support Node，网关GPRS支持节点。SGSN与GGSN 配合，共同完成移动通信网络分组业务（PS，Packet Service）功能。主要是起网关作用，它可以和多种不同的数据网络连接，如ISDN、PSPDN和LAN等，可以把GSM网中的GPRS分组数据包进行协议转换，从而可以把这些分组数据包传送到远端的TCP/IP或X.25网络。</p>
<h2 id="ATCA"><a href="#ATCA" class="headerlink" title="ATCA"></a>ATCA</h2><p>Advanced Telecom Computing Architecture，先进电信计算架构，可以理解为是为下一代融合通信及数据网络应用提供的一个高性价比的，基于模块化结构的、兼容的、并可扩展的硬件构架。</p>
<h2 id="ETCA"><a href="#ETCA" class="headerlink" title="ETCA"></a>ETCA</h2><p>Enhanced ATCA，增强型ATCA，可以理解为ATCA的强化版。</p>
<h2 id="SBA"><a href="#SBA" class="headerlink" title="SBA"></a>SBA</h2><p>Service Based Architecture，即基于服务的架构。SBA架构，基于云原生构架设计，借鉴了IT领域的“微服务”理念。把原来具有多个功能的整体，分拆为多个具有独自功能的个体。每个个体，实现自己的微服务。</p>
<h2 id="NFV"><a href="#NFV" class="headerlink" title="NFV"></a>NFV</h2><p>Network Functions Virtualization，利用<a href="https://baike.baidu.com/item/虚拟化技术/276750">虚拟化技术</a>，将<a href="https://baike.baidu.com/item/网络节点/9338583">网络节点</a>阶层的功能，分割成几个功能区块，分别以软件方式实现，不再局限于<a href="https://baike.baidu.com/item/硬件/479446">硬件</a>架构。</p>
<h2 id="IMS"><a href="#IMS" class="headerlink" title="IMS"></a>IMS</h2><p>IP Multimedia Subsystem，是一种全新的多媒体业务形式，它能够满足的<a href="https://baike.baidu.com/item/终端客户">终端客户</a>更新颖、更多样化多媒体业务的需求。IMS被认为是下一代网络的核心技术，也是解决移动与固网融合，引入语音、数据、视频三重融合等差异化业务的重要方式。但是，全球IMS网络多数处于初级阶段，应用方式也处于业界探讨当中。</p>
<h2 id="EPC"><a href="#EPC" class="headerlink" title="EPC"></a>EPC</h2><p>Evolved Packet Core，特点为仅有分组域而无电路域、基于全IP结构、控制与承载分离且网络结构扁平化，其中主要包含MME、SGW、PGW、PCRF等网元。其中SGW和PGW常常合设并被称为SAE-GW。</p>
<h2 id="HSS"><a href="#HSS" class="headerlink" title="HSS"></a>HSS</h2><p>Home Subscriber Server，是IMS（IP Multimedia Subsystem，<a href="https://baike.baidu.com/item/IP多媒体子系统/2841593">IP多媒体子系统</a>）中控制层的重要组成部分，支持用于处理调用/会话的IMS网络实体的主要用户数据库。它包含用户配置文件，执行用户的身份验证和授权，并可提供有关用户物理位置的信息。</p>
<h2 id="NRF"><a href="#NRF" class="headerlink" title="NRF"></a>NRF</h2><p>Network Repository Function，网络存储库功能，负责对网络功能服务注册登记、状态监测等，实现网络功能服务自动化管理、选择和可扩展，并允许每个网络功能发现其它网络功能提供的服务。</p>
<h2 id="PCF"><a href="#PCF" class="headerlink" title="PCF"></a>PCF</h2><p>Policy Control function，策略控制功能，支持统一的策略框架去管理网络行为，提供策略规则给网络实体去实施执行，访问统一数据仓库（UDR）的订阅信息。</p>
<h2 id="UDM"><a href="#UDM" class="headerlink" title="UDM"></a>UDM</h2><p>Unified Data Management，统一数据管理，负责用户标识、签约数据、鉴权数据的管理、用户的服务网元注册管理（比如当前为终端提供业务的AMF、SMF等，如当用户切换了访问的AMF时，UDM还会向旧的AMF发起注销消息，要求旧的AMF删除用户相关信息）。</p>
<h2 id="UDR"><a href="#UDR" class="headerlink" title="UDR"></a>UDR</h2><p>Unified Data Repository，统一数据仓库功能，用于UDM存储订阅数据或读取订阅数据以及PCF存储策略数据或者读取策略数据。</p>
<h2 id="SMF"><a href="#SMF" class="headerlink" title="SMF"></a>SMF</h2><p>Service Management Function，业务管理功能。</p>
<h2 id="AF"><a href="#AF" class="headerlink" title="AF"></a>AF</h2><p>Application Function， 应用功能。AF类似于一个应用服务器，其与其他5G核心网控制面NF交互，并提供业务服务。AF可以针对不同的应用服务而存在，可以由运营商或可信的第三方拥有。</p>
<h2 id="AUSF"><a href="#AUSF" class="headerlink" title="AUSF"></a>AUSF</h2><p>Authentication Server Function，鉴权服务功能 ，AUSF用于接收AMF（access and mobility management function，AMF）对UE进行身份验证的请求，通过向UDM请求密钥，再将UDM下发的密钥转发给AMF进行鉴权处理。</p>
<h2 id="AMF"><a href="#AMF" class="headerlink" title="AMF"></a>AMF</h2><p>Access and Mobility management Function，接入和移动管理功能。AMF负责UE身份验证、鉴权、注册、移动性管理和连接管理等功能。与4G EPC相比，AMF的功能类似于MME。</p>
<h2 id="R-AN"><a href="#R-AN" class="headerlink" title="(R)AN"></a>(R)AN</h2><p>Radio Access Network，无线接入网是指固定用户全部或部分以无线的方式接入到交换机,通常无线接入网所接入的交换机是指PSTN的交换机,但也可以是ISDN的交换机。</p>
<h2 id="UPF"><a href="#UPF" class="headerlink" title="UPF"></a>UPF</h2><p>User Plane Function，用户平面功能，数据从基站到网络的路由转发是它的主要功能，是核心网里唯一的处理数据的模块，剩下的模块都是处理信令的，也就是做网络控制的。5G核心网是彻底的控制面与用户面分离，就是用户面模块仅仅处理数据，控制面模块仅仅负责实现网络管控。</p>
<h2 id="UE"><a href="#UE" class="headerlink" title="UE"></a>UE</h2><p>User Equipment，用户设备（UE）是指在一台无线网络中的设备，其能够使用户通过无线通信网络通信。</p>
]]></content>
      <tags>
        <tag>通信技术</tag>
      </tags>
  </entry>
  <entry>
    <title>独立组网和非独立组网</title>
    <url>/2022/08/28/%E7%8B%AC%E7%AB%8B%E7%BB%84%E7%BD%91%E5%92%8C%E9%9D%9E%E7%8B%AC%E7%AB%8B%E7%BB%84%E7%BD%91/</url>
    <content><![CDATA[<p>4G技术刚落地没多久（按通信技术的代数来划分来说4G还是比较年轻的），5G就开始推广了。为了更充分发挥现有的4G基站设备，5G技术的发展迭代后诞生了NSA和NSA组网的两种方式，下文将简单解析。</p>
<p><img src="https://s2.loli.net/2022/08/28/RYD6uAb1SsX4WlZ.png" alt="image-20220828172224509" style="zoom:50%;" /></p>
<span id="more"></span>
<h1 id="独立（NSA）组网和非独立-NSA-组网"><a href="#独立（NSA）组网和非独立-NSA-组网" class="headerlink" title="独立（NSA）组网和非独立(NSA)组网"></a>独立（NSA）组网和非独立(NSA)组网</h1><h2 id="5G网络架构"><a href="#5G网络架构" class="headerlink" title="5G网络架构"></a>5G网络架构</h2><p>5G网络中有SA和NSA两种，在3GPP的R15版本中分成两个阶段，他们的部署是不同的。所谓SA即为<code>StandAlon</code>的缩写，NSA即为<code>NotStandAlone</code>，之所以有两种组网方式，是因为4G从推广普及到现在这个时间其实还不算很久，当初为了4G通信而购置的大量硬件设施的成本还没盈利回来，所以现阶段的5G通信为了推行技术，故对4G的设备进行了一定的兼容。这样，各大运营商可以使用上5G技术来赚米，又不会浪费现在的设备。</p>
<h2 id="SA和NSA简略介绍"><a href="#SA和NSA简略介绍" class="headerlink" title="SA和NSA简略介绍"></a>SA和NSA简略介绍</h2><p>如果从技术理论设计上来说，<strong>SA（独立组网）无疑是最佳的选择</strong>，但现实是 3GPP 不得不考虑目前各大运营 商已存在庞大的 4G 网络，如何能<strong>让就网络设备能继续发挥作用，节省投资，又能享受 5G 的体验，这就是 NSA （非独立组网）。</strong></p>
<h3 id="SA与NSA分类"><a href="#SA与NSA分类" class="headerlink" title="SA与NSA分类"></a>SA与NSA分类</h3><p><img src="https://s2.loli.net/2022/08/28/RYD6uAb1SsX4WlZ.png" alt="image-20220828172224509" style="zoom:50%;" /></p>
<center><small>图1 5G组网分类</small></center>

<p><img src="https://s2.loli.net/2022/08/28/aQ47rIyAvwtZW16.png" alt="image-20220828172703315" style="zoom:50%;" /></p>
<center><small>图2 SA和NSA组网方式</small></center>

<p>图2高亮的部分其实对应图1的物种组网方式。这么多的选项，就是 3GPP 提供给运营商更多的选择，主要为他们提供节省资源利旧，我们看一下它们的差别。</p>
<ul>
<li><p>SA-opt2（NGC+NR）：全新的 5G 核心网和无线网 gNB 组网，完全新建。这样的优势是可以完全发挥 5G 的各项性能， 按照 3GPP 的标准推进。缺点就需要浩大的投资。</p>
</li>
<li><p>SA-opt3（NGC+NR（CP）+LTE）：把原来的 4G 基站进行升级接入，它也属于独立组网。</p>
</li>
<li><p>NSA-opt3： 4G 核心网+（4G 基站与 5G 基站混合），运营商一般都爱用3x选项，把UPF数据分两部分，把对4G网络造成瓶颈的部分放到5G处理，剩下那部分走4G的LTE基站。</p>
<p><img src="https://s2.loli.net/2022/08/28/lzfWReDn8HUaGbX.png" alt="image-20220828173203767" style="zoom:50%;" /></p>
</li>
<li><p>NSA-opt4：5G 核心网+（4G 基站与 5G 基站混合）</p>
</li>
<li><p>NSA-op7：5G 核心网+（4G 基站与 5G 基站混合），但是UPF和CPF的方式不同。</p>
</li>
</ul>
<h3 id="技术要点总结"><a href="#技术要点总结" class="headerlink" title="技术要点总结"></a>技术要点总结</h3><ul>
<li>NSA 没有 5G 核心网，是利用现有的 4G 核心网接入，而 SA 则是全部采用 5G 架构，包括 5G 的核心网。</li>
<li>由于 NSA 是新建 5G 基站+4G 基站升级支持 5G 的，再连接 4G 核心网，因此，在 NSA 组网下，5G 与 4G 在接入网级互通复杂，虽然利旧了 4G 设备，但组网和运营成本大增；在 SA 组网下，5G 与 4G 仅在核心网级互 通，非常简单。</li>
<li>在 NSA 组网下，终端需要支持 LTE 和 NR 双连接，终端成本会更高；在 SA 组网下，终端仅连接 NR 一种 无线接入技术，对 4G 采用回落技术，简单成熟的技术。</li>
</ul>
<p>从技术的角度来说，NSA 肯定是要比 SA 差很远，但 NSA 可以利用现有的设备，节 省投资快速部署 5G，是运营商愿意使用的关键。</p>
<h3 id="功能差异对比"><a href="#功能差异对比" class="headerlink" title="功能差异对比"></a>功能差异对比</h3><div class="table-container">
<table>
<thead>
<tr>
<th style="text-align:center">功能名称</th>
<th style="text-align:center">SA支持情况</th>
<th style="text-align:center">NSA支持情况</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center">5G网络切片</td>
<td style="text-align:center">✅</td>
<td style="text-align:center">❌</td>
</tr>
<tr>
<td style="text-align:center">多接入边缘计算（MEC）</td>
<td style="text-align:center">✅</td>
<td style="text-align:center">❌</td>
</tr>
<tr>
<td style="text-align:center">网络安全与开放</td>
<td style="text-align:center">安全和开放能力增强</td>
<td style="text-align:center">安全能力与4G网络一致，无开放能力</td>
</tr>
<tr>
<td style="text-align:center">部署运维</td>
<td style="text-align:center">部署成本高，运维成本低</td>
<td style="text-align:center">部署成本低且快，运维成本高</td>
</tr>
</tbody>
</table>
</div>
<p>综上所述，SA 将是运营商未来的方向，NSA 只作为过渡快速部署和利旧的方案，会获得短期的应用。</p>
]]></content>
      <categories>
        <category>学习记录</category>
      </categories>
      <tags>
        <tag>通信技术</tag>
      </tags>
  </entry>
  <entry>
    <title>读《造神年代》的一些读后随想</title>
    <url>/2022/08/30/%E9%80%A0%E7%A5%9E%E5%B9%B4%E4%BB%A3/</url>
    <content><![CDATA[<p align="center">
    <img src="https://s2.loli.net/2022/08/30/EpnfvMBasDtQ1Tr.png" alt="pyecharts logo" width=768 height=563 />
</p>
<h1 align="center">造神年代真几把好看！</h1>
<p align="center"></p>




<span id="more"></span>
]]></content>
      <categories>
        <category>杂项</category>
      </categories>
      <tags>
        <tag>随想</tag>
      </tags>
  </entry>
  <entry>
    <title>【学习记录】2023-02-28</title>
    <url>/2023/02/28/23228/</url>
    <content><![CDATA[<p>本周主要是看一堆乱七八糟的论文，然后有喜欢的人了！</p>
<span id="more"></span>
<h2 id="激活函数设计与对抗训练"><a href="#激活函数设计与对抗训练" class="headerlink" title="激活函数设计与对抗训练"></a>激活函数设计与对抗训练</h2><p>这篇文章投的是ICLR2023，主要是从梯度的质量以及对抗训练的角度对激活函数进行一个新的思考。一般的卷积网络使用的是ReLU激活函数，这个函数在接近零点的地方梯度变化是非常大的，然后神经网络对抗攻击一般集中于图像领域，一般抵御对抗攻击的方法就是将对抗样本加入到训练样本中进行训练。在Tsipras等人的论文中有这么一个结论：<em>“对抗的鲁棒性是没有免费的午餐”</em>——即使用对抗样本需要在干净的样本的精度和对对抗攻击的鲁棒性进行权衡，一般来讲对对抗性攻击的抵御能力越强，在干净样本上的精确度就越低。</p>
<p>对抗训练的目标是优化下面这个式子：</p>
<script type="math/tex; mode=display">
\arg \min _{\theta}\mathbb E_{(x,y)\sim\mathbb D}{[\max _{\varepsilon\in \mathbb S}L(\theta,x+\varepsilon,y)]}</script><p>$\mathbb D$是数据的分布，$\mathbb S$是产生的对抗样本扰动的范围，一般情况下为了让对抗样本难以被人以肉眼观察到，会将这个范围设置的很小；$L$是损失函数，它和网络的参数$\theta$、对抗样本$x+\varepsilon$以及真实的样本标签有关。整个过程包含两个部分：首先是内部的最大化过程，该过程用于计算对抗性样本，然后最外层的最小化过程用于计算网络参数的更新。</p>
<p>作者认为是ReLU的陡峭性引入的梯度不连续的问题，这让我想到在之前文章中提到流形的观点。现实的数据（以图像为例）基本都是高维的，而所需要表达的信息其实是低维度的，Embed到高维流形的信息就和一棵大树的树干差不多，我们评价一棵树的年龄，一般都是按其树干的大小，而枝条、叶片其实是这棵树的额外的表达，枝条和叶片会随着气象的变化而变化，但是树干大部分时间是不变的。回到对抗样本产生的原因上来，对抗样本出现的原因就是因为神经网络学习到的函数一般都不是连续的，而正是这种不连续造就了学习到的目标的分布出现了“空隙”，对抗样本就是这些空隙中的一个“污点”。作者认为使用<strong>平滑</strong>一点的激活函数可能会减少对抗样本的出现。</p>
<p><strong>平滑</strong>一词的定义在这里指的是函数的一阶导数在任意地方都是连续的。作者使用了<code>Parametric Softplus</code>函数：$f(\alpha,x)=\frac{1}{\alpha}\log(1+exp(x))$对ReLU函数的平滑近似，它的一阶导数为：</p>
<script type="math/tex; mode=display">
\frac{d}{dx}f(\alpha,x)=\frac{1}{1+\exp (-\alpha x)}</script><p>作者使用$\alpha=10$以对ReLU进行更好的平滑近似，仅在反向传播使用了参数化softplus，而在模型的前向推断过程还是使用ReLU，因为推断过程一般都是用ReLU，对应的是上面对抗训练目标中在产生训练样本的过程中使用的ReLU，而在更新网络参数使用的是参数化softplus。</p>
<p>结论就是ReLU削弱了对抗训练的效果，即便在训练时长与对抗攻击迭代更多的情况下，这种退化的效果依然无法避免。使用平滑一点的激活函数也许能改变这种情况，比如说：</p>
<ul>
<li><p><strong>Softplus</strong>:$\mathrm{Softplus}(x)=\log(1+\exp (x))$，文章使用的是参数化形式的。</p>
</li>
<li><p><strong>SILU</strong>:$\mathrm{SILU}(x)=x\cdot sigmoid(x)$，对比于一般ReLU，在$x&lt;0$的部分不会有突变</p>
</li>
<li><p><strong>Expoential Linear Unit(ELU)</strong>:</p>
<script type="math/tex; mode=display">
ELU(x,\alpha)=\begin{cases}
x, if \, x\geq0\\
\alpha(\exp(x)-1), \, otherwise
\end{cases}</script><p>一般来说取$\alpha=1$。</p>
</li>
<li><p><strong>Gaussian Error Linear Unit(GELU)</strong>:$\mathrm{GELU(x)}=x\cdot \Phi(x)$，其中$\Phi(x)$是标准正态分布的累积分布函数。</p>
</li>
</ul>
<p>作者在ImageNet上用ResNet-50作为backbone进行实验，结论是SILU的鲁棒性能最优。然后作者提出了一种新的平滑ReLU：</p>
<script type="math/tex; mode=display">
\mathrm{SmoothReLU}(x,\alpha)=\begin{cases}
\begin{aligned}
&x-\frac{1}{\alpha}\log (\alpha x + 1),&x\geq 0\\
&0,& otherwise
\end{aligned}
\end{cases}</script><p>当$\alpha\rightarrow \infty$时就变成了ReLU。其一阶导是连续的：</p>
<script type="math/tex; mode=display">
\frac{d}{dx}\mathrm{SmoothReLU}(x,\alpha)=
\begin{cases}
\begin{aligned}
&\frac{\alpha x}{1+\alpha x},&x\geq0,\\
&0,&otherwise
\end{aligned}
\end{cases}</script><p>同样的配置又进行了实验，证明了平滑确实是提升鲁棒性的一个方法。具体的实验对比图如下：</p>
<p><img src="https://s2.loli.net/2023/02/28/2XQleMtgi8xhU3z.png" alt="image-20230228124711589"></p>
<p>结果越偏右上的地方的效果更好。</p>
<h2 id="Denoising-Diffusion-Probabilistic-Models初探"><a href="#Denoising-Diffusion-Probabilistic-Models初探" class="headerlink" title="Denoising Diffusion Probabilistic Models初探"></a>Denoising Diffusion Probabilistic Models初探</h2><p>作为一种20年兴起的生成模型，扩散模型与其他的生成模型GAN、基于流的模型不同，不再是通过一个“限制”（比如种类，风格等等）的输入，逐步添加信息，最终得到生成的图片/ 语音吗， 而是采用从高斯噪音中逐步依照一定条件 “采样” 特殊的分布，随着“采样”轮次的增加最终得到生成的图片/语音 。 换句话说，Diffusion Model 的合成过程是通过一次次迭代在噪声中提取出所需要的图像/音频，随着迭代步数的增加，合成质量也在越来越好 。</p>
<p>扩散模型的核心是马尔可夫链与朗之万动力学。所有的生成式模型的核心工作都是把输入特征转换到隐空间$z$上然后将其再反映射回去。扩散模型将输入映射到隐空间的方法是不断地往原始输入中加入噪声，然后解噪的过程就是反映射的过程。前向的加噪过程，在一般的生成模型中用$q$表示映射过程，扩散模型中的$q$是这样定义的：</p>
<script type="math/tex; mode=display">
q(\mathrm {x}_{1:T}|x_0):=\prod_{t=1}^{T}q(\mathrm x_t|\mathrm x_{t-1}),\\
q(\mathrm x_t|\mathrm x_{t-1}):=\mathcal N(\mathrm x_t;\sqrt{1-\beta_t}\mathrm x_{t-1},\beta_t \bold I)</script><p>解噪过程$p$是这么定义的：</p>
<script type="math/tex; mode=display">
p_\theta(\mathrm x_{0:T}):=p(\mathrm x_T)\prod_{t=1}^{T}p_\theta (\mathrm x_{t-1}|\mathrm x_t),\\
p_\theta(\mathrm x_{t-1}| \mathrm x_{t}):=\mathcal N(\mathrm x_{t-1};\bold \mu_\theta (\mathrm x_t, t),\Sigma_\theta(\mathrm x_t, t))</script><p>本质来讲，这个模型其实是要训练一个网络，这个网络可以识别到输入图像中的“噪音”然后将其去除还原图像。扩散模型的控制逻辑是马尔可夫链，因此概率论、采样、统计的相关知识将会发挥重要作用。</p>
<h3 id="训练目标——Score-Matching"><a href="#训练目标——Score-Matching" class="headerlink" title="训练目标——Score Matching"></a>训练目标——Score Matching</h3><p>Diffusion Model 的启迪需要追溯到一个叫去噪自编码器（Denoising Autoencoder）的结构和Score Matching方法。Score Matching 的提出是为了求解特定的概率密度函数，是一种比较有针对性的参数估计方法。比较经典的求解特定的概率密度函数的方法是<code>马尔可夫链蒙特卡洛方法</code>，蒙特卡洛采样不必多说了，加上了马尔可夫链就是为了迭代：先估计一个粗略的参数，然后通过状态转移的方式在估计下一个更为细致的参数。通过有限次的迭代达到预期的精度的参数估计。</p>
<p>Score Matching的方法的好处就是节省了时间，因为MCMC采样是非常耗时的。Score Matching的做法是通过最小化模型的对数概率梯度以及观测数据的对数密度梯度的期望的平方距离来估计参数。即，如果处理不了复杂的函数，那么就处理这个函数的导数。</p>
<p>然后我们就可以用各种方法进行参数估计的数值运算了，比如：分别计算<code>原始数据概率密度函数</code>和<code>模型的输出的概率密度函数的梯度</code>(因为我们的目标是训练一个能生成与原始数据分布相同数据的模型)， 然后通过比对两个梯度之间的差异，来代表原始数据与模型的输出概率密度函数的相似程度，这样就相当于模型的训练有了个目标，这个目标函数可以表示为两个梯度的差。有了目标函数就可以通过最大似然估计和梯度下降法来训练参数了。</p>
<h3 id="模型结构——Denoising-Autoencoder"><a href="#模型结构——Denoising-Autoencoder" class="headerlink" title="模型结构——Denoising Autoencoder"></a>模型结构——Denoising Autoencoder</h3><p>去噪自动编码器其实非常常见，将有噪声的图片输入到Encoder模型，然后编码成一个低维度的特征，再通过Decoder模型还原图片达到图像去噪的效果。</p>
]]></content>
      <categories>
        <category>学习记录</category>
      </categories>
      <tags>
        <tag>激活函数</tag>
        <tag>对抗训练</tag>
      </tags>
  </entry>
  <entry>
    <title>Embedding的概念与实现</title>
    <url>/2023/02/18/Embedding/</url>
    <content><![CDATA[<p>Embedding是流形假说中的一个常用概念，本质上来讲是高维数据到低维数据的映射。</p>
<span id="more"></span>
<h2 id="Embedding概念"><a href="#Embedding概念" class="headerlink" title="Embedding概念"></a>Embedding概念</h2><p>天才少年Colah的博客中的一篇文章<a href="https://colah.github.io/posts/2014-03-NN-Manifolds-Topology/">Neural Networks, Manifolds, and Topology </a>中记录了流形与神经网络的对应关系。Embedding（嵌入）是拓扑学里面的词，在深度学习中常常与Manifolds（流形）搭配使用。一个事物，它可以有很多种表示方法，举个例子：我们所处的空间是三维空间，但我们所处的地方可以用一个二维的经纬度坐标进行表示，我们称这个关系叫做三维数据到二维空间的一个嵌入。</p>
<p>Old school派对Embedding的理解是“自然的原始数据是低维的流形嵌入于(embedded in)原始数据所在的高维空间”，深度学习的任务就是将分布在高维空间的原始数据映射到低维空间，从而在低维空间上对事物进行划分。然而随着深度学习的发展以及概念的误用，Embedding逐渐变成了特征提取的过程，而输入与输出的关系不再仅限于是从高到低维的映射。</p>
<p>另一个问题就是，多模态里面为什么需要做Embedding。基于上面的假说，多模态本质上是针对任务进行信息的融合，而分布在不同的高维数据需要将他们映射到同一个向量空间中，再进行融合，所以这个映射需要用embedding实现。</p>
<h2 id="Embedding实现"><a href="#Embedding实现" class="headerlink" title="Embedding实现"></a>Embedding实现</h2><h3 id="简单实现"><a href="#简单实现" class="headerlink" title="简单实现"></a>简单实现</h3><p><code>Pytorch</code>中有<code>torch.nn.embedding(num_embeddings, embedding_dim, padding_idx)</code>这个类实现embedding，常见的一个应用场景是NLP的词向量嵌入。该函数有三个参数：</p>
<ul>
<li><strong>num_embeddings</strong>:词表大小</li>
<li><strong>embedding_dim</strong>:需要多少个维度表示一个符号</li>
<li><strong>padding_idx</strong>:即需要用0填充的符号在词表中的位置</li>
</ul>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> torch.nn <span class="keyword">as</span> nn</span><br><span class="line"></span><br><span class="line"><span class="comment">#词表</span></span><br><span class="line">word_to_id = &#123;<span class="string">&#x27;hello&#x27;</span>:<span class="number">0</span>, <span class="string">&#x27;&lt;PAD&gt;&#x27;</span>:<span class="number">1</span>,<span class="string">&#x27;world&#x27;</span>:<span class="number">2</span>&#125;</span><br><span class="line">embeds = nn.Embedding(<span class="built_in">len</span>(word_to_id), <span class="number">4</span>,padding_idx=word_to_id[<span class="string">&#x27;&lt;PAD&gt;&#x27;</span>])</span><br><span class="line"></span><br><span class="line">text = <span class="string">&#x27;hello world &lt;PAD&gt; &lt;PAD&gt;&#x27;</span></span><br><span class="line">hello_idx = torch.LongTensor([word_to_id[i] <span class="keyword">for</span> i <span class="keyword">in</span> text.split()])</span><br><span class="line"><span class="comment">#词嵌入得到词向量</span></span><br><span class="line">hello_embed = embeds(hello_idx)</span><br><span class="line"><span class="built_in">print</span>(hello_embed)</span><br><span class="line"></span><br><span class="line">tensor([[-<span class="number">1.1436</span>, <span class="number">1.4588</span>, -<span class="number">1.2755</span>, <span class="number">0.0077</span>],</span><br><span class="line">[-<span class="number">0.9600</span>, -<span class="number">1.9986</span>, -<span class="number">1.1087</span>, -<span class="number">0.1520</span>],</span><br><span class="line">[ <span class="number">0.0000</span>, <span class="number">0.0000</span>, <span class="number">0.0000</span>, <span class="number">0.0000</span>],</span><br><span class="line">[ <span class="number">0.0000</span>, <span class="number">0.0000</span>, <span class="number">0.0000</span>, <span class="number">0.0000</span>]], grad_fn=)</span><br></pre></td></tr></table></figure>
<h3 id="稍微复杂的实现"><a href="#稍微复杂的实现" class="headerlink" title="稍微复杂的实现"></a>稍微复杂的实现</h3><p>稍微复杂的实现是我在用指针网络解决TSP问题的过程中参考别人的代码时发现的：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">GraphEmbedding</span>(nn.Module):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, input_size, embedding_size, use_cuda=USE_CUDA</span>):</span><br><span class="line">        <span class="built_in">super</span>(GraphEmbedding, self).__init__()</span><br><span class="line">        self.embedding_size = em bedding_size</span><br><span class="line">        self.use_cuda = use_cuda</span><br><span class="line">        </span><br><span class="line">        self.embedding = nn.Parameter(torch.FloatTensor(input_size, embedding_size)) </span><br><span class="line">        self.embedding.data.uniform_(-(<span class="number">1.</span> / math.sqrt(embedding_size)), <span class="number">1.</span> / math.sqrt(embedding_size))</span><br><span class="line">        </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, inputs</span>):</span><br><span class="line">        batch_size = inputs.size(<span class="number">0</span>)</span><br><span class="line">        seq_len    = inputs.size(<span class="number">2</span>)</span><br><span class="line">        embedding = self.embedding.repeat(batch_size, <span class="number">1</span>, <span class="number">1</span>)  </span><br><span class="line">        embedded = []</span><br><span class="line">        inputs = inputs.unsqueeze(<span class="number">1</span>)</span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(seq_len):</span><br><span class="line">            embedded.append(torch.bmm(inputs[:, :, :, i].<span class="built_in">float</span>(), embedding))</span><br><span class="line">        embedded = torch.cat(embedded, <span class="number">1</span>)</span><br><span class="line">        <span class="keyword">return</span> embedded</span><br></pre></td></tr></table></figure>
<p>本质是一个矩阵乘法。</p>
]]></content>
      <categories>
        <category>学习记录</category>
      </categories>
      <tags>
        <tag>深度学习</tag>
        <tag>概念理解</tag>
      </tags>
  </entry>
  <entry>
    <title>神经网络组合优化</title>
    <url>/2023/02/18/Record/</url>
    <content><![CDATA[<h1 id="Neural-Combinatorial-Optimization-with-Reinforcement-Learning"><a href="#Neural-Combinatorial-Optimization-with-Reinforcement-Learning" class="headerlink" title="Neural Combinatorial Optimization with Reinforcement Learning"></a>Neural Combinatorial Optimization with Reinforcement Learning</h1><p>论文连接：<a href="https://arxiv.org/pdf/1611.09940.pdf">1611.09940.pdf (arxiv.org)</a>，记录自己的复现记录。</p>
<span id="more"></span>
<h2 id="引言"><a href="#引言" class="headerlink" title="引言"></a>引言</h2><p>组合优化问题是一个计算机科学的基础问题。文章主要针对旅行商（TSP）问题进行研究，而TSP问题是一个NP-Hard的问题，实践中一般都是使用手工设计的启发式算法指导寻找问题的求解。但这些方法的鲁棒性不太行，如果问题的规模或者问题的条件发生了变化，就需要重新迭代，相比之下机器学习可以基于训练数据自动进行启发式的搜索。</p>
<p>大部分成功的机器学习算法都是监督学习，不太适用于组合优化问题。但是强化学习的方法也许可以解决组合优化问题，作者展示了即使使用了最优解作为标签的监督学习的算法也不如使用强化学习方法寻找到的解的性能。</p>
<p>作者将他们的方法称为神经组合优化（Neural Combinatorial Optimization），这是一种使用神经网络的强化学习方法解决组合优化问题的框架，作者使用了两种基于策略梯度的方法。第一种是RL预训练，使用了训练集以优化循环神经网络（RNN）作为策略输出的参数，目标是拟合期望奖励，在测试过程中策略是固定的，然后使用$\varepsilon -greedy$策略或采样进行交互；第二种方法是激活搜索，不包含预训练过程，使用随机的策略并优化RNN的参数已达到预期的目标，同时也保持跟踪最佳的搜索采样的解。这两种效果都很不错。</p>
<p>在二维平面约100个节点的欧拉距离图上，神经组合优化比使用监督学习的方法效果要好，并且接近最优解。作者还在KnpSack问题上进行了测试，发现在200个物品下算法依然展现良好性能。说明神经网络可以作为一个组合优化问题的求解工具，尤其是当启发式算法很难设计相关元素的时候能发挥良好作用。</p>
<h2 id="先前工作"><a href="#先前工作" class="headerlink" title="先前工作"></a>先前工作</h2><p>略</p>
<h2 id="TSP问题的神经网络架构"><a href="#TSP问题的神经网络架构" class="headerlink" title="TSP问题的神经网络架构"></a>TSP问题的神经网络架构</h2><p>给定一个输入的图，用序列$s=\{x_i\}_{i=1}^{n}$表示$n$个城市的二维空间，其中$x_i\in\mathbb R^{2}$，我们期望找到一种点变换$\pi$，即旅行路线，使得只到访每个城市一次，并且使旅行路线最短。旅行路线所代表的点变换$\pi$的长度表示为：</p>
<script type="math/tex; mode=display">
L(\pi|s)=||x_{\pi(n)}-x_{\pi}(1)||_2+\sum_{i=1}^{n=1}||x_{\pi(i)}-x_{\pi(i+1)}||_2</script><p>其中$||\cdot||_2$是$L2$范数。期望优化随机策略$p(\pi|s)$，即给定点集$s$后以高概率输出短的旅程，以低的概率输出长的旅程。神经网络使用链式法则进行构造：</p>
<script type="math/tex; mode=display">
p(\pi|s)=\prod_{i=1}^{n}p(\pi(i)|\pi(<i),s)</script><p>然后使用softmax模块对上式右端表征概率。传统的seq2seq模型解决TSP时将TSP中的每一个城市表征为$\{1,2,\dots.n\}$，但是存在两个主要的问题：首先这种方式训练的神经网络并不能对问题规模超过$n$的实际场景求解；其次，需要拿到最优解才能使用条件对数似然优化seq2seq的模型参数。作者使用了一种利用非参数的softmax模块与注意力机制组合的指针网络以提升算法泛化能力，如图所示。</p>
<p><img src="https://s2.loli.net/2023/02/08/ImzgWKM3Sl29xLn.png" alt="image-20230208211936761" style="zoom:50%;" /></p>
<p>整体的网络包含两个RNN模块——编码器和解码器，他们都由LSTM单元组成。编码器模块读取输入序列$s$，每次读取一个元素然后将其转换为潜在记忆状态（latent memory states）$\{enc_i\}_{i=1}^{n}$，其中$enc_i\in \mathbb R^d$。在$i$时刻输入到编码器模块的是一个点$x_i$二维坐标$d$维的embedding，embedding是对所有输入点$x_i$共享参数的一个线性转换。解码器模块同样保存其潜在记忆状态$\{dec_i\}_{i=1}^{n}$，其中$dec_i\in \mathbb R^d$且在每一个时间步$i$使用指针机制产生下一个需要到访的城市概率分布。当下一个到访城市被选定后，它将会被传入到解码器作为其下一个输入。解码器的初始输入是一个$d$维的可训练的向量，在图中以$<g>$表示。</p>
<p>注意力函数将每一个向量$q=dec_i \in \mathbb R^d$以及一系列的参考向量$ref=\{enc_1,\dots,enc_k\}$作为输入，并针对$k$个参考生成概率分布$A(ref,q)$。概率分布代表了模型在见到了序列$q$后指向的下一个参考点$r_i$的程度。</p>
<h2 id="策略梯度优化"><a href="#策略梯度优化" class="headerlink" title="策略梯度优化"></a>策略梯度优化</h2><h3 id="策略梯度与改进方法"><a href="#策略梯度与改进方法" class="headerlink" title="策略梯度与改进方法"></a>策略梯度与改进方法</h3><p>在开始之前先要说说策略梯度是什么。它其实是MDP过程下的一个衍生的概念，给定一条状态-动作的交互轨迹$\tau=\{s_1,a_1,s_2,a_2,\dots\}$，参数为$\theta$的一个策略实体能复现这条轨迹的概率为：</p>
<script type="math/tex; mode=display">
\begin{aligned}
p_\theta(\tau)=&p(s_1)p(a_1|s_1)p(s_2|s_1,a_1)p(a_2|s_2)\dots\\
=&p(s_1)\prod_{t=1}^{T}p_{\theta}(a_t|s_t)p(s_{t+1}|s_t,a_t)
\end{aligned}</script><p>注意，策略只能控制通过观察状态选择动作这个过程，只有环境才能控制根据动作的选择作出响应。在每一次的交互过程中都会产生一个<strong>奖励（reward）</strong>$r_i$，这条轨迹上所有的reward加起来就是<strong>回报</strong>$R(\tau)$：</p>
<script type="math/tex; mode=display">
R(\tau)=\sum_{\tau}r_i</script><p>而回报的期望就是：</p>
<script type="math/tex; mode=display">
\overline R_\theta(\tau)=\sum_{\tau}p_\theta(\tau)R(\tau)=\mathbb E_{\tau\sim p_\theta(\tau)}[R(\tau)]</script><p>一般的MDP建模的主要目标之一就是最大化回报期望，因此一个可行的方法就是使用梯度上升法优化参数$\theta$使回报期望变大，而使用梯度上升的前提条件就是要计算优化式子的梯度：</p>
<script type="math/tex; mode=display">
\nabla_\theta [\overline R_\theta(\tau)]=\nabla_\theta[\sum_{\tau}R(\tau)p_\theta(\tau)]</script><p>注意到$R(\tau)$是和$\theta$无关的，因此可以改写成：</p>
<script type="math/tex; mode=display">
\nabla_\theta [\overline R_\theta(\tau)]=\sum_{\tau}R(\tau)\nabla_\theta p_\theta(\tau)]</script><p>注意上式中的$\nabla_\theta p_\theta(\tau)$满足如下式子：</p>
<script type="math/tex; mode=display">
\begin{aligned}
\nabla_\theta p_\theta(\tau)&=\nabla_\theta [e^{\log p_\theta(\tau)}]\\
&=e^{\log p_\theta(\tau)}\nabla_\theta[\log p_\theta(\tau)]\\
&=p_\theta(\tau)\cdot\nabla_\theta[\log p_\theta(\tau)]
\end{aligned}</script><p>所以回报期望的梯度可以表示为：</p>
<script type="math/tex; mode=display">
\nabla_\theta[\overline R_\theta(\tau)]=\sum_\tau R(\tau)\nabla_\theta\log p_\theta(\tau)</script><p>但实际上$\mathbb E_{\tau\sim p_\theta(\tau)}[R(\tau)]$是无法计算的，但可以从统计学的角度进行估计，具体做法就是采样$N$个$\tau$然后计算上式的值，把每一个值加起来求平均即可得到梯度的一个估计：</p>
<script type="math/tex; mode=display">
\begin{aligned}\mathbb E_{\tau\sim p_\theta(\tau)}[R(\tau)\nabla_\theta\log p_\theta(\tau)]&\approx\frac{1}{N}\sum_{n=1}^{N}R(\tau_n)
\nabla_\theta\log p_\theta(\tau_n)\\
&=\frac{1}{N}\sum_{n=1}^{N}\sum_{t=1}^{T}R(\tau_n)\nabla_\theta \log p_\theta(a_t^n|s_t^n)
\end{aligned}</script><p>上式就是所谓的策略梯度，我们将其标识为<code>PG</code>。</p>
<p>作者认为RL算法对组合优化问题有天然优势，因为这类问题的奖励机制很简单并且在实际部署时也可以用。网络用$\theta$表征，其优化的目标是希望给定输入图$s$后输出的旅程距离：</p>
<script type="math/tex; mode=display">
J(\bold{\theta}|s)=\mathbb E_{\pi\sim p_{\theta}(\cdot|s)}L(\pi|s)</script><p>训练过程中的输入图$s$是从$\mathcal S$采样得到的，训练的目标其实包含了这一部分，即$J(\theta|s)=\mathbb E_{s\sim \mathcal S}J(\theta|s)$。在使用策略梯度进行优化$\theta \leftarrow \eta+\nabla_\theta \overline R_\theta$时，可以使用一种叫做添加<strong>基线（baseline）</strong>的技巧。这种技巧是解决奖励函数设置为非负的情况出现的优化问题，如果对于任何状态$s_t$，无论执行什么动作都会产生非负的奖励，那么<code>PG</code>式就会等价为不管是什么动作，都要提升这个动作发生的概率，这显然有违“在观察环境后选取最优的动作”这一初衷。为了解决这个问题，我们可以把奖励减去$b$，从而保证$R(\tau)-b$这一项有正有负，当$R(\tau)&gt;b$时就让$(s,a)$的概率上升，否则就减少其概率。</p>
<p>$b$的取值可以通过在交互过程中记录下的$R(\tau)$并对其求平均值将其作为期望，即$b\approx\mathbb E[R(\tau)]$，这是最简单的方式，然而还是会有采样不均匀的问题，具体来说就是<strong>交互过程中可能得到一个好的结果，但并不代表整个过程中每一次交互的动作选择都是好的；同理交互过程可能得到一个坏结果，但并不代表整个过程中的每一次交互的动作选择都是坏的。</strong>解决这个问题的方法就是为动作分配一个权重，以此确定哪些动作在某个状态下是最好的。一般来说，$b$是一个神经网络估计出来的，这个神经网络我们称为Critic网络。它可以是依赖状态的，我们称$R(\tau)-b$这一项为优势函数<strong>（Advantage Function）</strong>，优势函数在意的不是绝对的“好”结果，而是相对的“好”结果，即<strong>相对优势</strong>。</p>
<h3 id="时序差分与蒙特卡洛方法"><a href="#时序差分与蒙特卡洛方法" class="headerlink" title="时序差分与蒙特卡洛方法"></a>时序差分与蒙特卡洛方法</h3><p>聊方法前，先明确下我们的核心目标：求解策略梯度。时序差法和蒙特卡洛方法其实就是求解方式的区别，借用磨菇书的图：</p>
<p><img src="https://datawhalechina.github.io/easy-rl/img/ch4/4.20.png" alt="img"></p>
<p>可以看到二者的区别主要是计算与学习更新的时机。常用的REINFORCE算法实现获取每个步骤获得的奖励，然后计算每个步骤的未来总奖励$G_t$，然后将$G_t$代入：</p>
<script type="math/tex; mode=display">
\nabla \overline R_\theta \approx\frac{1}{N}\sum_{n=1}^{N}\sum_{t=1}^{T_n}G_t^n\nabla \log \pi_\theta(a_t^n|s_t^n)</script><p>解释一下$G_t^n$中的$n$表示一个回合中的从第$n$步到最后一步的轨迹的子集，$t$则是步骤的下标。一般来讲$G_t$是奖励的加权和，即：</p>
<script type="math/tex; mode=display">
G_t=\sum_{k=t+1}^{T}\gamma^{k-t-1}r_k\\=r_{t+1}+\gamma G_{t+1}</script><p>REINFOCE算法需要产生一个回合的数据，即$\{(s_1,a_1,G_1),(s_2,a_2,G_2\},\cdots(s_T,a_T,G_T)\}$，然后针对每个动作计算梯度$\nabla \ln \pi(a_t|s_t,\theta)$，然后用NCEloss计算损失，将损失作为优化的目标进行优化，如图所示：</p>
<p><img src="https://datawhalechina.github.io/easy-rl/img/ch4/4.28.png" alt="img"></p>
<p>回到原文，使用随机梯度下降对参数进行优化。上式的梯度可以使用REINFORCE算法进行表述：</p>
<script type="math/tex; mode=display">
\nabla_\theta J(\theta|s)=\mathbb E_{\pi\sim p_{\theta}(\cdot|s)}[(L(\pi|s)-b(s))\nabla_{\theta}\log p_{\theta}(\pi|s)]</script><p>其中$b(s)$是独立于策略$\pi$的基线函数，它通过测量期望的旅程长度以减少梯度的方差。</p>
<p>从分布$\mathcal S$采样得到的独立同分布的$B$张图$s_1,s_2,\dots,s_B$并对每一张图进行旅程的一次采样（比如说使用一个策略$\pi_i\sim p_\theta(\cdot|s_i)$）后，上面的式子使用蒙特卡洛采样进行近似：</p>
<script type="math/tex; mode=display">
\nabla_{\theta}J(\theta)\approx\frac{1}{B}\sum_{i=1}^{B}(L(\pi_i)-b(s_i))\nabla_\theta \log p_\theta (\pi_i|s_i)</script><p>而基线函数$b(s)$考虑到策略会随着训练变得更好，因此可以选择网络取得的平均奖励，它是随着时间指数型变化的。这个基线函数也有问题，它不能辨别出两个不同的输入图像。特别的对于一个复杂图，最优的策略$\pi^{\star}$可能会使得$L(\pi^{\star}|s)&gt;b$，因为$b$是对一个batch里的所有图进行交互计算的。所以作者使用了critic网络为每一个$s$生成baseline，critic网络的参数用$\theta_v$表示，它将输出使用当前策略$p_\theta$对输入序列$s$判别后得到的最短路程。critic同样使用SGD进行训练优化，其优化目标是其输出$b_{\theta_v}(s)$与实际的策略采样得到的路程长度之差的平方，作为额外的优化项表述为：</p>
<script type="math/tex; mode=display">
\mathcal L(\theta_v)=\frac{1}{B}\sum_{i=1}^{B}||b_{\theta_v(s_i)-L(\pi_i|s_i)}||_2^2</script><h2 id="TSP问题下的Critic网络结构"><a href="#TSP问题下的Critic网络结构" class="headerlink" title="TSP问题下的Critic网络结构"></a>TSP问题下的Critic网络结构</h2><p>Critic网络映射输入序列$s$到一个基线函数$b_{\theta_v}$由如下几个模块组成：1.一个LSTM编码器 2. 一个LSTM处理模块 3. 一个两层的ReLu 神经网络解码器。其编码器和指针网络的编码器结构相同，将输入序列$s$转换为潜在记忆状态以及隐藏态$h$。处理模块和<a href="https://arxiv.org/abs/1506.03134">Vinyals</a>论文中的相似，对隐藏状态进行$\mathrm P$步计算，每一步都会通过使用glimpsing记忆对隐藏状态更新，并对glimpse函数的输出作为下一步处理的输入。在处理模块的最后，得到的隐藏状态会被随后通过两个分别含有d个和1个单元的全连接层编码成基线预测（单个标量）。作者提出的算法和A3C很相近，因为critic的预测和对一张图抽样得到的路程是优势函数的无偏估计。作者在多个CPU核上进行异步更新，但每一个核都处理一个迷你批次以获得更好的梯度估计，算法如下所示：</p>
<p><img src="https://s2.loli.net/2023/02/08/Z7b86OzXyDcPUIg.png" alt="image-20230208223443134"></p>
<h2 id="两种搜索策略"><a href="#两种搜索策略" class="headerlink" title="两种搜索策略"></a>两种搜索策略</h2><p>评估路径长度相对来说资源开销很小，因此推理阶段可以针对每张图的多种可选方法进行搜索并选择其中最好的一个，这个过程和在巨型的解空间搜索可行解很像，本文作者考虑了如下两种方法。</p>
<h3 id="采样（Sampling）"><a href="#采样（Sampling）" class="headerlink" title="采样（Sampling）"></a>采样（Sampling）</h3><p>就是简单的从多个的随机策略$p(\cdot|s)$中采样得到路程并选择最短的一个。和启发式方法不同，并不强迫模型在这个过程中采样不同的路程，然而我们可以通过一个temperature的超参数控制无参数的softmax的输出采样的密度（附录2）.该采样过程比贪心策略得到的提升更大，因为后者总是选择最大概率对应的索引。作者也考虑了对指针机制加入随机噪声的扰动并从修改后的策略中使用贪心策略，但这个没啥用。</p>
<h3 id="激活搜索（Acitive-Search）"><a href="#激活搜索（Acitive-Search）" class="headerlink" title="激活搜索（Acitive Search）"></a>激活搜索（Acitive Search）</h3><p>可以在单次测试阶段输入$s$ 后最小化$\mathbb E_{\pi \sim p_{\theta}(\cdot|s)L(\pi|s)}$对随机策略$p_{\theta}$的参数进行精调，而不是对固定的模型进行采样或忽略采样过程中的解的奖励信息。这种方法对训练过的模型进行改进，和对为训练过的模型进行调优都由不错性能，前者被作者称为RL预训练激活搜索，后者称为激活搜索，因为模型是在单词测试中搜索备选解时更新参数的。激活搜索的算法流程如下所示：</p>
<p><img src="https://s2.loli.net/2023/02/08/VgfIUdwE2Ha1JM8.png" alt="image-20230208225425577"></p>
<p>和Critic网络的更新算法很相似，但是激活搜索对单次测试时的备选解$\pi_1,\dots,\pi_B\sim p_\theta(\cdot|s)$进行了蒙特卡洛采样。它采取了一个指数型变换的平均基线，这和critic不同，因为它不需要对输入之间进行区分。值得注意的一点是，强化学习训练尽管不需要监督，它仍然是需要训练数据的，并且其泛化能力和数据分布非常相关。然而激活搜索是独立分布的，由于对城市进行了编码成序列，作者就在将输入序列输入金指针网络前将其打乱，这能增加采样过程的随机性并为激活搜索带来性能提升。</p>
<h2 id="实验结果"><a href="#实验结果" class="headerlink" title="实验结果"></a>实验结果</h2><p>略</p>
<h2 id="其他问题的泛化"><a href="#其他问题的泛化" class="headerlink" title="其他问题的泛化"></a>其他问题的泛化</h2><p>略</p>
<h2 id="结论"><a href="#结论" class="headerlink" title="结论"></a>结论</h2><p>略</p>
<h2 id="附录"><a href="#附录" class="headerlink" title="附录"></a>附录</h2><h3 id="Pointing-Mechanism"><a href="#Pointing-Mechanism" class="headerlink" title="Pointing Mechanism"></a>Pointing Mechanism</h3><p>这部分的计算是由两个注意力矩阵$W_{ref},W_q\in\mathbb R^{d\times d}$以及一个注意力矢量$v\in\mathbb R^{d}$表示的：</p>
<script type="math/tex; mode=display">
u_i=\begin{cases}
\begin{aligned}
&v^{\top}\cdot\tanh (W_{ref}\cdot r_i + W_q \cdot q) & i\neq \pi(j)\ \forall j<i\\
&-\infty& otherwise
\end{aligned}
\end{cases}</script><script type="math/tex; mode=display">
A(ref,q;W_{ref},W_q,v)=softmax(u)</script><p>指针网络在第$j$步时会依照下式输出下一个访问的点的概率分布：</p>
<script type="math/tex; mode=display">
p(\pi(j)|\pi(<j),s)=A(enc_i,dec_j)</script><p>将已经访问过的城市点的logits值设为$-\infty$，确保模型只会输出符合TSP要求的点。</p>
<h3 id="Attending-Mechanism"><a href="#Attending-Mechanism" class="headerlink" title="Attending Mechanism"></a>Attending Mechanism</h3><p>Glimpse函数$G(ref,q)$和注意力函数$A$采取相同的输入，他的计算表征由$W_{ref}^{g},W_q^g \in \mathbb R^{d\times d}$和$v^g \in \mathbb R^{d}$完成。依照如下式子进行计算：</p>
<script type="math/tex; mode=display">
p=A(ref,q;W_{req}^g,W_q^g,v^g)\\
G(ref,q;W_{ref}^g,W_q^g,v^g)=\sum_{i=1}^{k}r_i p_i</script><p>Glimpse函数是用注意力概率计算参考向量权重的线性组合，它同样可以在相同的参考集上运用多次：</p>
<script type="math/tex; mode=display">
g_0=q\\
g_l=G(ref,q_{l-1};W_{ref}^g,W_q^g,v^g)</script><p>最终，$g_l$向量将会传递到注意力函数$A(ref,g_l;W_{ref},W_q,v)$以产生pointing机制。我们观测到对于相同的模型参数多次使用glimpse和只使用一次相比并不能有效加快训练并提高训练结果。</p>
<h3 id="softmax-temperature"><a href="#softmax-temperature" class="headerlink" title="softmax temperature"></a>softmax temperature</h3><p>我们将注意力函数修改为如下式子：</p>
<script type="math/tex; mode=display">
A(ref,q,T;W_{ref},W_q,v)=softmax(u/T)</script><p>其中的$T$是<em>温度超参数</em>，并且在训练阶段设置为$T=1$。当$T&gt;1$时，$A(ref,q)$的分布会变得平缓些，因此可以避免模型出现过度置信的情况。</p>
<h3 id="logit-clipping"><a href="#logit-clipping" class="headerlink" title="logit clipping"></a>logit clipping</h3><p>修改注意力机制为如下式子：</p>
<script type="math/tex; mode=display">
A(ref,q;W_{ref},W_q,v)=softmax(C \tanh(u))</script><p>其中，$C$是控制logits值得超参数并借此控制$A(ref,q)$的熵。没了</p>
]]></content>
      <categories>
        <category>学习记录</category>
      </categories>
      <tags>
        <tag>深度学习</tag>
        <tag>组合优化</tag>
        <tag>指针网络</tag>
      </tags>
  </entry>
  <entry>
    <title>PEPN3T</title>
    <url>/2023/03/01/zwc/</url>
    <content><![CDATA[<p>你可以<a href="https://cybercolyce.cn/PEPN3T/">点我</a>访问这颗星球^_^</p>
<span id="more"></span>
<h2 id="背景历史"><a href="#背景历史" class="headerlink" title="背景历史"></a>背景历史</h2><p><img src="https://s2.loli.net/2023/03/01/2jyV7uDM8nZWaHv.jpg" alt=""></p>
<p><strong>Pepnet</strong>是宝瓶座的<strong>Samurai</strong>恒星系统中的一颗宜居行星，平均半径为3959旧英里，富含<code>水、石油以及矿物资源</code>，因其地表如火焰般燃烧的鲜红被调侃为<strong>椒星</strong>。该行星于公元3202年的2月21日被来自旧太阳系泽西岛的探索者<strong>Dr. Zhou Weichu</strong> 发现并命名。该行星有一颗卫星，卫星半径约为椒星的<code>3/8</code>。卫星的运转轨道非常规椭圆轨道，最远距离为925,000km，最近距离为<code>68,700km</code>，受到<strong>Samurai</strong>恒星的照射以及<strong>Pepnet</strong>光反射影响，该卫星在太空中观测为橙色，故称为橙星。橙星在<code>415</code>颗碎星组成的星环之间坚定地围绕椒星公转，在现在和未来见证椒星的每一个阶段。</p>
<p>在周博士的牵头引领下，Pepnet的肥沃土壤种植起了就太太阳系地球的一种美洲农作物——辣椒。周博士热爱音乐，她带领着团队在进行星球种植探索实验时曾说道<strong>“音乐是数学在灵魂中无意识的运算”</strong>，周博士以积极乐观、幽默风趣的领导风格带领团队拿下了科学技术进步奖，同时还和团队成员举办了多次音乐会以纪念他们以前的工作岁月。</p>
<p>周博士在带领团队进行辣椒种植实验时，充分发挥了其在高等院校所学习的知识。从太空中可以观测到有一层“骨架”包裹着椒星，这种骨架其实是种植辣椒的“人造温室”的框架，是周博士对宇宙元素的入门三分的理解之上的巧妙组合，将星球的可视半径扩张了1,000公里，兼备了美观与实用性，保障了椒星地表的辣椒种植的顺利，因此不论在何时观测，都能见到椒星的地表红火鲜艳——可能是本来就如凤凰般灿烂耀眼，也可能是这片土地上的点点滴滴都散发着光，顺带点亮了它的<strong>卫星橙星</strong>。</p>
]]></content>
      <categories>
        <category>摸鱼</category>
      </categories>
      <tags>
        <tag>小周</tag>
      </tags>
  </entry>
  <entry>
    <title>ISAC学习记录</title>
    <url>/2023/03/07/ISAC/</url>
    <content><![CDATA[<p align="center">
    <img src="https://s2.loli.net/2023/03/07/eON3wACGtfIKyUQ.png" alt="ISAC" />
</p>
<h1 align="center">ISAC 学习笔记</h1>
<p align="center">
    <em>待更新</em>
</p>


<p>ISAC笔记</p>
<span id="more"></span>
<h2 id="引言部分"><a href="#引言部分" class="headerlink" title="引言部分"></a>引言部分</h2><p>下一代的通信（B5G、6G）技术对无线连接能力和准确、高鲁棒的感知能力提出了高要求，这些技术都有一个共同的主题——感知。感知是嵌入在网络中的一种技术，或者说是一种能力，是用来给未来的潜在应用赋能或收集数据的。<code>S&amp;C</code>即<em>Sensing and Communication</em>的功能集合需要在未来网络进行联合的设计，即<em>Integrated Sensing and Communication</em>s（<code>ISAC</code>）。</p>
<p>感知和通信对应着两个方面。感知从含噪声的观测中收取并提炼信息，通信则是关注使用特定的信号传输信息然后将信息在接收端恢复。二者的统一是ISAC的终极目的，实现提升频谱或能效同时减少硬件与信令的消耗。</p>
<p>ISAC在之前有一堆乱七八糟的名字——RC、JCR、JRC、DFRC，主要集中在雷达感知领域，曾经也是ISAC的主流方向。雷达传感的联合感知与通信将是ISAC的核心。ISAC的发展历程如下：</p>
<p><img src="https://s2.loli.net/2023/03/06/2HAE5Oh3RWJwK4i.png" alt="image-20230306092652694"></p>
<p>感知在未来的无线网络中是一种原生的能力而不是一种额外附加的能力，本身就能为大量用户提供服务。联合增益与整体增益是ISAC发展的两个可能方向。具体的参照下图：</p>
<p><img src="https://s2.loli.net/2023/03/06/s4aWZFCxYT13JEA.png" alt="image-20230306095419941"></p>
<h2 id="工业进展与应用"><a href="#工业进展与应用" class="headerlink" title="工业进展与应用"></a>工业进展与应用</h2><p><img src="https://s2.loli.net/2023/03/08/UI1dKJsEhAFm4CV.png" alt="图片" style="zoom:80%;" /></p>
<p>感知服务：</p>
<ul>
<li>增强定位于跟踪：全球卫星导航下的卫星定位精度——米级。5G NR的最高定位标准是垂直/水平精度分别为0.2m/1 m， 难以满足未来的工业物联网需求。机器人操作精度5mm，室内人物动作识别精度1cm，距离多普勒处理。</li>
<li>区域成像：射频城乡的侵扰性更低，米级别的分辨率。毫米波以及mMIMO技术可以放到BS上面，RAN可以作为一个分布式的MIMO雷达，最终让UE感知到周边的环境。</li>
<li>无人机监测于管理：某些无人机体积小，热成像或摄像头难以监测，可能会出现擅入禁区的情况，ISAC的蜂窝网络可以提供监测和管理。</li>
</ul>
<p>智能家居和室内感知：</p>
<ul>
<li>人类活动识别：疲劳驾驶监测。智能人类居住环境的保障，比如说检测到睡眠状态降低环境中的环境的资源消耗之类的。</li>
<li>空间感知计算：室内设备的空间几何关系，对增强虚拟现实应用提供支持。</li>
</ul>
<p>V2X：</p>
<ul>
<li>车辆运作管理：传统方法基于领导-跟随者的框架，依赖多跳的V2V通信传输每辆车的状态信息，延迟很大。</li>
<li>SLAM</li>
</ul>
<p>智能建造和工业IoT：集群导航、节点的调度</p>
<p>遥感和地理科学：战区信息广播、空基雷达监测地球变化，4维度映射，安全相关。</p>
<p>环境监测：传输信号在不同的环境下的性能差异监测环境的变化</p>
<p>人机交互：虚拟键盘，谷歌Soli项目，无接触的人机交互，微多普勒识别的准确性。</p>
<p>总结如下：</p>
<p><img src="https://s2.loli.net/2023/03/07/oJCzSXxOI6FhDWP.png" alt="image-20230307104531125"></p>
<h2 id="性能评估"><a href="#性能评估" class="headerlink" title="性能评估"></a>性能评估</h2><p>从信息论的角度来看，感知的性能并不像通信的性能那样明确，信息论层面的感知性能分析还鲜有报道。因此，需要新的分析技术来评价通感一体系统，揭示两者在信息论层面上的基本理论极限。</p>
<h3 id="感知的评估"><a href="#感知的评估" class="headerlink" title="感知的评估"></a>感知的评估</h3><ul>
<li>检测：MMSE</li>
<li>估计：CRLB</li>
<li>认知：</li>
</ul>
<h3 id="通信的评估"><a href="#通信的评估" class="headerlink" title="通信的评估"></a>通信的评估</h3><ul>
<li>有效性：传输速率</li>
<li>可靠性：误码率</li>
</ul>
<h2 id="信息论的权衡"><a href="#信息论的权衡" class="headerlink" title="信息论的权衡"></a>信息论的权衡</h2><p>和ISAC相关的重要理论桥梁是最小均方误差和互信息的关系，它连接了通信衡量指标的输入输出的互信息和检测指标：</p>
<script type="math/tex; mode=display">
\frac{d}{d\,\mathrm{snr}}I(\mathrm{snr})=\frac{1}{2}MMSE(\mathrm{snr})</script><p>这里就有一个平衡的关系：一个高斯输入可以使得式子左边变大，但是同样会使得检测部分的错误上升，二者构成一个平衡。另一个容量-衰减的权衡是在一个经典场景下构建的：</p>
<p><img src="https://s2.loli.net/2023/03/07/B8fH6g45hv7oAiJ.png" alt="image-20230307230625015" style="zoom:67%;" /></p>
<p>发送端想传输纯信息（用$W\in\{1,2,\dotsm2^{nR}\}$表示信息的索引）和信道状态$S$的描述$\hat S$到接收端。在给定$W$和$S$的情况下，发射端以速率$R$传输一个编码$X(W,S)$到接收端。接收端的观测如下：</p>
<script type="math/tex; mode=display">
Y\sim\prod_{i=1}^{n}p(y_i|{x_i,s_i})</script><p>接收端随后从$Y$中解码信息$\hat W(Y)\in\{1,2,\dots,2^{nR}\}$，同时对状态进行估计为$\hat S(Y)$。译码的错误概率和状态估计的误差定义如下：</p>
<script type="math/tex; mode=display">
\begin{aligned}
\mathcal P_e^{(n)}&=\frac{1}{2^{nR}}\sum_{i=1}^{2^{nR}}\Pr\{\hat W\neq i|W=i\}\\
D&=\mathbb E\{d(S,\hat S\}
\end{aligned}</script><p>其中$d(S,\hat S)$是$S$和$\hat S$之间的失真度量。一个率失真对$(R,D)$如果存在这样一个序列$(2^{nR},n)$对$X(W,S)$进行编码，那么我们说它是可达的：</p>
<script type="math/tex; mode=display">
\mathbb E{\{d(S,\hat S)\}}\leq D,\mathcal P_{e}^{(n)}\rightarrow0,n\rightarrow \infty</script><p>如果失真函数选择为状态估计误差的平方，则MSE的估计可以表述为：</p>
<script type="math/tex; mode=display">
\mathbb E{\{d(S,\hat S)\}}=\frac{1}{n}\mathbb E{||S-\hat S(Y)||^2}</script><p>接下来还需要考虑状态独立的高斯信道$Y=X(W,S)+S+N$，其中$S_i\sim\mathcal N(0,Q_S)$，$N_i\sim(0,Q_N)$。举个列子，以$\gamma\in[0,1]$$(R,D)$对的帕累托最优边界为：</p>
<script type="math/tex; mode=display">
\begin{aligned}
(R,D)=&(\frac{1}{2}\log(1+\frac{\gamma P}{Q_N}),\\
&Q_S\frac{(\gamma P + Q_N)}{(\sqrt{Q_S}+\sqrt{(1-\gamma)P})^2 + \gamma P+Q_N}
)
\end{aligned}</script><p>其中的$P\geq\frac{1}{n}\mathbb E{\{\sum_{i=1}^{n}X_i^2(W,S)\}}$，表示为发射信号$X$的功率约束。可以看到传输的功率分割为两部分：$\gamma P$和$(1-\gamma)P$，分别对应着传输纯信息和状态信息，达到一种权衡。功率资源由纯信息和信道状态信息共享，这种方法也会在PHY的tradeoff中再次体现。</p>
<p>需要指出，上述的率失真的权衡不能捕捉到经典的ISAC场景中的某些特征，比如说某个目标的反射波的估计。在单静态雷达中，发射端是不能预先知道目标的信道状态的。另外，其也不需要感知目标。Kobayashi 和 Caire提出了将目标的返回信号建模为一个延迟回馈信道，如下图所示：</p>
<p><img src="https://s2.loli.net/2023/03/08/B2bRJCX5GQ6947n.png" alt="image-20230308092411212" style="zoom: 67%;" /></p>
<p>信道的状态在接收端是可知的，但是发射端是不知道的。在每次传输的时候，传输端利用一个估计器从延迟反馈的输出$Z\in\mathcal Z$对信道状态进行估计得到$\hat S$。选择一条信息$W$后，传输端使用一个基于$W$和$\hat S$的编码器发送一个符号$X\in\mathcal X$。信道的输出$Y\in\mathcal Y$会传输到接收端，随后返回一个信道状态到发送端。联合的分布$SXYZ\hat S$可以表述为：</p>
<script type="math/tex; mode=display">
\begin{aligned}
&P_{SXYZ\hat S}(s,x,y,z,\hat s)\\
&\quad =P_S(s)P_X(x)P_{YZ|XS}(y,z|x,s)P_{\hat S|XZ}(\hat s|x,z)
\end{aligned}</script><p>给定了一个失真$D$后，信道的容量$C$和失真的权衡表示为：</p>
<script type="math/tex; mode=display">
C(D)=\max_{P_X:\frac{1}{n}\sum_{i=1}^{n}\mathbb E\{X_i^2\leq P\}}I(X;Y|S)\\
s.t.\,\mathbb E(d(S,\hat S))\leq D</script><p>其中$P_X$代表了信道输入$X$的分布。上述的问题一般来说是一个凸优化问题，可以通过Blahut-Arimoto算法求解。</p>
<h2 id="物理层的权衡"><a href="#物理层的权衡" class="headerlink" title="物理层的权衡"></a>物理层的权衡</h2><p>在通信感知一体化场景中，感知和通信通常需要集成到同一套硬件平台并且共享相同的无线资源，并且在给定的资源配置中，感知性能和通信性能往往是相互对立、此消彼长的关系。物理层的权衡其实可以原生的通信/感知的评估指标进行表述，就在上文提到的信息论的框架下进行。当然也可以对感知提出新的评估指标，因为上文也说到了感知这方面的评估基础还比较空缺。</p>
<h3 id="原生的S-amp-C评估"><a href="#原生的S-amp-C评估" class="headerlink" title="原生的S&amp;C评估"></a>原生的S&amp;C评估</h3><p>物理层的感知性能一般用检测概率和MSE进行衡量。然而即便有MSE的闭式表示也不一定能获取到相关得计算数据，而CRB下界或许是一个可选项。</p>
<ul>
<li><p>检测vs.通信</p>
<p><img src="https://s2.loli.net/2023/03/08/lPIFLciRx3X1uUp.png" alt="image-20230308102531886" style="zoom:33%;" /></p>
<p>ISAC系统的发送端在总功率限制下发射一个感知波形$s_R(t)$和通信$s_C(t)$波形。两个信号使用的是正交的资源（时频）以防止出现互相干扰。感知接收器SR从直接信道和监督信道中接受$s_R(t)$，期望能在稍后检测到目标的存在与否。另一方面通信用户CU接收到包含有用信息的$s_C(t)$。下面的关键问题就是如何分配功率到感知/通信功能上，建模为如下优化问题：</p>
<script type="math/tex; mode=display">
\max_{P_R,P_C}\mathcal P_D \quad s.t.\, R\geq R_{th},P_R+P_C=P_T</script><p>$\mathcal P_D$代表了雷达的检测概率，$R=\log(1+P_C\gamma_c)$是可达速率，其中$\gamma_c$是含噪信道归一化增益，$R_{th}$是一个阈值。检测问题可以建模为二元假设测试问题：</p>
<script type="math/tex; mode=display">
\mathcal H_0:\begin{cases}
\mathrm y_d=\gamma_d\mathrm G_d\mathrm s_R+\mathrm n_d\\
\mathrm y_s=\mathrm n_s,
\end{cases} 
\qquad
\mathcal H_1:\begin{cases}
\mathrm y_d=\gamma_d\mathrm G_d\mathrm s_R+\mathrm n_d\\
\mathrm y_s=\gamma_s\mathrm G_s\mathrm s_R+\mathrm n_s,
\end{cases}</script><p>$\mathrm y_d$和$\mathrm y_s$是从直接信道于监督信道接收到的信号，$\mathrm G_d$和$\mathrm G_s$是一$L\times L$的单一多普勒算子矩阵矩阵，分别对应直接信道和监督信道，$\gamma_d,\gamma_s$分别是两个信道的标量系数，然后$n_d,n_s$是加性高斯白噪声，其方差为$\sigma ^2$。检测通过广义似然比测试进行评估，对应的$\mathcal P_D$可以如下近似：</p>
<script type="math/tex; mode=display">
\mathcal P_D \approx Q_1(\sqrt{\frac{2P_R|\gamma_d|^2}{\sigma^2}},\sqrt{2\gamma})</script><p>其中$Q_1(a,b)$表示了Marcum Q函数(第一类零阶修正贝塞尔函数)，$\gamma$表示了阈值。考虑到功率的约束以及速率的表达式，检测概率可以表示为：</p>
<script type="math/tex; mode=display">
\mathcal P_D\approx Q_1(\sqrt{2(P_T-\frac{1}{\gamma_c}(2^{R_{th}}-1)\frac{|\gamma_d|^2}{\sigma^2})},\sqrt{2\gamma})</script></li>
<li><p>估计vs.通信</p>
<p>一般的分析不会让资源复用，虽然便于理论分析但是造成了资源的极大浪费。一种多天线的ISAC收发机有$N_t$个发射天线和$N_r\geq N_t$个接收天线，为$K$个单天线用户服务，并同时检测目标，如图所示：</p>
<p><img src="https://s2.loli.net/2023/03/08/yVS3hD5H6sGfdlO.png" alt="image-20230308200417927" style="zoom: 50%;" /></p>
<p>这是种多用户多输入单输出的下行通信系统，也成为monostatic/active MIMO 雷达。使用ISAC波形矩阵$\mathrm X\in\mathbb C^{N_t\times L}$进行传输，受到功率约束$P_T$，基站接收到如下的回传信号：</p>
<script type="math/tex; mode=display">
\mathrm{Y}_R=\mathrm{GX}+\mathrm{N}_R</script><p>其中$\mathrm G \in \mathbb C^{N_r \times N_t}$代表了目标的响应矩阵（TRM），对于不同的目标模型会有不同的形式，同时$N_R$是方差为$\sigma_R^2$的AWGN矩阵。多用户通信的接受的信号模型表示为：</p>
<script type="math/tex; mode=display">
\mathrm{Y}_c=\mathrm{HX}+\mathrm{N}_C</script><p>其中$\mathrm{H}=[\mathrm{h_1,h_2,\dots,h_K}]^H\in\mathcal C^{K\times N_t}$是通信信道矩阵，且基站已知。同时$N_C$是方差为$\sigma_C^2$是AWGN矩阵。ISAC的波形设计可以建模为如下式子的优化问题：</p>
<script type="math/tex; mode=display">
\min_\mathrm{X}\, \mathrm{tr}(\mathrm{R_X^{-1}})\,\mathrm{s.t.}||\mathrm{X}||_F^2 \leq LP_T,c_i(\mathrm{X}\odot C_i)</script></li>
</ul>
<p>妈的，一拳把地球打爆</p>
]]></content>
      <categories>
        <category>ISAC</category>
      </categories>
      <tags>
        <tag>ISAC</tag>
      </tags>
  </entry>
  <entry>
    <title>OAI gNB构建</title>
    <url>/2023/03/29/BUILDOAI/</url>
    <content><![CDATA[<p>在Ubuntu 20.04中搭建OAI平台。</p>
<span id="more"></span>
<h2 id="前置条件"><a href="#前置条件" class="headerlink" title="前置条件"></a>前置条件</h2><p>先安装依赖包：</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">sudo apt install net-tools</span><br><span class="line">sudo apt install git</span><br><span class="line">sudo apt install -y libboost-all-dev libusb-1.0-0-dev doxygen python3-docutils python3-mako python3-numpy python3-requests python3-ruamel.yaml python3-setuptools cmake build-essential</span><br></pre></td></tr></table></figure>
<p>随后下载UHD镜像：</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">git <span class="built_in">clone</span> https://github.com/EttusResearch/uhd.git ~/uhd</span><br><span class="line"><span class="built_in">cd</span> ~/uhd</span><br><span class="line">git checkout v4.4.0.0</span><br><span class="line"><span class="built_in">cd</span> host</span><br><span class="line"><span class="built_in">mkdir</span> build</span><br><span class="line"><span class="built_in">cd</span> build</span><br><span class="line">cmake ../</span><br><span class="line">make -j $(<span class="built_in">nproc</span>)</span><br><span class="line">make <span class="built_in">test</span> <span class="comment"># This step is optional</span></span><br><span class="line">sudo make install</span><br><span class="line">sudo ldconfig</span><br><span class="line">sudo uhd_images_downloader</span><br></pre></td></tr></table></figure>
<p>下载完成后，接入USRP设备后可通过<code>uhd_find_devices</code>以及<code>uhd_usrp_probe</code>验证。</p>
<h2 id="构建OAI-gNB"><a href="#构建OAI-gNB" class="headerlink" title="构建OAI gNB"></a>构建OAI gNB</h2><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 获取源代码</span></span><br><span class="line">git <span class="built_in">clone</span> https://gitlab.eurecom.fr/oai/openairinterface5g.git ~/openairinterface5g</span><br><span class="line"><span class="built_in">cd</span> ~/openairinterface5g</span><br><span class="line">git checkout develop</span><br><span class="line"></span><br><span class="line"><span class="comment"># 安装OAI依赖</span></span><br><span class="line"><span class="built_in">cd</span> ~/openairinterface5g/cmake_targets</span><br><span class="line">./build_oai -I</span><br><span class="line"></span><br><span class="line"><span class="comment"># 构建OAI</span></span><br><span class="line"><span class="built_in">cd</span> ~/openairinterface5g</span><br><span class="line"><span class="built_in">source</span> oaienv</span><br><span class="line"><span class="built_in">cd</span> cmake_targets</span><br><span class="line">./build_oai -w USRP --ninja --gNB --build-lib <span class="string">&quot;nrscope&quot;</span> -c</span><br></pre></td></tr></table></figure>
<h2 id="运行OAI-gNB"><a href="#运行OAI-gNB" class="headerlink" title="运行OAI gNB"></a>运行OAI gNB</h2><p>根据USRP的板型号的差异，选择不同的配置。</p>
<h3 id="USRP-B210"><a href="#USRP-B210" class="headerlink" title="USRP B210"></a>USRP B210</h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="built_in">cd</span> ~/openairinterface5g</span><br><span class="line"><span class="built_in">source</span> oaienv</span><br><span class="line"><span class="built_in">cd</span> cmake_targets/ran_build/build</span><br><span class="line">sudo ./nr-softmodem -O ../../../targets/PROJECTS/GENERIC-NR-5GC/CONF/gnb.sa.band78.fr1.106PRB.usrpb210.conf --sa -E --continuous-tx</span><br></pre></td></tr></table></figure>
<h3 id="USRP-N300"><a href="#USRP-N300" class="headerlink" title="USRP N300"></a>USRP N300</h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="built_in">cd</span> ~/openairinterface5g</span><br><span class="line"><span class="built_in">source</span> oaienv</span><br><span class="line"><span class="built_in">cd</span> cmake_targets/ran_build/build</span><br><span class="line">sudo ./nr-softmodem -O ../../../targets/PROJECTS/GENERIC-NR-5GC/CONF/gnb.sa.band77.fr1.273PRB.2x2.usrpn300.conf --sa --usrp-tx-thread-config 1</span><br></pre></td></tr></table></figure>
<h3 id="USRP-X300"><a href="#USRP-X300" class="headerlink" title="USRP X300"></a>USRP X300</h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="built_in">cd</span> ~/openairinterface5g</span><br><span class="line"><span class="built_in">source</span> oaienv</span><br><span class="line"><span class="built_in">cd</span> cmake_targets/ran_build/build</span><br><span class="line">sudo ./nr-softmodem -O ../../../targets/PROJECTS/GENERIC-NR-5GC/CONF/gnb.sa.band77.fr1.273PRB.2x2.usrpn300.conf --sa --usrp-tx-thread-config 1 -E --continuous-tx</span><br></pre></td></tr></table></figure>
<h1 id=""><a href="#" class="headerlink" title=" "></a> </h1>]]></content>
      <categories>
        <category>学习记录</category>
      </categories>
      <tags>
        <tag>OAI</tag>
      </tags>
  </entry>
</search>
