---
title: 【学习记录】2023-02-28
mathjax: true
tags:
- 激活函数
- 对抗训练
categories:
- 学习记录
---

本周主要是看一堆乱七八糟的论文，然后有喜欢的人了！

<!-- more -->

## 激活函数设计与对抗训练

这篇文章投的是ICLR2023，主要是从梯度的质量以及对抗训练的角度对激活函数进行一个新的思考。一般的卷积网络使用的是ReLU激活函数，这个函数在接近零点的地方梯度变化是非常大的，然后神经网络对抗攻击一般集中于图像领域，一般抵御对抗攻击的方法就是将对抗样本加入到训练样本中进行训练。在Tsipras等人的论文中有这么一个结论：*“对抗的鲁棒性是没有免费的午餐”*——即使用对抗样本需要在干净的样本的精度和对对抗攻击的鲁棒性进行权衡，一般来讲对对抗性攻击的抵御能力越强，在干净样本上的精确度就越低。

对抗训练的目标是优化下面这个式子：
$$
\arg \min _{\theta}\mathbb E_{(x,y)\sim\mathbb D}{[\max _{\varepsilon\in \mathbb S}L(\theta,x+\varepsilon,y)]}
$$
$\mathbb D$是数据的分布，$\mathbb S$是产生的对抗样本扰动的范围，一般情况下为了让对抗样本难以被人以肉眼观察到，会将这个范围设置的很小；$L$是损失函数，它和网络的参数$\theta$、对抗样本$x+\varepsilon$以及真实的样本标签有关。整个过程包含两个部分：首先是内部的最大化过程，该过程用于计算对抗性样本，然后最外层的最小化过程用于计算网络参数的更新。

作者认为是ReLU的陡峭性引入的梯度不连续的问题，这让我想到在之前文章中提到流形的观点。现实的数据（以图像为例）基本都是高维的，而所需要表达的信息其实是低维度的，Embed到高维流形的信息就和一棵大树的树干差不多，我们评价一棵树的年龄，一般都是按其树干的大小，而枝条、叶片其实是这棵树的额外的表达，枝条和叶片会随着气象的变化而变化，但是树干大部分时间是不变的。回到对抗样本产生的原因上来，对抗样本出现的原因就是因为神经网络学习到的函数一般都不是连续的，而正是这种不连续造就了学习到的目标的分布出现了“空隙”，对抗样本就是这些空隙中的一个“污点”。作者认为使用**平滑**一点的激活函数可能会减少对抗样本的出现。

**平滑**一词的定义在这里指的是函数的一阶导数在任意地方都是连续的。作者使用了`Parametric Softplus`函数：$f(\alpha,x)=\frac{1}{\alpha}\log(1+exp(x))$对ReLU函数的平滑近似，它的一阶导数为：
$$
\frac{d}{dx}f(\alpha,x)=\frac{1}{1+\exp (-\alpha x)}
$$
作者使用$\alpha=10$以对ReLU进行更好的平滑近似，仅在反向传播使用了参数化softplus，而在模型的前向推断过程还是使用ReLU，因为推断过程一般都是用ReLU，对应的是上面对抗训练目标中在产生训练样本的过程中使用的ReLU，而在更新网络参数使用的是参数化softplus。

结论就是ReLU削弱了对抗训练的效果，即便在训练时长与对抗攻击迭代更多的情况下，这种退化的效果依然无法避免。使用平滑一点的激活函数也许能改变这种情况，比如说：

* **Softplus**:$\mathrm{Softplus}(x)=\log(1+\exp (x))$，文章使用的是参数化形式的。

* **SILU**:$\mathrm{SILU}(x)=x\cdot sigmoid(x)$，对比于一般ReLU，在$x<0$的部分不会有突变

* **Expoential Linear Unit(ELU)**:
  $$
  ELU(x,\alpha)=\begin{cases}
  x, if \, x\geq0\\
  \alpha(\exp(x)-1), \, otherwise
  \end{cases}
  $$
  一般来说取$\alpha=1$。

* **Gaussian Error Linear Unit(GELU)**:$\mathrm{GELU(x)}=x\cdot \Phi(x)$，其中$\Phi(x)$是标准正态分布的累积分布函数。

作者在ImageNet上用ResNet-50作为backbone进行实验，结论是SILU的鲁棒性能最优。然后作者提出了一种新的平滑ReLU：
$$
\mathrm{SmoothReLU}(x,\alpha)=\begin{cases}
\begin{aligned}
&x-\frac{1}{\alpha}\log (\alpha x + 1),&x\geq 0\\
&0,& otherwise
\end{aligned}
\end{cases}
$$
当$\alpha\rightarrow \infty$时就变成了ReLU。其一阶导是连续的：
$$
\frac{d}{dx}\mathrm{SmoothReLU}(x,\alpha)=
\begin{cases}
\begin{aligned}
&\frac{\alpha x}{1+\alpha x},&x\geq0,\\
&0,&otherwise
\end{aligned}
\end{cases}
$$
同样的配置又进行了实验，证明了平滑确实是提升鲁棒性的一个方法。具体的实验对比图如下：

![image-20230228124711589](https://s2.loli.net/2023/02/28/2XQleMtgi8xhU3z.png)

结果越偏右上的地方的效果更好。

## Denoising Diffusion Probabilistic Models初探

作为一种20年兴起的生成模型，扩散模型与其他的生成模型GAN、基于流的模型不同，不再是通过一个“限制”（比如种类，风格等等）的输入，逐步添加信息，最终得到生成的图片/ 语音吗， 而是采用从高斯噪音中逐步依照一定条件 “采样” 特殊的分布，随着“采样”轮次的增加最终得到生成的图片/语音 。 换句话说，Diffusion Model 的合成过程是通过一次次迭代在噪声中提取出所需要的图像/音频，随着迭代步数的增加，合成质量也在越来越好 。

扩散模型的核心是马尔可夫链与朗之万动力学。所有的生成式模型的核心工作都是把输入特征转换到隐空间$z$上然后将其再反映射回去。扩散模型将输入映射到隐空间的方法是不断地往原始输入中加入噪声，然后解噪的过程就是反映射的过程。前向的加噪过程，在一般的生成模型中用$q$表示映射过程，扩散模型中的$q$是这样定义的：
$$
q(\mathrm {x}_{1:T}|x_0):=\prod_{t=1}^{T}q(\mathrm x_t|\mathrm x_{t-1}),\\
q(\mathrm x_t|\mathrm x_{t-1}):=\mathcal N(\mathrm x_t;\sqrt{1-\beta_t}\mathrm x_{t-1},\beta_t \bold I)
$$
解噪过程$p$是这么定义的：
$$
p_\theta(\mathrm x_{0:T}):=p(\mathrm x_T)\prod_{t=1}^{T}p_\theta (\mathrm x_{t-1}|\mathrm x_t),\\
p_\theta(\mathrm x_{t-1}| \mathrm x_{t}):=\mathcal N(\mathrm x_{t-1};\bold \mu_\theta (\mathrm x_t, t),\Sigma_\theta(\mathrm x_t, t))
$$
本质来讲，这个模型其实是要训练一个网络，这个网络可以识别到输入图像中的“噪音”然后将其去除还原图像。扩散模型的控制逻辑是马尔可夫链，因此概率论、采样、统计的相关知识将会发挥重要作用。

### 训练目标——Score Matching

Diffusion Model 的启迪需要追溯到一个叫去噪自编码器（Denoising Autoencoder）的结构和Score Matching方法。Score Matching 的提出是为了求解特定的概率密度函数，是一种比较有针对性的参数估计方法。比较经典的求解特定的概率密度函数的方法是`马尔可夫链蒙特卡洛方法`，蒙特卡洛采样不必多说了，加上了马尔可夫链就是为了迭代：先估计一个粗略的参数，然后通过状态转移的方式在估计下一个更为细致的参数。通过有限次的迭代达到预期的精度的参数估计。

Score Matching的方法的好处就是节省了时间，因为MCMC采样是非常耗时的。Score Matching的做法是通过最小化模型的对数概率梯度以及观测数据的对数密度梯度的期望的平方距离来估计参数。即，如果处理不了复杂的函数，那么就处理这个函数的导数。

然后我们就可以用各种方法进行参数估计的数值运算了，比如：分别计算`原始数据概率密度函数`和`模型的输出的概率密度函数的梯度`(因为我们的目标是训练一个能生成与原始数据分布相同数据的模型)， 然后通过比对两个梯度之间的差异，来代表原始数据与模型的输出概率密度函数的相似程度，这样就相当于模型的训练有了个目标，这个目标函数可以表示为两个梯度的差。有了目标函数就可以通过最大似然估计和梯度下降法来训练参数了。

### 模型结构——Denoising Autoencoder

去噪自动编码器其实非常常见，将有噪声的图片输入到Encoder模型，然后编码成一个低维度的特征，再通过Decoder模型还原图片达到图像去噪的效果。
